id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2810718753,pull_request,closed,,Move more DAG parsing related config to dag_processor section,"This moves most of the DAG paring related config into the new ``dag_processor`` section.

The remaining options need more attention than just a straightforward move, so I'll tackle those separately for ease of review.
",jedcunningham,2025-01-25 03:06:45+00:00,[],2025-01-29 19:22:33+00:00,2025-01-29 19:22:30+00:00,https://github.com/apache/airflow/pull/46034,"[('full tests needed', 'We need to run full set of tests for this PR to merge'), ('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2622632500, 'issue_id': 2810718753, 'author': 'jedcunningham', 'body': 'Remaining failures are unrelated. Merging.', 'created_at': datetime.datetime(2025, 1, 29, 19, 22, 7, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2025-01-29 19:22:07 UTC): Remaining failures are unrelated. Merging.

"
2810692798,pull_request,closed,,Unify Data Models for Bulk Actions in Rest API (FastAPI),"closes: #45816

This could potentially help to unify actions for most of the CRUD endpoints for entities using services and common actions.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2025-01-25 01:59:04+00:00,[],2025-01-27 12:37:35+00:00,2025-01-26 20:09:57+00:00,https://github.com/apache/airflow/pull/46033,"[('area:API', ""Airflow's REST/HTTP API""), ('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2613933399, 'issue_id': 2810692798, 'author': 'bugraoz93', 'body': 'CC: @shubhamraj-git', 'created_at': datetime.datetime(2025, 1, 25, 11, 21, 58, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2025-01-25 11:21:58 UTC): CC: @shubhamraj-git

"
2810618163,pull_request,closed,,Add dynamic task mapping into TaskSDK runtime,"The big change here (other than just moving code around) is to introduce a
conceptual separation between Definition/Execution time and Scheduler time.

This means that the expansion of tasks (creating the TaskInstance rows with
different map_index values) is now done on the scheduler, and we now
deserialize to different classes. For example, when we deserialize the
`DictOfListsExpandInput` it gets turned into an instance of
SchedulerDictOfListsExpandInput. This is primarily designed so that DB access
is kept 100% out of the TaskSDK.

Some of the changes here are on the ""wat"" side of the scale, and this is
mostly designed to not break 100% of our tests, and we have #45549 to look at
that more holistically.

To support the ""reduce"" style task which takes as input a sequence of all the
pushed (mapped) XCom values, and to keep the previous behaviour of not loading
all values in to memory at once, we have added a new HEAD route to the Task
Execution interface that returns the number of mapped XCom values so that it
is possible to implement `__len__` on the new LazyXComSequence class.

I have deleted a tranche of tests from tests/models that were to do with
runtime behavoir and and now tested in the TaskSDK instead.


## Testing:

I have been testing this with Celery Executor and the example_dynamic_task_mapping dag, which is this:

```python
with DAG(dag_id=""example_dynamic_task_mapping"", schedule=None, start_date=datetime(2022, 3, 4)) as dag:
    @task
    def add_one(x: int):
        return x + 1

    @task
    def sum_it(values):
        total = sum(values)
        print(f""Total was {total}"")

    added_values = add_one.expand(x=[1, 2, 3])
    sum_it(added_values)
```

It now works, and the sum_it tasks logs show:

```
{""timestamp"":""2025-02-04T14:24:05.264679Z"",""level"":""info"",""event"":""Total was 9"",""chan"":""stdout"",""logger"":""task""}
```

Closes #44360

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2025-01-25 00:04:35+00:00,[],2025-02-06 17:58:36+00:00,2025-02-06 17:58:13+00:00,https://github.com/apache/airflow/pull/46032,"[('area:serialization', ''), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2636994188, 'issue_id': 2810618163, 'author': 'uranusjr', 'body': 'This looks good to me. I’d be even more confident if the map_index changes are taken out, but I’ll take Ash’s words they don’t affect anything else if they’re left in. Aside from that it’s just the seemingly redundant `type()` calls left. We should remove them if possible, or find out why they are needed.', 'created_at': datetime.datetime(2025, 2, 5, 14, 24, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2637034551, 'issue_id': 2810618163, 'author': 'ashb', 'body': ""> This looks good to me. I’d be even more confident if the map_index changes are taken out, but I’ll take Ash’s words they don’t affect anything else if they’re left in. Aside from that it’s just the seemingly redundant `type()` calls left. We should remove them if possible, or find out why they are needed.\r\n\r\nYeah, I'll back out the map index change and try/remove the `type` as it shouldn't be needed. Just sorting out all the typing and static checks right now first."", 'created_at': datetime.datetime(2025, 2, 5, 14, 38, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2640577659, 'issue_id': 2810618163, 'author': 'ashb', 'body': '> Use the command line to resolve conflicts before continuing.\r\n> `providers/src/airflow/providers/cncf/kubernetes/operators/pod.py`\r\n\r\nThis is a ""fake"" conflict. `git` on the CLI does it without complaining (it just got renamed). If this current run passes I am merging after rebasing without waiting for next tests to pass.', 'created_at': datetime.datetime(2025, 2, 6, 17, 46, 59, tzinfo=datetime.timezone.utc)}]","uranusjr on (2025-02-05 14:24:23 UTC): This looks good to me. I’d be even more confident if the map_index changes are taken out, but I’ll take Ash’s words they don’t affect anything else if they’re left in. Aside from that it’s just the seemingly redundant `type()` calls left. We should remove them if possible, or find out why they are needed.

ashb (Issue Creator) on (2025-02-05 14:38:48 UTC): Yeah, I'll back out the map index change and try/remove the `type` as it shouldn't be needed. Just sorting out all the typing and static checks right now first.

ashb (Issue Creator) on (2025-02-06 17:46:59 UTC): This is a ""fake"" conflict. `git` on the CLI does it without complaining (it just got renamed). If this current run passes I am merging after rebasing without waiting for next tests to pass.

"
2810472009,pull_request,closed,,Added extra links for Comprehend operators,"
---
Added extra links to Comprehend operators.
",ellisms,2025-01-24 22:15:15+00:00,[],2025-01-27 12:47:07+00:00,2025-01-26 07:57:21+00:00,https://github.com/apache/airflow/pull/46031,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2810416896,pull_request,open,,Make OTel metrics path configurable,"Prometheus support receiving [OTel metrics](https://prometheus.io/docs/guides/opentelemetry/) at a slightly different path than the supported by default. This change makes the path configurable.

Closes #42492

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",paolostancato,2025-01-24 21:36:24+00:00,[],2025-01-24 22:05:48+00:00,,https://github.com/apache/airflow/pull/46030,[],"[{'comment_id': 2613419373, 'issue_id': 2810416896, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 24, 21, 36, 27, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-24 21:36:27 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2810384761,pull_request,closed,,Store relative fileloc on DagModel and SerializedDAG,"Store the relative fileloc at parse time so that way when we queue the task for running, we can specify the real relative fileloc along with the  bundle name and version, and this will let the task run with the right file / bundle / version
",dstandish,2025-01-24 21:13:29+00:00,[],2025-01-30 13:12:35+00:00,2025-01-30 13:12:33+00:00,https://github.com/apache/airflow/pull/46029,"[('area:serialization', ''), ('area:DAG-processing', ''), ('AIP-66: DAG Bundle/Manifest', ''), ('area:task-sdk', None)]",[],
2810251447,pull_request,closed,,Add icons to task states,"Update `stateColor` to match an icon to each task instance state and try to use those icons with those states when possible.

Part of: #43054

Dags List:
<img width=""1258"" alt=""Screenshot 2025-01-24 at 5 47 11 PM"" src=""https://github.com/user-attachments/assets/6a2f41b5-7446-4ad9-a653-e9774bcdffc6"" />

Dag Details, list dag runs:
<img width=""1263"" alt=""Screenshot 2025-01-24 at 5 47 21 PM"" src=""https://github.com/user-attachments/assets/5bec224e-618f-43fd-8140-77fd86eb4ecf"" />

Dashboard:
<img width=""1266"" alt=""Screenshot 2025-01-24 at 5 34 02 PM"" src=""https://github.com/user-attachments/assets/560ee2be-ebc6-4ace-9457-3e98791429a5"" />

Graph View:
<img width=""1255"" alt=""Screenshot 2025-01-24 at 5 57 15 PM"" src=""https://github.com/user-attachments/assets/c6b037e9-f1e7-4633-b62c-2e58a874c389"" />



State badges with different variants for each state in light/dark mode:
<img width=""1190"" alt=""Screenshot 2025-01-24 at 5 19 48 PM"" src=""https://github.com/user-attachments/assets/0d4764cd-8971-4009-8889-4337038c594c"" />
<img width=""1175"" alt=""Screenshot 2025-01-24 at 5 19 43 PM"" src=""https://github.com/user-attachments/assets/5c964c14-55a3-429a-85fc-10f81c5eba3c"" />



---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2025-01-24 19:36:59+00:00,[],2025-01-27 12:49:10+00:00,2025-01-25 15:39:21+00:00,https://github.com/apache/airflow/pull/46028,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2613562091, 'issue_id': 2810251447, 'author': 'bbovenzi', 'body': ""I moved all the colors into the app theme file to support semantic tokens and color palettes. I think there's still some tag/badge/status components that can be consolidated to improve consistency."", 'created_at': datetime.datetime(2025, 1, 24, 23, 4, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614573801, 'issue_id': 2810251447, 'author': 'potiuk', 'body': 'NIIIIIIIICE!', 'created_at': datetime.datetime(2025, 1, 26, 20, 10, 27, tzinfo=datetime.timezone.utc)}]","bbovenzi (Issue Creator) on (2025-01-24 23:04:10 UTC): I moved all the colors into the app theme file to support semantic tokens and color palettes. I think there's still some tag/badge/status components that can be consolidated to improve consistency.

potiuk on (2025-01-26 20:10:27 UTC): NIIIIIIIICE!

"
2810126119,pull_request,closed,,Make Dag Card more responsive,"Before:
<img width=""747"" alt=""Screenshot 2025-01-24 at 1 24 50 PM"" src=""https://github.com/user-attachments/assets/719b42e9-eb63-4197-8e12-1d40cc5fbb42"" />



After:
<img width=""750"" alt=""Screenshot 2025-01-24 at 1 24 41 PM"" src=""https://github.com/user-attachments/assets/9e1b591a-1a5c-4800-8291-d24ab16e8856"" />




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2025-01-24 18:29:12+00:00,[],2025-01-27 12:53:18+00:00,2025-01-24 19:43:50+00:00,https://github.com/apache/airflow/pull/46024,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2810048970,pull_request,closed,,Rename the `dag_bundles` config section to `dag_processor`,"There are some non-bundle specific configs we will want to keep grouped together, and most importantly, not shoved into the scheduler section even though they are not really scheduler related (e.g.  `parsing_processes`). Those moves will come later, but for easier review this just renames the section for the options we have already in preparation.",jedcunningham,2025-01-24 17:57:10+00:00,[],2025-01-27 12:52:52+00:00,2025-01-24 20:44:44+00:00,https://github.com/apache/airflow/pull/46022,"[('area:CLI', ''), ('area:providers', ''), ('kind:documentation', ''), ('type:new-feature', 'Changelog: New Features'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:DAG-processing', ''), ('provider:fab', ''), ('AIP-66: DAG Bundle/Manifest', ''), ('area:task-sdk', None)]",[],
2810047088,pull_request,closed,,Tidy up dagrun tests by removing many uses of `ti.run()`,"While this wasn't a problem before, having `ti.run` in the dagrun tests makes
porting code to the TaskSDK much more complicated. It also arguably makes them
more of integration tests than unit tests, which is no bad thing in and of
itself, but `ti.run()` can't work on SerializedDAG, so it means that the tests
are not quite representative of what the Scheduler will actually be doing.

Most of this change is to swap from calling run to setting the state (and
sometimes adding a TaskMap row) and then checking the scheduling decisions
result.

I have added the need_serialized_dag marker to the tests I touched. In the
next PR I create (that I extracted this out of) I apply this marker to all the
entire file, but that also needs porting manny of the dynamic task mapping
tests, and since I will be moving those soon I didn't touch them here too.

The test_prev_dagrun_dep file has been removed as it was only used in two
specific tests in this file, so it's better to inline it directly there.

How is this change deleting so many files? By removing duplicated or
almost-duplicated tests, namely these pairs. There were too many tests that
had almost identical bodies.

For example, testing that reducing a map length to zero isn't noticably
different to testing that a map length reduces by 2.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2025-01-24 17:56:20+00:00,[],2025-01-24 19:06:59+00:00,2025-01-24 19:06:56+00:00,https://github.com/apache/airflow/pull/46021,[],[],
2809987402,pull_request,closed,,AIP-72: Port _validate_inlet_outlet_assets_activeness into Task SDK,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #45969

## Why?

Tasks can be defined with inlet and outlet events in it definition. For cases when `inactive` assets are defined either in inlets, outlets or both, `_validate_inlet_outlet_assets_activeness` is a function defined that checks for this scenario and fails those tasks. This was added as part of https://github.com/apache/airflow/issues/44600.

This behaviour needs to be ported into the task sdk to maintain synchronisation with the legacy DAGs written prior to Airflow 3.

## Approach

This was done like this earlier: https://github.com/apache/airflow/blob/4cab641fbe00601ac736f19f4a56adbcc7848e1b/airflow/models/taskinstance.py#L3718-L3729.

- The function gets all the unique keys of all the possible assets defined in a conjunction of inlets + outlets of the task
- Once this is retrieved, the `AssetUniqueKey` is constructed for above
- We define another function that gets the inactive keys by querying the database: https://github.com/apache/airflow/blob/4cab641fbe00601ac736f19f4a56adbcc7848e1b/airflow/models/taskinstance.py#L3732
- If any inactive assets, raise an exception.

Challenge with doing similar things for task sdk:
1. `inlets` and `outlets` are runtime parameters for tasks, so we can only get them at runtime.
2. These need to be sent to the execution API server, which can make a decision whether these validation succeed or not.


So, these lead to two possible approaches:

### Approach 1: Performing these checks while starting a `task` ie. in the `/run` endpoint.
This seemed like the most natural approach but there were a few challenges around here.

This is our start() in supervisor:
```
    @classmethod
    def start(  # type: ignore[override]
        cls,
        *,
        what: TaskInstance,
        dag_rel_path: str | os.PathLike[str],
        bundle_info,
        client: Client,
        target: Callable[[], None] = _subprocess_main,
        logger: FilteringBoundLogger | None = None,
        **kwargs,
    ) -> Self:
        """"""Fork and start a new subprocess to execute the given task.""""""
        proc: Self = super().start(id=what.id, client=client, target=target, logger=logger, **kwargs)
        # Tell the task process what it needs to do!
        proc._on_child_started(ti=what, dag_rel_path=dag_rel_path, bundle_info=bundle_info)
        return proc
```

We do super().start which starts the child process's entrypoint / target but it doesnt run it until a startup is recveived. And in _on_child_started , we do this:
```
    def _on_child_started(self, ti: TaskInstance, dag_rel_path: str | os.PathLike[str], bundle_info):
        """"""Send startup message to the subprocess.""""""
        try:
            # We've forked, but the task won't start doing anything until we send it the StartupDetails
            # message. But before we do that, we need to tell the server it's started (so it has the chance to
            # tell us ""no, stop!"" for any reason)
            ti_context = self.client.task_instances.start(ti.id, self.pid, datetime.now(tz=timezone.utc))
.
.
.
.
.


        msg = StartupDetails.model_construct(
            ti=ti,
            dag_rel_path=os.fspath(dag_rel_path),
            bundle_info=bundle_info,
            requests_fd=self._requests_fd,
            ti_context=ti_context,
        )

        # Send the message to tell the process what it needs to execute
        log.debug(""Sending"", msg=msg)

        try:
            self.stdin.write(msg.model_dump_json().encode())
            self.stdin.write(b""\n"")
```

We tell the server to `self.client.task_instances.start` and then send the startup message to the task runner when it actually starts.

The option would be to send the task outlets and inlets (defined as ti.task.inlets or ti.task.outlets) to the execution API. Challenge that makes it hard is that the ti_context comes from the run endpoint and we need that for startup details.

Maybe this can be a later optimisation with fewer network calls but require good amount of refactoring, so parking for now.

### Approach 2: Introduce a new endpoint at the execution API that can perform runtime checks and is called after startup and during run from task runner.

- Introduced a new endpoint: `/{task_instance_id}/runtime-checks`. Generic endpoint that can perform runtime checks for a TI. Right now limited to `_validate_inlet_outlet_assets_activeness` but easily extendable. Returns 200 if all ok, 204 if not applicable and 400 for failed checks.
- Called from task runner after the task has been fetched: `ti.task = ti.task.prepare_for_execution()` through the supervisor and the client.


## Implementation Details:

### Execution API Server
- New API: `runtime_checks` introduced on task instance, right now limited to checking behaviour assosiated with `_validate_inlet_outlet_assets_activeness` but can be extended.
- Returns 200 if all ok with (`{""message"": ""Runtime checks passed successfully.""}`), 204 if not applicable and 400 for failed checks.


### Client side

#### Comms
- `RuntimeCheckOnTask` payload introduced, this one is an extension of payload:
```
class TIRuntimeCheckPayload(BaseModel):
    """"""Payload for performing Runtime checks on the TaskInstance model as requested by the SDK.""""""

    inlet: list[AssetProfile] | None = None
    outlet: list[AssetProfile] | None = None
```
- The response from the server is translated to a simple `OKresponse`: `True` indicates that runtime checks passed from server, `False` is otherwise.


#### HTTP Client
- Simple POST call to the server API: `self.client.post(f""task-instances/{id}/runtime-checks"", content=body.model_dump_json())` and translates the response to `OKResponse`
- For a non 400 status code in failure, raises exception.

#### Task Runner
- Right after preparation for execution of a task, we check if inlets or outlets are defined on a task, if yes, construct the structure to call the API and send it to the supervisor.
- If supervisor returns a message indicating the runtime checks didnt pass on server, fail the task.

#### Supervisor
```
        elif isinstance(msg, RuntimeCheckOnTask):
            runtime_check_resp = self.client.task_instances.runtime_checks(id=self.id, msg=msg)
            resp = runtime_check_resp.model_dump_json().encode()
            if not runtime_check_resp.ok:
                log.debug(""Runtime checks failed on task %s, marking task as failed.."", self.id)
                self.client.task_instances.finish(
                    id=self.id, state=TerminalTIState.FAILED, when=datetime.now(tz=timezone.utc)
                )
```

- Calls the runtime checks API, if the response is not OK, immediately calls the `finish` endpoint with failed state.
- This optimises the flow as much as possible by having no need to communicate with the task runner.

#### Models/taskinstance.py
- Modified the `_validate_inlet_outlet_assets_activeness` to a structure that can accomodate the task sdk.
```
validate_inlet_outlet_assets_activeness(
        inlets: list[AssetProfile], outlets: list[AssetProfile], session: Session
    )
```

The signature now accepts the inlets and outlets directly.


### Testing results
DAG defined:
```
from airflow.models.dag import DAG
from airflow.operators.empty import EmptyOperator
from airflow.sdk.definitions.asset import Asset

with DAG(
    dag_id=""asset_dag"",
    start_date=None,
    schedule=None,
    catchup=False,
):

    outlet = EmptyOperator(
        task_id=""outlet"",
        outlets=[Asset(name=""outlet"", uri=""something-uri""), Asset(name=""outlet-new-name"", uri=""something-uri"")],
    )

    inlet = EmptyOperator(
        task_id=""inlet"",
        outlets=[Asset(name=""outlet"", uri=""something-uri""), Asset(name=""outlet-new-name"", uri=""something-uri"")],
    )

    outlet >> inlet

```

The issue with the DAG is that the same assets are present in the outlets and inlets and changed name with same URI. Hence once of them is inactive in `outlets`

#### Legacy
![image](https://github.com/user-attachments/assets/e2e614dc-cfda-4b2b-8e60-bdc0ca9e33e7)

Logs:
```
be976385dc7e
 ▶ Log message source details
[2025-01-27, 09:19:41 UTC] {local_task_job_runner.py:120} ▼ Pre task execution logs
[2025-01-27, 09:19:41 UTC] {taskinstance.py:2384} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: asset_dag.outlet manual__2025-01-27T09:19:35.134947+00:00 [queued]>
[2025-01-27, 09:19:41 UTC] {taskinstance.py:2384} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: asset_dag.outlet manual__2025-01-27T09:19:35.134947+00:00 [queued]>
[2025-01-27, 09:19:41 UTC] {taskinstance.py:2625} INFO - Starting attempt 1 of 1
[2025-01-27, 09:19:41 UTC] {taskinstance.py:2648} INFO - Executing <Task(EmptyOperator): outlet> on 2025-01-27 09:19:35.134947+00:00
[2025-01-27, 09:19:41 UTC] {standard_task_runner.py:131} INFO - Started process 557 to run task
[2025-01-27, 09:19:41 UTC] {standard_task_runner.py:147} INFO - Running: ['***', 'tasks', 'run', 'asset_dag', 'outlet', 'manual__2025-01-27T09:19:35.134947+00:00', '--raw', '--subdir', 'DAGS_FOLDER/producer_and_consumer.py', '--cfg-path', '/tmp/tmpocu3qfya']
[2025-01-27, 09:19:41 UTC] {standard_task_runner.py:148} INFO - Subtask outlet
[2025-01-27, 09:19:41 UTC] {task_command.py:474} INFO - Running <TaskInstance: asset_dag.outlet manual__2025-01-27T09:19:35.134947+00:00 [running]> on host be976385dc7e
[2025-01-27, 09:19:41 UTC] {taskinstance.py:3119} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 274, in _run_raw_task
    TaskInstance.validate_inlet_outlet_assets_activeness(inlets, outlets, session=session)
  File ""/opt/airflow/airflow/models/taskinstance.py"", line 3744, in validate_inlet_outlet_assets_activeness
    raise AirflowInactiveAssetInInletOrOutletException(inactive_asset_unique_keys)
airflow.exceptions.AirflowInactiveAssetInInletOrOutletException: Task has the following inactive assets in its inlets or outlets: Asset(name=""outlet-new-name"", uri=""something-uri"")
[2025-01-27, 09:19:41 UTC] {taskinstance.py:1130} INFO - Immediate failure requested. Marking task as FAILED. dag_id=asset_dag, task_id=outlet, run_id=manual__2025-01-27T09:19:35.134947+00:00, logical_date=20250127T091935, start_date=20250127T091941, end_date=20250127T091941
[2025-01-27, 09:19:41 UTC] {taskinstance.py:343} ▶ Post task execution logs
```

#### Task SDK
![image](https://github.com/user-attachments/assets/399cd332-be79-4569-b224-adc27e813506)

Error logs:
```
5c6cc67013a3
 ▶ Log message source details
{""logger"":""airflow.dag_processing.bundles.manager.DagBundlesManager"",""timestamp"":""2025-01-27T09:29:41.642326"",""event"":""DAG bundles loaded: dags-folder"",""level"":""info""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2025-01-27T09:29:41.642487"",""event"":""Filling up the DagBag from /files/dags/producer_and_consumer.py"",""level"":""info""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2025-01-27T09:29:41.642729"",""event"":""Importing /files/dags/producer_and_consumer.py"",""level"":""debug""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2025-01-27T09:29:41.645642"",""event"":""Loaded DAG <DAG: asset_dag>"",""level"":""debug""}
{""file"":""producer_and_consumer.py"",""timestamp"":""2025-01-27T09:29:41.645773"",""logger"":""task"",""event"":""DAG file parsed"",""level"":""debug""}
{""json"":""{\""inlet\"":[],\""outlet\"":[{\""name\"":\""outlet\"",\""uri\"":\""something-uri\"",\""asset_type\"":\""Asset\""},{\""name\"":\""outlet-new-name\"",\""uri\"":\""something-uri\"",\""asset_type\"":\""Asset\""}],\""type\"":\""RuntimeCheckOnTask\""}\n"",""timestamp"":""2025-01-27T09:29:41.646024"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""timestamp"":""2025-01-27T09:29:41.666578"",""logger"":""task"",""event"":""Runtime checks failed for task, marking task as failed.."",""level"":""info""}
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-24 17:32:47+00:00,['amoghrajesh'],2025-01-30 06:34:41+00:00,2025-01-30 06:34:39+00:00,https://github.com/apache/airflow/pull/46020,"[('area:task-sdk', None)]","[{'comment_id': 2613055460, 'issue_id': 2809987402, 'author': 'amoghrajesh', 'body': 'Need to work on few things:\r\n1. Fix the task runner tests\r\n2. Add tests for supervisor\r\n3. Revisit the `# type: ignore` checks -> added some cos it felt easier.\r\n4. Add PR description with plenty of details.', 'created_at': datetime.datetime(2025, 1, 24, 17, 33, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618372894, 'issue_id': 2809987402, 'author': 'amoghrajesh', 'body': 'Yeah, with the latest changes, the DAG passes:\r\n![image](https://github.com/user-attachments/assets/6686afd9-3606-460d-95f4-d99e3cfe0bfd)\r\n\r\nAnd the error handling is better:\r\n![image](https://github.com/user-attachments/assets/bcd74da7-4202-4d14-98ff-9bae63bd2a50)\r\n\r\n\r\nCC: @ashb', 'created_at': datetime.datetime(2025, 1, 28, 9, 9, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618383757, 'issue_id': 2809987402, 'author': 'amoghrajesh', 'body': 'Well OK, turns out the test has to be updated now!', 'created_at': datetime.datetime(2025, 1, 28, 9, 14, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618757361, 'issue_id': 2809987402, 'author': 'amoghrajesh', 'body': '@ashb handled your comments, let me know if the approval still stands :)', 'created_at': datetime.datetime(2025, 1, 28, 11, 38, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618923925, 'issue_id': 2809987402, 'author': 'ashb', 'body': 'Yup, still stands. When the changes requested are small enough I often ""pre-approve"" it to save an extra cycle, and then it\'s up to you as the PR author to decide it can be merged once the changes are made, or if you need to get a re-review.', 'created_at': datetime.datetime(2025, 1, 28, 12, 54, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2620723310, 'issue_id': 2809987402, 'author': 'amoghrajesh', 'body': 'The CI had some issues lately, just working on a green one so that this can be merged', 'created_at': datetime.datetime(2025, 1, 29, 4, 58, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2623631408, 'issue_id': 2809987402, 'author': 'amoghrajesh', 'body': 'After a hard battle with the CI, we have won! Merging this one', 'created_at': datetime.datetime(2025, 1, 30, 6, 34, 15, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2025-01-24 17:33:46 UTC): Need to work on few things:
1. Fix the task runner tests
2. Add tests for supervisor
3. Revisit the `# type: ignore` checks -> added some cos it felt easier.
4. Add PR description with plenty of details.

amoghrajesh (Issue Creator) on (2025-01-28 09:09:29 UTC): Yeah, with the latest changes, the DAG passes:
![image](https://github.com/user-attachments/assets/6686afd9-3606-460d-95f4-d99e3cfe0bfd)

And the error handling is better:
![image](https://github.com/user-attachments/assets/bcd74da7-4202-4d14-98ff-9bae63bd2a50)


CC: @ashb

amoghrajesh (Issue Creator) on (2025-01-28 09:14:33 UTC): Well OK, turns out the test has to be updated now!

amoghrajesh (Issue Creator) on (2025-01-28 11:38:54 UTC): @ashb handled your comments, let me know if the approval still stands :)

ashb on (2025-01-28 12:54:28 UTC): Yup, still stands. When the changes requested are small enough I often ""pre-approve"" it to save an extra cycle, and then it's up to you as the PR author to decide it can be merged once the changes are made, or if you need to get a re-review.

amoghrajesh (Issue Creator) on (2025-01-29 04:58:08 UTC): The CI had some issues lately, just working on a green one so that this can be merged

amoghrajesh (Issue Creator) on (2025-01-30 06:34:15 UTC): After a hard battle with the CI, we have won! Merging this one

"
2809872935,pull_request,closed,,AIP-84 Add patch task_instance dry_run endpoint,"## What it does
Similarly to the `POST backfills` in dry_run mode. This adds a dry_run mode endpoint for the patch task instances and patch  mapped task instances. Removed the `dry_run` param of the default patch TI and mapped TI endpoint, because it was only affecting the `state`, still mutating the note, which is a little bit weird.

## Why
While working on the front-end to mark task instances as success or failed, I realized that there wasn't a way to see affected task instances for a specific set state with settings (past / future / etc...). Legacy front-end was relying on a custom UI endpoint `/confirm`, I don't think we need yet another private endpoint to handle this, I think any user can be intersted before setting a task_state to something to see side effects on other affected tasks.


We could also just improve the existing patch endpoint to fully support a dry_run mode, but for the same reasons as we did for backfill, different endpoint is just clearer. (Same endpoint would have different return type based on the `dry_run` value. `dry_run: False`  would return a TI, but `dry_run: True` would return a list of affected tasks. That's confusing on the client side, and force manual casting or overloading. Also code path for dry_run and non dry_run would be intertwined in the same endpoint making it even more complex).",pierrejeambrun,2025-01-24 16:42:06+00:00,['pierrejeambrun'],2025-01-28 10:22:39+00:00,2025-01-28 10:22:37+00:00,https://github.com/apache/airflow/pull/46018,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2612977840, 'issue_id': 2809872935, 'author': 'bbovenzi', 'body': ""Good catch! I forgot that we weren't using the public rest api for this in the old UI.\r\n\r\nWhat if we made this a GET endpoint? Since its a dry_run, we're not actually changing anything and then it saves us the time of building a custom query wrapper like I just did for clearing in https://github.com/apache/airflow/pull/45987."", 'created_at': datetime.datetime(2025, 1, 24, 16, 53, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2612998968, 'issue_id': 2809872935, 'author': 'pierrejeambrun', 'body': ""> Good catch! I forgot that we weren't using the public rest api for this in the old UI.\r\n\r\n>What if we made this a GET endpoint? Since its a dry_run, we're not actually changing anything and then it saves us the time of building a custom query wrapper like I just did for clearing in https://github.com/apache/airflow/pull/45987.\r\n\r\nWe could do that, and indeed that will save some time on the front-end part. Transforming the current body into query parameters I suppose ?"", 'created_at': datetime.datetime(2025, 1, 24, 17, 3, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613100643, 'issue_id': 2809872935, 'author': 'pierrejeambrun', 'body': ""> What if we made this a GET endpoint? Since its a dry_run, we're not actually changing anything and then it saves us the time of building a custom query wrapper like I just did for clearing in https://github.com/apache/airflow/pull/45987.\r\n\r\nWe could do that to save an extra custom query wrapper in the front-end. We also have the create backfill endpoint that currently implements a `dry_run` version as well. If we are to put `dry_run` versions of endpoints on `GET` method, we most likely need to rework that create backfill dry_run endpoint to comply with that. Also we need to convert payloads used for the non dry_run version of POST / PATCH into query parameters and perform the same validation most likely instantiating back those data models. I think the work we save on the front-end is out-balanced by the extra work we need on the backend. (though all of that are minor efforts)\r\n\r\nAlso that's just me but as a user I wouldn't expect the method to change from a dry_run call to a non dry_run one.\r\n\r\nI would lean towards keeping the same method when implementing a dry_run version of an endpoint. Considering the elements above, let me know if that makes sense 😄"", 'created_at': datetime.datetime(2025, 1, 24, 18, 1, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615109566, 'issue_id': 2809872935, 'author': 'pierrejeambrun', 'body': 'cc: @atul-astronomer', 'created_at': datetime.datetime(2025, 1, 27, 8, 26, 36, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2025-01-24 16:53:45 UTC): Good catch! I forgot that we weren't using the public rest api for this in the old UI.

What if we made this a GET endpoint? Since its a dry_run, we're not actually changing anything and then it saves us the time of building a custom query wrapper like I just did for clearing in https://github.com/apache/airflow/pull/45987.

pierrejeambrun (Issue Creator) on (2025-01-24 17:03:58 UTC): We could do that, and indeed that will save some time on the front-end part. Transforming the current body into query parameters I suppose ?

pierrejeambrun (Issue Creator) on (2025-01-24 18:01:13 UTC): We could do that to save an extra custom query wrapper in the front-end. We also have the create backfill endpoint that currently implements a `dry_run` version as well. If we are to put `dry_run` versions of endpoints on `GET` method, we most likely need to rework that create backfill dry_run endpoint to comply with that. Also we need to convert payloads used for the non dry_run version of POST / PATCH into query parameters and perform the same validation most likely instantiating back those data models. I think the work we save on the front-end is out-balanced by the extra work we need on the backend. (though all of that are minor efforts)

Also that's just me but as a user I wouldn't expect the method to change from a dry_run call to a non dry_run one.

I would lean towards keeping the same method when implementing a dry_run version of an endpoint. Considering the elements above, let me know if that makes sense 😄

pierrejeambrun (Issue Creator) on (2025-01-27 08:26:36 UTC): cc: @atul-astronomer

"
2809868853,pull_request,open,,Handle future dates cases in Backfill,"Closes: https://github.com/apache/airflow/issues/46012
This PR fixes the below behaviors
1. Ensure dates which are in future with run_backwards=true are not inserted in backfilldagrun table
2. Raise 422 when all dates are in the future.
<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2025-01-24 16:40:07+00:00,[],2025-02-05 17:14:48+00:00,,https://github.com/apache/airflow/pull/46017,[],[],
2809608041,pull_request,closed,,Update contributors_quick_start_gitpod.rst,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",aditya0yadav,2025-01-24 14:34:57+00:00,[],2025-01-28 17:55:44+00:00,2025-01-28 17:55:44+00:00,https://github.com/apache/airflow/pull/46014,"[('area:dev-tools', '')]",[],
2809315170,pull_request,closed,,Add backward compatibility for old Airflow versions for CloudComposerDAGRunSensor,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have added backward compatibility for old Airflow versions for CloudComposerDAGRunSensor.

By this PR https://github.com/apache/airflow/pull/43902 inside the Airflow core for the DAG model `execution_date` was changed to the `logical_date`. This change was made for Airflow 3, but because it was renamed for the whole codebase it affected Google provider. The problem was faced , because the new google provider was released before Airflow 3.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2025-01-24 12:20:13+00:00,[],2025-01-27 12:45:57+00:00,2025-01-26 12:56:38+00:00,https://github.com/apache/airflow/pull/46011,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2809009437,pull_request,closed,,"Enable already existing ""task.scheduled_duration"" metric","# Overview

This PR enables the task.scheduled_duration metric.  It is already described here:
https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/logging-monitoring/metrics.html#timers
Search for ""task.scheduled_duration""
The metric is not working at the moment as the scheduled_dttm field is missing in the task_instance table.

I hope I catched all points in the code were the task_instance is set to scheduled state to collect the right time and that I understood the metric in the right way.
Idea of this PR to keep it as simple as possible to enable this metric.

# Details of changes:
* Add scheduled_dttm field to the task_instance table.
* Setting scheduled_dttm field if task is set to scheduled state.
* Enable metric calcuation.
* Update the api to return the task_instance with the new field.

Looking forward to start the discussion about this metric and getting this live with Airflow 3.

Relates: #30612 #34493 #34771",AutomationDev85,2025-01-24 09:51:07+00:00,[],2025-01-30 19:59:49+00:00,2025-01-30 19:59:49+00:00,https://github.com/apache/airflow/pull/46009,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:Triggerer', ''), ('area:db-migrations', 'PRs with DB migration'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2614096750, 'issue_id': 2809009437, 'author': 'eladkal', 'body': '> This PR enables the task.scheduled_duration metric\r\n\r\nDoes this mean the metric was never produced in Airflow 2.x?', 'created_at': datetime.datetime(2025, 1, 25, 20, 54, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614098718, 'issue_id': 2809009437, 'author': 'jscheffl', 'body': '> > This PR enables the task.scheduled_duration metric\r\n> \r\n> Does this mean the metric was never produced in Airflow 2.x?\r\n\r\nYes, it was defined but never filled - as the scheduled time was not recorded. Only the queued time was written into the DB then the metric was able to be produced. Good overview is in https://github.com/apache/airflow/pull/30612', 'created_at': datetime.datetime(2025, 1, 25, 21, 1, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614100536, 'issue_id': 2809009437, 'author': 'eladkal', 'body': ""> > > This PR enables the task.scheduled_duration metric\r\n> > \r\n> > \r\n> > Does this mean the metric was never produced in Airflow 2.x?\r\n> \r\n> Yes, it was defined but never filled - as the scheduled time was not recorded. Only the queued time was written into the DB then the metric was able to be produced. Good overview is in #30612\r\n\r\nhttps://github.com/apache/airflow/issues/45285 reports it was rarely sent. Not that it wasn't sent at all. That's odd."", 'created_at': datetime.datetime(2025, 1, 25, 21, 8, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616950185, 'issue_id': 2809009437, 'author': 'jscheffl', 'body': '> > > > This PR enables the task.scheduled_duration metric\r\n> > > \r\n> > > \r\n> > > Does this mean the metric was never produced in Airflow 2.x?\r\n> > \r\n> > \r\n> > Yes, it was defined but never filled - as the scheduled time was not recorded. Only the queued time was written into the DB then the metric was able to be produced. Good overview is in #30612\r\n> \r\n> #45285 reports it was rarely sent. Not that it wasn\'t sent at all. That\'s odd.\r\n\r\nI don\'t know in which cases it ""rarely"" was sent - @AutomationDev85 do you know in which cases the metric was emitted in the past?\r\n\r\n@eladkal does anything speak against merging this for Airflow 3 to make it ""proper""? (e.g. additional column that adds overhead?)', 'created_at': datetime.datetime(2025, 1, 27, 21, 38, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618773666, 'issue_id': 2809009437, 'author': 'AutomationDev85', 'body': '@jscheffl That is a good question. I´m not sure how this metric should be rarely exported. In the current implementation the metric would be exported if the start_date is available but from my point of view this start_date will be set after the task went from scheduled into queued state. \r\n\r\nMay be if a task reruns and the task_instance includes already a start_date and it is not moved into the task_instance_history then this metric could be exported but this value is wrong for this metric. But I do not know in which case we can end in such kind of state. :(', 'created_at': datetime.datetime(2025, 1, 28, 11, 46, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2625452023, 'issue_id': 2809009437, 'author': 'jscheffl', 'body': 'Nobody is objection - I thought it is a bit more of a discussion - I propose to merge this as an improvement for observability with the trade-off of an additional column in the DB', 'created_at': datetime.datetime(2025, 1, 30, 19, 59, 42, tzinfo=datetime.timezone.utc)}]","eladkal on (2025-01-25 20:54:44 UTC): Does this mean the metric was never produced in Airflow 2.x?

jscheffl on (2025-01-25 21:01:51 UTC): Yes, it was defined but never filled - as the scheduled time was not recorded. Only the queued time was written into the DB then the metric was able to be produced. Good overview is in https://github.com/apache/airflow/pull/30612

eladkal on (2025-01-25 21:08:35 UTC): https://github.com/apache/airflow/issues/45285 reports it was rarely sent. Not that it wasn't sent at all. That's odd.

jscheffl on (2025-01-27 21:38:03 UTC): I don't know in which cases it ""rarely"" was sent - @AutomationDev85 do you know in which cases the metric was emitted in the past?

@eladkal does anything speak against merging this for Airflow 3 to make it ""proper""? (e.g. additional column that adds overhead?)

AutomationDev85 (Issue Creator) on (2025-01-28 11:46:41 UTC): @jscheffl That is a good question. I´m not sure how this metric should be rarely exported. In the current implementation the metric would be exported if the start_date is available but from my point of view this start_date will be set after the task went from scheduled into queued state. 

May be if a task reruns and the task_instance includes already a start_date and it is not moved into the task_instance_history then this metric could be exported but this value is wrong for this metric. But I do not know in which case we can end in such kind of state. :(

jscheffl on (2025-01-30 19:59:42 UTC): Nobody is objection - I thought it is a bit more of a discussion - I propose to merge this as an improvement for observability with the trade-off of an additional column in the DB

"
2808781115,pull_request,closed,,ci(github-actions): add a script to check significant newsfragments,"## Why
Since https://github.com/apache/airflow/pull/45740, we further formalize the significant newsfragments format but have not yet added a script to check it in CI.

## What
A script is added for checking whether the format is correct, allow us to export summarization of these newsfragments and list down undone migration rules


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2025-01-24 07:49:15+00:00,['Lee-W'],2025-02-03 11:02:28+00:00,2025-02-03 11:02:26+00:00,https://github.com/apache/airflow/pull/46007,"[('area:dev-tools', '')]","[{'comment_id': 2617005113, 'issue_id': 2808781115, 'author': 'potiuk', 'body': 'Why not pre-commit ? you will be able to run it locally way before it even hits the CI.', 'created_at': datetime.datetime(2025, 1, 27, 22, 11, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2630063794, 'issue_id': 2808781115, 'author': 'Lee-W', 'body': '> Why not pre-commit ? you will be able to run it locally way before it even hits the CI.\r\n\r\nYep, sounds like a great idea! I just updated it to use pre-commit. Will merge it once the CI pass so that we can ensure the format is correct for future newsfragments.', 'created_at': datetime.datetime(2025, 2, 3, 6, 14, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2630623379, 'issue_id': 2808781115, 'author': 'Lee-W', 'body': ""as the ci failure has nothing to do with it and will be fixed by https://github.com/apache/airflow/pull/46368. I'll go ahead and merge this PR"", 'created_at': datetime.datetime(2025, 2, 3, 11, 2, 17, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-27 22:11:29 UTC): Why not pre-commit ? you will be able to run it locally way before it even hits the CI.

Lee-W (Issue Creator) on (2025-02-03 06:14:58 UTC): Yep, sounds like a great idea! I just updated it to use pre-commit. Will merge it once the CI pass so that we can ensure the format is correct for future newsfragments.

Lee-W (Issue Creator) on (2025-02-03 11:02:17 UTC): as the ci failure has nothing to do with it and will be fixed by https://github.com/apache/airflow/pull/46368. I'll go ahead and merge this PR

"
2808573093,pull_request,closed,,allow passing custom env to log groomer sidecar containers,"Issue Description:

Currently logGroomer sidecar container does not allow users to pass custom env vars 

Changes:
This PR introduces env vars support for all the log groomer sidecars to allow overridable env vars to workers,triggerer,scheduler,dag-processor  components",pgvishnuram,2025-01-24 05:57:35+00:00,[],2025-01-27 18:03:38+00:00,2025-01-27 18:02:48+00:00,https://github.com/apache/airflow/pull/46003,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2611871170, 'issue_id': 2808573093, 'author': 'pgvishnuram', 'body': '> I understand the need and like the idea, but do we need templating?\r\n\r\nIn every component of airflow helm template it was defined that way - so i included the same approach. I doesnt require we can directly do a toYaml directly as well', 'created_at': datetime.datetime(2025, 1, 24, 7, 46, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615837827, 'issue_id': 2808573093, 'author': 'eladkal', 'body': 'Tests are failing:\r\n```\r\n\r\n=========================== short test summary info ============================\r\nFAILED helm_tests/airflow_core/test_dag_processor.py::TestDagProcessorLogGroomer::test_log_groomer_collector_custom_env - tests.charts.helm_template_generator.HelmFailedError: Helm command failed. Args: (1, [\'helm\', \'template\', \'release-name\', \'/opt/airflow/chart\', \'--values\', \'/tmp/tmpyt3ly0zi\', \'--kube-version\', \'1.29.1\', \'--namespace\', \'default\', \'--show-only\', \'templates/dag-processor/dag-processor-deployment.yaml\'], b\'\', b""Error: values don\'t meet the specifications of the schema(s) in the following chart(s):\\nairflow:\\n- dagProcessor.logGroomerSidecar.env.0: name is required\\n- dagProcessor.logGroomerSidecar.env.0: Additional property name: is not allowed\\n- dagProcessor.logGroomerSidecar.env.1: name is required\\n- dagProcessor.logGroomerSidecar.env.1: Additional property name: is not allowed\\n\\n"")\r\nStderr: \r\nError: values don\'t meet the specifications of the schema(s) in the following chart(s):\r\nairflow:\r\n- dagProcessor.logGroomerSidecar.env.0: name is required\r\n- dagProcessor.logGroomerSidecar.env.0: Additional property name: is not allowed\r\n- dagProcessor.logGroomerSidecar.env.1: name is required\r\n- dagProcessor.logGroomerSidecar.env.1: Additional property name: is not allowed\r\nFAILED helm_tests/airflow_core/test_dag_processor.py::TestDagProcessorLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError\r\nFAILED helm_tests/airflow_core/test_scheduler.py::TestSchedulerLogGroomer::test_log_groomer_collector_custom_env - AssertionError\r\nFAILED helm_tests/airflow_core/test_scheduler.py::TestSchedulerLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError\r\nFAILED helm_tests/airflow_core/test_triggerer.py::TestTriggererLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError\r\nFAILED helm_tests/airflow_core/test_triggerer.py::TestTriggererLogGroomer::test_log_groomer_collector_custom_env - AssertionError\r\nFAILED helm_tests/airflow_core/test_worker.py::TestWorkerLogGroomer::test_log_groomer_collector_custom_env - AssertionError\r\nFAILED helm_tests/airflow_core/test_worker.py::TestWorkerLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError\r\n================== 8 failed, 469 passed, 5 warnings in 57.85s ==================\r\n```', 'created_at': datetime.datetime(2025, 1, 27, 13, 59, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615982556, 'issue_id': 2808573093, 'author': 'pgvishnuram', 'body': '> Tests are failing:\r\n> \r\n> ```\r\n> \r\n> =========================== short test summary info ============================\r\n> FAILED helm_tests/airflow_core/test_dag_processor.py::TestDagProcessorLogGroomer::test_log_groomer_collector_custom_env - tests.charts.helm_template_generator.HelmFailedError: Helm command failed. Args: (1, [\'helm\', \'template\', \'release-name\', \'/opt/airflow/chart\', \'--values\', \'/tmp/tmpyt3ly0zi\', \'--kube-version\', \'1.29.1\', \'--namespace\', \'default\', \'--show-only\', \'templates/dag-processor/dag-processor-deployment.yaml\'], b\'\', b""Error: values don\'t meet the specifications of the schema(s) in the following chart(s):\\nairflow:\\n- dagProcessor.logGroomerSidecar.env.0: name is required\\n- dagProcessor.logGroomerSidecar.env.0: Additional property name: is not allowed\\n- dagProcessor.logGroomerSidecar.env.1: name is required\\n- dagProcessor.logGroomerSidecar.env.1: Additional property name: is not allowed\\n\\n"")\r\n> Stderr: \r\n> Error: values don\'t meet the specifications of the schema(s) in the following chart(s):\r\n> airflow:\r\n> - dagProcessor.logGroomerSidecar.env.0: name is required\r\n> - dagProcessor.logGroomerSidecar.env.0: Additional property name: is not allowed\r\n> - dagProcessor.logGroomerSidecar.env.1: name is required\r\n> - dagProcessor.logGroomerSidecar.env.1: Additional property name: is not allowed\r\n> FAILED helm_tests/airflow_core/test_dag_processor.py::TestDagProcessorLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError\r\n> FAILED helm_tests/airflow_core/test_scheduler.py::TestSchedulerLogGroomer::test_log_groomer_collector_custom_env - AssertionError\r\n> FAILED helm_tests/airflow_core/test_scheduler.py::TestSchedulerLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError\r\n> FAILED helm_tests/airflow_core/test_triggerer.py::TestTriggererLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError\r\n> FAILED helm_tests/airflow_core/test_triggerer.py::TestTriggererLogGroomer::test_log_groomer_collector_custom_env - AssertionError\r\n> FAILED helm_tests/airflow_core/test_worker.py::TestWorkerLogGroomer::test_log_groomer_collector_custom_env - AssertionError\r\n> FAILED helm_tests/airflow_core/test_worker.py::TestWorkerLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError\r\n> ================== 8 failed, 469 passed, 5 warnings in 57.85s ==================\r\n> ```\r\n\r\n@eladkal there seems to be a typo in the pytest it will fixed in the new commits thanks', 'created_at': datetime.datetime(2025, 1, 27, 14, 55, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616532502, 'issue_id': 2808573093, 'author': 'jedcunningham', 'body': 'Oops, beat you @amoghrajesh :)', 'created_at': datetime.datetime(2025, 1, 27, 18, 3, 36, tzinfo=datetime.timezone.utc)}]","pgvishnuram (Issue Creator) on (2025-01-24 07:46:56 UTC): In every component of airflow helm template it was defined that way - so i included the same approach. I doesnt require we can directly do a toYaml directly as well

eladkal on (2025-01-27 13:59:17 UTC): Tests are failing:
```

=========================== short test summary info ============================
FAILED helm_tests/airflow_core/test_dag_processor.py::TestDagProcessorLogGroomer::test_log_groomer_collector_custom_env - tests.charts.helm_template_generator.HelmFailedError: Helm command failed. Args: (1, ['helm', 'template', 'release-name', '/opt/airflow/chart', '--values', '/tmp/tmpyt3ly0zi', '--kube-version', '1.29.1', '--namespace', 'default', '--show-only', 'templates/dag-processor/dag-processor-deployment.yaml'], b'', b""Error: values don't meet the specifications of the schema(s) in the following chart(s):\nairflow:\n- dagProcessor.logGroomerSidecar.env.0: name is required\n- dagProcessor.logGroomerSidecar.env.0: Additional property name: is not allowed\n- dagProcessor.logGroomerSidecar.env.1: name is required\n- dagProcessor.logGroomerSidecar.env.1: Additional property name: is not allowed\n\n"")
Stderr: 
Error: values don't meet the specifications of the schema(s) in the following chart(s):
airflow:
- dagProcessor.logGroomerSidecar.env.0: name is required
- dagProcessor.logGroomerSidecar.env.0: Additional property name: is not allowed
- dagProcessor.logGroomerSidecar.env.1: name is required
- dagProcessor.logGroomerSidecar.env.1: Additional property name: is not allowed
FAILED helm_tests/airflow_core/test_dag_processor.py::TestDagProcessorLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError
FAILED helm_tests/airflow_core/test_scheduler.py::TestSchedulerLogGroomer::test_log_groomer_collector_custom_env - AssertionError
FAILED helm_tests/airflow_core/test_scheduler.py::TestSchedulerLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError
FAILED helm_tests/airflow_core/test_triggerer.py::TestTriggererLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError
FAILED helm_tests/airflow_core/test_triggerer.py::TestTriggererLogGroomer::test_log_groomer_collector_custom_env - AssertionError
FAILED helm_tests/airflow_core/test_worker.py::TestWorkerLogGroomer::test_log_groomer_collector_custom_env - AssertionError
FAILED helm_tests/airflow_core/test_worker.py::TestWorkerLogGroomer::test_log_groomer_retention_days_overrides[None-None] - AssertionError
================== 8 failed, 469 passed, 5 warnings in 57.85s ==================
```

pgvishnuram (Issue Creator) on (2025-01-27 14:55:32 UTC): @eladkal there seems to be a typo in the pytest it will fixed in the new commits thanks

jedcunningham on (2025-01-27 18:03:36 UTC): Oops, beat you @amoghrajesh :)

"
2808450023,pull_request,closed,,AIP-84 - remove dry_run in post backfill tests,"I noticed a dry_run argument being sent in creating backfill tests. It's not part of the request body as per https://github.com/apache/airflow/blob/d4609728ede88a4b8c411f774911efcfdef01ed2/airflow/api_fastapi/core_api/datamodels/backfills.py#L26-L35


We can either add it to the model(but I don't see it being utilized by underlying functionality) or remove it from tests.

Found this issue while working on https://github.com/apache/airflow/pull/44306",rawwar,2025-01-24 04:09:42+00:00,[],2025-01-24 09:32:44+00:00,2025-01-24 09:32:44+00:00,https://github.com/apache/airflow/pull/46001,[],[],
2808445619,pull_request,closed,,[v2-10-test] Fix `FileTaskHandler` only read from default executor,"
closes: #45529
related PR: https://github.com/apache/airflow/pull/45631



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2025-01-24 04:05:03+00:00,[],2025-01-28 11:47:48+00:00,2025-01-26 17:36:45+00:00,https://github.com/apache/airflow/pull/46000,"[('area:logging', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor')]",[],
2808413671,pull_request,closed,,Call `get_current_version` less often in bundle refresh loop,"In the bundle refresh loop, we can call `get_current_version` a lot less often, as 1) we can skip it for bundles that do not support versioning and 2) for those that do, we already know the version from the last time we refreshed!

Since this is a local call, this isn't a huge gain. But every little bit helps.",jedcunningham,2025-01-24 03:30:46+00:00,[],2025-01-27 14:20:00+00:00,2025-01-24 21:10:10+00:00,https://github.com/apache/airflow/pull/45999,"[('area:DAG-processing', ''), ('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2613848267, 'issue_id': 2808413671, 'author': 'potiuk', 'body': 'Hey @jedcunningham -> reverting it temporarily in #46037 as it seem to break main. You should redo it with ""full tests needed"" to double check what\'s going on . It seems theat bundle_model might get None in the test and it could be a side-effect of other test that was not run in the original PR or maybe some other change merged since it succeeded caused it to fail.', 'created_at': datetime.datetime(2025, 1, 25, 8, 50, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614708132, 'issue_id': 2808413671, 'author': 'jedcunningham', 'body': 'Thanks. I\'m pretty close to just adding ""full tests"" on every one of my PRs...', 'created_at': datetime.datetime(2025, 1, 27, 1, 42, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615026371, 'issue_id': 2808413671, 'author': 'potiuk', 'body': '> Thanks. I\'m pretty close to just adding ""full tests"" on every one of my PRs...\r\n\r\nWe are moving fast and breaking things. Actually - until we stabilise thing, maybe it\'s worth to trigger ""full tests"" for all code that touches airlfow and ""task_sdk""?', 'created_at': datetime.datetime(2025, 1, 27, 7, 36, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615888957, 'issue_id': 2808413671, 'author': 'jedcunningham', 'body': ""There are definitely tradeoffs haha. I've probably just been more unlucky than average due to the changes I've been making though.\r\n\r\nGenerally speaking, I'm not held back by test duration though, so a bit more safety for main is a good trade I'd say."", 'created_at': datetime.datetime(2025, 1, 27, 14, 19, 42, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-25 08:50:25 UTC): Hey @jedcunningham -> reverting it temporarily in #46037 as it seem to break main. You should redo it with ""full tests needed"" to double check what's going on . It seems theat bundle_model might get None in the test and it could be a side-effect of other test that was not run in the original PR or maybe some other change merged since it succeeded caused it to fail.

jedcunningham (Issue Creator) on (2025-01-27 01:42:57 UTC): Thanks. I'm pretty close to just adding ""full tests"" on every one of my PRs...

potiuk on (2025-01-27 07:36:41 UTC): We are moving fast and breaking things. Actually - until we stabilise thing, maybe it's worth to trigger ""full tests"" for all code that touches airlfow and ""task_sdk""?

jedcunningham (Issue Creator) on (2025-01-27 14:19:42 UTC): There are definitely tradeoffs haha. I've probably just been more unlucky than average due to the changes I've been making though.

Generally speaking, I'm not held back by test duration though, so a bit more safety for main is a good trade I'd say.

"
2808036934,pull_request,closed,,Fix run task/run clearing,"There were a number of issues with clearing a run or task:

- we were calling PATCH run/task to update the note even if the note didnt change
- we were calling dry run when the button mounted even if the modal was never opened, which on the table of task instances could be 25 different API calls
- we weren't caching any of the dry_runs so we needed a new request any time the user toggled any options


Solution:
- check if the note has changed before adding that mutation
- Make custom hooks to turn the dry run mutations into queries which we can cache
- Pass `enabled: open` to only run the query when the modal is active
- react query allows us to cache dry run results
- Removed `useEffect` which is usually a bad practice
- Also default the accordions to show the affected tasks because thats more relevant for most users
- Updated DataTable to not show pagination when totalEntries === # of rows and the page would only ever be 1

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2025-01-23 22:18:51+00:00,[],2025-01-27 12:54:34+00:00,2025-01-24 16:46:17+00:00,https://github.com/apache/airflow/pull/45987,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2612100843, 'issue_id': 2808036934, 'author': 'pierrejeambrun', 'body': ""Nice idea to transform the dry-run mutation into a react query to replace the `useEffect` (I wasn't convinced by that useEffect either), also benefiting from caching, much more elegant 👍."", 'created_at': datetime.datetime(2025, 1, 24, 9, 49, 40, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2025-01-24 09:49:40 UTC): Nice idea to transform the dry-run mutation into a react query to replace the `useEffect` (I wasn't convinced by that useEffect either), also benefiting from caching, much more elegant 👍.

"
2808017168,pull_request,closed,,Make parameter `user` mandatory for all methods in the auth manager interface,"In Airflow 3 we do not use the session to store the user. Hence, there is no notion of ""current user"". Today, in the auth manager interface, all `is_authorized_*` APIs have the parameter `user` optional. If not provided, the current user is used.

This PR makes the parameter `user` required in all APIs, I also added the parameter in some APIs where it was missing (`batch_is_authorized_*` APIs).

Just one API/method in the auth manager will need some updates on that front as well: `def filter_permitted_menu_items(self, menu_items: list[MenuItem]) -> list[MenuItem]:`. Actually, this API will need multiple updates because:
1. It uses `MenuItem` that is a Flask object, we want to get rid of that
2. User is not part of the list of parameters and it should

This API will be updated in a future PR because I need to sync with the front-end team @bbovenzi and @pierrejeambrun to agree on a signature.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-23 22:04:30+00:00,[],2025-01-27 15:54:58+00:00,2025-01-27 15:48:20+00:00,https://github.com/apache/airflow/pull/45986,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:fab', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2616030299, 'issue_id': 2808017168, 'author': 'vincbeck', 'body': ""> Unrelated to this PR but, ideally we'll want to update the `def get_user` from the simple auth manager I think.\r\n> \r\n> Currently is uses the flask `session` object so we cannot use it in the flask context. We have to manually use the `core_api/security.py` `get_user` function that retrieve the user from the token instead, which is working but being able to use the auth_manager interface is maybe more convenient ?\r\n\r\nThe method `get_user` from the auth manager will be deleted. This is only used in AF2. We could, as you mentioned and similar to the function `get_jwt_token` in the auth manager interface, create a function `get_user_from_token` (or any other name) which basically does what the `get_user` in `core_api/security.py` does. It will be a thin wrapper around `deserialize_user`. I'll create a PR for it"", 'created_at': datetime.datetime(2025, 1, 27, 15, 13, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616140580, 'issue_id': 2808017168, 'author': 'vincbeck', 'body': ""> > Unrelated to this PR but, ideally we'll want to update the `def get_user` from the simple auth manager I think.\r\n> > Currently is uses the flask `session` object so we cannot use it in the flask context. We have to manually use the `core_api/security.py` `get_user` function that retrieve the user from the token instead, which is working but being able to use the auth_manager interface is maybe more convenient ?\r\n> \r\n> The method `get_user` from the auth manager will be deleted. This is only used in AF2. We could, as you mentioned and similar to the function `get_jwt_token` in the auth manager interface, create a function `get_user_from_token` (or any other name) which basically does what the `get_user` in `core_api/security.py` does. It will be a thin wrapper around `deserialize_user`. I'll create a PR for it\r\n\r\n#46135"", 'created_at': datetime.datetime(2025, 1, 27, 15, 54, 57, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2025-01-27 15:13:29 UTC): The method `get_user` from the auth manager will be deleted. This is only used in AF2. We could, as you mentioned and similar to the function `get_jwt_token` in the auth manager interface, create a function `get_user_from_token` (or any other name) which basically does what the `get_user` in `core_api/security.py` does. It will be a thin wrapper around `deserialize_user`. I'll create a PR for it

vincbeck (Issue Creator) on (2025-01-27 15:54:57 UTC): #46135

"
2807993398,pull_request,closed,,Add `consumer_secret` to Salesforce Connection,"Adds `consumer_secret` to `SalesforceHook` / Connection to allow OAuth2 login.
See https://github.com/simple-salesforce/simple-salesforce/pull/764

Does this need tests? It's passing a field directly through to the underlying library 🤔 not sure how to test, other than testing the libraries actual ability to login via this mechanism",fritz-astronomer,2025-01-23 21:51:10+00:00,[],2025-01-29 18:27:46+00:00,2025-01-26 09:34:26+00:00,https://github.com/apache/airflow/pull/45985,"[('area:providers', ''), ('provider:salesforce', '')]","[{'comment_id': 2614296762, 'issue_id': 2807993398, 'author': 'eladkal', 'body': 'Resolved in https://github.com/apache/airflow/pull/45954', 'created_at': datetime.datetime(2025, 1, 26, 9, 34, 26, tzinfo=datetime.timezone.utc)}]","eladkal on (2025-01-26 09:34:26 UTC): Resolved in https://github.com/apache/airflow/pull/45954

"
2807881865,pull_request,closed,,Update contributors_quick_start_gitpod.rst,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Update contributors_quick_start_gitpod.rst  
for development server

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",aditya0yadav,2025-01-23 20:53:03+00:00,[],2025-01-27 12:36:07+00:00,2025-01-26 21:54:34+00:00,https://github.com/apache/airflow/pull/45984,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2614407535, 'issue_id': 2807881865, 'author': 'potiuk', 'body': ""You need to replace single backticks with double ones - it's .rst file not .md"", 'created_at': datetime.datetime(2025, 1, 26, 12, 54, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614538564, 'issue_id': 2807881865, 'author': 'aditya0yadav', 'body': 'sir @potiuk \r\ni fix the issue in my pull request please check out this', 'created_at': datetime.datetime(2025, 1, 26, 18, 26, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-26 12:54:55 UTC): You need to replace single backticks with double ones - it's .rst file not .md

aditya0yadav (Issue Creator) on (2025-01-26 18:26:01 UTC): sir @potiuk 
i fix the issue in my pull request please check out this

"
2807849497,pull_request,closed,,Handle exceptions in GitDagBundle Auth,"The exceptions that are raised during bundle initialization should not break the dag processor.

",ephraimbuddy,2025-01-23 20:33:25+00:00,[],2025-01-27 12:49:50+00:00,2025-01-25 13:32:24+00:00,https://github.com/apache/airflow/pull/45982,"[('type:new-feature', 'Changelog: New Features'), ('area:DAG-processing', '')]",[],
2807756552,pull_request,closed,,Add icons for different slots under list pool page,"related: #43706 

This PR adds icons to all different slots for better identification.

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/7cef4f98-2dbb-4541-ada2-820bb26aac27"" />




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-23 19:38:23+00:00,[],2025-01-27 12:59:33+00:00,2025-01-23 19:50:21+00:00,https://github.com/apache/airflow/pull/45981,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2807707732,pull_request,closed,,Bump vite from 5.4.11 to 5.4.14 in /airflow/auth/managers/simple/ui,"Bumps [vite](https://github.com/vitejs/vite/tree/HEAD/packages/vite) from 5.4.11 to 5.4.14.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/vitejs/vite/releases"">vite's releases</a>.</em></p>
<blockquote>
<h2>v5.4.14</h2>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/v5.4.14/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
<h2>v5.4.13</h2>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/v5.4.13/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
<h2>v5.4.12</h2>
<p>This version contains a breaking change due to security fixes. See <a href=""https://github.com/vitejs/vite/security/advisories/GHSA-vg6x-rcgg-rjx6"">https://github.com/vitejs/vite/security/advisories/GHSA-vg6x-rcgg-rjx6</a> for more details.</p>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/v5.4.12/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/vitejs/vite/blob/v5.4.14/packages/vite/CHANGELOG.md"">vite's changelog</a>.</em></p>
<blockquote>
<h2><!-- raw HTML omitted -->5.4.14 (2025-01-21)<!-- raw HTML omitted --></h2>
<ul>
<li>fix: <code>preview.allowedHosts</code> with specific values was not respected (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/19246"">#19246</a>) (<a href=""https://github.com/vitejs/vite/commit/9df6e6beabf0d18988ec13b8b742d2aba29662f9"">9df6e6b</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/19246"">#19246</a></li>
<li>fix: allow CORS from loopback addresses by default (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/19249"">#19249</a>) (<a href=""https://github.com/vitejs/vite/commit/7d1699ccf673e2790704756d89d2e1e4ee478fb4"">7d1699c</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/19249"">#19249</a></li>
</ul>
<h2><!-- raw HTML omitted -->5.4.13 (2025-01-20)<!-- raw HTML omitted --></h2>
<ul>
<li>fix: try parse <code>server.origin</code> URL (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/19241"">#19241</a>) (<a href=""https://github.com/vitejs/vite/commit/5946215718e369c34f6cc9415391d2ca84efe327"">5946215</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/19241"">#19241</a></li>
</ul>
<h2><!-- raw HTML omitted -->5.4.12 (2025-01-20)<!-- raw HTML omitted --></h2>
<ul>
<li>fix!: check host header to prevent DNS rebinding attacks and introduce <code>server.allowedHosts</code> (<a href=""https://github.com/vitejs/vite/commit/9da4abc8dde7f032ca1f23f425c2060b9b9ebd34"">9da4abc</a>)</li>
<li>fix!: default <code>server.cors: false</code> to disallow fetching from untrusted origins (<a href=""https://github.com/vitejs/vite/commit/dfea38f1ff9f6fc0f0ca57927c527b0b9ffd2210"">dfea38f</a>)</li>
<li>fix: verify token for HMR WebSocket connection (<a href=""https://github.com/vitejs/vite/commit/b71a5c89a1b4b913813ae665e6e04dd9d18c189c"">b71a5c8</a>)</li>
<li>chore: add deps update changelog (<a href=""https://github.com/vitejs/vite/commit/ecd2375460edb4ae258fed4abe6c6f6ed7323b23"">ecd2375</a>)</li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/vitejs/vite/commit/e7eb3c5559e6f7ec6f5ca834c2ff4d680f58e81b""><code>e7eb3c5</code></a> release: v5.4.14</li>
<li><a href=""https://github.com/vitejs/vite/commit/7d1699ccf673e2790704756d89d2e1e4ee478fb4""><code>7d1699c</code></a> fix: allow CORS from loopback addresses by default (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/19249"">#19249</a>)</li>
<li><a href=""https://github.com/vitejs/vite/commit/9df6e6beabf0d18988ec13b8b742d2aba29662f9""><code>9df6e6b</code></a> fix: <code>preview.allowedHosts</code> with specific values was not respected (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/19246"">#19246</a>)</li>
<li><a href=""https://github.com/vitejs/vite/commit/a1824c5ff13578d590176275ac309a0ab48ee5b9""><code>a1824c5</code></a> release: v5.4.13</li>
<li><a href=""https://github.com/vitejs/vite/commit/5946215718e369c34f6cc9415391d2ca84efe327""><code>5946215</code></a> fix: try parse <code>server.origin</code> URL (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/19241"">#19241</a>)</li>
<li><a href=""https://github.com/vitejs/vite/commit/f428aa9af8534b214abb09fe4456653eb09913e7""><code>f428aa9</code></a> release: v5.4.12</li>
<li><a href=""https://github.com/vitejs/vite/commit/9da4abc8dde7f032ca1f23f425c2060b9b9ebd34""><code>9da4abc</code></a> fix!: check host header to prevent DNS rebinding attacks and introduce `serve...</li>
<li><a href=""https://github.com/vitejs/vite/commit/b71a5c89a1b4b913813ae665e6e04dd9d18c189c""><code>b71a5c8</code></a> fix: verify token for HMR WebSocket connection</li>
<li><a href=""https://github.com/vitejs/vite/commit/dfea38f1ff9f6fc0f0ca57927c527b0b9ffd2210""><code>dfea38f</code></a> fix!: default <code>server.cors: false</code> to disallow fetching from untrusted origins</li>
<li><a href=""https://github.com/vitejs/vite/commit/ecd2375460edb4ae258fed4abe6c6f6ed7323b23""><code>ecd2375</code></a> chore: add deps update changelog</li>
<li>See full diff in <a href=""https://github.com/vitejs/vite/commits/v5.4.14/packages/vite"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=vite&package-manager=npm_and_yarn&previous-version=5.4.11&new-version=5.4.14)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2025-01-23 19:10:26+00:00,[],2025-01-27 12:59:02+00:00,2025-01-23 20:01:17+00:00,https://github.com/apache/airflow/pull/45980,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]",[],
2807530800,pull_request,closed,,Invalidate task instance query on marking dagrun state to refetch task instance states.,"Whenever the dagrun is marked as success or failed the corresponding tasks in running or no state will be marked as success or skipped. During clear run the key is invalidated to fetch the updated task state. Similarly on marking the dagrun the key can be used to invalidate the query to fetch updated task states.

https://github.com/apache/airflow/blob/7a28f29842e4fa103466e8b49b2986389862f486/airflow/ui/src/queries/useClearRun.ts#L63-L68",tirkarthi,2025-01-23 17:42:10+00:00,[],2025-02-05 17:35:54+00:00,2025-02-05 17:35:54+00:00,https://github.com/apache/airflow/pull/45977,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2807461027,pull_request,closed,,Add DagBundle information to Serialized DagVersion table,"This will help us keep track of the different versions that we see in DagBundle since DagModel would always have the latest bundle version.

",ephraimbuddy,2025-01-23 17:09:28+00:00,[],2025-01-27 12:49:31+00:00,2025-01-25 13:32:47+00:00,https://github.com/apache/airflow/pull/45976,"[('area:serialization', ''), ('kind:documentation', ''), ('type:new-feature', 'Changelog: New Features'), ('area:db-migrations', 'PRs with DB migration')]",[],
2807368113,pull_request,closed,,K8s log line jarek fix [DO NOT MERGE],"This PR checks that https://github.com/apache/airflow/pull/45964 fixes tests for k8sexecutor
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dimberman,2025-01-23 16:28:21+00:00,[],2025-01-24 18:41:31+00:00,2025-01-24 18:41:30+00:00,https://github.com/apache/airflow/pull/45974,"[('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:celery', ''), ('provider:airbyte', ''), ('provider:apache-iceberg', ''), ('provider:standard', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2610863123, 'issue_id': 2807368113, 'author': 'potiuk', 'body': '@dimberman -> just rebase your commit on top of `main` not my ""move standard providers"" change - that should fix it - and I am working on fixing the failures in ""move standard providers""', 'created_at': datetime.datetime(2025, 1, 23, 19, 39, 22, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-23 19:39:22 UTC): @dimberman -> just rebase your commit on top of `main` not my ""move standard providers"" change - that should fix it - and I am working on fixing the failures in ""move standard providers""

"
2807246423,pull_request,closed,,Add `run_job_kwargs` as templated field in `GlueJobOperator`,closes: https://github.com/apache/airflow/issues/45036,eladkal,2025-01-23 15:40:17+00:00,[],2025-01-27 13:01:20+00:00,2025-01-23 16:36:51+00:00,https://github.com/apache/airflow/pull/45973,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2807114613,pull_request,closed,,Handle Hybrid executors for running task logs,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Using Hybrid executors where one of them is a Kubernetes-based executor (but not the first one) breaks live logs since we only try to fetch k8s pods logs if the default executor happens to be the Kubernetes executor. This PR fixes it.

_Note: it's my first PR and I probably don't have time to set up the whole testing environment. If you consider this change requires thorough testing please FFT to close this and revisit at a further date (just wanted to flag this)_

<!-- Please keep an empty line above the dashes. -->
",dmelchor-stripe,2025-01-23 14:51:27+00:00,[],2025-01-23 16:52:26+00:00,2025-01-23 16:52:25+00:00,https://github.com/apache/airflow/pull/45971,"[('area:logging', '')]","[{'comment_id': 2610017229, 'issue_id': 2807114613, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 23, 14, 51, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610408579, 'issue_id': 2807114613, 'author': 'o-nikolas', 'body': ""We already have an extensively tested and iterated on fix for the same issue here: https://github.com/apache/airflow/pull/45631\r\n\r\nI'll close this one in favour of the existing one. Thanks for the contribution though!"", 'created_at': datetime.datetime(2025, 1, 23, 16, 52, 26, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-23 14:51:33 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

o-nikolas on (2025-01-23 16:52:26 UTC): We already have an extensively tested and iterated on fix for the same issue here: https://github.com/apache/airflow/pull/45631

I'll close this one in favour of the existing one. Thanks for the contribution though!

"
2807027090,pull_request,closed,,Dagrun details page,"Add a details tab similar to task instance details page since the header is missing information like data interval start, data interval end, conf etc. I have ported the `RenderedJsonField` to accept only object with usage limited to `dagrun.conf` which is an object type as per the API. The diff is larger because taskinstance details was using `Run/Details` where run folder is for dagrun related pages. I have moved the taskinstance details code to `TaskInstance/Details` for clarity.

Please let me know if there is a different design for this page.

![image](https://github.com/user-attachments/assets/03f3acdd-bffd-4f81-9c9c-410b5abafc51)
",tirkarthi,2025-01-23 14:16:26+00:00,[],2025-01-27 12:59:54+00:00,2025-01-23 19:42:23+00:00,https://github.com/apache/airflow/pull/45970,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2610614800, 'issue_id': 2807027090, 'author': 'tirkarthi', 'body': ""I would opt for a new tab and not to include it in the task details tab. The rendered templates might need a discussion since the API doesn't return the file extension values and also nested fields as separate which are helpful in syntax highlighting."", 'created_at': datetime.datetime(2025, 1, 23, 18, 11, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610778282, 'issue_id': 2807027090, 'author': 'jscheffl', 'body': ""> I would opt for a new tab and not to include it in the task details tab. The rendered templates might need a discussion since the API doesn't return the file extension values and also nested fields as separate which are helpful in syntax highlighting.\r\n\r\nMakes sense for me. Also if all is on one page then it is quite long and might render slower."", 'created_at': datetime.datetime(2025, 1, 23, 18, 57, 1, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2025-01-23 18:11:08 UTC): I would opt for a new tab and not to include it in the task details tab. The rendered templates might need a discussion since the API doesn't return the file extension values and also nested fields as separate which are helpful in syntax highlighting.

jscheffl on (2025-01-23 18:57:01 UTC): Makes sense for me. Also if all is on one page then it is quite long and might render slower.

"
2806827290,pull_request,closed,,AIP-38 Mark DagRun as failed/success,"Related to: https://github.com/apache/airflow/issues/43712
Allow to mark runs as failed or success both in the:
- DagRun details view
- DagRuns list view


![Screenshot 2025-01-23 at 13 46 55](https://github.com/user-attachments/assets/027facc7-f62d-4768-9db3-b862a97aa8a7)
![Screenshot 2025-01-23 at 13 47 09](https://github.com/user-attachments/assets/80790ea6-1729-4914-863f-7be3e3fa3c22)
![Screenshot 2025-01-23 at 13 47 44](https://github.com/user-attachments/assets/f33e2b02-a8ac-4a07-a66b-fb526d93f2d5)
![Screenshot 2025-01-23 at 13 47 55](https://github.com/user-attachments/assets/f153f11c-f5b1-4ec4-a9a3-ae85011ceb4d)
![Screenshot 2025-01-23 at 13 48 06](https://github.com/user-attachments/assets/8e24aeae-0750-4db2-b3f0-8d8032ff5906)
![Screenshot 2025-01-23 at 13 48 26](https://github.com/user-attachments/assets/e1c22933-fe30-41e8-acb6-be63776b6c95)

",pierrejeambrun,2025-01-23 12:50:04+00:00,['pierrejeambrun'],2025-01-27 13:01:10+00:00,2025-01-23 16:41:09+00:00,https://github.com/apache/airflow/pull/45968,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]",[],
2806808346,pull_request,closed,,remove volumes when performing `breeze cleanup`,This PR adds volume removal to `breeze cleanup` command,rawwar,2025-01-23 12:41:28+00:00,[],2025-01-26 20:42:36+00:00,2025-01-26 20:42:36+00:00,https://github.com/apache/airflow/pull/45967,"[('area:dev-tools', '')]",[],
2806719611,pull_request,closed,,Add asset event source from trigger to extra.,"closes #44944

This is similar to events created through API adding the source info to extra. Recording this information for triggers will also help with UI in https://github.com/apache/airflow/pull/44961

https://github.com/apache/airflow/blob/c77c7f003a2458698a1d5a440670b9728783ff78/airflow/api_connexion/endpoints/asset_endpoint.py#L350",tirkarthi,2025-01-23 11:59:22+00:00,[],2025-01-27 12:54:04+00:00,2025-01-24 18:21:40+00:00,https://github.com/apache/airflow/pull/45965,"[('type:new-feature', 'Changelog: New Features'), ('area:Triggerer', '')]","[{'comment_id': 2613133957, 'issue_id': 2806719611, 'author': 'tirkarthi', 'body': 'Thanks @vincbeck', 'created_at': datetime.datetime(2025, 1, 24, 18, 21, 53, tzinfo=datetime.timezone.utc)}]","tirkarthi (Issue Creator) on (2025-01-24 18:21:53 UTC): Thanks @vincbeck

"
2806666232,pull_request,closed,,"Move standard, alibaba and common.sql provider to the new structure","This one also adds some missing steps in provider migration script. improves the output and instructions and make it more robust for various variations of provider features and usage of imports.

With those changes `standard` provider was 100% moved automatically.

Also common.sql needs to be added in order to migrate standard in
order to build production image.

Alibaba was added accidentally during demo at dev call so we are
committing it as well since it is already migrated.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-23 11:33:20+00:00,[],2025-01-27 12:47:28+00:00,2025-01-25 22:27:19+00:00,https://github.com/apache/airflow/pull/45964,"[('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:standard', '')]","[{'comment_id': 2610024713, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'Got some fixes in :crossed_fingers: . also found a few small things - now IDE integration works nicely with the providers in separate folders (it was broken for a few days for the new providers).', 'created_at': datetime.datetime(2025, 1, 23, 14, 54, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610034175, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'Also found out that `decorators/test_python.py` have not been moved to standards provider when we moved stuff :).\r\n\r\nThis is actually nice thing about this splitting - we will likely find out all the stuff where providers are  still imported from core tests :)', 'created_at': datetime.datetime(2025, 1, 23, 14, 57, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610101521, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'And there are still two things to fix I see :)', 'created_at': datetime.datetime(2025, 1, 23, 15, 22, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610323406, 'issue_id': 2806666232, 'author': 'dimberman', 'body': ""@potiuk I've created a PR here with a minimal k8s fix to ensure that the fix provided will fix our tests too. Thank you for responding quickly!\r\n\r\nhttps://github.com/apache/airflow/pull/45974"", 'created_at': datetime.datetime(2025, 1, 23, 16, 29, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610423204, 'issue_id': 2806666232, 'author': 'dimberman', 'body': ""@potiuk so far I'm seeing the same failures\r\n\r\nhttps://github.com/apache/airflow/actions/runs/12933644386/job/36073123320?pr=45974"", 'created_at': datetime.datetime(2025, 1, 23, 16, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610804387, 'issue_id': 2806666232, 'author': 'potiuk', 'body': ""> @potiuk so far I'm seeing the same failures\r\n> \r\n> https://github.com/apache/airflow/actions/runs/12933644386/job/36073123320?pr=45974\r\n\r\nOn it."", 'created_at': datetime.datetime(2025, 1, 23, 19, 8, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610816562, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'OK. looks like I have to convert common.sql first - to make that one succeed', 'created_at': datetime.datetime(2025, 1, 23, 19, 15, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610858496, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'Seems that easiest way is to :crossed_fingers: migrate common.sql and standard together', 'created_at': datetime.datetime(2025, 1, 23, 19, 36, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610864789, 'issue_id': 2806666232, 'author': 'potiuk', 'body': ""> @potiuk so far I'm seeing the same failures\r\n> \r\n> https://github.com/apache/airflow/actions/runs/12933644386/job/36073123320?pr=45974\r\n\r\nAh - you had the same errors because you rebased on top of my in-progress move standard providers, but if you do it direcly on main now - it should work."", 'created_at': datetime.datetime(2025, 1, 23, 19, 40, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610922769, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'Some more fun to check - but at least the image builds now. I am glad I decided to do it slowly and incrementally ;)', 'created_at': datetime.datetime(2025, 1, 23, 20, 11, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611825142, 'issue_id': 2806666232, 'author': 'dabla', 'body': ""@potiuk shouldn't we move the generic transfer already to the common sql provider here?"", 'created_at': datetime.datetime(2025, 1, 24, 7, 32, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613004981, 'issue_id': 2806666232, 'author': 'potiuk', 'body': ""> @potiuk shouldn't we move the generic transfer already to the common sql provider here?\r\n\r\nI wanted to avoid it to do too many things at the same time."", 'created_at': datetime.datetime(2025, 1, 24, 17, 6, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613152659, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'Hah... Found a few things missing from the previous moves - for example `task_sdk` was still present and installed in our compatibility tests - and started to mess around with pre-airflow-3 versions :).', 'created_at': datetime.datetime(2025, 1, 24, 18, 33, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613250864, 'issue_id': 2806666232, 'author': 'potiuk', 'body': ""I also accidentally added alibaba yesterday during demo :facepalm: ... But since it's already migrated, I will leave it in - updated description and title."", 'created_at': datetime.datetime(2025, 1, 24, 19, 37, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613252396, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'And added few more replacements (logo/ .pre-commit-config.yaml) that could also be automated easliy (standard provider did not have them - but alibaba did).', 'created_at': datetime.datetime(2025, 1, 24, 19, 38, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613683039, 'issue_id': 2806666232, 'author': 'gopidesupavan', 'body': '> Hah... Found a few things missing from the previous moves - for example `task_sdk` was still present and installed in our compatibility tests - and started to mess around with pre-[airflow-3](https://issues.apache.org/jira/browse/AIRFLOW-3) versions :).\r\n\r\noh good catch, thanks Jarek, this move revealing good stuff. :)', 'created_at': datetime.datetime(2025, 1, 25, 0, 54, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613683722, 'issue_id': 2806666232, 'author': 'gopidesupavan', 'body': '> Also found out that `decorators/test_python.py` have not been moved to standards provider when we moved stuff :).\r\n> \r\n> This is actually nice thing about this splitting - we will likely find out all the stuff where providers are still imported from core tests :)\r\n\r\nah i see, yes indeed.', 'created_at': datetime.datetime(2025, 1, 25, 0, 55, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613844232, 'issue_id': 2806666232, 'author': 'potiuk', 'body': '> oh good catch, thanks Jarek, this move revealing good stuff. :)\r\n\r\nYeah. I actually love to do these kinds of refactoring, they usually reval some `dead bodies in the closet` :D', 'created_at': datetime.datetime(2025, 1, 25, 8, 39, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613922104, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'And we need to add `task-sdk` at least for now - until we release it in PyPI - in order to run various provider verification tests as those are run with packages built and installed from sources :).\r\n\r\nAnother step closer to get to the package split - @ashb', 'created_at': datetime.datetime(2025, 1, 25, 10, 40, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614119350, 'issue_id': 2806666232, 'author': 'potiuk', 'body': 'Finally got it green... This single PR allowed me to trace and fix quite a number of small issues we had with moving to the ""providers"" and now to the ""newer providers"" strucuture... Next step will be to launch full-blown migration process :).', 'created_at': datetime.datetime(2025, 1, 25, 22, 27, 15, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-23 14:54:25 UTC): Got some fixes in :crossed_fingers: . also found a few small things - now IDE integration works nicely with the providers in separate folders (it was broken for a few days for the new providers).

potiuk (Issue Creator) on (2025-01-23 14:57:28 UTC): Also found out that `decorators/test_python.py` have not been moved to standards provider when we moved stuff :).

This is actually nice thing about this splitting - we will likely find out all the stuff where providers are  still imported from core tests :)

potiuk (Issue Creator) on (2025-01-23 15:22:33 UTC): And there are still two things to fix I see :)

dimberman on (2025-01-23 16:29:16 UTC): @potiuk I've created a PR here with a minimal k8s fix to ensure that the fix provided will fix our tests too. Thank you for responding quickly!

https://github.com/apache/airflow/pull/45974

dimberman on (2025-01-23 16:59:00 UTC): @potiuk so far I'm seeing the same failures

https://github.com/apache/airflow/actions/runs/12933644386/job/36073123320?pr=45974

potiuk (Issue Creator) on (2025-01-23 19:08:36 UTC): On it.

potiuk (Issue Creator) on (2025-01-23 19:15:17 UTC): OK. looks like I have to convert common.sql first - to make that one succeed

potiuk (Issue Creator) on (2025-01-23 19:36:52 UTC): Seems that easiest way is to :crossed_fingers: migrate common.sql and standard together

potiuk (Issue Creator) on (2025-01-23 19:40:18 UTC): Ah - you had the same errors because you rebased on top of my in-progress move standard providers, but if you do it direcly on main now - it should work.

potiuk (Issue Creator) on (2025-01-23 20:11:18 UTC): Some more fun to check - but at least the image builds now. I am glad I decided to do it slowly and incrementally ;)

dabla on (2025-01-24 07:32:52 UTC): @potiuk shouldn't we move the generic transfer already to the common sql provider here?

potiuk (Issue Creator) on (2025-01-24 17:06:58 UTC): I wanted to avoid it to do too many things at the same time.

potiuk (Issue Creator) on (2025-01-24 18:33:35 UTC): Hah... Found a few things missing from the previous moves - for example `task_sdk` was still present and installed in our compatibility tests - and started to mess around with pre-airflow-3 versions :).

potiuk (Issue Creator) on (2025-01-24 19:37:24 UTC): I also accidentally added alibaba yesterday during demo :facepalm: ... But since it's already migrated, I will leave it in - updated description and title.

potiuk (Issue Creator) on (2025-01-24 19:38:22 UTC): And added few more replacements (logo/ .pre-commit-config.yaml) that could also be automated easliy (standard provider did not have them - but alibaba did).

gopidesupavan on (2025-01-25 00:54:04 UTC): oh good catch, thanks Jarek, this move revealing good stuff. :)

gopidesupavan on (2025-01-25 00:55:16 UTC): ah i see, yes indeed.

potiuk (Issue Creator) on (2025-01-25 08:39:06 UTC): Yeah. I actually love to do these kinds of refactoring, they usually reval some `dead bodies in the closet` :D

potiuk (Issue Creator) on (2025-01-25 10:40:42 UTC): And we need to add `task-sdk` at least for now - until we release it in PyPI - in order to run various provider verification tests as those are run with packages built and installed from sources :).

Another step closer to get to the package split - @ashb

potiuk (Issue Creator) on (2025-01-25 22:27:15 UTC): Finally got it green... This single PR allowed me to trace and fix quite a number of small issues we had with moving to the ""providers"" and now to the ""newer providers"" strucuture... Next step will be to launch full-blown migration process :).

"
2806621972,pull_request,closed,,Fix default json encoder serialization in Task SDK logging,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

When presented with an non-stdlib object the current msgspec JSON encoder used by the Task SDK throws an ugly exception and causes the supervisor to crash. This can happen for example if presented with a Pydantic class such as is used between the supervisor and the API server.

This PR makes a very targeted change to provide the default encoding function to the msgspec encoder if it is supplied.
A test is added to ensure the JSON serialization works when a Pydantic class is supplied.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ianbuss,2025-01-23 11:13:32+00:00,[],2025-01-29 14:35:01+00:00,2025-01-29 09:59:43+00:00,https://github.com/apache/airflow/pull/45962,"[('area:task-sdk', None)]","[{'comment_id': 2621177810, 'issue_id': 2806621972, 'author': 'feluelle', 'body': 'Merging as the failed mypy check is unrelated.', 'created_at': datetime.datetime(2025, 1, 29, 9, 59, 39, tzinfo=datetime.timezone.utc)}]","feluelle on (2025-01-29 09:59:39 UTC): Merging as the failed mypy check is unrelated.

"
2806483097,pull_request,open,,Replace `external_trigger` check with DagRunType,"
closes: #45932 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2025-01-23 10:12:55+00:00,[],2025-02-09 07:42:40+00:00,,https://github.com/apache/airflow/pull/45961,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('provider:openlineage', 'AIP-53'), ('area:db-migrations', 'PRs with DB migration'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2646110394, 'issue_id': 2806483097, 'author': 'jason810496', 'body': 'The only failures are caused by:  \r\n- UI static check  \r\n- Compatibility tests for `2.9.3:P3.9` and `2.10.4:P3.10` providers (likely broken due to the new provider structure?)  \r\n- Flaky test: `TestWorkflowTrigger.test_task_workflow_trigger_skipped`  \r\n\r\nDo we need to fix the compatibility tests, or is this PR ready to be merged?', 'created_at': datetime.datetime(2025, 2, 9, 7, 42, 39, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2025-02-09 07:42:39 UTC): The only failures are caused by:  
- UI static check  
- Compatibility tests for `2.9.3:P3.9` and `2.10.4:P3.10` providers (likely broken due to the new provider structure?)  
- Flaky test: `TestWorkflowTrigger.test_task_workflow_trigger_skipped`  

Do we need to fix the compatibility tests, or is this PR ready to be merged?

"
2806421140,pull_request,open,,feat(task_sdk): add support for inlet_events in Task Context,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2025-01-23 09:45:47+00:00,[],2025-02-04 10:07:36+00:00,,https://github.com/apache/airflow/pull/45960,"[('area:task-sdk', None)]",[],
2806385505,pull_request,closed,,[EDGE]Enable edge worker maintenance mode,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Maintenance mode is enabled for the edge worker. In maintenance mode, the worker is alive, but cannot consume any jobs.
The maintenance mode can be triggered by a button from the edge worker status page. It writes the state ""maintenance request"" directly to the database as worker state. Then the worker will go to maintenance pending if there are running jobs, and maintenance mode if all jobs have finished.

When exiting maintenance mode, maintenance exit is written to the database. Then the worker will switch to running state if it was in state maintenance pending, and to idle if it was in maintenance mode.

![image](https://github.com/user-attachments/assets/47c2b5f4-7f67-40b9-b5f9-0540898fb318)

Why do we need the state maintenance exit?
If the user requested maintenance, so the maintenance request is in the database, and the user wants to exit maintenance immidiately e.g. for misclick, then we will not know if we should write running or idle to the database.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",majorosdonat,2025-01-23 09:30:35+00:00,[],2025-02-05 20:25:56+00:00,2025-02-03 10:26:47+00:00,https://github.com/apache/airflow/pull/45958,"[('area:providers', ''), ('type:new-feature', 'Changelog: New Features'), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2635921884, 'issue_id': 2806385505, 'author': 'eladkal', 'body': '> Then the worker will go to maintenance pending if there are running jobs, and maintenance mode if all jobs have finished.\r\n\r\nThe diagram suggest changing mode depends only on the count of jobs. Is there a way for cluster admin to force entering to mantanince mode? (Force kill all existed jobs)?', 'created_at': datetime.datetime(2025, 2, 5, 7, 31, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2635989996, 'issue_id': 2806385505, 'author': 'majorosdonat', 'body': ""> > Then the worker will go to maintenance pending if there are running jobs, and maintenance mode if all jobs have finished.\r\n> \r\n> The diagram suggest changing mode depends only on the count of jobs. Is there a way for cluster admin to force entering to mantanince mode? (Force kill all existed jobs)?\r\n\r\nThis is no option directly, although it is visible that which jobs are executed by the worker, so they can be killed individually.\r\nKilling the jobs would contradict the reason why maintenance mode was created. In maintenance mode and maintenance pending the worker cannot consume jobs, so maintenance can be done on-site without the worker picking up jobs. If we didn't care about the running jobs, then it would be easier to just delete the worker, but it would cause lot of headaches for the customers."", 'created_at': datetime.datetime(2025, 2, 5, 7, 52, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2637951431, 'issue_id': 2806385505, 'author': 'jscheffl', 'body': '> > Then the worker will go to maintenance pending if there are running jobs, and maintenance mode if all jobs have finished.\r\n> \r\n> The diagram suggest changing mode depends only on the count of jobs. Is there a way for cluster admin to force entering to mantanince mode? (Force kill all existed jobs)?\r\n\r\nI think a force maintenance still could be implemented. If somebody wants/needs this. The intend of the current implementation is a graceful drain of running jobs. The ""pending"" stzate is the transition, same like if you send a SIGINT to a Celery worker, then also the worker does not pull new jobs (stps consuming from queue) but will attempt to complete all jobs and then terminate.\r\n\r\nYeah, if there is a urgent demand (that is how I do during testing to be faster) I check the jobs list page and then find the task in execution and mark as failed/success. Not a single click solution but basically a manual workaround. Not often used by me, just in testing :-D', 'created_at': datetime.datetime(2025, 2, 5, 20, 25, 55, tzinfo=datetime.timezone.utc)}]","eladkal on (2025-02-05 07:31:10 UTC): The diagram suggest changing mode depends only on the count of jobs. Is there a way for cluster admin to force entering to mantanince mode? (Force kill all existed jobs)?

majorosdonat (Issue Creator) on (2025-02-05 07:52:13 UTC): This is no option directly, although it is visible that which jobs are executed by the worker, so they can be killed individually.
Killing the jobs would contradict the reason why maintenance mode was created. In maintenance mode and maintenance pending the worker cannot consume jobs, so maintenance can be done on-site without the worker picking up jobs. If we didn't care about the running jobs, then it would be easier to just delete the worker, but it would cause lot of headaches for the customers.

jscheffl on (2025-02-05 20:25:55 UTC): I think a force maintenance still could be implemented. If somebody wants/needs this. The intend of the current implementation is a graceful drain of running jobs. The ""pending"" stzate is the transition, same like if you send a SIGINT to a Celery worker, then also the worker does not pull new jobs (stps consuming from queue) but will attempt to complete all jobs and then terminate.

Yeah, if there is a urgent demand (that is how I do during testing to be faster) I check the jobs list page and then find the task in execution and mark as failed/success. Not a single click solution but basically a manual workaround. Not often used by me, just in testing :-D

"
2806252095,pull_request,closed,,Make logical date nullable and restore the uniqueness constraint on logical date,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
- Add (back) the unique constraint on logical_date
- Make logical_date nullable
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",sunank200,2025-01-23 08:30:49+00:00,[],2025-01-31 13:48:33+00:00,2025-01-31 13:48:32+00:00,https://github.com/apache/airflow/pull/45956,[],"[{'comment_id': 2627398546, 'issue_id': 2806252095, 'author': 'sunank200', 'body': 'Closing this as it is also being done in [46232/](https://github.com/apache/airflow/pull/46232/)', 'created_at': datetime.datetime(2025, 1, 31, 13, 48, 32, tzinfo=datetime.timezone.utc)}]","sunank200 (Issue Creator) on (2025-01-31 13:48:32 UTC): Closing this as it is also being done in [46232/](https://github.com/apache/airflow/pull/46232/)

"
2806049616,pull_request,closed,,"Move new provider tests to ""provider_tests"" submodule","While testing ""standard"" provider move to the new structure it turned out, that ""providers"" package used now to keep tests in the new providers is problematic - while it solves the ambiguity of ""from celery import"", it introduces another ambiguity when trying to import internal utility classes in tests. For example when trying to import BasePythonTest in standard operatori currently we refer to the import from root directory of Airflow::

```
from providers.tests.standard.operators.test_python
```

However, if we change the package structure to have `providers` as subpackage of `tests` and trying to import it from `tests` as root folder to tests, we have:

```
from providers.standard.operators.test_python
```

And it can ambiguously attempt to import

```
from airflow.providers.standard.operators.test_python
```

This confuses IDEs and attempts to run multiple tests together, because pytest modifies PYTHONPATH while running tests - and PYTHONPATH modification can be different, depending on which tests are selected to run.

Changing the sub-package to provider_tests makes it unambiguous and we can now import:

```
from provider_tests.standard.operators.test_python
```

This is unambiguous and allows to import the tests inside the provider package, without importing from root of Airlfow package - making provider package tests ""standalone"" inside provider.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-23 06:36:08+00:00,[],2025-01-27 13:02:33+00:00,2025-01-23 07:13:12+00:00,https://github.com/apache/airflow/pull/45955,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:celery', ''), ('provider:airbyte', ''), ('provider:apache-iceberg', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2805967252,pull_request,closed,,Implement fetching consumer_secret from Salesforce connection,"This PR introduces a new feature that allows users to retrieve the consumer_secret directly from the Connections service.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kanagaraj-dhanapal-89,2025-01-23 05:38:23+00:00,[],2025-01-27 12:46:30+00:00,2025-01-26 09:34:03+00:00,https://github.com/apache/airflow/pull/45954,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:salesforce', '')]","[{'comment_id': 2608904917, 'issue_id': 2805967252, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 23, 5, 38, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611533173, 'issue_id': 2805967252, 'author': 'kanagaraj-dhanapal-89', 'body': '> Please ammend the commit and PR title with meeaningful description\r\n\r\nDone', 'created_at': datetime.datetime(2025, 1, 24, 4, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611718343, 'issue_id': 2805967252, 'author': 'eladkal', 'body': ""Tests are failing\r\n\r\n```\r\nFAILED providers/tests/salesforce/hooks/test_salesforce.py::TestSalesforceHook::test_get_conn_default_to_none - AssertionError: expected call not found.\r\nExpected: Salesforce(username=None, *** security_token=None, domain=None, session_id=None, instance=None, instance_url=None, organizationId=None, version='59.0', proxies=None, session=None, client_id=None, consumer_key=None, privatekey_file=None, privatekey=None)\r\nActual: Salesforce(username=None, *** security_token=None, domain=None, session_id=None, instance=None, instance_url=None, organizationId=None, version='59.0', proxies=None, session=None, client_id=None, consumer_key=None, consumer_secret=None, privatekey_file=None, privatekey=None)\r\n```"", 'created_at': datetime.datetime(2025, 1, 24, 6, 44, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611764020, 'issue_id': 2805967252, 'author': 'kanagaraj-dhanapal-89', 'body': ""> Tests are failing\r\n> \r\n> ```\r\n> FAILED providers/tests/salesforce/hooks/test_salesforce.py::TestSalesforceHook::test_get_conn_default_to_none - AssertionError: expected call not found.\r\n> Expected: Salesforce(username=None, *** security_token=None, domain=None, session_id=None, instance=None, instance_url=None, organizationId=None, version='59.0', proxies=None, session=None, client_id=None, consumer_key=None, privatekey_file=None, privatekey=None)\r\n> Actual: Salesforce(username=None, *** security_token=None, domain=None, session_id=None, instance=None, instance_url=None, organizationId=None, version='59.0', proxies=None, session=None, client_id=None, consumer_key=None, consumer_secret=None, privatekey_file=None, privatekey=None)\r\n> ```\r\n\r\nchecking"", 'created_at': datetime.datetime(2025, 1, 24, 7, 15, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613702771, 'issue_id': 2805967252, 'author': 'kanagaraj-dhanapal-89', 'body': ""> > Tests are failing\r\n> > ```\r\n> > FAILED providers/tests/salesforce/hooks/test_salesforce.py::TestSalesforceHook::test_get_conn_default_to_none - AssertionError: expected call not found.\r\n> > Expected: Salesforce(username=None, *** security_token=None, domain=None, session_id=None, instance=None, instance_url=None, organizationId=None, version='59.0', proxies=None, session=None, client_id=None, consumer_key=None, privatekey_file=None, privatekey=None)\r\n> > Actual: Salesforce(username=None, *** security_token=None, domain=None, session_id=None, instance=None, instance_url=None, organizationId=None, version='59.0', proxies=None, session=None, client_id=None, consumer_key=None, consumer_secret=None, privatekey_file=None, privatekey=None)\r\n> > ```\r\n> \r\n> checking\r\n\r\nI hope its fixed now, could you please check?"", 'created_at': datetime.datetime(2025, 1, 25, 1, 20, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614218664, 'issue_id': 2805967252, 'author': 'eladkal', 'body': 'Still failing\r\nSee https://github.com/apache/airflow/actions/runs/12970501835/job/36178118560?pr=45954#step:6:8502', 'created_at': datetime.datetime(2025, 1, 26, 5, 27, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614296649, 'issue_id': 2805967252, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 26, 9, 34, 5, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-23 05:38:26 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

kanagaraj-dhanapal-89 (Issue Creator) on (2025-01-24 04:17:00 UTC): Done

eladkal on (2025-01-24 06:44:26 UTC): Tests are failing

```
FAILED providers/tests/salesforce/hooks/test_salesforce.py::TestSalesforceHook::test_get_conn_default_to_none - AssertionError: expected call not found.
Expected: Salesforce(username=None, *** security_token=None, domain=None, session_id=None, instance=None, instance_url=None, organizationId=None, version='59.0', proxies=None, session=None, client_id=None, consumer_key=None, privatekey_file=None, privatekey=None)
Actual: Salesforce(username=None, *** security_token=None, domain=None, session_id=None, instance=None, instance_url=None, organizationId=None, version='59.0', proxies=None, session=None, client_id=None, consumer_key=None, consumer_secret=None, privatekey_file=None, privatekey=None)
```

kanagaraj-dhanapal-89 (Issue Creator) on (2025-01-24 07:15:18 UTC): checking

kanagaraj-dhanapal-89 (Issue Creator) on (2025-01-25 01:20:35 UTC): I hope its fixed now, could you please check?

eladkal on (2025-01-26 05:27:45 UTC): Still failing
See https://github.com/apache/airflow/actions/runs/12970501835/job/36178118560?pr=45954#step:6:8502

boring-cyborg[bot] on (2025-01-26 09:34:05 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2805770036,pull_request,closed,,Move parsing docs out of scheduler page,This moves all the parsing specific stuff out of the scheduler and into the DAG processing page. I did minimal editing on the contents of both - the parsing stuff will certainly need a lot more attention as we start documenting bundles and their impact.,jedcunningham,2025-01-23 02:44:34+00:00,[],2025-01-27 13:03:09+00:00,2025-01-23 05:23:04+00:00,https://github.com/apache/airflow/pull/45953,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only'), ('area:DAG-processing', '')]",[],
2805496031,pull_request,closed,,Bump undici from 5.28.4 to 5.28.5 in /airflow/www,"Bumps [undici](https://github.com/nodejs/undici) from 5.28.4 to 5.28.5.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/nodejs/undici/releases"">undici's releases</a>.</em></p>
<blockquote>
<h2>v5.28.5</h2>
<h1>⚠️ Security Release ⚠️</h1>
<p>Fixes CVE CVE-2025-22150 <a href=""https://github.com/nodejs/undici/security/advisories/GHSA-c76h-2ccp-4975"">https://github.com/nodejs/undici/security/advisories/GHSA-c76h-2ccp-4975</a> (embargoed until 22-01-2025).</p>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/nodejs/undici/compare/v5.28.4...v5.28.5"">https://github.com/nodejs/undici/compare/v5.28.4...v5.28.5</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/nodejs/undici/commit/6139ed2e0c787853243de58ef7c4301b26ca66f2""><code>6139ed2</code></a> Bumped v5.28.5</li>
<li><a href=""https://github.com/nodejs/undici/commit/711e20772764c29f6622ddc937c63b6eefdf07d0""><code>711e207</code></a> Backport of c2d78cd</li>
<li>See full diff in <a href=""https://github.com/nodejs/undici/compare/v5.28.4...v5.28.5"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=undici&package-manager=npm_and_yarn&previous-version=5.28.4&new-version=5.28.5)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2025-01-22 22:45:29+00:00,[],2025-01-27 13:03:54+00:00,2025-01-23 00:01:17+00:00,https://github.com/apache/airflow/pull/45951,"[('area:webserver', 'Webserver related Issues'), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]",[],
2805490939,pull_request,closed,,docs: typo pyproject.toml,,raphaelauv,2025-01-22 22:40:59+00:00,[],2025-01-27 13:03:50+00:00,2025-01-22 23:22:48+00:00,https://github.com/apache/airflow/pull/45950,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2805459530,pull_request,open,,WIP basic ttl demo,"a proof of concept / demo

see task logs for proof that it actually detects old versions

![image](https://github.com/user-attachments/assets/5f731b0f-7a36-463d-bb46-a23fc5668f2f)
",dstandish,2025-01-22 22:15:30+00:00,[],2025-01-23 14:57:25+00:00,,https://github.com/apache/airflow/pull/45949,"[('area:DAG-processing', ''), ('area:task-sdk', None)]",[],
2805311901,pull_request,closed,,Fix transient issue in main,"#45820 was created to disable one flaky test that causes some failures in the CI for times to times. Shamefully .... I added the `@pytest.mark.skip(` to the implementation and not the test ... 😭 . This PR actually skips the test.

Example of error: https://apache-airflow.slack.com/archives/C015SLQF059/p1737578261968529

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-22 20:46:49+00:00,[],2025-01-27 13:03:28+00:00,2025-01-23 02:38:14+00:00,https://github.com/apache/airflow/pull/45947,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2805291497,pull_request,closed,,Add script to move providers to the new directory structure,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-22 20:33:36+00:00,[],2025-01-27 13:04:28+00:00,2025-01-22 22:43:57+00:00,https://github.com/apache/airflow/pull/45945,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2608217817, 'issue_id': 2805291497, 'author': 'potiuk', 'body': ""OK. I have the script that performs 9x% of provider's migration.  There are few small fixes needed in individual providers - like spellchecking fixes, somr inclusive language changes etc. - all should be found by pre-commits. \r\n\r\nAfter merging, I will try it on one or two providers and will ask people to help with migrating the rest."", 'created_at': datetime.datetime(2025, 1, 22, 20, 39, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2608472821, 'issue_id': 2805291497, 'author': 'gopidesupavan', 'body': 'Cool :)', 'created_at': datetime.datetime(2025, 1, 22, 23, 25, 6, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-22 20:39:15 UTC): OK. I have the script that performs 9x% of provider's migration.  There are few small fixes needed in individual providers - like spellchecking fixes, somr inclusive language changes etc. - all should be found by pre-commits. 

After merging, I will try it on one or two providers and will ask people to help with migrating the rest.

gopidesupavan on (2025-01-22 23:25:06 UTC): Cool :)

"
2805244895,pull_request,closed,,Remove redundant blank line in changelog generation for providers,,eladkal,2025-01-22 20:05:34+00:00,[],2025-01-23 03:33:01+00:00,2025-01-22 21:05:55+00:00,https://github.com/apache/airflow/pull/45943,"[('area:dev-tools', '')]",[],
2805240548,pull_request,closed,,Prepare docs for ad hoc release celery provider Jan 2025,,eladkal,2025-01-22 20:03:01+00:00,[],2025-01-27 13:02:20+00:00,2025-01-23 08:31:14+00:00,https://github.com/apache/airflow/pull/45942,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:celery', '')]",[],
2805221431,pull_request,closed,,[v2-10-test] Remove Scarf tracking (#45865),"Backport of https://github.com/apache/airflow/pull/45865 for v2-10-test

After discussions, we have decided to remove Scarf usage tracking for now. We might replace it with Matomo at a later stage.

https://matomo.org/guide/tracking-data/apps-sdks/

Discussion: https://lists.apache.org/thread/bkpn6rc8w1wsd3c29zlolfb8s8r4ldtq

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-22 19:52:02+00:00,[],2025-01-28 11:49:13+00:00,2025-01-22 21:46:18+00:00,https://github.com/apache/airflow/pull/45941,"[('area:CLI', ''), ('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2805132036,pull_request,closed,,Add Bulk API for Pool,"relates: https://github.com/apache/airflow/issues/45601

This Adds bulk api for pools.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-22 19:00:20+00:00,[],2025-01-27 13:00:42+00:00,2025-01-23 17:41:48+00:00,https://github.com/apache/airflow/pull/45939,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2805017228,pull_request,closed,,Improve speed of SSH & SFTP tests,"Before:

> 4 passed, 1 warning in 64.03s (0:01:04)

After:

> 4 passed, 1 warning in 4.60s

To run them:

```
pytest providers/tests/sftp/operators/test_sftp.py::TestSFTPOperator::test_arg_checking providers/tests/ssh/hooks/test_ssh.py::TestSSHHook::test_command_timeout_not_set providers/tests/ssh/hooks/test_ssh.py::TestSSHHook::test_command_timeout_success providers/tests/ssh/hooks/test_ssh.py::TestSSHHook::test_command_timeout_fail
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-22 17:58:33+00:00,[],2025-01-27 13:05:36+00:00,2025-01-22 18:22:28+00:00,https://github.com/apache/airflow/pull/45938,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:ssh', ''), ('provider:sftp', '')]",[],
2804730329,pull_request,closed,,Added support for certificate authentication with MSGraphAsyncOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR adds the ability to use certificate based authentication instead of the classic client_id/client_secret.

Instead of specifying a secret, you can now specify a certificate_data (holding the certificate data as a string) or certificate_path (file path to the certificate) parameter in the connection form UI.

Also added documentation for the MSGraph connection type.

![image](https://github.com/user-attachments/assets/8caa73a5-597b-455b-8360-6701abeff2b7)

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2025-01-22 15:44:22+00:00,[],2025-01-27 12:47:16+00:00,2025-01-26 06:42:02+00:00,https://github.com/apache/airflow/pull/45935,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2804669126,pull_request,closed,,AIP-38 Fix UI following Vite upgrade,"We recently upgraded vite in https://github.com/apache/airflow/pull/45868

Unfortunately [5.4.12](https://github.com/vitejs/vite/blob/v5.4.12/packages/vite/CHANGELOG.md) holds a breaking change that affect us. Straightening the dev server CORS policy making the UI not render.

We allow back any origin to access the vite dev webserver, our code is public so there's not really a point in trying to block that with a more restrictive rule.

## Before
![Screenshot 2025-01-22 at 16 21 36](https://github.com/user-attachments/assets/4e1a314d-dfc2-4630-9b0c-e098d37ae18a)


## After
![Screenshot 2025-01-22 at 16 18 06](https://github.com/user-attachments/assets/cb0886c7-1242-4656-9036-03e945549d40)
",pierrejeambrun,2025-01-22 15:18:41+00:00,['pierrejeambrun'],2025-01-27 13:06:13+00:00,2025-01-22 15:36:59+00:00,https://github.com/apache/airflow/pull/45934,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]","[{'comment_id': 2607543902, 'issue_id': 2804669126, 'author': 'pierrejeambrun', 'body': 'cc: @potiuk (It appears that Vite is a little bit more flexible on semver definition 😂, even if they seem to follow Semver stricktly https://vite.dev/releases)', 'created_at': datetime.datetime(2025, 1, 22, 15, 24, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607630102, 'issue_id': 2804669126, 'author': 'potiuk', 'body': '> cc: @potiuk (It appears that Vite is a little bit more flexible on semver definition 😂, even if they seem to follow Semver stricktly https://vite.dev/releases)\r\n\r\nActually - they are pretty conistent. The change in question is a fix - so it turned out the previous default was wrong and this one is fixing it:\r\n\r\n![image](https://github.com/user-attachments/assets/2d9a8862-2480-4945-adf7-4ead607987f5)\r\n\r\nThis is precisely as I always repeat - pretty much any change is breaking, otherwise it would not be a change. Change == Behaviour change, which means that if you rely on the changed behaviour, it will break your use. But breaking your use does not mean breaking semver, it means that there was some unintentional (usually buggy) behaviour that you relied on which has been classified by the authors are exactly this - unintentional, or even buggy. And they fixed :).\r\n\r\nSo. ... All is good.', 'created_at': datetime.datetime(2025, 1, 22, 15, 58, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607635153, 'issue_id': 2804669126, 'author': 'potiuk', 'body': 'Simply -> Semver does not 100% guarantee that after upgrade to patchlevel version everything will work as it did. If it did, then it means that applying any fix is impossible - because someone could have relied on that thing being broken :)', 'created_at': datetime.datetime(2025, 1, 22, 16, 0, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2608141709, 'issue_id': 2804669126, 'author': 'pierrejeambrun', 'body': ""I agree that's the implicit interface definition. We might rely on a bug. But here most users will have an issue upgrading, and we rely on the default behavior... changing the default is quite impactful IMO. (and that's public interface and not really a buggy one imo just not a secure one)\r\n\r\nIf we extend that logic it means that no interface is stable because any patch/minor level release of any library can be breaking. Then we need to always read all the patchnote of all libraries we upgrade... I don't see the point if we can't guarantee a general sense of stability. I don't expect all users to observe a breaking change after a patch upgrade. (but that's just me I guess)\r\n\r\nAnyway, all good :)"", 'created_at': datetime.datetime(2025, 1, 22, 19, 55, 39, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2025-01-22 15:24:39 UTC): cc: @potiuk (It appears that Vite is a little bit more flexible on semver definition 😂, even if they seem to follow Semver stricktly https://vite.dev/releases)

potiuk on (2025-01-22 15:58:36 UTC): Actually - they are pretty conistent. The change in question is a fix - so it turned out the previous default was wrong and this one is fixing it:

![image](https://github.com/user-attachments/assets/2d9a8862-2480-4945-adf7-4ead607987f5)

This is precisely as I always repeat - pretty much any change is breaking, otherwise it would not be a change. Change == Behaviour change, which means that if you rely on the changed behaviour, it will break your use. But breaking your use does not mean breaking semver, it means that there was some unintentional (usually buggy) behaviour that you relied on which has been classified by the authors are exactly this - unintentional, or even buggy. And they fixed :).

So. ... All is good.

potiuk on (2025-01-22 16:00:32 UTC): Simply -> Semver does not 100% guarantee that after upgrade to patchlevel version everything will work as it did. If it did, then it means that applying any fix is impossible - because someone could have relied on that thing being broken :)

pierrejeambrun (Issue Creator) on (2025-01-22 19:55:39 UTC): I agree that's the implicit interface definition. We might rely on a bug. But here most users will have an issue upgrading, and we rely on the default behavior... changing the default is quite impactful IMO. (and that's public interface and not really a buggy one imo just not a secure one)

If we extend that logic it means that no interface is stable because any patch/minor level release of any library can be breaking. Then we need to always read all the patchnote of all libraries we upgrade... I don't see the point if we can't guarantee a general sense of stability. I don't expect all users to observe a breaking change after a patch upgrade. (but that's just me I guess)

Anyway, all good :)

"
2804339837,pull_request,open,,Add config option [secrets]backends_order,"Introduce a new configuration option for specifying secret backends load order:
```
[secrets]backends_order = custom,environment_variable,metastore
```
The default value represents current behavior, thus nothing will change for existing users.",moiseenkov,2025-01-22 13:03:26+00:00,[],2025-02-06 10:29:00+00:00,,https://github.com/apache/airflow/pull/45931,"[('area:secrets', '')]","[{'comment_id': 2609151622, 'issue_id': 2804339837, 'author': 'moiseenkov', 'body': '@eladkal , please take a look at the updates.', 'created_at': datetime.datetime(2025, 1, 23, 8, 29, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614079156, 'issue_id': 2804339837, 'author': 'potiuk', 'body': 'I was initially against making it configurable, but seeing the simplicity and flexibility, I am in.', 'created_at': datetime.datetime(2025, 1, 25, 19, 46, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614079232, 'issue_id': 2804339837, 'author': 'potiuk', 'body': '@eladkal ?', 'created_at': datetime.datetime(2025, 1, 25, 19, 46, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2639426046, 'issue_id': 2804339837, 'author': 'VladaZakharova', 'body': 'hi there! \r\n@potiuk \r\nCan we merge this one please?', 'created_at': datetime.datetime(2025, 2, 6, 10, 29, tzinfo=datetime.timezone.utc)}]","moiseenkov (Issue Creator) on (2025-01-23 08:29:35 UTC): @eladkal , please take a look at the updates.

potiuk on (2025-01-25 19:46:16 UTC): I was initially against making it configurable, but seeing the simplicity and flexibility, I am in.

potiuk on (2025-01-25 19:46:32 UTC): @eladkal ?

VladaZakharova on (2025-02-06 10:29:00 UTC): hi there! 
@potiuk 
Can we merge this one please?

"
2804194188,pull_request,closed,,Add ui asset compilation to custom build target of Airflow package,"Since we have now also the UI assets builds we should compile them as well.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-22 11:57:11+00:00,[],2025-01-27 13:07:29+00:00,2025-01-22 12:50:45+00:00,https://github.com/apache/airflow/pull/45928,"[('type:misc/internal', 'Changelog: Misc changes that should appear in change log')]","[{'comment_id': 2607061516, 'issue_id': 2804194188, 'author': 'potiuk', 'body': '![image](https://github.com/user-attachments/assets/bae9b60e-3e04-493a-a779-2c44b58c2865)', 'created_at': datetime.datetime(2025, 1, 22, 12, 1, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607166604, 'issue_id': 2804194188, 'author': 'potiuk', 'body': 'Errors not related - they are being worked on in #45917  . Merging', 'created_at': datetime.datetime(2025, 1, 22, 12, 50, 41, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-22 12:01:47 UTC): ![image](https://github.com/user-attachments/assets/bae9b60e-3e04-493a-a779-2c44b58c2865)

potiuk (Issue Creator) on (2025-01-22 12:50:41 UTC): Errors not related - they are being worked on in #45917  . Merging

"
2804185513,pull_request,closed,,Simplify TaskSDK's CommsDecoder interface,"Most of the uses cases of `send_request` are also followed by `get_message` --
so lets do that for users -- this makes it closer to an HTTP request too,
where you send a request and get a request.

Some message types don't have a response, so in order to know if we should
call `get_message` or not we define a ""marker"" class of `NoResponseMessage`,
and if we subclass that then we don't expect, and don't read anything back.

The other option I considered was to have the supervisor always send a message
back (i.e. send an empty line when there is otherwise no response to send) and
have `get_message()` typed to be `ToTask | None`. It felt marginally better to
have `get_message()` typed and behave to always expect a messsage.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2025-01-22 11:52:59+00:00,[],2025-01-22 13:38:10+00:00,2025-01-22 13:37:34+00:00,https://github.com/apache/airflow/pull/45927,"[('area:task-sdk', None)]","[{'comment_id': 2607273340, 'issue_id': 2804185513, 'author': 'ashb', 'body': 'I\'ve changed my mind on this -- we should change everything to always have a resposne, even if that is `{""ok"": true}` so that we can catch and propagate exceptions to the Task code.', 'created_at': datetime.datetime(2025, 1, 22, 13, 37, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607274543, 'issue_id': 2804185513, 'author': 'ashb', 'body': ""I'm parking this change for now and will revisit it for fuller exception handling/propagation."", 'created_at': datetime.datetime(2025, 1, 22, 13, 38, 8, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2025-01-22 13:37:34 UTC): I've changed my mind on this -- we should change everything to always have a resposne, even if that is `{""ok"": true}` so that we can catch and propagate exceptions to the Task code.

ashb (Issue Creator) on (2025-01-22 13:38:08 UTC): I'm parking this change for now and will revisit it for fuller exception handling/propagation.

"
2803964976,pull_request,closed,,AIP-72: Port Registering of Asset Changes to Task SDK on task completion,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


closes: #45752


### Why?
When a task completed (moves into success) state, asset related events for that particular task should be stores into the metadata DB. Currently it is done like this: [airflow/airflow/models/taskinstance.py](https://github.com/apache/airflow/blob/051e617e0d7d0ebb995cb98063709350f279963c/airflow/models/taskinstance.py#L359).

This does a few things:
1. It extracts outlets from the task
2. For every outlet and its asset events, it creates record in the database in various tables:
`asset`
`asset_alias`
`asset_alias_asset`
`asset_alias_asset_event`
`asset_event`
3. The support is not limited to Asset type only, it also works with AssetAliases and refs for Assets like name ref and uri ref.

This behaviour needs to be ported into the task sdk.

### Approach

The idea is to implement this logic in the `patch` ti state endpoint in the execution API server. The reasoning is so that we needn't make an additional API call but when ""finishing"" a task from the task runner, we can send in the relevant details like the task outlets, the outlet events and take care of the rest in `ti_update_state` endpoint.

#### Interface changes
- We have a new payload: `TISuccessStatePayload` to mark a state as success from the task runner in the execution API -> reason being, we do not want to coagulate the `TITerminalStatePayload` with additional information slowing down the API request for no need.
- The structure contains:
`task_outlets`: translates to `ti.task.outlets` at execution time sent from the task runner
`outlet_events`: these are the events for a `outlet` object. For example, for `Assets` it translates to `context[""outlet_events""][Asset Object]`
`asset_type`: we send the type of object (class name) the exeuction API has to deal with. This is to avoid any additional mental gymnastics on the server side to find the kind of object we are dealing with as it will be serialised.

#### Server Side
- In the `ti_update_state` added an additional branch for success state where we call `register_asset_changes` which is a similar function to https://github.com/apache/airflow/blob/051e617e0d7d0ebb995cb98063709350f279963c/airflow/models/taskinstance.py#L359 but adjusted for the execution API.
- This function does a few things: for every `task_outlet`, it registers the events for different types:
1. For Asset, it receives events from the task runner, so it just registers those.
2. For AssetNameRef and AssetUriRef, it find the relevant Asset for those and registers the events.
3. For AssetAlias, it creates a map of number of events to be registered on the basis of unique pairs of `tuple[asset uri, extra]`, and generates events for those by handling some cases. Docs: https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/datasets.html#how-to-use-datasetalias

#### Execution side

##### Task Runner
The task runner runs the task as usual and before finishing, checks for task outlets defined. If task outlets are defined, it populates the `task_outlets`, `outlet_events` and `asset_type` for the outlets present. 

For `Asset`:
1. Populates the `task_outlets` and `outlet_events` as `events[obj]` where `events = context[""outlet_events""]`

For `AssetNameRef` and `AssetUriRef`:
1. Populates the `task_outlets` as needed and populates all the events possible as we cannot access the DB to get the model being referenced

For `AssetAlias`:
We dont care about the `task_outlets`, we only care about the `asset_alias_events`, so those are populated in `outlet_events`

Once this is done, a `SucceedTask` is sent to supervisor.

##### Supervisor
Supervisor starts treating the success state as `STATES_SENT_DIRECTLY` from now. Once it receives a `SuceedTask` message from the task runner, it calls
```
            self.client.task_instances.succeed(
                id=self.id,
                when=msg.end_date,
                task_outlets=msg.task_outlets,
                outlet_events=msg.outlet_events,
                asset_type=msg.asset_type,
            )
```

##### HTTP client in task sdk
Introduced a new method called: `succeed` which will call the `ti_patch_state` api with `TISuccessStatePayload`


### Testing
Using the DAG: https://github.com/apache/airflow/blob/main/airflow/example_dags/example_asset_alias.py

DAGS:
![image](https://github.com/user-attachments/assets/4824e373-6990-428b-bd14-305a5764636c)

#### Non aliases assets

1. Unpause: asset_s3_bucket_consumer and asset_s3_bucket_producer
2. Run the producer dag first:
![image](https://github.com/user-attachments/assets/38333dba-3d8c-4470-a61f-39a881dc5549)

Event: 
```
{""json"":""{\""state\"":\""success\"",\""end_date\"":\""2025-01-22T10:01:24.675957Z\"",\""task_outlets\"":[{\""name\"":\""s3://bucket/my-task\"",\""uri\"":\""s3://bucket/my-task\""}],\""outlet_events\"":[{\""key\"":{\""name\"":\""s3://bucket/my-task\"",\""uri\"":\""s3://bucket/my-task\""},\""extra\"":{},\""asset_alias_events\"":[]}],\""asset_type\"":\""Asset\"",\""type\"":\""SucceedTask\""}\n"",""timestamp"":""2025-01-22T10:01:24.676014"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
```

Consumer DAG also gets triggered:
<img width=""1713"" alt=""image"" src=""https://github.com/user-attachments/assets/01a993f2-b08d-495c-b5ea-7b7f706cdc5c"" />

#### Aliases assets

1. Unpause: asset_alias_example_alias_producer and asset_alias_example_alias_consumer
2. Trigger asset_alias_example_alias_producer dag

<img width=""1713"" alt=""image"" src=""https://github.com/user-attachments/assets/5d93cfa2-ee1c-4a99-8bac-99163fc9bd79"" />

Event:
```
{""json"":""{\""state\"":\""success\"",\""end_date\"":\""2025-01-22T10:05:01.268374Z\"",\""task_outlets\"":[],\""outlet_events\"":[{\""source_alias_name\"":\""example-alias\"",\""dest_asset_key\"":{\""name\"":\""s3://bucket/my-task\"",\""uri\"":\""s3://bucket/my-task\""},\""extra\"":{}}],\""asset_type\"":\""AssetAlias\"",\""type\"":\""SucceedTask\""}\n"",""timestamp"":""2025-01-22T10:05:01.268428"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
```

This triggers two DAGs now: asset_alias_example_alias_consumer and asset_s3_bucket_consumer since the aliased asset was updated

Fails due to `inlet_events` still not being ported:
<img width=""1713"" alt=""image"" src=""https://github.com/user-attachments/assets/ec7d09c6-0e5f-4006-b93f-15a265a4b479"" />


<img width=""1713"" alt=""image"" src=""https://github.com/user-attachments/assets/26833ef5-c564-4517-9757-7c8ec4f8aa5b"" />


<img width=""1708"" alt=""image"" src=""https://github.com/user-attachments/assets/6243c1f8-4da8-466e-a79a-10d702b90799"" />


#### DB level checks
Asset created:
![image](https://github.com/user-attachments/assets/71865be5-80b3-4d6f-9cee-40dad7ec764f)

Asset Alias:
![image](https://github.com/user-attachments/assets/eb447b94-37cf-4279-8c73-d4b34e8b8f5c)

Asset Alias Asset mapping:
![image](https://github.com/user-attachments/assets/9e2d5b58-fa1b-43ed-8f4a-37257d24f323)

Asset event: (first one triggered by asset, second by alias)
![image](https://github.com/user-attachments/assets/1adcd328-336e-4219-8728-35196f418016)

Alias Event mapping:
![image](https://github.com/user-attachments/assets/117739c1-e84d-4528-8cde-0d6118400e75)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-22 10:14:04+00:00,[],2025-01-27 12:56:44+00:00,2025-01-24 06:41:38+00:00,https://github.com/apache/airflow/pull/45924,"[('type:new-feature', 'Changelog: New Features'), ('area:task-sdk', None)]","[{'comment_id': 2606992208, 'issue_id': 2803964976, 'author': 'amoghrajesh', 'body': 'Working on fixing the tests', 'created_at': datetime.datetime(2025, 1, 22, 11, 29, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609087454, 'issue_id': 2803964976, 'author': 'amoghrajesh', 'body': 'With the new changes, tested both for legacy and task sdk DAGs (cc @ashb)\r\n\r\nLegacy Results:\r\n![image](https://github.com/user-attachments/assets/78fbd716-b512-4f74-9d1c-36ef8b183b73)\r\n\r\n\r\nTask SDK Results:\r\n(asset_s3_bucket_producer first 2 failures are unrelated and the failure for asset_alias_example_alias_consumer is because of inlet_events not yet woirking)\r\n![image](https://github.com/user-attachments/assets/5f5b5178-ba07-4566-b1a4-2fe91690dec8)', 'created_at': datetime.datetime(2025, 1, 23, 7, 54, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609212969, 'issue_id': 2803964976, 'author': 'amoghrajesh', 'body': 'Looks like the changes in this PR break some test cases for inlet_events. Looking into it', 'created_at': datetime.datetime(2025, 1, 23, 8, 59, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609282772, 'issue_id': 2803964976, 'author': 'amoghrajesh', 'body': ""Legacy without my changes:\r\n```\r\n2f107d64f771\r\n ▶ Log message source details\r\n[2025-01-23, 09:14:33 UTC] {local_task_job_runner.py:120} ▶ Pre task execution logs\r\n[2025-01-23, 09:14:33 UTC] {logging_mixin.py:212} INFO - AssetEvent(id=2, asset_id=1, extra={}, source_task_id='produce_asset_events_through_asset_alias', source_dag_id='asset_alias_example_alias_producer', source_run_id='manual__2025-01-23T09:14:17.503997+00:00', source_map_index=-1, source_aliases=[AssetAliasModel(name='example-alias')])\r\n[2025-01-23, 09:14:33 UTC] {python.py:198} INFO - Done. Returned value was: None\r\n[2025-01-23, 09:14:33 UTC] {taskinstance.py:331} ▶ Post task execution logs\r\n```\r\n\r\n\r\nLegacy with my changes:\r\n```\r\nae19b24f9ec4\r\n ▶ Log message source details\r\n[2025-01-23, 09:18:54 UTC] {local_task_job_runner.py:120} ▶ Pre task execution logs\r\n[2025-01-23, 09:18:54 UTC] {logging_mixin.py:212} INFO - AssetEvent(id=2, asset_id=1, extra={}, source_task_id='produce_asset_events_through_asset_alias', source_dag_id='asset_alias_example_alias_producer', source_run_id='manual__2025-01-23T09:18:36.263671+00:00', source_map_index=-1, source_aliases=[AssetAliasModel(name='example-alias')])\r\n[2025-01-23, 09:18:54 UTC] {python.py:198} INFO - Done. Returned value was: None\r\n[2025-01-23, 09:18:54 UTC] {taskinstance.py:332} ▶ Post task execution logs\r\n```\r\n\r\nWhich is the same, so likely its a change needed in the test cases."", 'created_at': datetime.datetime(2025, 1, 23, 9, 20, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609303044, 'issue_id': 2803964976, 'author': 'amoghrajesh', 'body': 'Ok I think I figured out the reason for failure, working on a fix', 'created_at': datetime.datetime(2025, 1, 23, 9, 28, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611619373, 'issue_id': 2803964976, 'author': 'amoghrajesh', 'body': 'I will just resolve the conversations with relevant replies, rebase & merge this', 'created_at': datetime.datetime(2025, 1, 24, 5, 16, 16, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2025-01-22 11:29:42 UTC): Working on fixing the tests

amoghrajesh (Issue Creator) on (2025-01-23 07:54:27 UTC): With the new changes, tested both for legacy and task sdk DAGs (cc @ashb)

Legacy Results:
![image](https://github.com/user-attachments/assets/78fbd716-b512-4f74-9d1c-36ef8b183b73)


Task SDK Results:
(asset_s3_bucket_producer first 2 failures are unrelated and the failure for asset_alias_example_alias_consumer is because of inlet_events not yet woirking)
![image](https://github.com/user-attachments/assets/5f5b5178-ba07-4566-b1a4-2fe91690dec8)

amoghrajesh (Issue Creator) on (2025-01-23 08:59:43 UTC): Looks like the changes in this PR break some test cases for inlet_events. Looking into it

amoghrajesh (Issue Creator) on (2025-01-23 09:20:37 UTC): Legacy without my changes:
```
2f107d64f771
 ▶ Log message source details
[2025-01-23, 09:14:33 UTC] {local_task_job_runner.py:120} ▶ Pre task execution logs
[2025-01-23, 09:14:33 UTC] {logging_mixin.py:212} INFO - AssetEvent(id=2, asset_id=1, extra={}, source_task_id='produce_asset_events_through_asset_alias', source_dag_id='asset_alias_example_alias_producer', source_run_id='manual__2025-01-23T09:14:17.503997+00:00', source_map_index=-1, source_aliases=[AssetAliasModel(name='example-alias')])
[2025-01-23, 09:14:33 UTC] {python.py:198} INFO - Done. Returned value was: None
[2025-01-23, 09:14:33 UTC] {taskinstance.py:331} ▶ Post task execution logs
```


Legacy with my changes:
```
ae19b24f9ec4
 ▶ Log message source details
[2025-01-23, 09:18:54 UTC] {local_task_job_runner.py:120} ▶ Pre task execution logs
[2025-01-23, 09:18:54 UTC] {logging_mixin.py:212} INFO - AssetEvent(id=2, asset_id=1, extra={}, source_task_id='produce_asset_events_through_asset_alias', source_dag_id='asset_alias_example_alias_producer', source_run_id='manual__2025-01-23T09:18:36.263671+00:00', source_map_index=-1, source_aliases=[AssetAliasModel(name='example-alias')])
[2025-01-23, 09:18:54 UTC] {python.py:198} INFO - Done. Returned value was: None
[2025-01-23, 09:18:54 UTC] {taskinstance.py:332} ▶ Post task execution logs
```

Which is the same, so likely its a change needed in the test cases.

amoghrajesh (Issue Creator) on (2025-01-23 09:28:43 UTC): Ok I think I figured out the reason for failure, working on a fix

amoghrajesh (Issue Creator) on (2025-01-24 05:16:16 UTC): I will just resolve the conversations with relevant replies, rebase & merge this

"
2803868529,pull_request,closed,,"When Task SDK sources change, we also run provider tests","When Task SDK sources change, provider code is impacted as they are using Task SDK - some tests might fail because of changes there.

Example case: #45917

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-22 09:32:52+00:00,[],2025-01-22 11:56:43+00:00,2025-01-22 10:32:00+00:00,https://github.com/apache/airflow/pull/45921,"[('area:dev-tools', '')]","[{'comment_id': 2606863342, 'issue_id': 2803868529, 'author': 'potiuk', 'body': 'Merging. The failures are unrelated and worked in on in #45917', 'created_at': datetime.datetime(2025, 1, 22, 10, 31, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607050327, 'issue_id': 2803868529, 'author': 'amoghrajesh', 'body': 'Yeah, looks nice!', 'created_at': datetime.datetime(2025, 1, 22, 11, 56, 42, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-22 10:31:56 UTC): Merging. The failures are unrelated and worked in on in #45917

amoghrajesh on (2025-01-22 11:56:42 UTC): Yeah, looks nice!

"
2803821610,pull_request,closed,,[providers-fab/v1-5] Upgrade to FAB 4.5.3 (#45874),"(cherry picked from commit 573cd95db524ea129df55dc36bc12c6081e438d3)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-22 09:12:48+00:00,[],2025-01-22 10:19:18+00:00,2025-01-22 10:19:16+00:00,https://github.com/apache/airflow/pull/45918,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:fab', '')]","[{'comment_id': 2606677695, 'issue_id': 2803821610, 'author': 'potiuk', 'body': 'backport of #45874', 'created_at': datetime.datetime(2025, 1, 22, 9, 13, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606681753, 'issue_id': 2803821610, 'author': 'potiuk', 'body': 'cc: @eladkal Precisely what I was foreseeing. I am glad I ported the ""pull_request_target"" removal before - it would have been so painful to recall all the details now :) (see https://github.com/apache/airflow/pull/45591#issuecomment-2585793226)', 'created_at': datetime.datetime(2025, 1, 22, 9, 15, 26, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-22 09:13:36 UTC): backport of #45874

potiuk (Issue Creator) on (2025-01-22 09:15:26 UTC): cc: @eladkal Precisely what I was foreseeing. I am glad I ported the ""pull_request_target"" removal before - it would have been so painful to recall all the details now :) (see https://github.com/apache/airflow/pull/45591#issuecomment-2585793226)

"
2803819113,pull_request,closed,,Fix failures on main related to DagRun validation,"Some test failures like https://github.com/apache/airflow/actions/runs/12903540392/job/35979200770?pr=45865 were not caught in https://github.com/apache/airflow/pull/45834/

Follow-up of https://github.com/apache/airflow/pull/45834/

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-22 09:11:36+00:00,[],2025-01-27 13:05:55+00:00,2025-01-22 17:01:16+00:00,https://github.com/apache/airflow/pull/45917,"[('area:providers', ''), ('area:logging', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:redis', ''), ('provider:openlineage', 'AIP-53'), ('provider:apache-spark', ''), ('provider:apache-kylin', '')]","[{'comment_id': 2606705706, 'issue_id': 2803819113, 'author': 'potiuk', 'body': 'Yes. I think we should run all provider tests when task_sdk files change. I will add it to selective checks.', 'created_at': datetime.datetime(2025, 1, 22, 9, 25, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606723526, 'issue_id': 2803819113, 'author': 'potiuk', 'body': 'PR for selective checks  to avoid such failures in the future https://github.com/apache/airflow/pull/45921', 'created_at': datetime.datetime(2025, 1, 22, 9, 33, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607640968, 'issue_id': 2803819113, 'author': 'potiuk', 'body': 'ALMOST !', 'created_at': datetime.datetime(2025, 1, 22, 16, 2, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607666613, 'issue_id': 2803819113, 'author': 'kaxil', 'body': '> ALMOST !\r\n\r\nShould be finally fully green 🤞', 'created_at': datetime.datetime(2025, 1, 22, 16, 12, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607770617, 'issue_id': 2803819113, 'author': 'potiuk', 'body': ':crossed_fingers: :crossed_fingers:', 'created_at': datetime.datetime(2025, 1, 22, 16, 55, 4, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-22 09:25:44 UTC): Yes. I think we should run all provider tests when task_sdk files change. I will add it to selective checks.

potiuk on (2025-01-22 09:33:38 UTC): PR for selective checks  to avoid such failures in the future https://github.com/apache/airflow/pull/45921

potiuk on (2025-01-22 16:02:43 UTC): ALMOST !

kaxil (Issue Creator) on (2025-01-22 16:12:41 UTC): Should be finally fully green 🤞

potiuk on (2025-01-22 16:55:04 UTC): :crossed_fingers: :crossed_fingers:

"
2803782637,pull_request,open,,[v2-10-test] Resolve OOM When Reading Large Logs in Webserver,"
related issue: #45079 
related PR: #45129
related discussion on slack: https://apache-airflow.slack.com/archives/CCZRF2U5A/p1736767159693839




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2025-01-22 08:56:26+00:00,[],2025-02-08 12:03:19+00:00,,https://github.com/apache/airflow/pull/45914,"[('area:webserver', 'Webserver related Issues'), ('area:logging', ''), ('area:API', ""Airflow's REST/HTTP API""), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2803487505,pull_request,closed,,Add shortcut key support for search dags.,"The PR adds ""ctrl+k"" as shortcut to open search dags modal in dag details page. The shortcut is similar to Chakra docs and other websites. The shortcut key is added to the button for reference.

![image](https://github.com/user-attachments/assets/b5ede534-ca16-42f6-a63d-ae861eaa7d09)
",tirkarthi,2025-01-22 06:15:56+00:00,[],2025-01-30 20:10:09+00:00,2025-01-30 20:10:08+00:00,https://github.com/apache/airflow/pull/45908,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2803358367,pull_request,closed,,[v2-10-test] Add ready_for_review to workflow pull_request types (#45855),"backport of #45855
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-22 04:39:19+00:00,[],2025-01-22 08:20:26+00:00,2025-01-22 08:20:26+00:00,https://github.com/apache/airflow/pull/45906,"[('area:dev-tools', '')]",[],
2803263481,pull_request,closed,,"Add ""area:DAG-processing"" label to boring-cyborg",,jedcunningham,2025-01-22 03:13:05+00:00,[],2025-01-22 08:36:11+00:00,2025-01-22 08:36:10+00:00,https://github.com/apache/airflow/pull/45893,"[('area:dev-tools', '')]",[],
2803244662,pull_request,closed,,Set up dag file parsing logs with structlog,"This gets the dag file parsing logs working with structlog. This will be further refactored, particularly to make it configurable for end users. But in the meantime, this gets the logs being written again.
",jedcunningham,2025-01-22 02:55:49+00:00,[],2025-01-27 13:04:12+00:00,2025-01-22 23:08:33+00:00,https://github.com/apache/airflow/pull/45888,"[('type:new-feature', 'Changelog: New Features'), ('area:DAG-processing', '')]",[],
2803039467,pull_request,closed,,add log line,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->
Add a log line to test CI/CD
<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dimberman,2025-01-21 23:41:40+00:00,[],2025-01-24 18:41:24+00:00,2025-01-24 18:41:24+00:00,https://github.com/apache/airflow/pull/45876,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]",[],
2803028996,pull_request,closed,,[v2-10-test] Move DAG file processing docs into admin/deployment section (#45873),"This topic is more of admin/deployment than it is a
authoring/scheduler.

(There are a bunch more docs changes necessary, but
I'm going to do it in chunks so it's easier to review.)
(cherry picked from commit 8c93a257030566f2c84360da8ec8f7a8c2aa73b5)

Co-authored-by: Jed Cunningham <66968678+jedcunningham@users.noreply.github.com>",github-actions[bot],2025-01-21 23:32:11+00:00,[],2025-01-21 23:45:16+00:00,2025-01-21 23:45:16+00:00,https://github.com/apache/airflow/pull/45875,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', '')]","[{'comment_id': 2605963689, 'issue_id': 2803028996, 'author': 'jedcunningham', 'body': ""This can't be backported as-is - the standalone dag processor is optional for AF2."", 'created_at': datetime.datetime(2025, 1, 21, 23, 40, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605965671, 'issue_id': 2803028996, 'author': 'jedcunningham', 'body': ""I'd be inclined to leave it as-is for AF2 docs."", 'created_at': datetime.datetime(2025, 1, 21, 23, 42, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605968958, 'issue_id': 2803028996, 'author': 'potiuk', 'body': 'I see. yeah . Makes sense. I was mislead by ""more admindeployment than authoring"" - but yes Airflow 2 backport is likely not needed.', 'created_at': datetime.datetime(2025, 1, 21, 23, 45, 16, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2025-01-21 23:40:10 UTC): This can't be backported as-is - the standalone dag processor is optional for AF2.

jedcunningham on (2025-01-21 23:42:09 UTC): I'd be inclined to leave it as-is for AF2 docs.

potiuk on (2025-01-21 23:45:16 UTC): I see. yeah . Makes sense. I was mislead by ""more admindeployment than authoring"" - but yes Airflow 2 backport is likely not needed.

"
2803000439,pull_request,closed,,Upgrade to FAB 4.5.3,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-21 23:08:20+00:00,[],2025-01-29 16:54:22+00:00,2025-01-22 08:57:18+00:00,https://github.com/apache/airflow/pull/45874,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:fab', ''), ('backport-to-providers-fab/v1-5', '')]","[{'comment_id': 2606643458, 'issue_id': 2803000439, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: providers-fab/v1-5. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12904610913\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>providers-fab/v1-5</td>\n        <td><a href=""https://github.com/apache/airflow/commit/573cd95db524ea129df55dc36bc12c6081e438d3""><img src=\'https://img.shields.io/badge/Commit-573cd95-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 573cd95 providers-fab/v1-5\n```\n\nThis should apply the commit to the providers-fab/v1-5 branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2025, 1, 22, 8, 58, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622137977, 'issue_id': 2803000439, 'author': 'vincbeck', 'body': '@potiuk I am not sure this is possible. We might need to revert this one. Or maybe there is another solution I do not see. This PR introduces a bug in FAB auth manager, if you try to log in with wrong creds, the webserver will crash. The error is `unsupported hash type scrypt`. `scrypt` has been introduced in `werkzeug` in 2.3. Thus we need to set the minimum version of `werkzeug` to 2.3. When I do that, I got some conflict dependencies because `connexion[flask]` depends on `werkzeug < 2.3`. We would need then to upgrade `connexion` to 3, which is another story.\r\n\r\nWDYT?', 'created_at': datetime.datetime(2025, 1, 29, 16, 33, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622190949, 'issue_id': 2803000439, 'author': 'potiuk', 'body': ""Oh that's a big bummer. I will see to it later today or tomorrow"", 'created_at': datetime.datetime(2025, 1, 29, 16, 54, 21, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-22 08:58:07 UTC): ### Backport failed to create: providers-fab/v1-5. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12904610913'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>providers-fab/v1-5</td>
        <td><a href=""https://github.com/apache/airflow/commit/573cd95db524ea129df55dc36bc12c6081e438d3""><img src='https://img.shields.io/badge/Commit-573cd95-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 573cd95 providers-fab/v1-5
```

This should apply the commit to the providers-fab/v1-5 branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

vincbeck on (2025-01-29 16:33:10 UTC): @potiuk I am not sure this is possible. We might need to revert this one. Or maybe there is another solution I do not see. This PR introduces a bug in FAB auth manager, if you try to log in with wrong creds, the webserver will crash. The error is `unsupported hash type scrypt`. `scrypt` has been introduced in `werkzeug` in 2.3. Thus we need to set the minimum version of `werkzeug` to 2.3. When I do that, I got some conflict dependencies because `connexion[flask]` depends on `werkzeug < 2.3`. We would need then to upgrade `connexion` to 3, which is another story.

WDYT?

potiuk (Issue Creator) on (2025-01-29 16:54:21 UTC): Oh that's a big bummer. I will see to it later today or tomorrow

"
2802996683,pull_request,closed,,Move DAG file processing docs into admin/deployment section,"This topic is more of admin/deployment than it is a authoring/scheduler.

(There are a bunch more docs changes necessary, but I'm going to do it in chunks so it's easier to review.)",jedcunningham,2025-01-21 23:05:31+00:00,[],2025-01-27 13:09:56+00:00,2025-01-21 23:31:24+00:00,https://github.com/apache/airflow/pull/45873,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('type:new-feature', 'Changelog: New Features'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2605953847, 'issue_id': 2802996683, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45875""><img src=""https://img.shields.io/badge/PR-45875-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2025, 1, 21, 23, 32, 13, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-21 23:32:13 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45875""><img src=""https://img.shields.io/badge/PR-45875-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2802896794,pull_request,closed,,Test PR for testing workflows,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",karenbraganz,2025-01-21 21:58:38+00:00,[],2025-01-27 15:48:59+00:00,2025-01-27 15:48:59+00:00,https://github.com/apache/airflow/pull/45870,"[('provider:celery', '')]",[],
2802883817,pull_request,closed,,Test PR for testing workflows,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",karenbraganz,2025-01-21 21:50:10+00:00,[],2025-01-21 21:51:43+00:00,2025-01-21 21:51:43+00:00,https://github.com/apache/airflow/pull/45869,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('provider:celery', '')]",[],
2802883520,pull_request,closed,,Bump vite from 5.4.6 to 5.4.12 in /airflow/ui,"Bumps [vite](https://github.com/vitejs/vite/tree/HEAD/packages/vite) from 5.4.6 to 5.4.12.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/vitejs/vite/releases"">vite's releases</a>.</em></p>
<blockquote>
<h2>v5.4.12</h2>
<p>This version contains a breaking change due to security fixes. See <a href=""https://github.com/vitejs/vite/security/advisories/GHSA-vg6x-rcgg-rjx6"">https://github.com/vitejs/vite/security/advisories/GHSA-vg6x-rcgg-rjx6</a> for more details.</p>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/v5.4.12/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
<h2>v5.4.11</h2>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/ecd2375460edb4ae258fed4abe6c6f6ed7323b23/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
<h2>v5.4.10</h2>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/v5.4.10/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
<h2>v5.4.9</h2>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/v5.4.9/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
<h2>v5.4.8</h2>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/v5.4.8/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
<h2>v5.4.7</h2>
<p>Please refer to <a href=""https://github.com/vitejs/vite/blob/v5.4.7/packages/vite/CHANGELOG.md"">CHANGELOG.md</a> for details.</p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/vitejs/vite/blob/v5.4.12/packages/vite/CHANGELOG.md"">vite's changelog</a>.</em></p>
<blockquote>
<h2><!-- raw HTML omitted -->5.4.12 (2025-01-20)<!-- raw HTML omitted --></h2>
<ul>
<li>fix!: check host header to prevent DNS rebinding attacks and introduce <code>server.allowedHosts</code> (<a href=""https://github.com/vitejs/vite/commit/9da4abc8dde7f032ca1f23f425c2060b9b9ebd34"">9da4abc</a>)</li>
<li>fix!: default <code>server.cors: false</code> to disallow fetching from untrusted origins (<a href=""https://github.com/vitejs/vite/commit/dfea38f1ff9f6fc0f0ca57927c527b0b9ffd2210"">dfea38f</a>)</li>
<li>fix: verify token for HMR WebSocket connection (<a href=""https://github.com/vitejs/vite/commit/b71a5c89a1b4b913813ae665e6e04dd9d18c189c"">b71a5c8</a>)</li>
<li>chore: add deps update changelog (<a href=""https://github.com/vitejs/vite/commit/ecd2375460edb4ae258fed4abe6c6f6ed7323b23"">ecd2375</a>)</li>
</ul>
<h2><!-- raw HTML omitted -->5.4.11 (2024-11-11)<!-- raw HTML omitted --></h2>
<ul>
<li>fix(deps): update dependencies of postcss-modules (<a href=""https://github.com/vitejs/vite/commit/ceb15db613d107e29f7cc1d441364f7b5c831ed3"">ceb15db</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18617"">#18617</a></li>
</ul>
<h2><!-- raw HTML omitted -->5.4.10 (2024-10-23)<!-- raw HTML omitted --></h2>
<ul>
<li>fix: backport <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18367"">#18367</a>,augment hash for CSS files to prevent chromium erroring by loading previous fil (<a href=""https://github.com/vitejs/vite/commit/7d1a3bcc436e1697b314bdc9d24c948664a1afb7"">7d1a3bc</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18367"">#18367</a> <a href=""https://redirect.github.com/vitejs/vite/issues/18412"">#18412</a></li>
</ul>
<h2><!-- raw HTML omitted -->5.4.9 (2024-10-14)<!-- raw HTML omitted --></h2>
<ul>
<li>fix: bump launch-editor-middleware to v2.9.1 (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18348"">#18348</a>) (<a href=""https://github.com/vitejs/vite/commit/508d9ab83412c36e33f4c4ca57b891171429cdd3"">508d9ab</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18348"">#18348</a></li>
<li>fix(css): fix lightningcss dep url resolution with custom root (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18125"">#18125</a>) (<a href=""https://github.com/vitejs/vite/commit/eae00b561e04f1fe1679d3acf4f88b3c42019e4d"">eae00b5</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18125"">#18125</a></li>
<li>fix(data-uri): only match ids starting with <code>data:</code> (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18241"">#18241</a>) (<a href=""https://github.com/vitejs/vite/commit/96084d6e752c03332d101a50bce161a8e3f311cc"">96084d6</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18241"">#18241</a></li>
<li>fix(deps): bump tsconfck (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18322"">#18322</a>) (<a href=""https://github.com/vitejs/vite/commit/dc5434ce8781d206bcc4b55e90201691125e662c"">dc5434c</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18322"">#18322</a></li>
<li>fix(hmr): don't try to rewrite imports for direct CSS soft invalidation (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18252"">#18252</a>) (<a href=""https://github.com/vitejs/vite/commit/851b258c346fdddd4467a12f41189b7855df8c43"">851b258</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18252"">#18252</a></li>
<li>fix(ssr): (backport <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18150"">#18150</a>) fix source map remapping with multiple sources (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18204"">#18204</a>) (<a href=""https://github.com/vitejs/vite/commit/262a8796d4be2c4b9c812f203ea9177f42360b13"">262a879</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18204"">#18204</a></li>
<li>chore: update all url references of vitejs.dev to vite.dev (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18276"">#18276</a>) (<a href=""https://github.com/vitejs/vite/commit/c23558a7af341d13f0c9da691047713965bc7e7d"">c23558a</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18276"">#18276</a></li>
<li>chore: update license copyright (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18278"">#18278</a>) (<a href=""https://github.com/vitejs/vite/commit/1864eb17b21ef21564bd66c6f6a30c2c495e2d4e"">1864eb1</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18278"">#18278</a></li>
<li>docs: update homepage (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18274"">#18274</a>) (<a href=""https://github.com/vitejs/vite/commit/ae4416349e1a373023d0e9e05955d96ae5fa9ab2"">ae44163</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18274"">#18274</a></li>
</ul>
<h2><!-- raw HTML omitted -->5.4.8 (2024-09-25)<!-- raw HTML omitted --></h2>
<ul>
<li>fix(css): backport <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18113"">#18113</a>, fix missing source file warning with sass modern api custom importer (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18"">#18</a> (<a href=""https://github.com/vitejs/vite/commit/7d47fc1c749053095a3345ca1d47406a5f31792a"">7d47fc1</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18183"">#18183</a></li>
<li>fix(css): backport <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18128"">#18128</a>, ensure sass compiler initialized only once (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18184"">#18184</a>) (<a href=""https://github.com/vitejs/vite/commit/8464d976b1d9280ed915622c0e7477b36bdb7d8c"">8464d97</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18128"">#18128</a> <a href=""https://redirect.github.com/vitejs/vite/issues/18184"">#18184</a></li>
</ul>
<h2><!-- raw HTML omitted -->5.4.7 (2024-09-20)<!-- raw HTML omitted --></h2>
<ul>
<li>fix: treat config file as ESM in Deno (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18158"">#18158</a>) (<a href=""https://github.com/vitejs/vite/commit/b5908a24ba0808380e3c8ec415624b108c65e08d"">b5908a2</a>), closes <a href=""https://redirect.github.com/vitejs/vite/issues/18158"">#18158</a></li>
</ul>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/vitejs/vite/commit/f428aa9af8534b214abb09fe4456653eb09913e7""><code>f428aa9</code></a> release: v5.4.12</li>
<li><a href=""https://github.com/vitejs/vite/commit/9da4abc8dde7f032ca1f23f425c2060b9b9ebd34""><code>9da4abc</code></a> fix!: check host header to prevent DNS rebinding attacks and introduce `serve...</li>
<li><a href=""https://github.com/vitejs/vite/commit/b71a5c89a1b4b913813ae665e6e04dd9d18c189c""><code>b71a5c8</code></a> fix: verify token for HMR WebSocket connection</li>
<li><a href=""https://github.com/vitejs/vite/commit/dfea38f1ff9f6fc0f0ca57927c527b0b9ffd2210""><code>dfea38f</code></a> fix!: default <code>server.cors: false</code> to disallow fetching from untrusted origins</li>
<li><a href=""https://github.com/vitejs/vite/commit/ecd2375460edb4ae258fed4abe6c6f6ed7323b23""><code>ecd2375</code></a> chore: add deps update changelog</li>
<li><a href=""https://github.com/vitejs/vite/commit/c54c860f9d90e4074e5321648f9c5ee9fbda7038""><code>c54c860</code></a> release: v5.4.11</li>
<li><a href=""https://github.com/vitejs/vite/commit/5f52bc8b9e4090cdcaf3f704278db30dafc825cc""><code>5f52bc8</code></a> release: v5.4.10</li>
<li><a href=""https://github.com/vitejs/vite/commit/7d1a3bcc436e1697b314bdc9d24c948664a1afb7""><code>7d1a3bc</code></a> fix: backport <a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18367"">#18367</a>,augment hash for CSS files to prevent chromium erroring ...</li>
<li><a href=""https://github.com/vitejs/vite/commit/898d61f94b4316993963f593644821aae221d375""><code>898d61f</code></a> release: v5.4.9</li>
<li><a href=""https://github.com/vitejs/vite/commit/508d9ab83412c36e33f4c4ca57b891171429cdd3""><code>508d9ab</code></a> fix: bump launch-editor-middleware to v2.9.1 (<a href=""https://github.com/vitejs/vite/tree/HEAD/packages/vite/issues/18348"">#18348</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/vitejs/vite/commits/v5.4.12/packages/vite"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=vite&package-manager=npm_and_yarn&previous-version=5.4.6&new-version=5.4.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/apache/airflow/network/alerts).

</details>",dependabot[bot],2025-01-21 21:49:58+00:00,[],2025-01-27 13:10:30+00:00,2025-01-21 22:50:44+00:00,https://github.com/apache/airflow/pull/45868,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('area:dependencies', 'Issues related to dependencies problems'), ('javascript', 'Pull requests that update Javascript code')]",[],
2802830548,pull_request,closed,,Remove Scarf tracking,"After discussions, we have decided to remove Scarf usage tracking for now. We might replace it with Matomo at a later stage.

https://matomo.org/guide/tracking-data/apps-sdks/

Discussion: https://lists.apache.org/thread/bkpn6rc8w1wsd3c29zlolfb8s8r4ldtq

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-21 21:17:48+00:00,[],2025-01-27 13:04:52+00:00,2025-01-22 19:24:51+00:00,https://github.com/apache/airflow/pull/45865,"[('area:CLI', ''), ('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2608086993, 'issue_id': 2802830548, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12915570558\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/70a8a8a9c3696e7a63aad5a0c11bbc4d8578faa9""><img src=\'https://img.shields.io/badge/Commit-70a8a8a-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 70a8a8a v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2025, 1, 22, 19, 25, 46, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-22 19:25:46 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12915570558'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/70a8a8a9c3696e7a63aad5a0c11bbc4d8578faa9""><img src='https://img.shields.io/badge/Commit-70a8a8a-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 70a8a8a v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2802787320,pull_request,closed,,Allow passing empty labels in the spark kubernetes driver config,"""labels"" section of the k8s yaml configuration is optional for both [kubernetes client](https://github.com/kubernetes-client/python/blob/e93f240759935f37465ee5bd61e279bae143ea4a/kubernetes/client/models/v1_object_meta.py#L108C9-L108C31) and [spark-operator](https://github.com/kubeflow/spark-operator/blob/master/docs/api-docs.md). However, if labels are not passed as part of the configuration then the job fails with the following exception:

```python
[2025-01-21, 18:10:50 UTC] {custom_object_launcher.py:312} ERROR - Exception when attempting to create spark job
Traceback (most recent call last):
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/cncf/kubernetes/operators/custom_object_launcher.py"", line 294, in start_spark_job
    labels=self.spark_obj_spec[""spec""][""driver""][""labels""],
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
KeyError: 'labels'
[2025-01-21, 18:10:50 UTC] {taskinstance.py:3311} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py"", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py"", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py"", line 422, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/cncf/kubernetes/operators/spark_kubernetes.py"", line 302, in execute
    self.pod = self.get_or_create_spark_crd(self.launcher, context)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/cncf/kubernetes/operators/spark_kubernetes.py"", line 258, in get_or_create_spark_crd
    driver_pod, spark_obj_spec = launcher.start_spark_job(
                                 ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py"", line 336, in wrapped_f
    return copy(f, *args, **kw)
           ^^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py"", line 475, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py"", line 376, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py"", line 398, in <lambda>
    self._add_action_func(lambda rs: rs.outcome.result())
                                     ^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/concurrent/futures/_base.py"", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/lib/python3.12/concurrent/futures/_base.py"", line 401, in __get_result
    raise self._exception
  File ""/home/airflow/.local/lib/python3.12/site-packages/tenacity/__init__.py"", line 478, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/cncf/kubernetes/operators/custom_object_launcher.py"", line 313, in start_spark_job
    raise e
  File ""/home/airflow/.local/lib/python3.12/site-packages/airflow/providers/cncf/kubernetes/operators/custom_object_launcher.py"", line 294, in start_spark_job
    labels=self.spark_obj_spec[""spec""][""driver""][""labels""],
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^
KeyError: 'labels'
```

Proposed fix is just to use `get` method, which instead of KeyError would return `None`, which should be perfectly fine for the `V1ObjectMeta` object.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",logarithm,2025-01-21 20:52:04+00:00,[],2025-02-06 14:31:15+00:00,2025-02-06 12:36:45+00:00,https://github.com/apache/airflow/pull/45864,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2605714215, 'issue_id': 2802787320, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 21, 20, 52, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614106108, 'issue_id': 2802787320, 'author': 'potiuk', 'body': 'Can you please add a unit test showing the issue and preventing regression in the future? Thanks in advance!', 'created_at': datetime.datetime(2025, 1, 25, 21, 30, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622970523, 'issue_id': 2802787320, 'author': 'logarithm', 'body': ""@potiuk - sure, I'll work on it in the next few days and update the PR. Thank you for taking a look!"", 'created_at': datetime.datetime(2025, 1, 29, 22, 8, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2626028063, 'issue_id': 2802787320, 'author': 'logarithm', 'body': '@potiuk - I looked at the code and how it can be unit-tested, and this is more challenging than I thought at first.\r\n\r\nInside the `start_spark_job` it calls `create_namespaced_custom_object` from the `custom_obj_api`, which makes a call to kubernetes API and returns the response object (simple dictionary).\r\n\r\nThe best option to implement the unit test was to mock the response of the `custom_object_api.create_namespaced_custom_object`.\r\n\r\n@potiuk - please let me know if this is what would be a good enough test or if you have any other options in mind. Thank you for your review in advance!', 'created_at': datetime.datetime(2025, 1, 31, 0, 41, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2634813603, 'issue_id': 2802787320, 'author': 'logarithm', 'body': '@potiuk @hussein-awala @jedcunningham - hey everyone,\r\n\r\nAppreciate you taking time to review this MR. Could you please take a look whenever you have time so that we can merge this simple change and include it into the next version of airflow release if possible. Thank you in advance!', 'created_at': datetime.datetime(2025, 2, 4, 18, 58, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2639711504, 'issue_id': 2802787320, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 2, 6, 12, 36, 47, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-21 20:52:08 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2025-01-25 21:30:54 UTC): Can you please add a unit test showing the issue and preventing regression in the future? Thanks in advance!

logarithm (Issue Creator) on (2025-01-29 22:08:50 UTC): @potiuk - sure, I'll work on it in the next few days and update the PR. Thank you for taking a look!

logarithm (Issue Creator) on (2025-01-31 00:41:09 UTC): @potiuk - I looked at the code and how it can be unit-tested, and this is more challenging than I thought at first.

Inside the `start_spark_job` it calls `create_namespaced_custom_object` from the `custom_obj_api`, which makes a call to kubernetes API and returns the response object (simple dictionary).

The best option to implement the unit test was to mock the response of the `custom_object_api.create_namespaced_custom_object`.

@potiuk - please let me know if this is what would be a good enough test or if you have any other options in mind. Thank you for your review in advance!

logarithm (Issue Creator) on (2025-02-04 18:58:59 UTC): @potiuk @hussein-awala @jedcunningham - hey everyone,

Appreciate you taking time to review this MR. Could you please take a look whenever you have time so that we can merge this simple change and include it into the next version of airflow release if possible. Thank you in advance!

boring-cyborg[bot] on (2025-02-06 12:36:47 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2802718609,pull_request,closed,,fix documentation brokerUrl secret name,Update `airflow-brokerUrl` to `airflow-broker-url`.,chrisluedtke,2025-01-21 20:11:51+00:00,[],2025-01-21 21:57:32+00:00,2025-01-21 21:56:53+00:00,https://github.com/apache/airflow/pull/45863,"[('area:helm-chart', 'Airflow Helm Chart'), ('kind:documentation', '')]","[{'comment_id': 2605821811, 'issue_id': 2802718609, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 21, 21, 56, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605822737, 'issue_id': 2802718609, 'author': 'jedcunningham', 'body': 'Thanks @chrisluedtke! Congrats on your first commit 🎉', 'created_at': datetime.datetime(2025, 1, 21, 21, 57, 31, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-21 21:56:55 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

jedcunningham on (2025-01-21 21:57:31 UTC): Thanks @chrisluedtke! Congrats on your first commit 🎉

"
2802716456,pull_request,closed,,"Deprecate methods `is_logged_in`, `get_user` and `get_url_logout` from base auth manager","Today the auth manager is used both in the Flask application (Airflow 2 UI) and the Fastapi application (Airflow 3 UI). We introduced some methods in the interface that were needed for Airflow 3 use cases while keeping some that are only needed for Airflow 2.

Nevertheless, the auth manager interface `base_auth_manager` should deprecate and not make abstract the methods only needed in Airflow 2. When Airflow 3 is released, if a user wants to implement a custom auth manager, they should not have to implement methods specific to Airflow 2.

I deprecate them and not remove them because the auth manager is still used in Airflow 2. We will be able to delete them when the legacy UI is gone. Some other methods from the auth manager interface might be deprecated/deleted later but since they are not abstract, that will not be a breaking change. 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-21 20:10:34+00:00,[],2025-01-27 15:08:05+00:00,2025-01-27 15:01:32+00:00,https://github.com/apache/airflow/pull/45862,"[('kind:documentation', '')]","[{'comment_id': 2607474065, 'issue_id': 2802716456, 'author': 'vincbeck', 'body': '> Are these just not used _yet_, or they will never be used in AF3? Naively these seem like the former.\r\n\r\nNop, it is the latter. They should never be used in AF3.', 'created_at': datetime.datetime(2025, 1, 22, 14, 58, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615998445, 'issue_id': 2802716456, 'author': 'vincbeck', 'body': ""I'll close this one actually. I realize it will be easier to do the cleanup after the legacy UI is removed. Once the legacy UI removed, I'll be able to remove unused methods in the auth manager interface. Doing beforehand does not add value.\r\n\r\nAlso, I dont think emitting deprecation warnings is necessary. Deprecation warnings are useful for DAG authors, they can anticipate breaking changes by reading the deprecation warnings and fix them. The auth manager interface is not used by DAG authors but by deployment managers/developers. It is expected from there to read the changelog to figure what breaking changes have been introduced in the auth manager interface."", 'created_at': datetime.datetime(2025, 1, 27, 15, 1, 32, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2025-01-22 14:58:13 UTC): Nop, it is the latter. They should never be used in AF3.

vincbeck (Issue Creator) on (2025-01-27 15:01:32 UTC): I'll close this one actually. I realize it will be easier to do the cleanup after the legacy UI is removed. Once the legacy UI removed, I'll be able to remove unused methods in the auth manager interface. Doing beforehand does not add value.

Also, I dont think emitting deprecation warnings is necessary. Deprecation warnings are useful for DAG authors, they can anticipate breaking changes by reading the deprecation warnings and fix them. The auth manager interface is not used by DAG authors but by deployment managers/developers. It is expected from there to read the changelog to figure what breaking changes have been introduced in the auth manager interface.

"
2802604698,pull_request,closed,,AIP-66: Make DAG callbacks bundle aware,"This involves using relative paths in the callbacks, resolving the full path and using it to queue the callback in the file processor process.

Closes: https://github.com/apache/airflow/issues/45496

",ephraimbuddy,2025-01-21 19:06:27+00:00,[],2025-02-04 01:44:09+00:00,2025-02-04 01:44:07+00:00,https://github.com/apache/airflow/pull/45860,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2802590136,pull_request,closed,,Wait before exiting in `FileTrigger`,"In the current implementation of FileTrigger, the trigger fires and exits immediately upon detecting the file. This behavior works well in Airflow 2 because triggers are exclusively used for deferrable operators, which are designed to fire only once (as the trigger is deleted after firing).

In Airflow 3, however, triggers are also used to schedule DAGs based on events, and in this context, triggers are long-running, remaining active even after firing. For `FileTrigger`, this creates a scenario where multiple events can be sent simultaneously because the trigger exits immediately after detecting the file. Pausing before exiting gives some breathing room between checks (and potentially give some time for other system to delete the file to avoid other DAG executions).

This has no consequence for deferrable operators. The trigger will just leave `self.poke_interval` seconds more in the triggerer. Since it is an async operation, there is no harm.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-21 18:58:24+00:00,[],2025-01-28 17:30:47+00:00,2025-01-27 22:09:00+00:00,https://github.com/apache/airflow/pull/45859,"[('area:providers', ''), ('area:Triggerer', ''), ('provider:standard', '')]","[{'comment_id': 2616762078, 'issue_id': 2802590136, 'author': 'vincbeck', 'body': ""> Just to be sure I'm groking the issue and goal of this PR. In the context of event based scheduling, we're trying to give time for the mechanism which is waiting for the file to exist to then remove it or move it before it triggers the workflow again? Otherwise we can fall into a tight loop of firing the trigger repeatedly?\r\n\r\nYou got it right :)"", 'created_at': datetime.datetime(2025, 1, 27, 19, 55, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2617001131, 'issue_id': 2802590136, 'author': 'vincbeck', 'body': 'Closing this one in favor of https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1737999509008529.', 'created_at': datetime.datetime(2025, 1, 27, 22, 8, 59, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2025-01-27 19:55:27 UTC): You got it right :)

vincbeck (Issue Creator) on (2025-01-27 22:08:59 UTC): Closing this one in favor of https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1737999509008529.

"
2802482801,pull_request,closed,,Add ready_for_review to workflow pull_request types,"We have added draft config option for backport automation, which creates pr in draft state. When we sets to ready for review the workflow needs to be triggered but it requires ready_for_review type.

We have see this today in https://github.com/apache/airflow/pull/45826 , workflow not triggered, due to ready_for_review type missing.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-21 17:58:13+00:00,[],2025-01-22 08:20:51+00:00,2025-01-21 21:48:28+00:00,https://github.com/apache/airflow/pull/45855,"[('area:dev-tools', '')]","[{'comment_id': 2605960497, 'issue_id': 2802482801, 'author': 'potiuk', 'body': 'Hmmm... did not help in https://github.com/apache/airflow/pull/45875. I had to close/reopen it to run the workflows :(', 'created_at': datetime.datetime(2025, 1, 21, 23, 37, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606253690, 'issue_id': 2802482801, 'author': 'gopidesupavan', 'body': 'I think this changes also required in v2-10-test branch ?', 'created_at': datetime.datetime(2025, 1, 22, 4, 17, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606255111, 'issue_id': 2802482801, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12901085908\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/dabb6635070466c51490257d6b706107b9c775d3""><img src=\'https://img.shields.io/badge/Commit-dabb663-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker dabb663 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2025, 1, 22, 4, 18, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606569443, 'issue_id': 2802482801, 'author': 'potiuk', 'body': ""Likely :). Let's see."", 'created_at': datetime.datetime(2025, 1, 22, 8, 20, 50, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-21 23:37:28 UTC): Hmmm... did not help in https://github.com/apache/airflow/pull/45875. I had to close/reopen it to run the workflows :(

gopidesupavan (Issue Creator) on (2025-01-22 04:17:03 UTC): I think this changes also required in v2-10-test branch ?

github-actions[bot] on (2025-01-22 04:18:41 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12901085908'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/dabb6635070466c51490257d6b706107b9c775d3""><img src='https://img.shields.io/badge/Commit-dabb663-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker dabb663 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

potiuk on (2025-01-22 08:20:50 UTC): Likely :). Let's see.

"
2802394907,pull_request,closed,,Bump openlineage-airflow from 1.26.0 to 1.27.0,"Bumps openlineage-airflow from 1.26.0 to 1.27.0.


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=openlineage-airflow&package-manager=pip&previous-version=1.26.0&new-version=1.27.0)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2025-01-21 17:12:37+00:00,[],2025-01-27 13:10:46+00:00,2025-01-21 22:18:51+00:00,https://github.com/apache/airflow/pull/45851,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:dependencies', 'Issues related to dependencies problems')]",[],
2802344042,pull_request,closed,,Do not print content of loaded toml file from new providers in CI,"When running breeze in CI we run it with VERBOSE=""true"". We print the content of the loaded pyproject.toml provider when read via verbose command and that pollutes the CI logs.

This PR will only print content of such pyproject.toml when there is a decode error (which was the main reason for this printing).

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-21 16:48:16+00:00,[],2025-01-21 22:34:13+00:00,2025-01-21 22:34:12+00:00,https://github.com/apache/airflow/pull/45848,"[('area:dev-tools', '')]",[],
2802307461,pull_request,closed,,Use consistent field names between render tests,"Template field rendering tests for expand() and expand_kwargs() use the same field names to test different things. Although both tests on their own are correct, the field naming is confusing when you read both tests side by side.

This changes the field names to be more specific, so different things are always tested with different names.",uranusjr,2025-01-21 16:31:15+00:00,[],2025-01-22 05:29:43+00:00,2025-01-22 05:29:41+00:00,https://github.com/apache/airflow/pull/45843,[],[],
2802118514,pull_request,open,,Add deferrable mode to the PubSubPullOperator,"Add deferrable mode to the `PubSubPullOperator`
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",molcay,2025-01-21 15:11:34+00:00,[],2025-02-07 14:47:52+00:00,,https://github.com/apache/airflow/pull/45835,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2628929927, 'issue_id': 2802118514, 'author': 'potiuk', 'body': 'We are about to migrate Google to the new provider structure, so you will have to rebase your change with the moved files and fix the problems there.', 'created_at': datetime.datetime(2025, 2, 1, 12, 16, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2638180632, 'issue_id': 2802118514, 'author': 'potiuk', 'body': 'Migrated. You should rebase @molcay', 'created_at': datetime.datetime(2025, 2, 5, 22, 27, 25, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-02-01 12:16:29 UTC): We are about to migrate Google to the new provider structure, so you will have to rebase your change with the moved files and fix the problems there.

potiuk on (2025-02-05 22:27:25 UTC): Migrated. You should rebase @molcay

"
2802067772,pull_request,closed,,Use Task SDK's Context dict in `models/taskinstance.py`,"This PR re-uses the Context dict from the Task SDK in `models/taskinstance.py`.

Once, CeleryExecutor & KubernetesExecutor are ported over to Task SDK, we can remove all of this code. This PR unifies some of that code.

This also uncovered flawed logic where a Task/TI is in running state but DagRun is in Queued or None state!!!

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-21 14:51:00+00:00,[],2025-01-27 13:09:09+00:00,2025-01-22 07:32:40+00:00,https://github.com/apache/airflow/pull/45834,"[('area:dev-tools', ''), ('type:new-feature', 'Changelog: New Features'), ('area:task-sdk', None)]","[{'comment_id': 2606489177, 'issue_id': 2802067772, 'author': 'kaxil', 'body': '>Yeah changes look good. Can we add TODO in taskinstance.py for the parts that we want to undo once Celery / K8s executors are integrated?\r\n\r\nMost of that file we get nuked :)', 'created_at': datetime.datetime(2025, 1, 22, 7, 32, 30, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2025-01-22 07:32:30 UTC): Most of that file we get nuked :)

"
2801813218,pull_request,closed,,AIP-38 TI and DagRun note rendering in headers,"Update how TI and DagRun note are rendered in the different pages.

Reworked the DocumentationMarkdown component to be able to reuse it for notes.

### Before
![Screenshot 2025-01-21 at 14 09 28](https://github.com/user-attachments/assets/b99bd759-38b7-4fd8-bd80-1970a822a7da)
![Screenshot 2025-01-21 at 14 09 44](https://github.com/user-attachments/assets/398e161f-5967-4f84-a5d7-738324a65b31)

### After:
![Screenshot 2025-01-21 at 14 08 02](https://github.com/user-attachments/assets/5e0a8662-986a-4d6b-85ef-dc15fb25aefb)
![Screenshot 2025-01-21 at 14 09 07](https://github.com/user-attachments/assets/1513ebf1-ce90-44fd-8dd6-03f045d1b008)


### Dag and Task Documentation remains unchanged.
![Screenshot 2025-01-21 at 14 07 31](https://github.com/user-attachments/assets/ec43d6d9-2e97-4685-86e9-4cf03866afdb)
![Screenshot 2025-01-21 at 14 07 48](https://github.com/user-attachments/assets/f069f450-e042-4211-8b88-d77ea5b8df6c)
",pierrejeambrun,2025-01-21 13:10:20+00:00,['pierrejeambrun'],2025-01-22 10:25:54+00:00,2025-01-21 23:46:20+00:00,https://github.com/apache/airflow/pull/45829,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]","[{'comment_id': 2606261980, 'issue_id': 2801813218, 'author': 'tirkarthi', 'body': 'Thanks, this should resolve https://github.com/apache/airflow/issues/45216', 'created_at': datetime.datetime(2025, 1, 22, 4, 21, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606847578, 'issue_id': 2801813218, 'author': 'pierrejeambrun', 'body': ""Indeed, thanks @tirkarthi, I wan't aware of that issue."", 'created_at': datetime.datetime(2025, 1, 22, 10, 25, 2, tzinfo=datetime.timezone.utc)}]","tirkarthi on (2025-01-22 04:21:30 UTC): Thanks, this should resolve https://github.com/apache/airflow/issues/45216

pierrejeambrun (Issue Creator) on (2025-01-22 10:25:02 UTC): Indeed, thanks @tirkarthi, I wan't aware of that issue.

"
2801647499,pull_request,closed,,Remove breakpoint in airflow/models/dagrun.py,"We missed it in the PR!

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-21 12:03:52+00:00,[],2025-01-21 13:46:49+00:00,2025-01-21 13:46:49+00:00,https://github.com/apache/airflow/pull/45828,[],"[{'comment_id': 2604783750, 'issue_id': 2801647499, 'author': 'potiuk', 'body': '😱 \r\n🙀', 'created_at': datetime.datetime(2025, 1, 21, 13, 46, 46, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-21 13:46:46 UTC): 😱 
🙀

"
2801625465,pull_request,closed,,Fix test file name,"`task_sdk/tests/definitions/test_minxins.py` -> `task_sdk/tests/definitions/test_mixins.py`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-21 11:55:17+00:00,[],2025-01-21 13:46:18+00:00,2025-01-21 13:46:18+00:00,https://github.com/apache/airflow/pull/45827,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:task-sdk', None)]",[],
2801527483,pull_request,closed,,[v2-10-test] Improve speed of tests by not creating connections at parse time (#45690),"The DAG serialization tests load all of the example and system test DAGs, and
there were two places that these tests opened connections at parse time
resulting in loads of extra of test time.

- The SystemTestContextBuilder was trying to fetch things from SSM. This was
  addressed by adding a functools.cache on the function
- The Bedrock example dag was setting/caching the underlying conn object
  globally. This was addressed by making the Airflow connection a global,
  rather than the Bedrock conn. This fix is not _great_, but it does massively
  help

Before:

> 111 passed, 1 warning in 439.37s (0:07:19)

After:

> 111 passed, 1 warning in 71.76s (0:01:11)
(cherry picked from commit 102e853)

Co-authored-by: Ash Berlin-Taylor <ash@apache.org>",github-actions[bot],2025-01-21 11:23:11+00:00,[],2025-01-21 12:24:42+00:00,2025-01-21 12:15:51+00:00,https://github.com/apache/airflow/pull/45826,"[('area:system-tests', '')]",[],
2801328381,pull_request,closed,,Fix directory name for `task_sdk/tests/definitions`,"`defintions` -> `definitions`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-21 10:10:57+00:00,[],2025-01-21 11:49:48+00:00,2025-01-21 11:49:46+00:00,https://github.com/apache/airflow/pull/45825,"[('area:task-sdk', None)]",[],
2801311549,pull_request,closed,,Get `skipmixin` working temporarily,"`SKIPMIXIN` will be overhauled as part of https://github.com/apache/airflow/issues/45823 - to refactor DB usage. This PR makes it work temporarily until we get to that task.

<img width=""1698"" alt=""image"" src=""https://github.com/user-attachments/assets/648803ee-89ef-465a-80dd-4151017f4237"" />


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-21 10:04:09+00:00,[],2025-01-21 12:22:39+00:00,2025-01-21 12:22:36+00:00,https://github.com/apache/airflow/pull/45824,[],[],
2800714783,pull_request,closed,,Added Appier to the list of companies using Apache Airflow,Added Appier to the list of companies using Apache Airflow,nailo2c,2025-01-21 05:07:39+00:00,[],2025-01-21 05:37:02+00:00,2025-01-21 05:36:58+00:00,https://github.com/apache/airflow/pull/45822,[],"[{'comment_id': 2603667618, 'issue_id': 2800714783, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 21, 5, 7, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603699468, 'issue_id': 2800714783, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 21, 5, 37, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-21 05:07:43 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2025-01-21 05:37:00 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2800402092,pull_request,closed,,AIP-38 Fix clear mapped task with a note,"Clearing a mapped task instance while updating the `note` would fail. We were not providing the mapIndex in the request.

## Before
![Screenshot 2025-01-21 at 00 20 16](https://github.com/user-attachments/assets/c2edd22f-6299-4242-8044-72e522a6cc8d)

## After
![Screenshot 2025-01-21 at 00 18 34](https://github.com/user-attachments/assets/348896e5-7bdc-4541-8d32-c21d7fc19dd7)
",pierrejeambrun,2025-01-20 23:20:37+00:00,['pierrejeambrun'],2025-01-21 09:40:23+00:00,2025-01-21 09:40:02+00:00,https://github.com/apache/airflow/pull/45821,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2800353788,pull_request,closed,,Disable test because of flakyness,"Resolves #45818.

This test will be removed soon because the compatibility of Simple auth manager with Flask will be removed soon (after #45696 is merged). In the meantime, disabling it.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-20 22:25:22+00:00,[],2025-01-20 22:44:48+00:00,2025-01-20 22:43:57+00:00,https://github.com/apache/airflow/pull/45820,[],[],
2800349706,pull_request,closed,,Fail if rebuilding image fails,"We did not check if image building succeeded when ""y"" was chosen as answer to ""do you want to rebuild the image"".

Adding missing return code will make the command that triggered it to fail.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-20 22:20:59+00:00,[],2025-01-20 22:31:40+00:00,2025-01-20 22:31:38+00:00,https://github.com/apache/airflow/pull/45819,"[('area:dev-tools', '')]",[],
2800319213,pull_request,closed,,Make test_handle_stuck_queued_tasks_multiple_attempts less flaky,"This test - very rarely - fails in CI because it did not order the log events. Ordering by id should fix the flakiness.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-20 21:50:47+00:00,[],2025-01-20 22:31:54+00:00,2025-01-20 22:31:53+00:00,https://github.com/apache/airflow/pull/45817,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2800236645,pull_request,closed,,Bring back mypy checks for new-structure providers,"The providers moved to the news structure have not been chedked by mypy checks when run in ""canary"" or ""full tests needed"" builds. This change adds possibility to pass multiple folders to mypy check and adds special ""all_new_providers"" special argument that gets automatically resolved to all new provider folders.

Also few mypy checks started to appear and they are fixed now.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-20 20:37:52+00:00,[],2025-01-20 21:45:04+00:00,2025-01-20 21:45:02+00:00,https://github.com/apache/airflow/pull/45815,"[('area:dev-tools', '')]","[{'comment_id': 2603266145, 'issue_id': 2800236645, 'author': 'potiuk', 'body': 'Moar teething issues :)', 'created_at': datetime.datetime(2025, 1, 20, 21, 42, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603268171, 'issue_id': 2800236645, 'author': 'potiuk', 'body': 'Nice: \r\n\r\n\r\n<img width=""1556"" alt=""Screenshot 2025-01-20 at 22 44 25"" src=""https://github.com/user-attachments/assets/5adca2ac-124a-4d43-befd-572f494d09fb"" />', 'created_at': datetime.datetime(2025, 1, 20, 21, 44, 40, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-20 21:42:34 UTC): Moar teething issues :)

potiuk (Issue Creator) on (2025-01-20 21:44:40 UTC): Nice: 


<img width=""1556"" alt=""Screenshot 2025-01-20 at 22 44 25"" src=""https://github.com/user-attachments/assets/5adca2ac-124a-4d43-befd-572f494d09fb"" />

"
2800228372,pull_request,closed,,AIP-72: Get Previous Successful Dag Run in Task Context,"closes https://github.com/apache/airflow/issues/45814

Adds following keys to the Task Context:

- prev_data_interval_start_success
- prev_data_interval_end_success
- prev_start_date_success
- prev_end_date_success

<img width=""1688"" alt=""image"" src=""https://github.com/user-attachments/assets/cae09659-bd80-4821-b98c-3c67ce6f9571"" />

<img width=""1707"" alt=""image"" src=""https://github.com/user-attachments/assets/4df84c0e-301d-4fe4-b857-188696381787"" />


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-20 20:31:01+00:00,[],2025-01-21 05:44:27+00:00,2025-01-21 05:44:25+00:00,https://github.com/apache/airflow/pull/45813,"[('area:task-sdk', None)]",[],
2800114285,pull_request,closed,,Add `endpoint_prefix` to `LivyHook`,"adding endpoint_prefix to allow for accessing livy that is behind a reverse proxy and not available on the root path of the server

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gpathak128,2025-01-20 19:00:36+00:00,[],2025-02-01 01:23:50+00:00,2025-02-01 01:23:47+00:00,https://github.com/apache/airflow/pull/45811,"[('area:providers', ''), ('provider:apache-livy', '')]","[{'comment_id': 2603083493, 'issue_id': 2800114285, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 20, 19, 0, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613348037, 'issue_id': 2800114285, 'author': 'gpathak128', 'body': 'yeah looks like a few formatting changes.', 'created_at': datetime.datetime(2025, 1, 24, 20, 43, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614208469, 'issue_id': 2800114285, 'author': 'Lee-W', 'body': '> yeah looks like a few formatting changes.\r\n\r\nYep, would be nice if we can take care of it. Thanks!', 'created_at': datetime.datetime(2025, 1, 26, 4, 38, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622672992, 'issue_id': 2800114285, 'author': 'gpathak128', 'body': 'Re-based the PR against main. Should make this PR merge-able after the tests run.', 'created_at': datetime.datetime(2025, 1, 29, 19, 38, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2624513799, 'issue_id': 2800114285, 'author': 'gpathak128', 'body': 'post re-base some core tests are failing. all the provider tests pass.  im stuck on how to fix this.', 'created_at': datetime.datetime(2025, 1, 30, 13, 26, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627683660, 'issue_id': 2800114285, 'author': 'gpathak128', 'body': '@Lee-W  looks like this is good to go :)', 'created_at': datetime.datetime(2025, 1, 31, 15, 58, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2628660551, 'issue_id': 2800114285, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 2, 1, 1, 23, 50, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-20 19:00:41 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

gpathak128 (Issue Creator) on (2025-01-24 20:43:50 UTC): yeah looks like a few formatting changes.

Lee-W on (2025-01-26 04:38:21 UTC): Yep, would be nice if we can take care of it. Thanks!

gpathak128 (Issue Creator) on (2025-01-29 19:38:51 UTC): Re-based the PR against main. Should make this PR merge-able after the tests run.

gpathak128 (Issue Creator) on (2025-01-30 13:26:10 UTC): post re-base some core tests are failing. all the provider tests pass.  im stuck on how to fix this.

gpathak128 (Issue Creator) on (2025-01-31 15:58:26 UTC): @Lee-W  looks like this is good to go :)

boring-cyborg[bot] on (2025-02-01 01:23:50 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2800071273,pull_request,closed,,Export selected variables on variables list page,"Relates: [#43709](https://github.com/apache/airflow/issues/43709)

Export selected variables on variables list page as variables.json

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/a894c834-e065-4622-96ef-c8045f2f429a"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-20 18:29:33+00:00,[],2025-01-21 01:38:55+00:00,2025-01-20 22:54:44+00:00,https://github.com/apache/airflow/pull/45810,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2603456144, 'issue_id': 2800071273, 'author': 'shubhamraj-git', 'body': '@jscheffl I thought the same, maybe we can introduce import/export with description, with an option to also perform the old way.', 'created_at': datetime.datetime(2025, 1, 21, 1, 38, 54, tzinfo=datetime.timezone.utc)}]","shubhamraj-git (Issue Creator) on (2025-01-21 01:38:54 UTC): @jscheffl I thought the same, maybe we can introduce import/export with description, with an option to also perform the old way.

"
2800057775,pull_request,closed,,Move apache.iceberg provider to new providers structure,"This also add the feature of managing devel-dependencies via dependency groups in pyproject.toml and adjust tests to cover case where providers can be two levels deeper.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-20 18:19:25+00:00,[],2025-01-27 13:11:03+00:00,2025-01-21 16:26:54+00:00,https://github.com/apache/airflow/pull/45809,"[('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:apache-iceberg', '')]","[{'comment_id': 2603326225, 'issue_id': 2800057775, 'author': 'potiuk', 'body': 'Did I say I love 💔  sphinx .... ?', 'created_at': datetime.datetime(2025, 1, 20, 22, 50, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605064025, 'issue_id': 2800057775, 'author': 'potiuk', 'body': 'OK. I think I got to an agreement with Sphinx finally 🤞 ...\r\n\r\nI also moved ""example_dags"" (i.e. system tests) from `tests.system.providers.<provider_id>` to `tests.system.<provider_id>`. I realized that `tests.system.` packages were previously exposed via inventory - and if there are any cross-providers references in the documentation, that would break the documentation links cross-providers. And we do not really need that extra ""providers"" package in the middle.\r\n\r\nI moved the `airbyte` system tests back as well in this change.\r\n\r\nThis is the current `apache.iceberg` provider\'s inventory:\r\n\r\n```\r\nroot@986a47c0f1f9:/opt/airflow/docs/_inventory_cache# python3 -m sphinx.ext.intersphinx apache-airflow-providers-apache-iceberg/objects.inv\r\npy:attribute\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_id                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_id\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_name_attr                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_name_attr\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_type                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_type\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.default_conn_name                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.default_conn_name\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.hook_name                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.hook_name\r\npy:class\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook\r\npy:data\r\n    airflow.providers.apache.iceberg.__version__                                         : _api/airflow/providers/apache/iceberg/index.html#airflow.providers.apache.iceberg.__version__\r\n    airflow.providers.apache.iceberg.hooks.iceberg.TOKENS_ENDPOINT                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.TOKENS_ENDPOINT\r\n    tests.system.apache.iceberg.example_iceberg.bash_command                                         : _api/tests/system/apache/iceberg/example_iceberg/index.html#tests.system.apache.iceberg.example_iceberg.bash_command\r\n    tests.system.apache.iceberg.example_iceberg.test_run                                         : _api/tests/system/apache/iceberg/example_iceberg/index.html#tests.system.apache.iceberg.example_iceberg.test_run\r\npy:method\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_conn                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_conn\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_token_macro                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_token_macro\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_ui_field_behaviour                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_ui_field_behaviour\r\n    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.test_connection                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.test_connection\r\npy:module\r\n    airflow.providers.apache.iceberg                                                 : _api/airflow/providers/apache/iceberg/index.html#module-airflow.providers.apache.iceberg\r\n    airflow.providers.apache.iceberg.hooks                                           : _api/airflow/providers/apache/iceberg/hooks/index.html#module-airflow.providers.apache.iceberg.hooks\r\n    airflow.providers.apache.iceberg.hooks.iceberg                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#module-airflow.providers.apache.iceberg.hooks.iceberg\r\n    tests.system.apache.iceberg                                                      : _api/tests/system/apache/iceberg/index.html#module-tests.system.apache.iceberg\r\n    tests.system.apache.iceberg.example_iceberg                                         : _api/tests/system/apache/iceberg/example_iceberg/index.html#module-tests.system.apache.iceberg.example_iceberg\r\nstd:doc\r\n    _api/airflow/providers/apache/iceberg/hooks/iceberg/index airflow.providers.apache.iceberg.hooks.iceberg: _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html\r\n    _api/airflow/providers/apache/iceberg/hooks/index airflow.providers.apache.iceberg.hooks  : _api/airflow/providers/apache/iceberg/hooks/index.html\r\n    _api/airflow/providers/apache/iceberg/index airflow.providers.apache.iceberg        : _api/airflow/providers/apache/iceberg/index.html\r\n    _api/tests/system/apache/iceberg/example_iceberg/index tests.system.apache.iceberg.example_iceberg: _api/tests/system/apache/iceberg/example_iceberg/index.html\r\n    _api/tests/system/apache/iceberg/index   tests.system.apache.iceberg             : _api/tests/system/apache/iceberg/index.html\r\n    changelog                                Changelog                               : changelog.html\r\n    commits                                  Package apache-airflow-providers-apache-iceberg: commits.html\r\n    connections                              Connecting to Iceberg                   : connections.html\r\n    index                                    apache-airflow-providers-apache-iceberg : index.html\r\n    installing-providers-from-sources        Installing from sources                 : installing-providers-from-sources.html\r\n    security                                 Releasing security patches              : security.html\r\nstd:label\r\n    genindex                                 Index                                   : genindex.html\r\n    howto/connection:iceberg                 Connecting to Iceberg                   : connections.html#howto-connection-iceberg\r\n    modindex                                 Module Index                            : py-modindex.html\r\n    py-modindex                              Python Module Index                     : py-modindex.html\r\n    search                                   Search Page                             : search.html\r\n```', 'created_at': datetime.datetime(2025, 1, 21, 15, 35, 32, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-20 22:50:03 UTC): Did I say I love 💔  sphinx .... ?

potiuk (Issue Creator) on (2025-01-21 15:35:32 UTC): OK. I think I got to an agreement with Sphinx finally 🤞 ...

I also moved ""example_dags"" (i.e. system tests) from `tests.system.providers.<provider_id>` to `tests.system.<provider_id>`. I realized that `tests.system.` packages were previously exposed via inventory - and if there are any cross-providers references in the documentation, that would break the documentation links cross-providers. And we do not really need that extra ""providers"" package in the middle.

I moved the `airbyte` system tests back as well in this change.

This is the current `apache.iceberg` provider's inventory:

```
root@986a47c0f1f9:/opt/airflow/docs/_inventory_cache# python3 -m sphinx.ext.intersphinx apache-airflow-providers-apache-iceberg/objects.inv
py:attribute
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_id                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_id
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_name_attr                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_name_attr
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_type                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.conn_type
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.default_conn_name                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.default_conn_name
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.hook_name                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.hook_name
py:class
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook
py:data
    airflow.providers.apache.iceberg.__version__                                         : _api/airflow/providers/apache/iceberg/index.html#airflow.providers.apache.iceberg.__version__
    airflow.providers.apache.iceberg.hooks.iceberg.TOKENS_ENDPOINT                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.TOKENS_ENDPOINT
    tests.system.apache.iceberg.example_iceberg.bash_command                                         : _api/tests/system/apache/iceberg/example_iceberg/index.html#tests.system.apache.iceberg.example_iceberg.bash_command
    tests.system.apache.iceberg.example_iceberg.test_run                                         : _api/tests/system/apache/iceberg/example_iceberg/index.html#tests.system.apache.iceberg.example_iceberg.test_run
py:method
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_conn                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_conn
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_token_macro                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_token_macro
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_ui_field_behaviour                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.get_ui_field_behaviour
    airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.test_connection                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#airflow.providers.apache.iceberg.hooks.iceberg.IcebergHook.test_connection
py:module
    airflow.providers.apache.iceberg                                                 : _api/airflow/providers/apache/iceberg/index.html#module-airflow.providers.apache.iceberg
    airflow.providers.apache.iceberg.hooks                                           : _api/airflow/providers/apache/iceberg/hooks/index.html#module-airflow.providers.apache.iceberg.hooks
    airflow.providers.apache.iceberg.hooks.iceberg                                         : _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html#module-airflow.providers.apache.iceberg.hooks.iceberg
    tests.system.apache.iceberg                                                      : _api/tests/system/apache/iceberg/index.html#module-tests.system.apache.iceberg
    tests.system.apache.iceberg.example_iceberg                                         : _api/tests/system/apache/iceberg/example_iceberg/index.html#module-tests.system.apache.iceberg.example_iceberg
std:doc
    _api/airflow/providers/apache/iceberg/hooks/iceberg/index airflow.providers.apache.iceberg.hooks.iceberg: _api/airflow/providers/apache/iceberg/hooks/iceberg/index.html
    _api/airflow/providers/apache/iceberg/hooks/index airflow.providers.apache.iceberg.hooks  : _api/airflow/providers/apache/iceberg/hooks/index.html
    _api/airflow/providers/apache/iceberg/index airflow.providers.apache.iceberg        : _api/airflow/providers/apache/iceberg/index.html
    _api/tests/system/apache/iceberg/example_iceberg/index tests.system.apache.iceberg.example_iceberg: _api/tests/system/apache/iceberg/example_iceberg/index.html
    _api/tests/system/apache/iceberg/index   tests.system.apache.iceberg             : _api/tests/system/apache/iceberg/index.html
    changelog                                Changelog                               : changelog.html
    commits                                  Package apache-airflow-providers-apache-iceberg: commits.html
    connections                              Connecting to Iceberg                   : connections.html
    index                                    apache-airflow-providers-apache-iceberg : index.html
    installing-providers-from-sources        Installing from sources                 : installing-providers-from-sources.html
    security                                 Releasing security patches              : security.html
std:label
    genindex                                 Index                                   : genindex.html
    howto/connection:iceberg                 Connecting to Iceberg                   : connections.html#howto-connection-iceberg
    modindex                                 Module Index                            : py-modindex.html
    py-modindex                              Python Module Index                     : py-modindex.html
    search                                   Search Page                             : search.html
```

"
2799961693,pull_request,closed,,Fix Failing scheduler test,"This test fails consistently in local dev.
The bundle referenced in the test is not in the DB and also dag_version
is being removed in dag_maker.create_dagrun kwargs. This PR fixes the issues",ephraimbuddy,2025-01-20 17:19:59+00:00,[],2025-01-20 22:56:19+00:00,2025-01-20 22:56:17+00:00,https://github.com/apache/airflow/pull/45806,"[('area:Scheduler', 'including HA (high availability) scheduler')]","[{'comment_id': 2602953073, 'issue_id': 2799961693, 'author': 'ashb', 'body': ""If the bundle isn't needed a better fix might be to apply the `@pytest.mark.need_serialized_dag` marker"", 'created_at': datetime.datetime(2025, 1, 20, 17, 27, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602970860, 'issue_id': 2799961693, 'author': 'ephraimbuddy', 'body': ""> If the bundle isn't needed a better fix might be to apply the `@pytest.mark.need_serialized_dag` marker\r\n\r\nLooks like dag_version was being removed in dag_maker.create_dagrun. See : https://github.com/apache/airflow/pull/45806/commits/84e66393238a143914beca4e9098d5610026bb67"", 'created_at': datetime.datetime(2025, 1, 20, 17, 39, 13, tzinfo=datetime.timezone.utc)}]","ashb on (2025-01-20 17:27:51 UTC): If the bundle isn't needed a better fix might be to apply the `@pytest.mark.need_serialized_dag` marker

ephraimbuddy (Issue Creator) on (2025-01-20 17:39:13 UTC): Looks like dag_version was being removed in dag_maker.create_dagrun. See : https://github.com/apache/airflow/pull/45806/commits/84e66393238a143914beca4e9098d5610026bb67

"
2799885445,pull_request,closed,,Speed up fixing-ownership when leaving breeze on Linux,"When leaving breeze on Linux we are fixing ownership of potential new generated files to be the same as the HOST user - because files created in container will be owned by root.

This takes quite some time however, especially when you have .venv or node_modules or other folders with large amount of files.

This change skips such files from being considered in fixing ownership if the folders are already properly owned.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-20 16:52:15+00:00,[],2025-01-20 17:15:03+00:00,2025-01-20 17:15:01+00:00,https://github.com/apache/airflow/pull/45805,"[('area:dev-tools', '')]","[{'comment_id': 2602932215, 'issue_id': 2799885445, 'author': 'potiuk', 'body': '> nice optimisation :)\r\n\r\nI got a bit annoyed with about a second and a half delay', 'created_at': datetime.datetime(2025, 1, 20, 17, 14, 54, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-20 17:14:54 UTC): I got a bit annoyed with about a second and a half delay

"
2799752202,pull_request,closed,,Update documentation about new provider structure,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-20 16:16:44+00:00,[],2025-01-20 17:14:09+00:00,2025-01-20 17:14:07+00:00,https://github.com/apache/airflow/pull/45804,"[('area:dev-tools', '')]",[],
2799627428,pull_request,closed,,Fix pre-commit checking provider's doc consistency,"The pre-commit was not working since the move of providers to the `providers` top-level folder (#42505) - but we also have not added many new providers since. This PR updates the check to work again only for providers that follow the new structure and to be more verbose on what it is doing.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-20 15:43:33+00:00,[],2025-01-20 16:53:17+00:00,2025-01-20 16:53:15+00:00,https://github.com/apache/airflow/pull/45803,"[('area:dev-tools', ''), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2602760263, 'issue_id': 2799627428, 'author': 'potiuk', 'body': 'Example output: \r\n\r\n![image](https://github.com/user-attachments/assets/93edaaa3-3356-41dd-b58c-6640c20d9a6e)', 'created_at': datetime.datetime(2025, 1, 20, 15, 50, 31, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-20 15:50:31 UTC): Example output: 

![image](https://github.com/user-attachments/assets/93edaaa3-3356-41dd-b58c-6640c20d9a6e)

"
2799591802,pull_request,closed,,AIP-84 Add ordering to task instances and mapped task instances list,"Closes: [#43778](https://github.com/apache/airflow/issues/43778)

Added additional ordering options to list task instance and mapped task instances.",prabhusneha,2025-01-20 15:34:10+00:00,[],2025-01-27 13:02:04+00:00,2025-01-23 09:08:15+00:00,https://github.com/apache/airflow/pull/45802,"[('type:new-feature', 'Changelog: New Features'), ('AIP-84', 'Modern Rest API')]",[],
2799580686,pull_request,closed,,feat: Add OpenLineage support for BigQueryDataTransferServiceStartTransferRunsOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
BigQueryDataTransferServiceStartTransferRunsOperator can be used with different sources solutions like s3, mysql etc.

This PR implements OpenLineage support for: s3, gcs, azure blob storage, mysql, oracle, postgres and scheduled query.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2025-01-20 15:30:23+00:00,[],2025-01-27 12:55:02+00:00,2025-01-24 13:27:48+00:00,https://github.com/apache/airflow/pull/45801,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2799421725,pull_request,closed,,Add pre-commit to check consistency of new provider's workspace setup,"The new-structure providers require to be added to pyproject.toml in a few places. This pre-commit makes sure tha this is done.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-20 14:31:01+00:00,[],2025-01-20 16:17:07+00:00,2025-01-20 16:17:05+00:00,https://github.com/apache/airflow/pull/45800,"[('area:dev-tools', '')]",[],
2799406709,pull_request,closed,,Add new Dataplex Catalog Entry Type operators,"This PR adds new operators for Dataplex Catalog to perform Create, Update, List, Delete and Get operations on Entry Type resource.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2025-01-20 14:24:42+00:00,[],2025-01-20 15:56:35+00:00,2025-01-20 15:56:35+00:00,https://github.com/apache/airflow/pull/45799,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]",[],
2799242730,pull_request,closed,,limit amount of assets collected by hook lineage collector,"In some extreme cases collection of lineage can cause memory issues. This limits the collected assets now, with potential to do more reasonable optimizations later.",mobuchowski,2025-01-20 13:14:06+00:00,[],2025-01-21 13:36:25+00:00,2025-01-21 12:45:34+00:00,https://github.com/apache/airflow/pull/45798,"[('area:lineage', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2604640575, 'issue_id': 2799242730, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12887243233\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/5942c98ea7d2aa4bc34b999ff863a5ba55cc05db""><img src=\'https://img.shields.io/badge/Commit-5942c98-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 5942c98 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2025, 1, 21, 12, 46, 24, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-21 12:46:24 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12887243233'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/5942c98ea7d2aa4bc34b999ff863a5ba55cc05db""><img src='https://img.shields.io/badge/Commit-5942c98-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 5942c98 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2798721249,pull_request,open,,Create operators for working with Clusters for GCP Apache Kafka,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

In this PR I have created operators for working with Clusters for GCP Managed Service for Apache Kafka

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MaksYermak,2025-01-20 09:36:53+00:00,[],2025-02-06 09:42:17+00:00,,https://github.com/apache/airflow/pull/45795,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2604240371, 'issue_id': 2798721249, 'author': 'VladaZakharova', 'body': 'hi @potiuk ! Can you please check changes from this PR? :)', 'created_at': datetime.datetime(2025, 1, 21, 10, 5, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2616095447, 'issue_id': 2798721249, 'author': 'MaksYermak', 'body': '@eladkal I have updated the naming for hook and operators. Could you please check PR one more time?', 'created_at': datetime.datetime(2025, 1, 27, 15, 37, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2633501316, 'issue_id': 2798721249, 'author': 'VladaZakharova', 'body': 'Hi @eladkal ! Can you please check changes here? Thanks :)', 'created_at': datetime.datetime(2025, 2, 4, 10, 33, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2633528602, 'issue_id': 2798721249, 'author': 'eladkal', 'body': ""> Hi @eladkal ! Can you please check changes here? Thanks :)\r\n\r\nsorry won't get to it in the next 1-2 weeks. Maybe someone else can review"", 'created_at': datetime.datetime(2025, 2, 4, 10, 45, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2633531567, 'issue_id': 2798721249, 'author': 'VladaZakharova', 'body': ""> > Hi @eladkal ! Can you please check changes here? Thanks :)\r\n> \r\n> sorry won't get to it in the next 1-2 weeks. Maybe someone else can review\r\n\r\nOh, i see, thanks for reply! \r\n\r\n@potiuk Can you please check then? :)"", 'created_at': datetime.datetime(2025, 2, 4, 10, 46, 20, tzinfo=datetime.timezone.utc)}]","VladaZakharova on (2025-01-21 10:05:11 UTC): hi @potiuk ! Can you please check changes from this PR? :)

MaksYermak (Issue Creator) on (2025-01-27 15:37:54 UTC): @eladkal I have updated the naming for hook and operators. Could you please check PR one more time?

VladaZakharova on (2025-02-04 10:33:32 UTC): Hi @eladkal ! Can you please check changes here? Thanks :)

eladkal on (2025-02-04 10:45:07 UTC): sorry won't get to it in the next 1-2 weeks. Maybe someone else can review

VladaZakharova on (2025-02-04 10:46:20 UTC): Oh, i see, thanks for reply! 

@potiuk Can you please check then? :)

"
2797789435,pull_request,closed,,Improve the contributors_quick_start_gitpod.rst,"Add instructions for installing and configuring Breeze with Gitpod and Airflow

- Added instructions for installing Breeze using `uv` and `pipx`.
- Added the command to start Airflow using Breeze in Gitpod.
",aditya0yadav,2025-01-19 19:25:12+00:00,[],2025-01-20 11:00:12+00:00,2025-01-20 10:08:12+00:00,https://github.com/apache/airflow/pull/45791,"[('area:dev-tools', '')]","[{'comment_id': 2600989942, 'issue_id': 2797789435, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 19, 19, 25, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2601969984, 'issue_id': 2797789435, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 20, 10, 8, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602106745, 'issue_id': 2797789435, 'author': 'aditya0yadav', 'body': '> Nice!\n\nThanks sir', 'created_at': datetime.datetime(2025, 1, 20, 11, 0, 10, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-19 19:25:16 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2025-01-20 10:08:14 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

aditya0yadav (Issue Creator) on (2025-01-20 11:00:10 UTC): Thanks sir

"
2797759879,pull_request,closed,,Connect Trigger UI Conf with the flexible form,"This PR is the continuation of [#45270](https://github.com/apache/airflow/pull/45270) by @jscheffl 

Future Work (Not decided, might need discussion):

1. Introduce a reset button 
2. Have a asterisk on the accordion item which contains a required field inside.
3. If we face error when Trigger button when clicked, related field should turn in error mode.

closes: #22408 #44858

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-19 18:15:29+00:00,[],2025-01-27 12:48:40+00:00,2025-01-25 19:11:05+00:00,https://github.com/apache/airflow/pull/45790,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2797724738,pull_request,closed,,Fix DbApiHook.insert_rows logging incorrect number of rows commited,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

`DbApiHook.insert_rows` is logging the incorrect number of commited rows when `executemany` is supported by the database.

The current behavior is like this:
```
[2025-01-19, 16:51:32 UTC] {sql.py:681} INFO - Loaded 1000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:32 UTC] {sql.py:681} INFO - Loaded 1000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:32 UTC] {sql.py:681} INFO - Loaded 1000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:33 UTC] {sql.py:681} INFO - Loaded 1000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:33 UTC] {sql.py:681} INFO - Loaded 1000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:34 UTC] {sql.py:681} INFO - Loaded 1000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:34 UTC] {sql.py:681} INFO - Loaded 1000 rows into postgres.public.my_table so far
```

Since it says 'so far', logging the accumulated number of rows commited makes more sense:
```
[2025-01-19, 16:51:32 UTC] {sql.py:681} INFO - Loaded 1000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:32 UTC] {sql.py:681} INFO - Loaded 2000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:32 UTC] {sql.py:681} INFO - Loaded 3000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:33 UTC] {sql.py:681} INFO - Loaded 4000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:33 UTC] {sql.py:681} INFO - Loaded 5000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:34 UTC] {sql.py:681} INFO - Loaded 6000 rows into postgres.public.my_table so far
[2025-01-19, 16:51:34 UTC] {sql.py:681} INFO - Loaded 7000 rows into postgres.public.my_table so far
```


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",plutaniano,2025-01-19 16:57:38+00:00,[],2025-01-28 15:02:27+00:00,2025-01-27 10:27:50+00:00,https://github.com/apache/airflow/pull/45789,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:common-sql', '')]","[{'comment_id': 2600942045, 'issue_id': 2797724738, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 19, 16, 57, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614462945, 'issue_id': 2797724738, 'author': 'plutaniano', 'body': ""> would it be possible for us to add a test here?\r\n\r\nI've added a test but I am not really sure how to run it."", 'created_at': datetime.datetime(2025, 1, 26, 15, 10, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615371028, 'issue_id': 2797724738, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 27, 10, 27, 52, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-19 16:57:42 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

plutaniano (Issue Creator) on (2025-01-26 15:10:52 UTC): I've added a test but I am not really sure how to run it.

boring-cyborg[bot] on (2025-01-27 10:27:52 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2797602227,pull_request,closed,,Move Celery provider to new provider code structure,"This also solves quite a few teething issues with providers move:

* Boring-Cyborg only needs only one-liner now for new providers
* Additional-Extras in new provider is moved to ""optional-dependencies""
  in pyproject.toml
* generated pyproject.toml in new providers has better comments now
  explaining that dependencies can be edited in-place even if the file
  is generated
* comments in dependencies are preserved when regenerating the
  pyproject.toml files
* missing cross-project dependencies are added as optional-extras
  automatically when regenerating pyproject.toml
* LICENSE file for providers does not contain additional projects
  that are included in Airflow LICENCE
* Provider package tests do not have `__init__.py` in `providers`
  package - this way `celery` import is not importing the celery
  package from tests.providers
* When preparing package with --version-suffix-for-pypi - the
  pyproject.toml is updated temporarily with suffix added to airflow
  dependencies
* various constants in breeze code refering to providers were moved
  to path_utils and made consistent
* in case generated pyproject.toml file with pypi suffix has an error,
  content of it is printed when generating package. Also the content of
  pyproject.toml is printed when --verbose flag is used.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-19 12:35:06+00:00,[],2025-01-20 12:46:36+00:00,2025-01-20 12:46:35+00:00,https://github.com/apache/airflow/pull/45786,"[('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('provider:celery', ''), ('provider:airbyte', '')]","[{'comment_id': 2600842138, 'issue_id': 2797602227, 'author': 'potiuk', 'body': 'cc: @jscheffl -> this one also includes fixing LICENSE generation for providers, and making tests adaptible - so that we don not have to modify them when we move next provider in.', 'created_at': datetime.datetime(2025, 1, 19, 12, 36, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2600843051, 'issue_id': 2797602227, 'author': 'potiuk', 'body': 'Ah.. I need to do one more thing with ""additional-extras"" and comment removal during pyproject.toml generation !', 'created_at': datetime.datetime(2025, 1, 19, 12, 38, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2601958344, 'issue_id': 2797602227, 'author': 'potiuk', 'body': 'Ok. I think I got all the things needed for celery one and added/fixed quite a few missing thing in the provider move.\r\n\r\nThere is still few things I need to add for other providers (devel deps support) and some pre-commits checking for completeness/consistency of workspace settings - but those will come as next steps when moving few more providers with those.', 'created_at': datetime.datetime(2025, 1, 20, 10, 3, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2601964938, 'issue_id': 2797602227, 'author': 'potiuk', 'body': ""Let's see if the tests pass 🤞"", 'created_at': datetime.datetime(2025, 1, 20, 10, 6, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602102824, 'issue_id': 2797602227, 'author': 'potiuk', 'body': 'One more issue where pytest has a problem with duplicated modules of the same name inside providers :(', 'created_at': datetime.datetime(2025, 1, 20, 10, 58, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602118947, 'issue_id': 2797602227, 'author': 'potiuk', 'body': 'Ok. I think I got that one 🤯', 'created_at': datetime.datetime(2025, 1, 20, 11, 4, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602339344, 'issue_id': 2797602227, 'author': 'potiuk', 'body': 'OK. Looks good now :)', 'created_at': datetime.datetime(2025, 1, 20, 12, 46, 31, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-19 12:36:42 UTC): cc: @jscheffl -> this one also includes fixing LICENSE generation for providers, and making tests adaptible - so that we don not have to modify them when we move next provider in.

potiuk (Issue Creator) on (2025-01-19 12:38:51 UTC): Ah.. I need to do one more thing with ""additional-extras"" and comment removal during pyproject.toml generation !

potiuk (Issue Creator) on (2025-01-20 10:03:42 UTC): Ok. I think I got all the things needed for celery one and added/fixed quite a few missing thing in the provider move.

There is still few things I need to add for other providers (devel deps support) and some pre-commits checking for completeness/consistency of workspace settings - but those will come as next steps when moving few more providers with those.

potiuk (Issue Creator) on (2025-01-20 10:06:18 UTC): Let's see if the tests pass 🤞

potiuk (Issue Creator) on (2025-01-20 10:58:31 UTC): One more issue where pytest has a problem with duplicated modules of the same name inside providers :(

potiuk (Issue Creator) on (2025-01-20 11:04:59 UTC): Ok. I think I got that one 🤯

potiuk (Issue Creator) on (2025-01-20 12:46:31 UTC): OK. Looks good now :)

"
2797215728,pull_request,closed,,Fix authentication for cases where webserver.base_url is not defined and worker is not using localhost in 2.10.,"While testing edge deployment with @cmarteepants we found one problem when running Edge Provider in Airflow 2.10.4 - The authentication required to set webserver.base_url parameter to cut the server name from the called URL. This leads to failures when the base_url is not set and you run edge worker not on localhost.

This PR changes authentication in 2.10 to be the same like in main and not using base_url but take only the authentication URL part after the API prefix.",jscheffl,2025-01-18 21:38:34+00:00,[],2025-01-20 17:50:00+00:00,2025-01-20 17:49:59+00:00,https://github.com/apache/airflow/pull/45785,"[('area:providers', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]",[],
2797149983,pull_request,closed,,Improve cross-provider dependency detection,"When another provider is only used in example dags, we should not make it ""cross-provider"" dependency - this happened to ""edge"" provider having ""common.compat"" as cross-provider dependency.

It has been previously only implemented for ""standard"" provider but this is a universal rule that could be applied to any other provider.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-18 19:41:46+00:00,[],2025-01-18 20:25:38+00:00,2025-01-18 20:25:37+00:00,https://github.com/apache/airflow/pull/45784,"[('area:dev-tools', '')]",[],
2797131099,pull_request,closed,,Move Edge to new provider structure,"As the airbyte provider was the first test-baloon, wanted to attempt to be a fast-follower. THis PR moves the new edge-provider as second into new structures.

I am not sure if I made it right, let's see if CI gets green and most probably needs a good review by @potiuk ",jscheffl,2025-01-18 18:53:40+00:00,[],2025-01-19 12:29:05+00:00,2025-01-19 12:29:05+00:00,https://github.com/apache/airflow/pull/45783,"[('area:dev-tools', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2599845714, 'issue_id': 2797131099, 'author': 'potiuk', 'body': 'Oh ... how cool is that :) ... 👀 . I was just about to make two or three more providers, this weekend, so I might also verify that one together :)', 'created_at': datetime.datetime(2025, 1, 18, 19, 13, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599846216, 'issue_id': 2797131099, 'author': 'jscheffl', 'body': '> Oh ... how cool is that :) ... 👀 . I was just about to make two or three more providers, this weekend, so I might also verify that one together :)\r\n\r\nOh, how cool. I thought notifications are only sent after leaving draft. Still this is a test baloon, let me find the basic glitches first :-D', 'created_at': datetime.datetime(2025, 1, 18, 19, 15, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599848606, 'issue_id': 2797131099, 'author': 'potiuk', 'body': '> Oh, how cool. I thought notifications are only sent after leaving draft. Still this is a test baloon, let me find the basic glitches first :-D\r\n\r\nNotifications - yes. But I am looking at EVERY issue and PR in airflow repo.', 'created_at': datetime.datetime(2025, 1, 18, 19, 24, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599855651, 'issue_id': 2797131099, 'author': 'potiuk', 'body': 'You will also need to add the `apache-airflow-providers-edge` to .gitignore in `docs`', 'created_at': datetime.datetime(2025, 1, 18, 19, 49, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599868462, 'issue_id': 2797131099, 'author': 'potiuk', 'body': 'You will likely also have to copy ""conftest.py"" from `providers/airbyte/tests/conftest.py`. We would likely want to auto-generate this one as well (separate PR is coming).', 'created_at': datetime.datetime(2025, 1, 18, 20, 37, 11, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-18 19:13:05 UTC): Oh ... how cool is that :) ... 👀 . I was just about to make two or three more providers, this weekend, so I might also verify that one together :)

jscheffl (Issue Creator) on (2025-01-18 19:15:06 UTC): Oh, how cool. I thought notifications are only sent after leaving draft. Still this is a test baloon, let me find the basic glitches first :-D

potiuk on (2025-01-18 19:24:32 UTC): Notifications - yes. But I am looking at EVERY issue and PR in airflow repo.

potiuk on (2025-01-18 19:49:38 UTC): You will also need to add the `apache-airflow-providers-edge` to .gitignore in `docs`

potiuk on (2025-01-18 20:37:11 UTC): You will likely also have to copy ""conftest.py"" from `providers/airbyte/tests/conftest.py`. We would likely want to auto-generate this one as well (separate PR is coming).

"
2796965663,pull_request,open,,Add bundle name arg to list dags cli command,"closes: #45646 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ambika-garg,2025-01-18 12:56:19+00:00,[],2025-02-08 22:06:46+00:00,,https://github.com/apache/airflow/pull/45779,"[('area:CLI', ''), ('AIP-66: DAG Bundle/Manifest', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2644052437, 'issue_id': 2796965663, 'author': 'jedcunningham', 'body': ""@ambika-garg, check our #46571 which just made it so more than 1 bundle can be passed via the cli. You'll need to refactor a tiny bit to support that here."", 'created_at': datetime.datetime(2025, 2, 7, 20, 22, 17, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2025-02-07 20:22:17 UTC): @ambika-garg, check our #46571 which just made it so more than 1 bundle can be passed via the cli. You'll need to refactor a tiny bit to support that here.

"
2796960278,pull_request,closed,,Enable draft_pr config in cherry-picker automation,"We have added a support for this config in cherry-picker repository. its release yesterday. 

This enables pr's created from automated backport in draft state. And when committer changes state to ready for review it helps to trigger workflows. no need to close and re-open the PR

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-18 12:42:48+00:00,[],2025-01-18 14:35:00+00:00,2025-01-18 12:59:15+00:00,https://github.com/apache/airflow/pull/45778,"[('area:dev-tools', '')]","[{'comment_id': 2599742103, 'issue_id': 2796960278, 'author': 'potiuk', 'body': 'WHOA!', 'created_at': datetime.datetime(2025, 1, 18, 14, 34, 58, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-18 14:34:58 UTC): WHOA!

"
2796862057,pull_request,closed,,Switch to pnpm hash commit after it's been allowed by INFRA,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-18 08:51:09+00:00,[],2025-01-18 09:02:49+00:00,2025-01-18 09:02:47+00:00,https://github.com/apache/airflow/pull/45776,"[('area:dev-tools', '')]",[],
2796861203,pull_request,closed,,Replace usage of `model_construct` where not needed,"`model_construct` should only be used to avoid model validation as mentioned in https://docs.pydantic.dev/latest/concepts/models/#creating-models-without-validation

>Pydantic also provides the model_construct() method, which allows models to be created without validation. This can be useful in at least a few cases:
>
> when working with complex data that is already known to be valid (for performance reasons)
> when one or more of the validator functions are non-idempotent
> when one or more of the validator functions have side effects that you don't want to be triggered.

With Warning:

> `model_construct()` does not do any validation, meaning it can create models which are invalid. You should only ever use the model_construct() method with data which has already been validated, or that you definitely trust.

<img width=""786"" alt=""image"" src=""https://github.com/user-attachments/assets/2c423acc-8295-44c4-a5a9-622f7335cef9"" />


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-18 08:48:40+00:00,[],2025-01-18 12:57:56+00:00,2025-01-18 12:57:17+00:00,https://github.com/apache/airflow/pull/45775,"[('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('area:task-sdk', None)]","[{'comment_id': 2599688098, 'issue_id': 2796861203, 'author': 'jscheffl', 'body': 'Should we back-port this to 2.10?', 'created_at': datetime.datetime(2025, 1, 18, 11, 59, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599707496, 'issue_id': 2796861203, 'author': 'kaxil', 'body': '> Should we back-port this to 2.10?\n\nAll the classes changed should all be just in main, since they are part of Task SDK.', 'created_at': datetime.datetime(2025, 1, 18, 12, 57, 55, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-18 11:59:04 UTC): Should we back-port this to 2.10?

kaxil (Issue Creator) on (2025-01-18 12:57:55 UTC): All the classes changed should all be just in main, since they are part of Task SDK.

"
2796370741,pull_request,closed,,Make FAB auth manager login process compatible with Airflow 3 UI,"The plan to support FAB auth manager in Airflow 3 is:
- Create a trimmed version of the Airflow 2 Flask application in FAB provider. This is done ✅ 
- Embed this Flask application in fastapi application using `WSGIMiddleware` when FAB auth manager is the auth manager configured in the Airflow environment. This is done ✅ 
- Update the FAB provider Flask application login process to be compatible with Airflow 3 UI. This is this PR
- Update `get_url_login` method in FAB auth manager to return the appropriate login URL so that the fastapi application can retrieve this value and pass it to the front-end. On the front-end, if the user is not authenticated, it will redirect the user to this URL. It will be done in a future PR.

### Testing

You can test this PR by going to `<endpoint>/auth/login`and enter credentials. If you get successfully authenticated you'll be redirected to Airflow 3 UI with a JWT token.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-17 21:56:41+00:00,[],2025-01-21 15:52:02+00:00,2025-01-21 15:52:00+00:00,https://github.com/apache/airflow/pull/45765,"[('area:providers', ''), ('provider:fab', '')]",[],
2796357199,pull_request,closed,,Handle DagRun `conf` errors in FAB's list view,"**Before**:


<img width=""864"" alt=""image"" src=""https://github.com/user-attachments/assets/91fc1f1f-8f96-4304-bd8f-4f58e58b3135"" />

---

**After**:

<img width=""747"" alt=""image"" src=""https://github.com/user-attachments/assets/70f74c9e-6032-4224-a54a-31aea2351af3"" />

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-17 21:44:27+00:00,[],2025-01-17 22:24:41+00:00,2025-01-17 22:24:40+00:00,https://github.com/apache/airflow/pull/45763,"[('area:webserver', 'Webserver related Issues')]",[],
2796342343,pull_request,closed,,Use Protocol for `OutletEventAccessor`,"Follow-up of https://github.com/apache/airflow/pull/45727 to use Protocol to allow auto-completion on IDE while not introducing runtime dep

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-17 21:33:58+00:00,[],2025-01-20 10:44:25+00:00,2025-01-20 10:44:23+00:00,https://github.com/apache/airflow/pull/45762,"[('area:serialization', ''), ('area:task-sdk', None)]",[],
2796231765,pull_request,closed,,Enable Bulk Delete variables on variables list page,"related: #43709 

This enables the bulk delete option for variables.

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/48b6c7a3-222d-4527-a643-7b63c7d55537"" />
<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/96251c84-95bf-4af6-a7b5-994f3eaaf129"" />



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-17 20:20:35+00:00,[],2025-01-18 16:36:57+00:00,2025-01-18 16:36:57+00:00,https://github.com/apache/airflow/pull/45761,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2796215835,pull_request,closed,,Fix rowcount logging in exasol provider (#44022),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #44022 
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->

Fix logging the rowcount in the exasol provider by actually calling the method
closes: #44022 

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Briimbo,2025-01-17 20:08:39+00:00,[],2025-01-18 16:40:23+00:00,2025-01-18 16:40:20+00:00,https://github.com/apache/airflow/pull/45760,"[('area:providers', ''), ('provider:exasol', '')]","[{'comment_id': 2599111913, 'issue_id': 2796215835, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 17, 20, 8, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599598482, 'issue_id': 2796215835, 'author': 'Briimbo', 'body': 'Thanks for the feedback, I removed the newsfragment', 'created_at': datetime.datetime(2025, 1, 18, 7, 50, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599618018, 'issue_id': 2796215835, 'author': 'jscheffl', 'body': '> Thanks for the feedback, I removed the newsfragment\r\n\r\nPytests reveal... is is not a method but a property. Are you sure your fix is correct?', 'created_at': datetime.datetime(2025, 1, 18, 8, 15, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599633110, 'issue_id': 2796215835, 'author': 'Briimbo', 'body': 'Yes I am sure it is correct. We use it in our production app and always get a reference to the method in the log, which is identical to what is descibed in the bug report 44022.\r\n\r\nAlso, if you take a look at the [pyexasol implementation of rowcount](https://github.com/exasol/pyexasol/blob/af98ab7305e90e26a0912eba77eb99f950ab84ba/pyexasol/statement.py#L228), you can see that it is actually a method instead of a property. There is a property `row_count`, but the rowcount method should be used.\r\n\r\nI will look into fixing the tests', 'created_at': datetime.datetime(2025, 1, 18, 8, 44, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599780836, 'issue_id': 2796215835, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 18, 16, 40, 22, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-17 20:08:43 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

Briimbo (Issue Creator) on (2025-01-18 07:50:13 UTC): Thanks for the feedback, I removed the newsfragment

jscheffl on (2025-01-18 08:15:19 UTC): Pytests reveal... is is not a method but a property. Are you sure your fix is correct?

Briimbo (Issue Creator) on (2025-01-18 08:44:40 UTC): Yes I am sure it is correct. We use it in our production app and always get a reference to the method in the log, which is identical to what is descibed in the bug report 44022.

Also, if you take a look at the [pyexasol implementation of rowcount](https://github.com/exasol/pyexasol/blob/af98ab7305e90e26a0912eba77eb99f950ab84ba/pyexasol/statement.py#L228), you can see that it is actually a method instead of a property. There is a property `row_count`, but the rowcount method should be used.

I will look into fixing the tests

boring-cyborg[bot] on (2025-01-18 16:40:22 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2796030444,pull_request,closed,,Move Pod*Exceptions to separate module to avoid unnecessary slow imports in CLI,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Pod*Exceptions has been moved from core to providers back in https://github.com/apache/airflow/commit/de92a81f002e6c1b3e74ad9d074438b65acb87b6, but kept in `airflow/exceptions.py` under try-case for backwards compatibility and allow for usage of an older k8s provider with a newer core airflow.

This resulted in 2 unintended side-effects:

1. Any CLI command started taking ~ 1s longer to start. That is because importing anything from `airflow` resulted in importing `kubernetes` client. It is effectively the most expensive import out of all CLI does for any command, even though it is used by very few commands. Here are the timings of a trivial `airflow dag-processor --help`
  - Before this PR: 6.0s https://pastebin.com/zb0QHFq9
  - After this PR: 4.97s https://pastebin.com/QC5Rbyt5
 2. Some time ago the compatibility import broke altogether. Because of the amount of imports in `pod_generator.py`, the import from `exceptions.py` failed even if providers were up to date with recursive import. But it was caught by exception handling, resulting in `from airflow.exceptions import PodMutationHookException` and `from airflow.providers.cncf.kubernetes.pod_generator import PodMutationHookException` pointing to different classes defeating the purpose of the fallback.

This PR addresses both by moving PodGenerator exceptions to the separate module that only import its base class. This keeps imports backwards compatible, doesn't attempt to load k8s modules and fixes the divergence of exception classes in `airflow.providers.cncf.kubernetes.pod_generator` and `airflow.exceptions`.

It is worth noting, that all usages of those exceptions in core Airflow also has been cleaned up since then, so if you believe that we need to remove those exceptions from `airflow/exceptions.py`, please let me know.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",IKholopov,2025-01-17 18:06:06+00:00,[],2025-01-18 08:41:18+00:00,2025-01-18 08:33:27+00:00,https://github.com/apache/airflow/pull/45759,"[('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2598945116, 'issue_id': 2796030444, 'author': 'potiuk', 'body': 'I applied ""full tests needed"" and rebased it - I think that one should run full suite of tests due to potential compatibility issues.', 'created_at': datetime.datetime(2025, 1, 17, 18, 22, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599294921, 'issue_id': 2796030444, 'author': 'IKholopov', 'body': 'Looks like the only failure is unrelated one (already failing on parent commit, same failure as here: https://github.com/apache/airflow/pull/45727#issuecomment-2599130122 - `providers/tests/common/sql/hooks/test_dbapi.py::TestDbApiHook::test_run_no_log `).', 'created_at': datetime.datetime(2025, 1, 17, 22, 9, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599632038, 'issue_id': 2796030444, 'author': 'potiuk', 'body': 'Added an issue for the flaky stuff https://github.com/apache/airflow/issues/45774', 'created_at': datetime.datetime(2025, 1, 18, 8, 40, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599632246, 'issue_id': 2796030444, 'author': 'potiuk', 'body': 'It looks like another ""caplog issue""', 'created_at': datetime.datetime(2025, 1, 18, 8, 41, 16, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-17 18:22:12 UTC): I applied ""full tests needed"" and rebased it - I think that one should run full suite of tests due to potential compatibility issues.

IKholopov (Issue Creator) on (2025-01-17 22:09:38 UTC): Looks like the only failure is unrelated one (already failing on parent commit, same failure as here: https://github.com/apache/airflow/pull/45727#issuecomment-2599130122 - `providers/tests/common/sql/hooks/test_dbapi.py::TestDbApiHook::test_run_no_log `).

potiuk on (2025-01-18 08:40:29 UTC): Added an issue for the flaky stuff https://github.com/apache/airflow/issues/45774

potiuk on (2025-01-18 08:41:16 UTC): It looks like another ""caplog issue""

"
2795824348,pull_request,closed,,Skip serialization tests when latest botocore is installed,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-17 16:11:27+00:00,[],2025-01-17 17:08:49+00:00,2025-01-17 17:08:49+00:00,https://github.com/apache/airflow/pull/45755,"[('area:serialization', '')]",[],
2795766887,pull_request,closed,,Add deferrable mode to google cloud storage transfer sensor and operators,"Add deferrable mode to google cloud storage transfer sensor and operators.

- CloudDataTransferServiceS3ToGCSOperator
- CloudDataTransferServiceGCSToGCSOperator
- CloudDataTransferServiceJobStatusSensor",tnk-ysk,2025-01-17 15:41:46+00:00,[],2025-02-01 12:15:42+00:00,2025-02-01 12:15:42+00:00,https://github.com/apache/airflow/pull/45754,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2602003678, 'issue_id': 2795766887, 'author': 'VladaZakharova', 'body': 'Hi! Thank you for preparing PR with changes :)\r\nCan you please add a system tests for this? As a new task with deferrable mode for every operator that you have modified.\r\nCan you please provide also screenshots of successfully executed system tests with your changes? Thanks!', 'created_at': datetime.datetime(2025, 1, 20, 10, 21, 45, tzinfo=datetime.timezone.utc)}]","VladaZakharova on (2025-01-20 10:21:45 UTC): Hi! Thank you for preparing PR with changes :)
Can you please add a system tests for this? As a new task with deferrable mode for every operator that you have modified.
Can you please provide also screenshots of successfully executed system tests with your changes? Thanks!

"
2795751706,pull_request,closed,,Add deferrable mode to cloud storage transfer sensor and operators,"Add deferrable mode to cloud storage transfer sensor and operators.

- CloudDataTransferServiceS3ToGCSOperator
- CloudDataTransferServiceGCSToGCSOperator
- CloudDataTransferServiceJobStatusSensor",tnk-ysk-san,2025-01-17 15:34:05+00:00,[],2025-01-17 15:35:05+00:00,2025-01-17 15:35:05+00:00,https://github.com/apache/airflow/pull/45753,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2598623196, 'issue_id': 2795751706, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 17, 15, 34, 10, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-17 15:34:10 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2795669110,pull_request,closed,,Add new Dataplex Catalog Entry Group operators,"This PR adds new operators for Dataplex Catalog to perform Create, Update, List, Delete and Get operations on Entry Group resource.
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",VladaZakharova,2025-01-17 14:55:51+00:00,[],2025-01-18 10:24:58+00:00,2025-01-18 10:24:58+00:00,https://github.com/apache/airflow/pull/45751,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2598932100, 'issue_id': 2795669110, 'author': 'potiuk', 'body': 'Rebased to account for fixed main failure + flaky test', 'created_at': datetime.datetime(2025, 1, 17, 18, 14, 53, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-17 18:14:53 UTC): Rebased to account for fixed main failure + flaky test

"
2795578074,pull_request,closed,,Bump UV to 0.5.20,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-17 14:12:12+00:00,[],2025-01-17 17:08:27+00:00,2025-01-17 17:08:19+00:00,https://github.com/apache/airflow/pull/45750,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2598807639, 'issue_id': 2795578074, 'author': 'gopidesupavan', 'body': 'Merging now, one test failed, fix here https://github.com/apache/airflow/pull/45755', 'created_at': datetime.datetime(2025, 1, 17, 17, 8, 9, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2025-01-17 17:08:09 UTC): Merging now, one test failed, fix here https://github.com/apache/airflow/pull/45755

"
2795541552,pull_request,closed,,"Add Webserver parameters: max_form_parts, max_form_memory_size","The problem resolved in this PR:
- `max_form_parts` (https://flask.palletsprojects.com/en/stable/api/#flask.Request.max_form_parts) is not configurable in Airflow web server (1000 is the default value).
- `max_form_parts` is relevant for a ""role edit"" form in Airflow UI.
- Size of the role (number of permissions) contributes to the number of form parts in POST request generated by Airflow UI.
- There are real-life cases (roles with hundreds of permissions) where max_form_parts is exceeded (error 413) and blocks updating roles through the Airflow UI.

In order to overcome this limitation, two more webserver config options were introduced:
- `[webserver]max_form_parts = 1000`
- `[webserver]max_form_memory_size = 500000`",moiseenkov,2025-01-17 13:56:16+00:00,[],2025-01-29 15:26:34+00:00,2025-01-29 15:25:45+00:00,https://github.com/apache/airflow/pull/45749,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2602747746, 'issue_id': 2795541552, 'author': 'pierrejeambrun', 'body': ""Should this be considered a bug fix ? (for big installs).\r\n\r\nAsking because no new features will be release for airflow 2. And that's not needed for airflow 3."", 'created_at': datetime.datetime(2025, 1, 20, 15, 45, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2621965751, 'issue_id': 2795541552, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/46243""><img src=""https://img.shields.io/badge/PR-46243-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2025, 1, 29, 15, 26, 33, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2025-01-20 15:45:13 UTC): Should this be considered a bug fix ? (for big installs).

Asking because no new features will be release for airflow 2. And that's not needed for airflow 3.

github-actions[bot] on (2025-01-29 15:26:33 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/46243""><img src=""https://img.shields.io/badge/PR-46243-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2795458425,pull_request,closed,,Fix links in template email to point to versioned URL,"Fixes: #45747

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-17 13:15:17+00:00,[],2025-01-17 13:32:09+00:00,2025-01-17 13:32:09+00:00,https://github.com/apache/airflow/pull/45748,"[('area:dev-tools', '')]",[],
2795442865,pull_request,closed,,Fixes compat issue HTTPX proxy configuration in KiotaRequestAdapterHook and fixed retry in MSGraphSensor,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: [#45741](https://github.com/apache/airflow/pull/45741)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fixes compatibility issue between HTTP 0.2.7 and 0.28 regarding proxy configuration in KiotaRequestAdapterHook, that way we are future proof when Airflow would use the newer httpx library in the future.

Also fixed an issue with retry_execute method in MSGraphSensor due to missing event parameter, updated unit test for that case.

We thought the issue was fixed in previous [PR](https://github.com/apache/airflow/pull/45741) regarding difference between HTTPX 0.27 and 0.28 but is was not, this should fix it now.

Would be nice if this [PR](https://github.com/apache/airflow/pull/45478/) could also be merged as this will allow re-usability of test helpers which where first used here.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2025-01-17 13:07:42+00:00,[],2025-01-19 13:33:17+00:00,2025-01-19 13:33:17+00:00,https://github.com/apache/airflow/pull/45746,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]",[],
2795306990,pull_request,open,,Update DockerSwarmOperator auto_remove to align with DockerOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The description of the auto_remove field didn't match the field types defined in DockerOperator.
Also ""success"" and ""force"" currently don't behave as expected.

<!-- Please keep an empty line above the dashes. -->
---",niklasr22,2025-01-17 11:55:39+00:00,[],2025-02-08 15:29:13+00:00,,https://github.com/apache/airflow/pull/45745,"[('area:providers', ''), ('provider:docker', '')]","[{'comment_id': 2598204058, 'issue_id': 2795306990, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 17, 11, 55, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2645784426, 'issue_id': 2795306990, 'author': 'niklasr22', 'body': 'sorry for the review request mess...', 'created_at': datetime.datetime(2025, 2, 8, 15, 29, 8, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-17 11:55:43 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

niklasr22 (Issue Creator) on (2025-02-08 15:29:08 UTC): sorry for the review request mess...

"
2795304675,pull_request,closed,,Use bulk API for importing variables,"Since we now have Bulk API for variables.
There is no need for specific import API. This can be easily done by the bulk API.
There is no visual Difference.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-17 11:54:22+00:00,[],2025-01-17 22:42:03+00:00,2025-01-17 22:42:03+00:00,https://github.com/apache/airflow/pull/45744,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2795240358,pull_request,closed,,Issue deprecation warning for plugins registering `ti_deps`,"This is removed in Airflow3 via #45713

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2025-01-17 11:22:00+00:00,[],2025-01-29 11:09:23+00:00,2025-01-29 11:03:16+00:00,https://github.com/apache/airflow/pull/45742,"[('area:plugins', '')]",[],
2795203728,pull_request,closed,,Fixed assignment of proxies in KiotaRequestAdapter for HTTPX 0.28.x compliancy,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: [#45464](https://github.com/apache/airflow/pull/45464)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

The previous PR [#45464](https://github.com/apache/airflow/pull/45464) did some changes to be HTTPX 0.28.x, unfortunately it broke the parametrization of the proxies parameter, this is fixed in this PR.

As the proxies parameter is deprecated in HTTPX 0.27.x and is removed in 0.28.x, it was wrongly assigned to the mounts parameter, it should in fact be assigned to the proxy parameter, this PR fixes it.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2025-01-17 11:08:34+00:00,[],2025-01-17 11:32:04+00:00,2025-01-17 11:32:04+00:00,https://github.com/apache/airflow/pull/45741,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]",[],
2795186534,pull_request,closed,,Add missing significant newsfragments and migration rules needed,"Add missing significant newsfragments and migration rules needed for #41564, #42794, #43609, #43890, #44053, #44288

Closes: https://github.com/apache/airflow/issues/44482

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2025-01-17 11:02:09+00:00,[],2025-01-20 09:26:55+00:00,2025-01-20 09:26:52+00:00,https://github.com/apache/airflow/pull/45740,[],"[{'comment_id': 2598530001, 'issue_id': 2795186534, 'author': 'Lee-W', 'body': '> Thanks :)\r\n> \r\n> is it also comes under code interface change?\r\n\r\nI think `Dag changes` should be good enough for this one 🤔', 'created_at': datetime.datetime(2025, 1, 17, 14, 48, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2601867973, 'issue_id': 2795186534, 'author': 'Lee-W', 'body': 'https://github.com/astral-sh/ruff/pull/15611 has been created to add these rules to ruff', 'created_at': datetime.datetime(2025, 1, 20, 9, 26, 47, tzinfo=datetime.timezone.utc)}]","Lee-W (Issue Creator) on (2025-01-17 14:48:08 UTC): I think `Dag changes` should be good enough for this one 🤔

Lee-W (Issue Creator) on (2025-01-20 09:26:47 UTC): https://github.com/astral-sh/ruff/pull/15611 has been created to add these rules to ruff

"
2794967532,pull_request,closed,,Add newsfragment and migration rules for `scheduler.dag_dir_list_interval` → `dag_bundles.refresh_interval` configuration change,"## Why
https://github.com/apache/airflow/pull/45722 changes a configuration, which may be better to have a news fragment and migration rules.

## What
Add newsfragment and migrations rules `scheduler.dag_dir_list_interval` → `dag_bundles.refresh_interval`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2025-01-17 09:23:44+00:00,['Lee-W'],2025-01-17 18:16:15+00:00,2025-01-17 18:16:05+00:00,https://github.com/apache/airflow/pull/45737,"[('area:CLI', ''), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2794951708,pull_request,open,,"Backport ""airflow config lint""","Backport https://github.com/apache/airflow/pull/44908 to Airflow 2.11

Closes: https://github.com/apache/airflow/issues/45632

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2025-01-17 09:15:35+00:00,[],2025-02-05 13:39:44+00:00,,https://github.com/apache/airflow/pull/45736,"[('area:CLI', '')]",[],
2794880551,pull_request,closed,,Remove extra bracket in query,"This was causing errors in dag processor manager logging

",ephraimbuddy,2025-01-17 08:36:41+00:00,[],2025-01-17 09:13:56+00:00,2025-01-17 09:13:54+00:00,https://github.com/apache/airflow/pull/45735,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2794807183,pull_request,closed,,Add run_after column to DagRun model,"See [AIP-83 amendment to support classic Airflow authoring style](https://cwiki.apache.org/confluence/x/Ngv0Ew) and [Option 2 clarification doc WIP](https://cwiki.apache.org/confluence/x/sokgF) (Question 3) for context.

This is one of the less controversial approaches to solve ordering and run ID generation for runs with a null logical date.

Depending on the run type, the value is set to:
    
* BACKFILL_JOB: DagRunInfo.run_after
* SCHEDULED: DagModel.next_run_create_after (this is the same as backfill, only calculated earlier in the scheduler loop and stored in db)
* MANUAL: data_interval.end
* ASSET_TRIGGERED: Creation time of the last triggering asset event",uranusjr,2025-01-17 07:52:06+00:00,[],2025-02-03 10:44:40+00:00,2025-02-03 10:44:38+00:00,https://github.com/apache/airflow/pull/45732,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('area:db-migrations', 'PRs with DB migration'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2601557396, 'issue_id': 2794807183, 'author': 'uranusjr', 'body': 'Hell yeah this works. We shouldn’t merge this before we resolve the discussion on this, but feel free to review the changes and get an idea what will change (not a lot).', 'created_at': datetime.datetime(2025, 1, 20, 7, 9, 57, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2025-01-20 07:09:57 UTC): Hell yeah this works. We shouldn’t merge this before we resolve the discussion on this, but feel free to review the changes and get an idea what will change (not a lot).

"
2794691936,pull_request,closed,,AIP-84 Handle backfill for DAGs with when depends_on_past is True,"Currently below two scenarios results in HTTP500. This PR handles it.

1. When  `depends_on_past `= True is set for a Task and `reprocess_behavior` is ""none""
  **Before:**
  ![image](https://github.com/user-attachments/assets/eb97800b-a9a7-4ab2-a3c1-df8e4fad4a3e)

    **After:**
    <img width=""1485"" alt=""image"" src=""https://github.com/user-attachments/assets/5b421c2d-5dad-4f91-b48a-dc41aea52a71"" />

2. When  `depends_on_past `= True is set for a Task and `run_backwards`=True
  **Before:**
    <img width=""1423"" alt=""image"" src=""https://github.com/user-attachments/assets/1bc53002-f009-4c0a-952d-07c8b323c0e9"" />

      **After:**
         <img width=""1415"" alt=""image"" src=""https://github.com/user-attachments/assets/7f6e64f7-be0a-4853-bdec-c4bcb501c248"" />

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2025-01-17 06:32:56+00:00,[],2025-01-27 13:06:54+00:00,2025-01-22 13:47:47+00:00,https://github.com/apache/airflow/pull/45731,"[('type:new-feature', 'Changelog: New Features'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2602175560, 'issue_id': 2794691936, 'author': 'pierrejeambrun', 'body': 'cc: @dstandish', 'created_at': datetime.datetime(2025, 1, 20, 11, 30, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602795515, 'issue_id': 2794691936, 'author': 'pierrejeambrun', 'body': ""Don't hesitate to `resolve` comments that you addressed. Also I think a couple of them are marked as `done` but I don't see the related change yet. (maybe you have some local unpushed code ?)"", 'created_at': datetime.datetime(2025, 1, 20, 16, 6, 9, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2025-01-20 11:30:33 UTC): cc: @dstandish

pierrejeambrun on (2025-01-20 16:06:09 UTC): Don't hesitate to `resolve` comments that you addressed. Also I think a couple of them are marked as `done` but I don't see the related change yet. (maybe you have some local unpushed code ?)

"
2794515745,pull_request,closed,,Remove dag processor from the scheduler,"We will only support a standalone DAG processor. Doing so removes complexity from the scheduler, and offers better isolation between these two different workloads.",jedcunningham,2025-01-17 04:20:03+00:00,[],2025-01-20 17:52:55+00:00,2025-01-20 17:52:53+00:00,https://github.com/apache/airflow/pull/45729,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2597732398, 'issue_id': 2794515745, 'author': 'kaxil', 'body': 'Nice, look at all that deleted code 👨\u200d💻!!!', 'created_at': datetime.datetime(2025, 1, 17, 8, 53, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597733274, 'issue_id': 2794515745, 'author': 'kaxil', 'body': '#protm', 'created_at': datetime.datetime(2025, 1, 17, 8, 54, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598923157, 'issue_id': 2794515745, 'author': 'potiuk', 'body': ""We'll have many good candidates this month"", 'created_at': datetime.datetime(2025, 1, 17, 18, 9, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2600953399, 'issue_id': 2794515745, 'author': 'jscheffl', 'body': 'Can you please add a newsfragment before merging because from deployment point of view it is a breaking change.', 'created_at': datetime.datetime(2025, 1, 19, 17, 31, 55, tzinfo=datetime.timezone.utc)}]","kaxil on (2025-01-17 08:53:51 UTC): Nice, look at all that deleted code 👨‍💻!!!

kaxil on (2025-01-17 08:54:21 UTC): #protm

potiuk on (2025-01-17 18:09:27 UTC): We'll have many good candidates this month

jscheffl on (2025-01-19 17:31:55 UTC): Can you please add a newsfragment before merging because from deployment point of view it is a breaking change.

"
2794109717,pull_request,closed,,AIP-72: Add support for `outlet_events` in Task Context,"part of https://github.com/apache/airflow/issues/45717

This PR adds support for `outlet_events` in Context dict within the Task SDK by adding an endpoint on the API Server which is fetched when outlet_events is accessed.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-17 00:28:43+00:00,[],2025-01-20 06:23:41+00:00,2025-01-17 20:21:29+00:00,https://github.com/apache/airflow/pull/45727,"[('area:serialization', ''), ('area:task-sdk', None)]","[{'comment_id': 2598187444, 'issue_id': 2794109717, 'author': 'ashb', 'body': 'Did you consider sending these via the initial context we send in the response to the Run request?', 'created_at': datetime.datetime(2025, 1, 17, 11, 45, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599130122, 'issue_id': 2794109717, 'author': 'kaxil', 'body': 'Following failure is unrelated\r\n\r\n```\r\nFAILED providers/tests/common/sql/hooks/test_dbapi.py::TestDbApiHook::test_run_no_log \r\n```', 'created_at': datetime.datetime(2025, 1, 17, 20, 22, 2, tzinfo=datetime.timezone.utc)}]","ashb on (2025-01-17 11:45:51 UTC): Did you consider sending these via the initial context we send in the response to the Run request?

kaxil (Issue Creator) on (2025-01-17 20:22:02 UTC): Following failure is unrelated

```
FAILED providers/tests/common/sql/hooks/test_dbapi.py::TestDbApiHook::test_run_no_log 
```

"
2793789640,pull_request,open,,Add AWS SageMaker Unified Studio Workflow Operator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
## Description

Adds an operator used for executing Jupyter Notebooks, Querybooks, and Visual ETL jobs within the context of a SageMaker Unified Studio project.

[SageMaker Unified Studio](https://aws.amazon.com/sagemaker/unified-studio/) (SUS) supports development of Airflow DAGs (called ""workflows"" within the product) that are run on an MWAA cluster managed by the project. These workflows have the ability to orchestrate the execution of Unified Studio artifacts that can connect to data assets stored in a SUS project. 

Implementation-wise, these notebooks are executed on a SageMaker Training Job running a [SageMaker Distribution ](https://github.com/aws/sagemaker-distribution) environment within the context of a SUS project.

### Components
- **SageMakerNotebookOperator:** this operator allows users to execute Unified Studio artifacts within the context of their project.
- **SageMakerNotebookHook:** this hook provides a wrapper around the notebook execution
- **SageMakerNotebookSensor:** this sensor waits on status updates from the notebook execution
- **SageMakerNotebookJobTrigger:** this trigger activates when the notebook execution completes

### Usage
Note that this operator introduces a dependency on the SageMaker Studio SDK https://www.pypi.org/project/sagemaker-studio
```python
with DAG(...) as dag:
    ...
    run_notebook = SageMakerNotebookOperator(
        task_id=""initial"",
        input_config={""input_path"": <notebook_path_in_s3>, ""input_params"": {}},
        output_config={""output_formats"": [""NOTEBOOK""]},
        wait_for_completion=True,
        poll_interval=5,
    )
   ...
```

## Testing
MWAA uses python 3.11 and postgres backend, so we will set those values for all tests.
### Unit tests
```shell
breeze testing core-tests -p 3.11 -b postgres providers/tests/amazon/aws/*/test_sagemaker_unified_studio.py
```

### System tests
Ensure a properly configured SageMaker Unified Domain and Project as indicated in the `example_sagemaker_unified_studio.py` file. Also ensure AWS credentials are populated and up to date. Then, populate the `DOMAIN_ID`, `PROJECT_ID`, `ENVIRONMENT_ID`, and `S3_PATH` in `files/airflow-breeze-config/variables.env` and run:
```shell
breeze testing system-tests -p 3.11 -b postgres --forward-credentials --test-timeout 600 providers/tests/system/amazon/aws/example_sagemaker_unified_studio.py
```

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",agupta01,2025-01-16 21:21:39+00:00,[],2025-01-30 20:25:06+00:00,,https://github.com/apache/airflow/pull/45726,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2596912242, 'issue_id': 2793789640, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 16, 21, 21, 44, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-16 21:21:44 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2793787883,pull_request,closed,,Generate partition aware STS endpoints for EKS Hook,"Up until now the STS endpoint url used by the EKS hook (during token generation) was hardcoded to be the commercial partition. This change ensures the endpoint urls respect partitions and regions.

fixes #45368

Prior work and context:
- Initial work from @vincbeck: #45469 #45520 #45526
  - Some fixes were attempted which did not work out, then reverted.
- I have run this change through our system test suite and got passes for all the eks tests.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",o-nikolas,2025-01-16 21:20:27+00:00,[],2025-01-16 22:46:40+00:00,2025-01-16 22:46:39+00:00,https://github.com/apache/airflow/pull/45725,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2793783360,pull_request,closed,,Do not start fast-api when `--use-airflow-version` uses Airflow 2,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-16 21:17:22+00:00,[],2025-01-16 21:22:10+00:00,2025-01-16 21:22:09+00:00,https://github.com/apache/airflow/pull/45724,"[('area:dev-tools', '')]","[{'comment_id': 2596908855, 'issue_id': 2793783360, 'author': 'potiuk', 'body': ""> Good Idea! I was so far always ignoring the failed start in the un-needed panel - but this makes it better! Thanks!\r\n\r\nYeah. It's been pretty annoying :)"", 'created_at': datetime.datetime(2025, 1, 16, 21, 19, 25, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-16 21:19:25 UTC): Yeah. It's been pretty annoying :)

"
2793782456,pull_request,closed,,Default to standalone DAG processor in breeze,"(alternate of #45699)

We are moving to only support a standalone DAG processor in Airflow 3, so let's switch breeze to default to a standalone DAG processor, while still allowing it to be explicitly disabled for Airflow 2.

",jedcunningham,2025-01-16 21:16:46+00:00,[],2025-01-16 21:45:40+00:00,2025-01-16 21:45:40+00:00,https://github.com/apache/airflow/pull/45723,"[('area:dev-tools', '')]","[{'comment_id': 2596919638, 'issue_id': 2793782456, 'author': 'potiuk', 'body': '> BTW. We could even FAIL if standalone dag processor is disabled for Airflow 3. But that might be another PR some day.\r\n\r\nProbably good thing to add when we completely remove the code for embedded DagFileProcessor.', 'created_at': datetime.datetime(2025, 1, 16, 21, 26, 32, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-16 21:26:32 UTC): Probably good thing to add when we completely remove the code for embedded DagFileProcessor.

"
2793738443,pull_request,closed,,Move `[scheduler]dag_dir_list_interval` to `[dag_bundles]refresh_interval`,"This config should be the default refresh_interval in AF3, so move its predecessor.",jedcunningham,2025-01-16 20:47:10+00:00,[],2025-01-17 09:26:29+00:00,2025-01-17 08:38:48+00:00,https://github.com/apache/airflow/pull/45722,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2597770631, 'issue_id': 2793738443, 'author': 'Lee-W', 'body': ""I think we'll need to mark it as a breaking change and add a migration rule 🤔  I'll create PR for it"", 'created_at': datetime.datetime(2025, 1, 17, 9, 13, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597795596, 'issue_id': 2793738443, 'author': 'Lee-W', 'body': 'PR https://github.com/apache/airflow/pull/45737 created', 'created_at': datetime.datetime(2025, 1, 17, 9, 26, 27, tzinfo=datetime.timezone.utc)}]","Lee-W on (2025-01-17 09:13:38 UTC): I think we'll need to mark it as a breaking change and add a migration rule 🤔  I'll create PR for it

Lee-W on (2025-01-17 09:26:27 UTC): PR https://github.com/apache/airflow/pull/45737 created

"
2793674875,pull_request,closed,,Move dags-folder bundle to LocalDagBundle; rename kwarg,"This moves the dags-folder bundle to use LocalDagBundle, instead of having its own class. A follow up will remove the `[core] dags_folder` config as well, but that will be much larger reaching.

I've also renamed the `local_folder` kwarg to `path` - just a nicer name for it.",jedcunningham,2025-01-16 20:05:56+00:00,[],2025-01-17 04:40:01+00:00,2025-01-17 04:40:00+00:00,https://github.com/apache/airflow/pull/45721,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:providers', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:fab', ''), ('AIP-66: DAG Bundle/Manifest', ''), ('area:task-sdk', None)]",[],
2793674632,pull_request,closed,,Rename latest_version to version in bundle orm / code clarification,"1. did a little work to try to make the code a little clearer in the dag processor where we compare versions.  Instead of current and new, which is confusing, I call it pre-refresh and after-refresh, essentially, which makes the logic a little more intelligible.  Also I provide a var `was seen` to show the intention of the `name in list` check.

2. I propose (and do so here) renaming `latest_version` to `version` in bundle for reasons similar to https://github.com/apache/airflow/pull/45719.  I think it makes sense to think of the orm object as _itself_ representing the latest or current or last refreshed version. So the latest version cannot itself _have_ a latest version -- the latest version just has a version.  That's sorta conceptually the issue.  In any event, by saying less, we can let the docs explain the nuance.
",dstandish,2025-01-16 20:05:47+00:00,[],2025-01-16 23:24:10+00:00,2025-01-16 23:24:08+00:00,https://github.com/apache/airflow/pull/45720,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2793574620,pull_request,closed,,Rename latest bundle version to bundle version,"Why .... well because it might not always be the version of that bundle.  It's the bundle version that was seen when this dag was last processed, which, could be stale.

The thing is, for the current dag (as represented by this model), there is only ever one bundle version -- the bundle version that was seen when the dag was parsed.  So I think by simply calling it bundle version, we are less likely to confuse.",dstandish,2025-01-16 19:17:28+00:00,[],2025-01-16 20:50:22+00:00,2025-01-16 20:50:20+00:00,https://github.com/apache/airflow/pull/45719,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('area:db-migrations', 'PRs with DB migration'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2793450235,pull_request,closed,,Add default for refresh_interval in dag bundles,"This way we don't have to supply the default for each bundle unless we want to change it.

Default chosen is 300 seconds.",dstandish,2025-01-16 18:22:03+00:00,[],2025-01-16 20:08:36+00:00,2025-01-16 20:08:34+00:00,https://github.com/apache/airflow/pull/45716,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2793365971,pull_request,closed,,Unified Bulk Patch Endpoint for Connections in Rest API (FastAPI),"relates: #45601 

* Implementing the unified approach for bulk endpoints.



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2025-01-16 17:34:14+00:00,[],2025-01-27 13:08:25+00:00,2025-01-22 10:11:10+00:00,https://github.com/apache/airflow/pull/45715,"[('area:API', ""Airflow's REST/HTTP API""), ('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2603239451, 'issue_id': 2793365971, 'author': 'bugraoz93', 'body': '> Nice\r\n> \r\n> A few suggestions, and hint for follow up PRs. Almost ready to merge.\r\n\r\nThanks for the quick review! I updated the code according to the comments. \r\n\r\nI agree with all the other comments and created an issue for it too #45816.\r\nWhile making fields `enums`, I tried to create a baseline for unifying data models for bulk operations in general which could be applied for any unification for data models. I moved them in `common.py`. I have included `TODO` for further unification for `datamodels` from this story.', 'created_at': datetime.datetime(2025, 1, 20, 21, 16, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606799580, 'issue_id': 2793365971, 'author': 'pierrejeambrun', 'body': 'Nice', 'created_at': datetime.datetime(2025, 1, 22, 10, 4, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606860463, 'issue_id': 2793365971, 'author': 'potiuk', 'body': 'NIIIIICE!', 'created_at': datetime.datetime(2025, 1, 22, 10, 30, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607684237, 'issue_id': 2793365971, 'author': 'shubhamraj-git', 'body': 'Hey @bugraoz93 ,\r\nwe replaced `action_if_exists ` and `action_if_not_exists` with `action_on_existence`\r\n1. This contains, ""overwrite"", which would be not relevant in case of delete and update, and will fail.\r\n2. Also, `action_on_existence` seems misleading in case of update and delete, since the operations here were for if the value is not present and not on existence, when either it fails or skip.\r\n3. [In context of Pools bulk API] Since the PoolBulkCreateAction and PoolBulkUpdateAction models share the same structure (both have an action field and a pools list), pydantic may incorrectly parse an update action as a create action because it matches the first type (PoolBulkCreateAction) in the union. This issue here is because the PoolBulkCreateAction and PoolBulkUpdateAction have pools type as different list[PoolPostBody] and list[PoolPatchBody] respectively. [Can refer the below attached PR]\r\n\r\nWas this intentional? Or just a miss, in case I can rectify this in upcoming PR for bulk pool.\r\n\r\nFor now, based upon above comments, I have included that in https://github.com/apache/airflow/pull/45939', 'created_at': datetime.datetime(2025, 1, 22, 16, 19, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2608067378, 'issue_id': 2793365971, 'author': 'bugraoz93', 'body': '> Hey @bugraoz93 , we replaced `action_if_exists ` and `action_if_not_exists` with `action_on_existence`\r\n> \r\n> 1. This contains, ""overwrite"", which would be not relevant in case of delete and update, and will fail.\r\n> 2. Also, `action_on_existence` seems misleading in case of update and delete, since the operations here were for if the value is not present and not on existence, when either it fails or skip.\r\n> \r\n> Was this intentional? Or just a miss, in case I can rectify this in upcoming PR for bulk pool.\r\n\r\nHey @shubhamraj-git , \r\nThis was the baseline for making things common for the bulk endpoints so implementation is still from surface at the moment. I think things are getting clearer while we implement more use cases/endpoints. \r\n\r\nOn the documentation perspective `overwrite` is not relevant and it could be a side effect/bug since we are allowing to call the endpoints with `overwrite` in this case. I think we can drive from a parent `enum class` to make documentation nice and separate the `enum classes` according to action types. \r\n\r\nI am planning to do more unification for the datamodels in #45816. I can cover this one over there, it seems relevant. Please bring up anything in that issue to discuss more. Thanks for pointing out! I would be happy to bounce ideas and am going to tag you in the next PR.', 'created_at': datetime.datetime(2025, 1, 22, 19, 14, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2608081214, 'issue_id': 2793365971, 'author': 'shubhamraj-git', 'body': ""Thanks @bugraoz93 , Sounds great.\r\n\r\nFor now, I have solved the bug by removing the action_on_existence from BaseModel, and included that differently for create and (delete & update). This solves all the three issues. This can be later unified when you are working on https://github.com/apache/airflow/issues/45816 . Let me know if you need to do this in other way.\r\n\r\nAlso, I did this since the Pool Bulk PR https://github.com/apache/airflow/pull/45939 is ready, and this seems to be earliest solution, didn't brainstorm more, since you are already working on https://github.com/apache/airflow/issues/45816 which will anyways refactor these all."", 'created_at': datetime.datetime(2025, 1, 22, 19, 22, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2608090615, 'issue_id': 2793365971, 'author': 'bugraoz93', 'body': "">For now, based upon above comments, I have included that in https://github.com/apache/airflow/pull/45939\r\n\r\nI just saw this update after sending my message :) Feel free to change that part in your MR, I don't want to block you on that. Thanks!\r\n\r\n>For now, I have solved the bug by removing the action_on_existence from BaseModel, and included that differently for create and (delete & update). This solves all the three issues. This can be later unified when you are working on https://github.com/apache/airflow/issues/45816 . Let me know if you need to do this in other way.\r\n>\r\n>Also, I did this since the Pool Bulk PR https://github.com/apache/airflow/pull/45939 is ready, and this seems to be earliest solution, didn't brainstorm more, since you are already working on https://github.com/apache/airflow/issues/45816 which will anyways refactor these all.\r\n \r\nAmazing, thanks! Looks good! I agree, fixing is enough and no need for brainstorming. I was trying to not put the work on you (mostly updating tests since they are unified now) :) I can move from there."", 'created_at': datetime.datetime(2025, 1, 22, 19, 27, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2608136825, 'issue_id': 2793365971, 'author': 'pierrejeambrun', 'body': ""Nice guys, thanks for highlighting that @shubhamraj-git. Indeed that's a big part and the implementation is a little bit rough but i'm sure we will improve it iteratively. (sounds like we have a plan for that, I'll gladly review any PR on the front 😄)"", 'created_at': datetime.datetime(2025, 1, 22, 19, 53, 9, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2025-01-20 21:16:27 UTC): Thanks for the quick review! I updated the code according to the comments. 

I agree with all the other comments and created an issue for it too #45816.
While making fields `enums`, I tried to create a baseline for unifying data models for bulk operations in general which could be applied for any unification for data models. I moved them in `common.py`. I have included `TODO` for further unification for `datamodels` from this story.

pierrejeambrun on (2025-01-22 10:04:30 UTC): Nice

potiuk on (2025-01-22 10:30:46 UTC): NIIIIICE!

shubhamraj-git on (2025-01-22 16:19:47 UTC): Hey @bugraoz93 ,
we replaced `action_if_exists ` and `action_if_not_exists` with `action_on_existence`
1. This contains, ""overwrite"", which would be not relevant in case of delete and update, and will fail.
2. Also, `action_on_existence` seems misleading in case of update and delete, since the operations here were for if the value is not present and not on existence, when either it fails or skip.
3. [In context of Pools bulk API] Since the PoolBulkCreateAction and PoolBulkUpdateAction models share the same structure (both have an action field and a pools list), pydantic may incorrectly parse an update action as a create action because it matches the first type (PoolBulkCreateAction) in the union. This issue here is because the PoolBulkCreateAction and PoolBulkUpdateAction have pools type as different list[PoolPostBody] and list[PoolPatchBody] respectively. [Can refer the below attached PR]

Was this intentional? Or just a miss, in case I can rectify this in upcoming PR for bulk pool.

For now, based upon above comments, I have included that in https://github.com/apache/airflow/pull/45939

bugraoz93 (Issue Creator) on (2025-01-22 19:14:43 UTC): Hey @shubhamraj-git , 
This was the baseline for making things common for the bulk endpoints so implementation is still from surface at the moment. I think things are getting clearer while we implement more use cases/endpoints. 

On the documentation perspective `overwrite` is not relevant and it could be a side effect/bug since we are allowing to call the endpoints with `overwrite` in this case. I think we can drive from a parent `enum class` to make documentation nice and separate the `enum classes` according to action types. 

I am planning to do more unification for the datamodels in #45816. I can cover this one over there, it seems relevant. Please bring up anything in that issue to discuss more. Thanks for pointing out! I would be happy to bounce ideas and am going to tag you in the next PR.

shubhamraj-git on (2025-01-22 19:22:33 UTC): Thanks @bugraoz93 , Sounds great.

For now, I have solved the bug by removing the action_on_existence from BaseModel, and included that differently for create and (delete & update). This solves all the three issues. This can be later unified when you are working on https://github.com/apache/airflow/issues/45816 . Let me know if you need to do this in other way.

Also, I did this since the Pool Bulk PR https://github.com/apache/airflow/pull/45939 is ready, and this seems to be earliest solution, didn't brainstorm more, since you are already working on https://github.com/apache/airflow/issues/45816 which will anyways refactor these all.

bugraoz93 (Issue Creator) on (2025-01-22 19:27:22 UTC): I just saw this update after sending my message :) Feel free to change that part in your MR, I don't want to block you on that. Thanks!

 
Amazing, thanks! Looks good! I agree, fixing is enough and no need for brainstorming. I was trying to not put the work on you (mostly updating tests since they are unified now) :) I can move from there.

pierrejeambrun on (2025-01-22 19:53:09 UTC): Nice guys, thanks for highlighting that @shubhamraj-git. Indeed that's a big part and the implementation is a little bit rough but i'm sure we will improve it iteratively. (sounds like we have a plan for that, I'll gladly review any PR on the front 😄)

"
2793326394,pull_request,open,,Add pre-commit To Prevent Usage of session.query In Core Airflow ,"closes : #45461 
Introduce a pre-commit hook to prevent the use of `session.query` in the core Airflow code. 
This is limited to the source code and excludes the tests/ package. 


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Prab-27,2025-01-16 17:14:38+00:00,[],2025-01-18 01:45:01+00:00,,https://github.com/apache/airflow/pull/45714,"[('area:dev-tools', '')]","[{'comment_id': 2596354814, 'issue_id': 2793326394, 'author': 'Prab-27', 'body': ""a conflict occurred with the images, and I'm not sure how to resolve it. Would you please help me?"", 'created_at': datetime.datetime(2025, 1, 16, 17, 51, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596844944, 'issue_id': 2793326394, 'author': 'potiuk', 'body': 'as explained in slack - you can replace the confilcting images / .txt with either versions, rebase and re-run pre-commit. The images wil get regenerated to be ""latest"" automatically (in fact it should happen automatically when you rebase your PR and resolve the conflicts if you did `pre-commit install` before).', 'created_at': datetime.datetime(2025, 1, 16, 20, 38, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599459949, 'issue_id': 2793326394, 'author': 'Prab-27', 'body': 'Could you please clarify it for me?\r\n1 Is it okay to include` providers` in this pre-commit hook ?  \r\n2 Do I need to remove `session.query` from the codebases to pass this pre-commit check ?', 'created_at': datetime.datetime(2025, 1, 18, 1, 44, 29, tzinfo=datetime.timezone.utc)}]","Prab-27 (Issue Creator) on (2025-01-16 17:51:50 UTC): a conflict occurred with the images, and I'm not sure how to resolve it. Would you please help me?

potiuk on (2025-01-16 20:38:18 UTC): as explained in slack - you can replace the confilcting images / .txt with either versions, rebase and re-run pre-commit. The images wil get regenerated to be ""latest"" automatically (in fact it should happen automatically when you rebase your PR and resolve the conflicts if you did `pre-commit install` before).

Prab-27 (Issue Creator) on (2025-01-18 01:44:29 UTC): Could you please clarify it for me?
1 Is it okay to include` providers` in this pre-commit hook ?  
2 Do I need to remove `session.query` from the codebases to pass this pre-commit check ?

"
2793296604,pull_request,closed,,"Removed the ability for Operators to specify their own ""scheduling deps"".","This is not talking about the relationship between tasks, but the conditions
on an operator that the scheduler checks before it can be schedules -- things
like ""are my upstreams complete"" or ""am I out of my retry period"" etc)

With the split of Task SDK and Task Execution interface this feature has
become untennable to support with the split responsibilty mosel, and it is
such a rarely used feature that the right approach is to remove it.

This makes future code and PRs much much easier.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2025-01-16 17:00:01+00:00,[],2025-01-29 14:32:30+00:00,2025-01-17 10:43:47+00:00,https://github.com/apache/airflow/pull/45713,"[('area:serialization', ''), ('area:plugins', ''), ('type:misc/internal', 'Changelog: Misc changes that should appear in change log'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('area:task-sdk', None)]",[],
2793207204,pull_request,closed,,Bump trove-classifiers from 2025.1.10.15 to 2025.1.15.22,"Bumps [trove-classifiers](https://github.com/pypa/trove-classifiers) from 2025.1.10.15 to 2025.1.15.22.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/trove-classifiers/commit/5e6ed293a095c9a335198907911028108b38a747""><code>5e6ed29</code></a> Add CUDA 12.6 classifier (<a href=""https://redirect.github.com/pypa/trove-classifiers/issues/203"">#203</a>)</li>
<li>See full diff in <a href=""https://github.com/pypa/trove-classifiers/compare/2025.1.10.15...2025.1.15.22"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=trove-classifiers&package-manager=pip&previous-version=2025.1.10.15&new-version=2025.1.15.22)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2025-01-16 16:20:11+00:00,[],2025-01-16 20:01:38+00:00,2025-01-16 20:01:29+00:00,https://github.com/apache/airflow/pull/45712,"[('area:dependencies', 'Issues related to dependencies problems')]",[],
2793172832,pull_request,closed,,GitHook no longer depends on SSHHook,,jedcunningham,2025-01-16 16:05:34+00:00,[],2025-01-16 17:02:00+00:00,2025-01-16 17:01:57+00:00,https://github.com/apache/airflow/pull/45711,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2792839199,pull_request,closed,,Handle backfill for DAGs with no schedule,"Backfill does not work when a DAG has no schedule. Currently, we are adding backfill details to the `backfill` table even for DAGs without a schedule. As a result, the [_get_info_list](https://github.com/apache/airflow/blob/4fe78dd87673a809ca9b2aa42733b7b8447c0615/airflow/models/backfill.py#L349C28-L349C42) method does not return any details for such DAGs, and no dag_run is created in `backfill_dag_run` table. This creates a false impression for users that a backfill has been created, even though no backfill DAG run exists. This PR addresses and resolves this issue.
<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2025-01-16 13:50:37+00:00,[],2025-01-16 17:44:09+00:00,2025-01-16 17:44:07+00:00,https://github.com/apache/airflow/pull/45709,[],"[{'comment_id': 2595905624, 'issue_id': 2792839199, 'author': 'vatsrahul1001', 'body': '> Can you provide more context on why you are doing this change, in the description?\r\n\r\nUpdated @phanikumv, I missed it.', 'created_at': datetime.datetime(2025, 1, 16, 14, 39, 28, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2025-01-16 14:39:28 UTC): Updated @phanikumv, I missed it.

"
2792745490,pull_request,closed,,Improve grammar in cloud_composer.rst,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",aaabramov,2025-01-16 13:16:48+00:00,[],2025-01-16 19:59:20+00:00,2025-01-16 19:59:16+00:00,https://github.com/apache/airflow/pull/45708,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2595637603, 'issue_id': 2792745490, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 16, 13, 16, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596782629, 'issue_id': 2792745490, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 16, 19, 59, 19, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-16 13:16:53 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2025-01-16 19:59:19 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2792338532,pull_request,closed,,Refactor DAG not found handling for backfills,"Currently, we are getting HTTP500 with FastAPI when we try to create a backfill for non exiting DAG. This better handles it better. 


**Before:**
<img width=""1470"" alt=""image"" src=""https://github.com/user-attachments/assets/25a3925b-017b-42af-86e6-26683510c88f"" />
<img width=""521"" alt=""image"" src=""https://github.com/user-attachments/assets/e56daa9f-4188-4743-9fb0-774ecf158344"" />

**Now:**
<img width=""1480"" alt=""image"" src=""https://github.com/user-attachments/assets/c9dae496-535a-4356-8889-b930d662419c"" />

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2025-01-16 10:36:45+00:00,[],2025-01-17 08:17:57+00:00,2025-01-17 08:17:54+00:00,https://github.com/apache/airflow/pull/45707,[],[],
2792259630,pull_request,closed,,feat: Add Hook Level Lineage support for BigQueryHook,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Adding hook level lineage support for GCS Hook. Similar PR for GCS Hook: #42507


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2025-01-16 10:04:42+00:00,[],2025-01-16 14:15:15+00:00,2025-01-16 14:14:26+00:00,https://github.com/apache/airflow/pull/45706,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2792256706,pull_request,open,,"Deprecating email, email_on_retry, email_on_failure in `BaseOperator`","This PR is against **v2-10-test**

I'd like to make sure we deliver deprecation notice as early as possible.
Users should migrate to SmtpNotifier. Email is just another notification integration it should not be favoured by Airflow core.
We have a very nice template introduced in https://github.com/apache/airflow/pull/36226 so migration should be simple enough.

Removal of email integration from main branch will be handled as part of https://github.com/apache/airflow/pull/30531",eladkal,2025-01-16 10:03:45+00:00,[],2025-01-23 12:20:27+00:00,,https://github.com/apache/airflow/pull/45705,[],"[{'comment_id': 2603832863, 'issue_id': 2792256706, 'author': 'uranusjr', 'body': 'Not specific to this PR, are patches to v2-10-test at this point going into a 2.10 patch release, or 2.11.0?', 'created_at': datetime.datetime(2025, 1, 21, 7, 18, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603837850, 'issue_id': 2792256706, 'author': 'eladkal', 'body': ""> Not specific to this PR, are patches to v2-10-test at this point going into a 2.10 patch release, or 2.11.0?\r\n\r\nDepends on what if we decide to do 2.11 - I think this was not yet decided in the last dev call.\r\nRegardless 2.11 branch will be cut from 2.10 branch so from PRs point of view it's the same process for merging"", 'created_at': datetime.datetime(2025, 1, 21, 7, 21, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609408727, 'issue_id': 2792256706, 'author': 'utkarsharma2', 'body': '@eladkal I think we need to add `ignore::RemovedInAirflow3Warning` in [pyproject.py](https://github.com/apache/airflow/blob/f01c53a73573a5dacb2107944d32a5fd731d64f6/pyproject.toml#L468) for the tests to pass.', 'created_at': datetime.datetime(2025, 1, 23, 10, 15, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609669963, 'issue_id': 2792256706, 'author': 'eladkal', 'body': ""> @eladkal I think we need to add `ignore::RemovedInAirflow3Warning` in [pyproject.py](https://github.com/apache/airflow/blob/f01c53a73573a5dacb2107944d32a5fd731d64f6/pyproject.toml#L468) for the tests to pass.\r\n\r\nWe can't because of\r\n\r\nhttps://github.com/apache/airflow/blob/f01c53a73573a5dacb2107944d32a5fd731d64f6/pyproject.toml#L492-L499\r\n\r\nThe issue is `RemovedInAirflow3Warning` already there yet tests are failing"", 'created_at': datetime.datetime(2025, 1, 23, 12, 20, 25, tzinfo=datetime.timezone.utc)}]","uranusjr on (2025-01-21 07:18:03 UTC): Not specific to this PR, are patches to v2-10-test at this point going into a 2.10 patch release, or 2.11.0?

eladkal (Issue Creator) on (2025-01-21 07:21:15 UTC): Depends on what if we decide to do 2.11 - I think this was not yet decided in the last dev call.
Regardless 2.11 branch will be cut from 2.10 branch so from PRs point of view it's the same process for merging

utkarsharma2 on (2025-01-23 10:15:07 UTC): @eladkal I think we need to add `ignore::RemovedInAirflow3Warning` in [pyproject.py](https://github.com/apache/airflow/blob/f01c53a73573a5dacb2107944d32a5fd731d64f6/pyproject.toml#L468) for the tests to pass.

eladkal (Issue Creator) on (2025-01-23 12:20:25 UTC): We can't because of

https://github.com/apache/airflow/blob/f01c53a73573a5dacb2107944d32a5fd731d64f6/pyproject.toml#L492-L499

The issue is `RemovedInAirflow3Warning` already there yet tests are failing

"
2792198810,pull_request,closed,,Prevent get_connection from being called in example_dags,"Follow up after #45690

Wee already had protection against example dags not using database, but it turns out that just calling get_connection() of the BaseHook involves calling out to secrets manager which - depending on the configuration, providers and where it is called - might cause external calls, timeout and various side effects.

This PR adds explicit test for that. As part of the change we also added `--load-example-dags` and `--load-default-connections` to breeze shell as it allows to easily test the case where default connections are loaded in the database.

Note that the ""example_bedrock_retrieve_and_generate"" explicitly avoided attempting to load the connections by specifing aws_conn_id to None, because it was likely causing problems with fetching SSM when get_connection was actually called during dag parsing, so this aws_conn_id = None would also bypass this check, but we can't do much about it - at least after this chanege, the contributor will see failing test with explicit ""get_connection() should not be called during DAG parsing"".

That also makes the example dag more of a ""real"" example as it does not nullify the connection id and it can use ""aws_default"" connection to actually ... be a good example. Also it allows to run the example dag as system test for someone who would like to do it with ""aws_default"" as a connection id to connect to their AWS account.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-16 09:43:07+00:00,[],2025-01-16 20:53:14+00:00,2025-01-16 20:53:12+00:00,https://github.com/apache/airflow/pull/45704,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:dev-tools', '')]","[{'comment_id': 2595121668, 'issue_id': 2792198810, 'author': 'potiuk', 'body': '> get_connection isn\'t used/called for the BedrockAgentHook in example_bedrock_retrieve_and_generate.py (nor in any of the AwsHooks either) so I don\'t think this test is enough as it stands\r\n\r\nYes. It was not called when aws_hook_conn_id was None - it fall-back to ""default"" retrieval (i.e. from AWS env vars or workload identity). But if you leave conn_id as default, it will try to get connection first', 'created_at': datetime.datetime(2025, 1, 16, 10, 18, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595129236, 'issue_id': 2792198810, 'author': 'potiuk', 'body': '> > get_connection isn\'t used/called for the BedrockAgentHook in example_bedrock_retrieve_and_generate.py (nor in any of the AwsHooks either) so I don\'t think this test is enough as it stands\r\n> \r\n> Yes. It was not called when aws_hook_conn_id was None - it fall-back to ""default"" retrieval (i.e. from AWS env vars or workload identity). But if you leave conn_id as default, it will try to get connection first\r\n\r\nThis is actually what I found out while testing it. I reverted https://github.com/apache/airflow/pull/45690 and indeed get_connection was not called - not until I removed ""aws_conn_id=None"" in the original code. But it was called after I removed it and the test nicely failed as expected.\r\n\r\n(you can actually even see all that in the PR description :) )', 'created_at': datetime.datetime(2025, 1, 16, 10, 21, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595160874, 'issue_id': 2792198810, 'author': 'potiuk', 'body': ""BTW. I can split out the breeze change if needed. It's related (as it allowed to test me what happens when the default connections are / aren't defined - but it's a different change :)"", 'created_at': datetime.datetime(2025, 1, 16, 10, 36, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595169596, 'issue_id': 2792198810, 'author': 'ashb', 'body': ""Out of interest how long does this new test take? It's possible we could add this to the existing `tests/serialization/test_dag_serialization.py::TestStringifiedDAGs::test_serialization` test which loads all example dags."", 'created_at': datetime.datetime(2025, 1, 16, 10, 39, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595200236, 'issue_id': 2792198810, 'author': 'potiuk', 'body': '> Out of interest how long does this new test take? It\'s possible we could add this to the existing `tests/serialization/test_dag_serialization.py::TestStringifiedDAGs::test_serialization` test which loads all example dags.\r\n\r\nThis particular test takes less than few seconds or so when run for the whole test module.\r\n\r\nBut this is because -  if you look above - there are two earliert tests like that already - > whether example_dags are importable (this is run first) and whether there are no DB calls (second), and the first one takes all the bulk time of importing all the classes from all the providers - the DB and now the ""get_connection"" test are of course order of magnitude faster after all those classes are imported in ""importable"". I think all of the tests takes 60s or so - including first time DB intialization.\r\n\r\nWe could potentially combine all those tests together as a (slight) optimisation, but I think that would be at a huge expense of concern separation. It\'s a bit cumbersome, counter-intuitive and confusing to test ""importability"" ""db access"" and ""get_connection"" access in dag serialization and vice-versa. So I think it\'s better to leave them separate even if they are slightly ""slower"".', 'created_at': datetime.datetime(2025, 1, 16, 10, 53, 21, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-16 10:18:10 UTC): Yes. It was not called when aws_hook_conn_id was None - it fall-back to ""default"" retrieval (i.e. from AWS env vars or workload identity). But if you leave conn_id as default, it will try to get connection first

potiuk (Issue Creator) on (2025-01-16 10:21:44 UTC): This is actually what I found out while testing it. I reverted https://github.com/apache/airflow/pull/45690 and indeed get_connection was not called - not until I removed ""aws_conn_id=None"" in the original code. But it was called after I removed it and the test nicely failed as expected.

(you can actually even see all that in the PR description :) )

potiuk (Issue Creator) on (2025-01-16 10:36:15 UTC): BTW. I can split out the breeze change if needed. It's related (as it allowed to test me what happens when the default connections are / aren't defined - but it's a different change :)

ashb on (2025-01-16 10:39:48 UTC): Out of interest how long does this new test take? It's possible we could add this to the existing `tests/serialization/test_dag_serialization.py::TestStringifiedDAGs::test_serialization` test which loads all example dags.

potiuk (Issue Creator) on (2025-01-16 10:53:21 UTC): This particular test takes less than few seconds or so when run for the whole test module.

But this is because -  if you look above - there are two earliert tests like that already - > whether example_dags are importable (this is run first) and whether there are no DB calls (second), and the first one takes all the bulk time of importing all the classes from all the providers - the DB and now the ""get_connection"" test are of course order of magnitude faster after all those classes are imported in ""importable"". I think all of the tests takes 60s or so - including first time DB intialization.

We could potentially combine all those tests together as a (slight) optimisation, but I think that would be at a huge expense of concern separation. It's a bit cumbersome, counter-intuitive and confusing to test ""importability"" ""db access"" and ""get_connection"" access in dag serialization and vice-versa. So I think it's better to leave them separate even if they are slightly ""slower"".

"
2792080519,pull_request,closed,, Fix empty task instance for log (#45702),Backport of https://github.com/apache/airflow/pull/45702,jscheffl,2025-01-16 08:51:07+00:00,[],2025-01-16 15:46:34+00:00,2025-01-16 15:46:34+00:00,https://github.com/apache/airflow/pull/45703,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2791959491,pull_request,closed,,Fix empty task instance for log,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",MishchenkoYuriy,2025-01-16 07:56:59+00:00,[],2025-01-16 08:41:55+00:00,2025-01-16 08:41:09+00:00,https://github.com/apache/airflow/pull/45702,"[('area:webserver', 'Webserver related Issues'), ('type:bug-fix', 'Changelog: Bug Fixes'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2594759664, 'issue_id': 2791959491, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 16, 7, 57, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594872649, 'issue_id': 2791959491, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 16, 8, 41, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594875779, 'issue_id': 2791959491, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12805111435\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/e8f55b3a3d4e45285c6f11099794ddceb6ea4491""><img src=\'https://img.shields.io/badge/Commit-e8f55b3-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker e8f55b3 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2025, 1, 16, 8, 41, 53, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-16 07:57:04 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2025-01-16 08:41:12 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

github-actions[bot] on (2025-01-16 08:41:53 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12805111435'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/e8f55b3a3d4e45285c6f11099794ddceb6ea4491""><img src='https://img.shields.io/badge/Commit-e8f55b3-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker e8f55b3 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2791934250,pull_request,closed,,"Extend and fix ""airflow config lint"" rules","* feat
    * warn `webserver.cookie_samesite` usage
        * config removed 
    * warn `core.dataset_manager_class` and `core.dataset_manager_kwargs` usage
        * replace them with `core.asset_manager_class` and `core.asset_manager_kwargs` 
* fix
    * warn `strict_dataset_uri_validation` instead of `strict_asset_uri_validation`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2025-01-16 07:42:24+00:00,[],2025-01-17 08:35:26+00:00,2025-01-17 08:35:25+00:00,https://github.com/apache/airflow/pull/45701,"[('area:CLI', '')]",[],
2791710251,pull_request,closed,,Always use standalone DAG processor in breeze,"We are moving to only support a standalone DAG processor in Airflow 3, so let's switch breeze to always use a standalone DAG processor.",jedcunningham,2025-01-16 05:02:22+00:00,[],2025-01-16 21:46:44+00:00,2025-01-16 21:46:43+00:00,https://github.com/apache/airflow/pull/45699,"[('area:dev-tools', '')]","[{'comment_id': 2596962223, 'issue_id': 2791710251, 'author': 'potiuk', 'body': 'Closing after merging https://github.com/apache/airflow/pull/45723', 'created_at': datetime.datetime(2025, 1, 16, 21, 46, 43, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-16 21:46:43 UTC): Closing after merging https://github.com/apache/airflow/pull/45723

"
2791605187,pull_request,closed,,Use standalone DAG processor in standalone command,"We are moving to only support a standalone DAG processor in Airflow 3, so let's switch the standalone command to use it.",jedcunningham,2025-01-16 03:27:15+00:00,[],2025-01-16 16:06:06+00:00,2025-01-16 16:06:04+00:00,https://github.com/apache/airflow/pull/45698,"[('area:CLI', ''), ('kind:documentation', '')]",[],
2791235758,pull_request,closed,,Move config item dag_bundle_storage_path to dag_bundles section,"Just as title says. Also, rename backends to config_list.",dstandish,2025-01-15 23:35:51+00:00,[],2025-01-17 16:26:24+00:00,2025-01-17 16:26:22+00:00,https://github.com/apache/airflow/pull/45697,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2791067355,pull_request,closed,,Update Simple auth manager to define its UI (login form) using fastapi,"`SimpleAuthManager` is a minimalist auth manager in core Airflow. It defines its own login form in order for users to log in. Example below:

![Screenshot 2025-01-15 at 5 06 01 PM](https://github.com/user-attachments/assets/9070abec-0c13-4193-8a49-9753e5d137a9)

Simple auth manager has its UI defined using Flask, you can then use it with Airflow 2 UI. But the goal is to use simple auth manager in Airflow 3. In order to use simple auth manager with Airflow 3 UI, we need to implement its views in the fastapi application. This is the goal of this PR.

After this PR is merged, I'll remove the UI/views definitions of simple auth manager in Flask. We do not need the simple auth manager to be compatible with Airflow 2 UI (although that was necessary for testing it).

As a result of this PR, multiple endpoints are added:
- <env_endpoint>/auth/webapp/login: the login form
- <env_endpoint>/auth/static/assets/index-......js: the JS/React artifact defining the login form
- POST <env_endpoint>/auth/token: to create a JWT token given username and password

(Sorry for the massive PR).

### Testing

To test this PR and play around with the simple auth manager login form:

* Set export `AIRFLOW__CORE__AUTH_MANAGER=""airflow.auth.managers.simple.simple_auth_manager.SimpleAuthManager""`
* In `airflow/auth/managers/simple/ui/`, run npm run build. I need to update the pre-commit script to do that automatically
* Run Airflow and go to <endpoint>/auth/webapp/login

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-15 22:16:55+00:00,[],2025-01-27 13:00:23+00:00,2025-01-23 19:08:53+00:00,https://github.com/apache/airflow/pull/45696,"[('area:dev-tools', ''), ('type:improvement', 'Changelog: Improvements')]","[{'comment_id': 2596839843, 'issue_id': 2791067355, 'author': 'vincbeck', 'body': ""> Tested locally. It works!\r\n> \r\n> I'd like us to match the main UI's setup a bit more. Use `pnpm` instead of `npm` and I want to see if we can share the same linting/prettier rules.\r\n\r\nI agree that would be great. I made multiple tries but could not come up with something working. Typescript could not recognize types defined in the simple auth manager UI directory. We could give it another try later. I dont think this is a must have for now"", 'created_at': datetime.datetime(2025, 1, 16, 20, 34, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602610114, 'issue_id': 2791067355, 'author': 'vincbeck', 'body': ""> That's a little unclear for me where we're at and what we want to do for auth managers.\r\n> \r\n> For other auth managers, especially FAB one, do we plan to use the flask middleware to be able to render all of those flask views into fastapi ? (avoiding the flask <-> fastapi convertion, I think this is what was suggested by Jed.)\r\n> \r\n> Then we only do this work for the simple auth manager because we do not need backward compat and because it's more convenient to have that in native FastAPI ?\r\n\r\nYes to everything :)\r\n\r\nEdit: more details. Mainly because it does not make sense to define the UI in Flask in core Airflow while the future of Airflow is clearly fastapi."", 'created_at': datetime.datetime(2025, 1, 20, 14, 45, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2602922129, 'issue_id': 2791067355, 'author': 'jedcunningham', 'body': 'tldr core + simple auth manager should not require flask to be installed at all.\r\n\r\nThat ship has already sailed if you are using the fab auth manager though, so might as well use the middleware and not rewrite stuff.', 'created_at': datetime.datetime(2025, 1, 20, 17, 9, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603009251, 'issue_id': 2791067355, 'author': 'vincbeck', 'body': '> tldr core + simple auth manager should not require flask to be installed at all.\r\n> \r\n> That ship has already sailed if you are using the fab auth manager though, so might as well use the middleware and not rewrite stuff.\r\n\r\nYep, this is what I did in #45765 for FAB :)', 'created_at': datetime.datetime(2025, 1, 20, 18, 5, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2603294050, 'issue_id': 2791067355, 'author': 'vincbeck', 'body': 'Any other concerns/questions?', 'created_at': datetime.datetime(2025, 1, 20, 22, 12, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605123850, 'issue_id': 2791067355, 'author': 'vincbeck', 'body': 'Question for the audience :)\r\n\r\nI am looking into updating the basic tests to include tests from the simple auth manager UI as part of the [tests-ui](https://github.com/apache/airflow/blob/main/.github/workflows/basic-tests.yml#L87). Some caching is done that I am not familiar with. Do I need to do the same or just\r\n\r\n```\r\n- run: cd airflow/auth/managers/simple/ui && pnpm install --frozen-lockfile\r\n- run: cd airflow/auth/managers/simple/ui && pnpm test\r\n  env:\r\n    FORCE_COLOR: 2\r\n```', 'created_at': datetime.datetime(2025, 1, 21, 15, 58, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605126975, 'issue_id': 2791067355, 'author': 'vincbeck', 'body': '> > Any other concerns/questions?\r\n> \r\n> No, thanks for answering my questions.\r\n> \r\n> Overall code looks good and I agree with the general approach.\r\n> \r\n> I think Brent is already working on a detailed review and functional testing.\r\n\r\nFantastic! Thank you :)', 'created_at': datetime.datetime(2025, 1, 21, 16, 0, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605160908, 'issue_id': 2791067355, 'author': 'pierrejeambrun', 'body': '> Question for the audience :)\r\n\r\n> I am looking into updating the basic tests to include tests from the simple auth manager UI as part of the [tests-ui](https://github.com/apache/airflow/blob/main/.github/workflows/basic-tests.yml#L87). Some caching is done that I am not familiar with. Do I need to do the same or just\r\n\r\n\r\nI am not super familiar with this workflow but by the look of it I would say that caching the node_modules is always helpful. I think we can just follow the same logic and apply that to the `airflow/auth/managers/simple/ui/node_modules` folder.\r\n(basically duplicating the Restore and Save cache steps before and after the `pnpm install`)', 'created_at': datetime.datetime(2025, 1, 21, 16, 11, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2608236694, 'issue_id': 2791067355, 'author': 'vincbeck', 'body': '~~I dont understand what is going on ... The command `breeze release-management prepare-airflow-package --package-format wheel` fails because the pre-commit `Compile ui assets (manual)` fails because of `sh: 1: vite: not found`. See [error](https://github.com/apache/airflow/actions/runs/12916300336/job/36020735118?pr=45696).~~\r\n\r\n~~However when I run the script `scripts/ci/pre_commit/compile_ui_assets.py` locally, it works like a charm. `vite` is listed in `package.json` so I really dont understand why it cannot find it~~\r\n\r\nEDIT: I found it', 'created_at': datetime.datetime(2025, 1, 22, 20, 50, 47, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2025-01-16 20:34:49 UTC): I agree that would be great. I made multiple tries but could not come up with something working. Typescript could not recognize types defined in the simple auth manager UI directory. We could give it another try later. I dont think this is a must have for now

vincbeck (Issue Creator) on (2025-01-20 14:45:57 UTC): Yes to everything :)

Edit: more details. Mainly because it does not make sense to define the UI in Flask in core Airflow while the future of Airflow is clearly fastapi.

jedcunningham on (2025-01-20 17:09:11 UTC): tldr core + simple auth manager should not require flask to be installed at all.

That ship has already sailed if you are using the fab auth manager though, so might as well use the middleware and not rewrite stuff.

vincbeck (Issue Creator) on (2025-01-20 18:05:03 UTC): Yep, this is what I did in #45765 for FAB :)

vincbeck (Issue Creator) on (2025-01-20 22:12:10 UTC): Any other concerns/questions?

vincbeck (Issue Creator) on (2025-01-21 15:58:56 UTC): Question for the audience :)

I am looking into updating the basic tests to include tests from the simple auth manager UI as part of the [tests-ui](https://github.com/apache/airflow/blob/main/.github/workflows/basic-tests.yml#L87). Some caching is done that I am not familiar with. Do I need to do the same or just

```
- run: cd airflow/auth/managers/simple/ui && pnpm install --frozen-lockfile
- run: cd airflow/auth/managers/simple/ui && pnpm test
  env:
    FORCE_COLOR: 2
```

vincbeck (Issue Creator) on (2025-01-21 16:00:12 UTC): Fantastic! Thank you :)

pierrejeambrun on (2025-01-21 16:11:42 UTC): I am not super familiar with this workflow but by the look of it I would say that caching the node_modules is always helpful. I think we can just follow the same logic and apply that to the `airflow/auth/managers/simple/ui/node_modules` folder.
(basically duplicating the Restore and Save cache steps before and after the `pnpm install`)

vincbeck (Issue Creator) on (2025-01-22 20:50:47 UTC): ~~I dont understand what is going on ... The command `breeze release-management prepare-airflow-package --package-format wheel` fails because the pre-commit `Compile ui assets (manual)` fails because of `sh: 1: vite: not found`. See [error](https://github.com/apache/airflow/actions/runs/12916300336/job/36020735118?pr=45696).~~

~~However when I run the script `scripts/ci/pre_commit/compile_ui_assets.py` locally, it works like a charm. `vite` is listed in `package.json` so I really dont understand why it cannot find it~~

EDIT: I found it

"
2790856483,pull_request,closed,,Handle removed source by removal of installed packages,"When breeze is run with sources removed, we need to also remove editable distributions installed from those sources.

If we do not do it, ModuleNotFoundError is thrown where entrypoints or distribution information are loaded.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-15 20:49:48+00:00,[],2025-01-16 07:14:41+00:00,2025-01-15 21:51:33+00:00,https://github.com/apache/airflow/pull/45695,"[('area:dev-tools', '')]","[{'comment_id': 2593988661, 'issue_id': 2790856483, 'author': 'gopidesupavan', 'body': 'Cool :)', 'created_at': datetime.datetime(2025, 1, 15, 21, 37, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594695116, 'issue_id': 2790856483, 'author': 'potiuk', 'body': ""> I am (another time) astonished how fast you find the root cause, I feel I would have searched for at least an hour to know what to fix,,,,\r\n\r\n:D.  About 5 years of doing the stuff :).  The trick is like with Sherlock Holmes's deduction. I just know where to NOT look and what's left are just a few places to check."", 'created_at': datetime.datetime(2025, 1, 16, 7, 14, 40, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2025-01-15 21:37:11 UTC): Cool :)

potiuk (Issue Creator) on (2025-01-16 07:14:40 UTC): :D.  About 5 years of doing the stuff :).  The trick is like with Sherlock Holmes's deduction. I just know where to NOT look and what's left are just a few places to check.

"
2790829412,pull_request,closed,,AIP-72: Support DAG parsing context in Task SDK,"closes https://github.com/apache/airflow/issues/45693

Adds support for the Magic Loop: https://airflow.apache.org/docs/apache-airflow/stable/howto/dynamic-dag-generation.html#optimizing-dag-parsing-delays-during-execution with Task SDK

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-15 20:39:50+00:00,[],2025-01-16 09:09:14+00:00,2025-01-15 22:23:03+00:00,https://github.com/apache/airflow/pull/45694,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('provider:celery', ''), ('airflow3.0:breaking', 'Candidates for Airflow 3.0 that contain breaking changes'), ('area:task-sdk', None)]","[{'comment_id': 2594014121, 'issue_id': 2790829412, 'author': 'kaxil', 'body': '> Looks good, but we likely need a compat import shim for `airflow/utils/dag_parsing_context.py` -- do we have a place to capture those anywhere.\r\n> \r\n> Also cc @Lee-W @uranusjr Another deprecated import to track in Ruff please.\r\n\r\nGood point, Yeah, https://github.com/apache/airflow/issues/41641\r\n\r\nAdded newsfragment too', 'created_at': datetime.datetime(2025, 1, 15, 21, 52, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594956778, 'issue_id': 2790829412, 'author': 'Lee-W', 'body': 'ruff PR created https://github.com/astral-sh/ruff/pull/15525', 'created_at': datetime.datetime(2025, 1, 16, 9, 9, 13, tzinfo=datetime.timezone.utc)}]","kaxil (Issue Creator) on (2025-01-15 21:52:41 UTC): Good point, Yeah, https://github.com/apache/airflow/issues/41641

Added newsfragment too

Lee-W on (2025-01-16 09:09:13 UTC): ruff PR created https://github.com/astral-sh/ruff/pull/15525

"
2790698225,pull_request,closed,,Just fixing an incomplete comment I came acros.,"@ashb got distracted by a squirrel. :rofl: 



<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ferruzzi,2025-01-15 19:47:21+00:00,[],2025-01-16 03:43:10+00:00,2025-01-16 03:43:10+00:00,https://github.com/apache/airflow/pull/45692,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2790571556,pull_request,closed,,Improve speed of tests by not creating connections at parse time,"The DAG serialization tests load all of the example and system test DAGs, and
there were two places that these tests opened connections at parse time
resulting in loads of extra of test time.

- The SystemTestContextBuilder was trying to fetch things from SSM. This was
  addressed by adding a functools.cache on the function
- The Bedrock example dag was setting/caching the underlying conn object
  globally. This was addressed by making the Airflow connection a global,
  rather than the Bedrock conn. This fix is not _great_, but it does massively
  help

Before:

> 111 passed, 1 warning in 439.37s (0:07:19)

After:

> 111 passed, 1 warning in 71.76s (0:01:11)
",ashb,2025-01-15 18:35:25+00:00,[],2025-01-21 13:43:13+00:00,2025-01-15 21:56:39+00:00,https://github.com/apache/airflow/pull/45690,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2593703147, 'issue_id': 2790571556, 'author': 'ashb', 'body': 'Prepare package failed due to a node tls timeout', 'created_at': datetime.datetime(2025, 1, 15, 18, 50, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595051640, 'issue_id': 2790571556, 'author': 'potiuk', 'body': '> That Bedrock one was on me. I thought I was just saving a bunch of repetition and didn\'t realize the impact of that small change. Well spotted, and thanks for fixing it.\r\n\r\nAs part of ""clearing the path""  - here is https://github.com/apache/airflow/pull/45704 as a follow up to prevent it in the future.\r\n\r\nWith one caveat .... the test would not have caught the error in this case because `aws_conn_id` was set to None, so actually ... get_connection() was not called. But I think that\'s something we cannot actually easily prevent, but it\'s a bit of bad practice to set aws_conn_id for ""example_dags"" - because it makes it ... bad example , and not good candidates to run as system tests. \r\n\r\nThe added test will make it quite obvious though: when someone adds example_dag with `get_connection` retrieval, the error will be:\r\n\r\n```\r\n  f""BaseHook.get_connection() should not be called during DAG parsing. ""\r\n  f""It was called {mock_get_connection.call_count} times. Please make sure that no ""\r\n  ""connections are created during DAG parsing. NOTE! Do not set conn_id to None to avoid it, just make ""\r\n  ""sure that you do not create connection object in the `__init__` method of your operator.""\r\n```\r\n\r\nI hope this will be helpful to avoid such mistake  in the future :)', 'created_at': datetime.datetime(2025, 1, 16, 9, 51, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604454603, 'issue_id': 2790571556, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45826""><img src=""https://img.shields.io/badge/PR-45826-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2025, 1, 21, 11, 23, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604774988, 'issue_id': 2790571556, 'author': 'potiuk', 'body': 'BTW. There was no need to backport this one - provider tests are skipped on v2-10-test.', 'created_at': datetime.datetime(2025, 1, 21, 13, 43, 11, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2025-01-15 18:50:30 UTC): Prepare package failed due to a node tls timeout

potiuk on (2025-01-16 09:51:46 UTC): As part of ""clearing the path""  - here is https://github.com/apache/airflow/pull/45704 as a follow up to prevent it in the future.

With one caveat .... the test would not have caught the error in this case because `aws_conn_id` was set to None, so actually ... get_connection() was not called. But I think that's something we cannot actually easily prevent, but it's a bit of bad practice to set aws_conn_id for ""example_dags"" - because it makes it ... bad example , and not good candidates to run as system tests. 

The added test will make it quite obvious though: when someone adds example_dag with `get_connection` retrieval, the error will be:

```
  f""BaseHook.get_connection() should not be called during DAG parsing. ""
  f""It was called {mock_get_connection.call_count} times. Please make sure that no ""
  ""connections are created during DAG parsing. NOTE! Do not set conn_id to None to avoid it, just make ""
  ""sure that you do not create connection object in the `__init__` method of your operator.""
```

I hope this will be helpful to avoid such mistake  in the future :)

github-actions[bot] on (2025-01-21 11:23:13 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45826""><img src=""https://img.shields.io/badge/PR-45826-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

potiuk on (2025-01-21 13:43:11 UTC): BTW. There was no need to backport this one - provider tests are skipped on v2-10-test.

"
2790489179,pull_request,closed,,Remove `airflow/compat/` dir,"The last module in this dir was removed in https://github.com/apache/airflow/pull/42766

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-15 17:57:06+00:00,[],2025-01-15 18:48:53+00:00,2025-01-15 18:48:51+00:00,https://github.com/apache/airflow/pull/45689,[],[],
2790482120,pull_request,closed,,Remove redundant `airflow/utils/empty_set.py`,"This is now no longer needed as we removed `set` function in this file in https://github.com/apache/airflow/pull/43530

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-15 17:53:26+00:00,[],2025-01-15 18:26:13+00:00,2025-01-15 18:26:11+00:00,https://github.com/apache/airflow/pull/45688,"[('area:dev-tools', '')]",[],
2790468326,pull_request,closed,,Remove unused `ParamSpec`,"This isn't used in the file

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-15 17:46:16+00:00,[],2025-01-15 18:49:07+00:00,2025-01-15 18:49:05+00:00,https://github.com/apache/airflow/pull/45687,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2790232469,pull_request,open,,[draft] AIP-85 PoC,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
This is a simple draft with PoC of AIP-85 https://cwiki.apache.org/confluence/display/AIRFLOW/AIP-85+Extendable+DAG+parsing+controls.

The key highlights and proposed interfaces/implementations are:
1) `airflow/dag_processing/dag_importer.py`: DagImporter - a mechanism abstracting a way of how a ""path"" is translated into one or more parsed DAGs. 
   - Default implementation is `FSDagImporter` (`airflow/dag_processing/fs_dag_importer.py`) - read a DAG from definition in a Python file. 
   - Alternative ""demo"" implementation - `NotebooksImporter` (`providers/src/airflow/providers/google/common/importers/notebooks_importer.py`), which imports Python definitions from Jupyter notebook files (for demonstration purposes only, not part of the actual AIP).

2) `airflow/dag_processing/dag_ingester.py`: DagIngester - a mechanism to abstract away the logic of operations of parsing/adding/updating/removing DAGs and their importing metadata (i.e. importing errors/warnings). Sample implementations:
   - Continuous ingester (`airflow/dag_processing/continuous_ingester.py`) - replication of the current regular dag-processor paring logic (by reusing current DagFileProcessingManagers)
   - Once ingester (`airflow/dag_processing/once_ingester.py`) - ingester that only imports DAGs once

Those 2 interfaces (that are allowed to be extended by providers/core Airflow) build a foundation to address AIP-85 requirements - increase flexibility of how DAGs are being updated and how they can be defined.

Apart from that, DagBag usage is replaced in most places with one of the following components:
  - DagStore (`airflow/dag_processing/dag_store.py`) - access to Airflow DAGs in metadata DBs (no access to DAG sources required). Used by any component that requires access to DAG's metadata (i.e. by scheduler, public API, etc.).
  - DagParser (`airflow/dag_processing/dag_parser.py`) - access to parsed DAGs (used by worker and dag-processor).

A lot of things are ""swept under the rug"" here as this is just a PoC based on an older Airflow branch before most of Airflow 3 changes landed. Big things that are missing:
  - Callbacks are not yet moved to a separate component (temporarily disabled)
  - Integration with bundles
  - Missing optimizations around module importing
  - DagCode is not propagated for non-FSDagImporter


**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",IKholopov,2025-01-15 15:59:43+00:00,[],2025-01-15 15:59:48+00:00,,https://github.com/apache/airflow/pull/45684,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API"")]",[],
2790073641,pull_request,closed,,Catch BaseException (excpt ctrl-c) when parsing DAG files.,"This doesn't affect ""production""/when running the dag parser normally as it
runs things in a subprocess per dag file already, but in our tests, especially
the serialized DAG ones, we often process files directly.

I discovered this when running tests locally where I didn't have the required
packages for Terradata installed and this... caused the entire test to be
skipped!

This is because the example dag file has `pytest.skip()` in a try/exepct
ImportError block, and since that exception does not inherit from Exception
(only BaseExecption) it was bubbling all the way up to the pytest runner and
causing `TestStringifiedDAGs::test_serialization` to be marked as skipped --
not really what we want. This change will also now make it capture `exit()` in
a DAG file and record that as an import error where as before I think it would
have just not parsed anything from that file.

In short, this doesn't affect things outside of tests, but it's more correct
to do it this way.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2025-01-15 14:56:53+00:00,[],2025-01-15 15:53:50+00:00,2025-01-15 15:32:02+00:00,https://github.com/apache/airflow/pull/45682,[],[],
2789771043,pull_request,closed,,feat: Add OpenLineage check in gcs_upload_download system test,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Now we'll check OpenLineage events emitted by this system test.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2025-01-15 12:51:02+00:00,[],2025-01-28 15:07:49+00:00,2025-01-22 12:04:34+00:00,https://github.com/apache/airflow/pull/45681,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2789744493,pull_request,closed,,Backport #41832 - fix: rm skip_if and run_if in python source,"Backport #41832 for resolving #43354

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",josix,2025-01-15 12:42:18+00:00,[],2025-01-28 11:49:36+00:00,2025-01-15 18:17:47+00:00,https://github.com/apache/airflow/pull/45680,"[('type:bug-fix', 'Changelog: Bug Fixes')]",[],
2789648975,pull_request,closed,,fix(XCom): /xcom/list got exception when applying filter on the value column,"closes: #42720 (although we are going to remove FAB lol)

- [x] Implementation 
- [ ] E2E Test
- [ ] Unit Test

* Added `XComFilterStartsWith`, `XComFilterEndsWith`, `XComFilterEqual`, `XComFilterContains`, `XComFilterNotStartsWith`, `XComFilterNotEndsWith`, `XComFilterNotContains`, and `XComFilterNotEqual` classes to handle different types of filtering for XCom values.
* Updated the `AirflowFilterConverter` class to include the new XCom filters in its conversion table.
* Added the `is_xcom_value` method to check if a column name corresponds to an XCom value.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",josix,2025-01-15 12:09:23+00:00,[],2025-01-26 11:12:15+00:00,2025-01-26 11:12:15+00:00,https://github.com/apache/airflow/pull/45679,"[('area:webserver', 'Webserver related Issues')]",[],
2789541512,pull_request,closed,,Update existing significant newsfragments with the later introduced template format,"## Why

Since https://github.com/apache/airflow/pull/44378, we have implemented a newsfragments template to track the breaking changes we have made. However, this template was introduced after many of our earlier breaking changes, which means that most of the existing news fragments do not conform to this format. By updating the existing entries to match the template, we will be able to create a script that summarizes the breaking changes made in Airflow 3.0.

## What

Update existing significant newsfragments with the type of changes and migration rules we added in https://github.com/apache/airflow/issues/41641

Closes: #45673 

 - [ ] #41453 @uranusjr
 - [x] #40029 @jscheffl
 - [ ] #40931 @dirrao
 - [ ] #41096 @dirrao
 - [x] #41348 @Lee-W
 - [ ] #41366 @jedcunningham
 - [ ] #41367 @jedcunningham
 - [ ] #41368 @jedcunningham
 - [x] #41390 @kaxil
 - [ ] #41391 @kaxil
 - [ ] #41435 @vincbeck
 - [x] #41394 @kaxil
 - [ ] #41395 @kaxil
 - [ ] #41695 @Avihais12344
 - [x] #41434 @vincbeck
 - [ ] #41440 @dstandish
 - [ ] #41453 @uranusjr
 - [ ] #41496 @dirrao
 - [ ] #41520 @dirrao
 - [x] #41533 @gopidesupavan
 - [ ] #41539 @dirrao
 - [ ] #41550 @dirrao
 - [ ] #41552 @dirrao
 - [ ] #41579 @dirrao
 - [ ] #41609 @dirrao
 - [ ] #41635 @dirrao
 - [ ] #41642 @dirrao
 - [ ] #41663 @dirrao
 - [ ] #41693 @dirrao
 - [ ] #41708 @dirrao
 - [x] #41733 @jscheffl
 - [x] #41735 @jscheffl
 - [x] #41736 @jscheffl
 - [x] #41737 @jscheffl
 - [ ] #41739 @dirrao
 - [ ] #41748 @dirrao
 - [x] #41758 @jscheffl
 - [x] #41761 @jscheffl
 - [x] #41762 @jscheffl
 - [x] #41774 @jscheffl
 - [x] #41776 @jscheffl
 - [x] #41778 @jscheffl
 - [x] #41779 @jscheffl
 - [x] #41780 @jscheffl
 - [ ] #41784 @dirrao
 - [x] #41808 @jscheffl
 - [x] #41857 @pierrejeambrun
 - [ ] #41910 @dirrao
 - [ ] #41964 @jedcunningham
 - [ ] #41975 @dirrao
 - [x] #42023 @Lee-W
 - [x] #42042 @vincbeck
 - [ ] #42066 @topherinternational
 - [ ] #42060 @dirrao
 - [ ] #42088 @dirrao
 - [ ] #42100 @dirrao
 - [ ] #42126 @dirrao
 - [ ] #42129 @dirrao
 - [x] #42137 @potiuk
 - [x] #42280 @vincbeck
 - [x] #42285 @ferruzzi
 - [ ] #42343 @uranusjr
 - [ ] #42404 @sunank200
 - [ ] #42436 @uranusjr
 - [ ] #42548 @dstandish
 - [x] #42579 @Lee-W
 - [ ] #42640 @dirrao
 - [ ] #42647 @dirrao
 - [ ] #42658 @dirrao
 - [ ] #42660 @dirrao
 - [x] #42766 @jscheffl
 - [ ] #42776 @dirrao
 - [ ] #43564 @kaxil
 - [ ] #43067 @dstandish
 - [ ] #43073 @Lee-W
 - [x] #43096 @vincbeck
 - [ ] #43102 @bugraoz93
 - [ ] #43183 @dstandish
 - [x] #43289 @kaxil
 - [ ] #43291 @kaxil
 - [x] #44741 @shahar1
 - [x] #43490 @kaxil
 - [x] #43530 @kaxil
 - [x] #43533 @kaxil
 - [x] #43562 @kaxil
 - [x] #43568 @potiuk
 - [x] #43611 @jscheffl
 - [x] #43612 @jscheffl
 - [x] #43774 @Lee-W
 - [ ] #43902 @sunank200
 - [ ] #43915 @uranusjr
 - [ ] #43943 @ashb
 - [ ] #43949 @ephraimbuddy
 - [x] #43975 @kaxil
 - [ ] #44080 @jedcunningham
 - [x] #44475 @Lee-W
 - [x] #44533 @vatsrahul1001
 - [ ] #44706 @jedcunningham
 - [x] #44820 @kaxil
 - [ ] #45065 @jedcunningham
 - [x] #45530 @jscheffl
 - [ ] #45694 @kaxil
 - [ ] #43551 @ashb
 - [x] #45009 @vincbeck
 - [x] #44378 @Lee-W


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Lee-W,2025-01-15 11:25:43+00:00,[],2025-01-27 12:57:36+00:00,2025-01-24 03:19:56+00:00,https://github.com/apache/airflow/pull/45678,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2593608649, 'issue_id': 2789541512, 'author': 'kaxil', 'body': '#protm', 'created_at': datetime.datetime(2025, 1, 15, 18, 2, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596418278, 'issue_id': 2789541512, 'author': 'potiuk', 'body': 'The list moved to the top.', 'created_at': datetime.datetime(2025, 1, 16, 18, 27, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596421341, 'issue_id': 2789541512, 'author': 'potiuk', 'body': 'A bit of ""magic"" scripting and I generated list of PRs + authors in a checklist form - this should make it easier to know who should review what and keep track of it.', 'created_at': datetime.datetime(2025, 1, 16, 18, 29, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596422458, 'issue_id': 2789541512, 'author': 'gopidesupavan', 'body': '> A bit of ""magic"" scripting and I generated list of PRs + authors in a checklist form - this should make it easier to know who should review what and keep track of it.\r\n\r\nSuper 😍', 'created_at': datetime.datetime(2025, 1, 16, 18, 29, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596425866, 'issue_id': 2789541512, 'author': 'potiuk', 'body': 'reviewed mine and marked them in the list', 'created_at': datetime.datetime(2025, 1, 16, 18, 31, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2596432207, 'issue_id': 2789541512, 'author': 'potiuk', 'body': '@Lee-W -> If you want - you can move the list up from the comment I made to the description of the PR - to keep it at the top.', 'created_at': datetime.datetime(2025, 1, 16, 18, 33, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597252889, 'issue_id': 2789541512, 'author': 'Lee-W', 'body': '> A bit of ""magic"" scripting and I generated list of PRs + authors in a checklist form - this should make it easier to know who should review what and keep track of it.\r\n\r\nyep, it\'s super helpful! just updated it', 'created_at': datetime.datetime(2025, 1, 17, 1, 37, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597383962, 'issue_id': 2789541512, 'author': 'vatsrahul1001', 'body': 'Thanks @Lee-W. I have reviewed my changes newsfragments/44533.significant.rst. LGTM!', 'created_at': datetime.datetime(2025, 1, 17, 3, 59, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597426182, 'issue_id': 2789541512, 'author': 'Lee-W', 'body': ""I'll keep it open for around 1 week so that everyone can take a look"", 'created_at': datetime.datetime(2025, 1, 17, 4, 45, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597548885, 'issue_id': 2789541512, 'author': 'shahar1', 'body': 'I\'d be happy for an explanation about what each ""type of change"" covers. In my case, I removed a a deprecated `TriggerRule` and it was considered only as a ""DAG change"". Should it be marked also as a ""Code interface change"" and/or ""Behaviour changes"" (due to the interface breaking)?', 'created_at': datetime.datetime(2025, 1, 17, 6, 46, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598541991, 'issue_id': 2789541512, 'author': 'Lee-W', 'body': '> I\'d be happy for an explanation about what each ""type of change"" covers. In my case, I removed a a deprecated `TriggerRule` and it was considered only as a ""DAG change"". Should it be marked also as a ""Code interface change"" and/or ""Behaviour changes"" (due to the interface breaking)?\r\n\r\nI tried to add some descriptions based on my understanding.', 'created_at': datetime.datetime(2025, 1, 17, 14, 54, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599756678, 'issue_id': 2789541512, 'author': 'bugraoz93', 'body': 'Thank you for all the effort! I have reviewed mine. It looks good.', 'created_at': datetime.datetime(2025, 1, 18, 15, 17, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2606928318, 'issue_id': 2789541512, 'author': 'Lee-W', 'body': ""[newsfragment_summary.csv](https://github.com/user-attachments/files/18504249/newsfragment_summary.csv)\r\n\r\nI just implemented a script to check the format of existing news fragments and make a quick summary. Here's what I got. For simplicity, I'll probably create another PR for that script. But would be nice if anyone could take a look and check whether this summary helps \r\n\r\ncc @kaxil @vikramkoka"", 'created_at': datetime.datetime(2025, 1, 22, 11, 0, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611462421, 'issue_id': 2789541512, 'author': 'Lee-W', 'body': ""I think we already have enough checks for this one. Merge it. Thanks for everyone's help!"", 'created_at': datetime.datetime(2025, 1, 24, 3, 19, 50, tzinfo=datetime.timezone.utc)}]","kaxil on (2025-01-15 18:02:33 UTC): #protm

potiuk on (2025-01-16 18:27:28 UTC): The list moved to the top.

potiuk on (2025-01-16 18:29:14 UTC): A bit of ""magic"" scripting and I generated list of PRs + authors in a checklist form - this should make it easier to know who should review what and keep track of it.

gopidesupavan on (2025-01-16 18:29:51 UTC): Super 😍

potiuk on (2025-01-16 18:31:46 UTC): reviewed mine and marked them in the list

potiuk on (2025-01-16 18:33:58 UTC): @Lee-W -> If you want - you can move the list up from the comment I made to the description of the PR - to keep it at the top.

Lee-W (Issue Creator) on (2025-01-17 01:37:07 UTC): yep, it's super helpful! just updated it

vatsrahul1001 on (2025-01-17 03:59:11 UTC): Thanks @Lee-W. I have reviewed my changes newsfragments/44533.significant.rst. LGTM!

Lee-W (Issue Creator) on (2025-01-17 04:45:53 UTC): I'll keep it open for around 1 week so that everyone can take a look

shahar1 on (2025-01-17 06:46:52 UTC): I'd be happy for an explanation about what each ""type of change"" covers. In my case, I removed a a deprecated `TriggerRule` and it was considered only as a ""DAG change"". Should it be marked also as a ""Code interface change"" and/or ""Behaviour changes"" (due to the interface breaking)?

Lee-W (Issue Creator) on (2025-01-17 14:54:03 UTC): I tried to add some descriptions based on my understanding.

bugraoz93 on (2025-01-18 15:17:58 UTC): Thank you for all the effort! I have reviewed mine. It looks good.

Lee-W (Issue Creator) on (2025-01-22 11:00:19 UTC): [newsfragment_summary.csv](https://github.com/user-attachments/files/18504249/newsfragment_summary.csv)

I just implemented a script to check the format of existing news fragments and make a quick summary. Here's what I got. For simplicity, I'll probably create another PR for that script. But would be nice if anyone could take a look and check whether this summary helps 

cc @kaxil @vikramkoka

Lee-W (Issue Creator) on (2025-01-24 03:19:50 UTC): I think we already have enough checks for this one. Merge it. Thanks for everyone's help!

"
2789469801,pull_request,closed,,Adding SageMaker Transform extra link,"
---
Adding extra link to SageMaker Transform Operator.
Closes #45618 
",ellisms,2025-01-15 10:52:15+00:00,[],2025-01-15 17:47:41+00:00,2025-01-15 17:47:41+00:00,https://github.com/apache/airflow/pull/45677,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2789415391,pull_request,open,,docs: update link to context.py in callbacks.rst,"Updated the link in callbacks.rst to point to the correct context.py file in the Airflow GitHub repository. 
Ensured the documentation provides accurate references to the available variables in the context.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",crynut84,2025-01-15 10:29:16+00:00,[],2025-01-17 08:20:26+00:00,,https://github.com/apache/airflow/pull/45676,"[('kind:documentation', '')]","[{'comment_id': 2592258227, 'issue_id': 2789415391, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 15, 10, 29, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593632953, 'issue_id': 2789415391, 'author': 'potiuk', 'body': 'Actually better fix will be to link to the context class(you can see how such linka aeedone in other places) rather than link to URL. This way we will get an error whene context class is again moved', 'created_at': datetime.datetime(2025, 1, 15, 18, 11, 52, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-15 10:29:21 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2025-01-15 18:11:52 UTC): Actually better fix will be to link to the context class(you can see how such linka aeedone in other places) rather than link to URL. This way we will get an error whene context class is again moved

"
2788754770,pull_request,closed,,Fix typing/docstring on dag helper methods,,jedcunningham,2025-01-15 03:31:10+00:00,[],2025-01-15 04:07:43+00:00,2025-01-15 04:07:42+00:00,https://github.com/apache/airflow/pull/45672,"[('AIP-66: DAG Bundle/Manifest', '')]",[],
2788547367,pull_request,closed,,Add support for timeout to BatchOperator,"Redo of https://github.com/apache/airflow/pull/45619 to avoid merge commit


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",nrobinson-intelycare,2025-01-15 00:26:10+00:00,[],2025-02-06 15:35:24+00:00,2025-01-17 21:56:06+00:00,https://github.com/apache/airflow/pull/45660,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2593946624, 'issue_id': 2788547367, 'author': 'nrobinson-intelycare', 'body': ""@o-nikolas @vincbeck @eladkal\r\n\r\nAnything I'm missing blocking this from being merged?"", 'created_at': datetime.datetime(2025, 1, 15, 21, 12, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593981457, 'issue_id': 2788547367, 'author': 'vincbeck', 'body': '> @o-nikolas @vincbeck @eladkal\r\n> \r\n> Anything I\'m missing blocking this from being merged?\r\n\r\nJust curious, have you tested it manually when `submit_job_timeout` is not provided? In that case `timeout` is passed to the the api `submit_job` with value `{""attemptDurationSeconds"": None}`. I am wondering it Boto3 is okay with that', 'created_at': datetime.datetime(2025, 1, 15, 21, 33, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594006801, 'issue_id': 2788547367, 'author': 'nrobinson-intelycare', 'body': '> > @o-nikolas @vincbeck @eladkal\r\n> > Anything I\'m missing blocking this from being merged?\r\n> \r\n> Just curious, have you tested it manually when `submit_job_timeout` is not provided? In that case `timeout` is passed to the the api `submit_job` with value `{""attemptDurationSeconds"": None}`. I am wondering it Boto3 is okay with that\r\n\r\nI\'ve changed it to only add `timeout` to the `args` dict if submit_job_timeout is not None:\r\n\r\nhttps://github.com/apache/airflow/pull/45660/files#diff-730ff9a9f5255ee440584231fc8733730c53a6a1a3fa3c2edd993c9d5157f219R322', 'created_at': datetime.datetime(2025, 1, 15, 21, 47, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594015899, 'issue_id': 2788547367, 'author': 'vincbeck', 'body': '> > > @o-nikolas @vincbeck @eladkal\r\n> > > Anything I\'m missing blocking this from being merged?\r\n> > \r\n> > \r\n> > Just curious, have you tested it manually when `submit_job_timeout` is not provided? In that case `timeout` is passed to the the api `submit_job` with value `{""attemptDurationSeconds"": None}`. I am wondering it Boto3 is okay with that\r\n> \r\n> I\'ve changed it to only add `timeout` to the `args` dict if submit_job_timeout is not None:\r\n> \r\n> https://github.com/apache/airflow/pull/45660/files#diff-730ff9a9f5255ee440584231fc8733730c53a6a1a3fa3c2edd993c9d5157f219R322\r\n\r\nI missed that! LGTM :)', 'created_at': datetime.datetime(2025, 1, 15, 21, 53, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599279469, 'issue_id': 2788547367, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 17, 21, 56, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607492449, 'issue_id': 2788547367, 'author': 'nrobinson-intelycare', 'body': '@o-nikolas @vincbeck \r\n\r\nAny idea when a new release of [apache-airflow-providers-amazon](https://pypi.org/project/apache-airflow-providers-amazon/) will be made? Looking forward to using this.', 'created_at': datetime.datetime(2025, 1, 22, 15, 4, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607522985, 'issue_id': 2788547367, 'author': 'vincbeck', 'body': 'Usually releases are done every 2 weeks but @eladkal should be able to give you more details about the next wave.', 'created_at': datetime.datetime(2025, 1, 22, 15, 16, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607647249, 'issue_id': 2788547367, 'author': 'eladkal', 'body': ""Will have to wait after Celery release.\r\nI don't have time to parallel releases. Sorry."", 'created_at': datetime.datetime(2025, 1, 22, 16, 5, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607713670, 'issue_id': 2788547367, 'author': 'nrobinson-intelycare', 'body': ""> Will have to wait after Celery release. I don't have time to parallel releases. Sorry.\r\n\r\nNo worries, thanks!"", 'created_at': datetime.datetime(2025, 1, 22, 16, 31, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622868611, 'issue_id': 2788547367, 'author': 'nrobinson-intelycare', 'body': '@eladkal Any chance of a release this week? Thanks.', 'created_at': datetime.datetime(2025, 1, 29, 21, 15, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2640163935, 'issue_id': 2788547367, 'author': 'nrobinson-intelycare', 'body': '@eladkal @vincbeck Any plans for making a release soon?', 'created_at': datetime.datetime(2025, 2, 6, 15, 35, 22, tzinfo=datetime.timezone.utc)}]","nrobinson-intelycare (Issue Creator) on (2025-01-15 21:12:47 UTC): @o-nikolas @vincbeck @eladkal

Anything I'm missing blocking this from being merged?

vincbeck on (2025-01-15 21:33:23 UTC): Just curious, have you tested it manually when `submit_job_timeout` is not provided? In that case `timeout` is passed to the the api `submit_job` with value `{""attemptDurationSeconds"": None}`. I am wondering it Boto3 is okay with that

nrobinson-intelycare (Issue Creator) on (2025-01-15 21:47:38 UTC): I've changed it to only add `timeout` to the `args` dict if submit_job_timeout is not None:

https://github.com/apache/airflow/pull/45660/files#diff-730ff9a9f5255ee440584231fc8733730c53a6a1a3fa3c2edd993c9d5157f219R322

vincbeck on (2025-01-15 21:53:51 UTC): I missed that! LGTM :)

boring-cyborg[bot] on (2025-01-17 21:56:09 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

nrobinson-intelycare (Issue Creator) on (2025-01-22 15:04:52 UTC): @o-nikolas @vincbeck 

Any idea when a new release of [apache-airflow-providers-amazon](https://pypi.org/project/apache-airflow-providers-amazon/) will be made? Looking forward to using this.

vincbeck on (2025-01-22 15:16:36 UTC): Usually releases are done every 2 weeks but @eladkal should be able to give you more details about the next wave.

eladkal on (2025-01-22 16:05:12 UTC): Will have to wait after Celery release.
I don't have time to parallel releases. Sorry.

nrobinson-intelycare (Issue Creator) on (2025-01-22 16:31:44 UTC): No worries, thanks!

nrobinson-intelycare (Issue Creator) on (2025-01-29 21:15:09 UTC): @eladkal Any chance of a release this week? Thanks.

nrobinson-intelycare (Issue Creator) on (2025-02-06 15:35:22 UTC): @eladkal @vincbeck Any plans for making a release soon?

"
2788495025,pull_request,closed,,Use standalone dag processor for AF3 in chart,"We are moving to only support a standalone DAG processor in Airflow 3, so let's switch our chart to always use it.",jedcunningham,2025-01-14 23:48:28+00:00,[],2025-02-05 15:52:04+00:00,2025-01-15 07:54:02+00:00,https://github.com/apache/airflow/pull/45659,"[('area:helm-chart', 'Airflow Helm Chart')]",[],
2788493516,pull_request,closed,,Fix selection of providers for tests in new provider's structure,"There was a  teething problem after #45259 - when running tests for all providers rather than selectively the ""new structure"" providers (currently airbyte) tests were not running when ""all"" provider tests were run. There were two problems:

* typo in ""tests"" (was ""test"") folder name for providers
* full local paths were passed from Host (rather than relative paths from airlfow root) for found providers

Also the ""new"" providers are moved to be first in the list of pytest folders to see that it is actually working.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-14 23:47:25+00:00,[],2025-01-15 09:56:17+00:00,2025-01-15 09:56:04+00:00,https://github.com/apache/airflow/pull/45658,"[('area:dev-tools', '')]",[],
2788356161,pull_request,closed,,Add other instances of Context type hints,"Follow-up of https://github.com/apache/airflow/pull/45583

closes https://github.com/apache/airflow/issues/45454

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-14 21:58:19+00:00,[],2025-01-15 05:36:02+00:00,2025-01-15 05:36:00+00:00,https://github.com/apache/airflow/pull/45657,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('area:task-sdk', None)]",[],
2788312336,pull_request,closed,,Remove unused function in `airflow/api/common/mark_tasks.py`,"This function isn't used anywhere

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-14 21:28:40+00:00,[],2025-01-14 21:55:27+00:00,2025-01-14 21:55:25+00:00,https://github.com/apache/airflow/pull/45655,"[('area:API', ""Airflow's REST/HTTP API"")]",[],
2788305826,pull_request,closed,,Remove redundant `airflow/template` directoy,"This is now an empty directory following https://github.com/apache/airflow/pull/45583 and can be removed.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-14 21:24:19+00:00,[],2025-01-14 21:55:41+00:00,2025-01-14 21:55:39+00:00,https://github.com/apache/airflow/pull/45654,[],[],
2788021277,pull_request,closed,,"Switch to latest ""stash"" action from apache/infrastructure-actions","There are a few improvements just merged in the latest version of the ""stash"" suite of actions that we contributed.

Most of the changes were result of making the #45289 works with stash action and since the changes were added we found that we need to do things differently (for example rather than storing .cache directly we need to tar the directories because we need to preserve permissions and symbolic links). There is however one useful feature that remained - namely protecting against accidentally downloading stash from the main branch, when the PR needs only ""its own"" artifact (helpful in case of typos in the workflow where wrong image artifact name is specified).

This PR switches to latest version of the action and enables the protection in ""prepare images"" composite actions.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-14 18:36:03+00:00,[],2025-01-14 19:56:45+00:00,2025-01-14 19:24:32+00:00,https://github.com/apache/airflow/pull/45653,"[('area:dev-tools', '')]","[{'comment_id': 2590834105, 'issue_id': 2788021277, 'author': 'potiuk', 'body': 'cc: @assignUser', 'created_at': datetime.datetime(2025, 1, 14, 18, 36, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2590987274, 'issue_id': 2788021277, 'author': 'gopidesupavan', 'body': 'Nice :)', 'created_at': datetime.datetime(2025, 1, 14, 19, 56, 43, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-14 18:36:21 UTC): cc: @assignUser

gopidesupavan on (2025-01-14 19:56:43 UTC): Nice :)

"
2787913778,pull_request,closed,,dag run state change endpoints notify listeners about state change,"When DagRun state changes due to manual or API based actions, listeners are not notified about those. This PR fixes this.

Solves https://github.com/apache/airflow/issues/40735",mobuchowski,2025-01-14 17:48:26+00:00,[],2025-01-15 16:24:35+00:00,2025-01-15 16:24:35+00:00,https://github.com/apache/airflow/pull/45652,[],[],
2787898255,pull_request,closed,,Add standalone DAG processor to docker compose,"We are moving to only support a standalone DAG processor in Airflow 3, so let's switch our compose setup to have it. We can remove the env var once that's the only option, but for now it let's us avoid a massive PR :)",jedcunningham,2025-01-14 17:42:12+00:00,[],2025-01-14 20:04:49+00:00,2025-01-14 20:04:47+00:00,https://github.com/apache/airflow/pull/45650,"[('kind:documentation', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2590767535, 'issue_id': 2787898255, 'author': 'potiuk', 'body': 'It does :)', 'created_at': datetime.datetime(2025, 1, 14, 18, 13, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2590769565, 'issue_id': 2787898255, 'author': 'potiuk', 'body': 'Ah no .. we need to add `full-tests-needed` - this one is not properly recognized in selective checks as triggering the tests for docker compose.', 'created_at': datetime.datetime(2025, 1, 14, 18, 15, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-14 18:13:57 UTC): It does :)

potiuk on (2025-01-14 18:15:01 UTC): Ah no .. we need to add `full-tests-needed` - this one is not properly recognized in selective checks as triggering the tests for docker compose.

"
2787483155,pull_request,closed,,Fix escaping of special characters or reserved words as column names in dialects of common sql provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Not only fixes escaping of reserved words or special characters as column names but also fixes un-escaping of column names or table names.

Unit tests have been added accordingly.

Also allow ""escape_word_format"", ""insert_statement_format"" and ""replace_statement_format"" to be defined in extra of connection, this is handy when using Jdbc or Odbc based hooks.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2025-01-14 15:23:35+00:00,[],2025-01-27 12:45:45+00:00,2025-01-26 14:04:21+00:00,https://github.com/apache/airflow/pull/45640,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:common-sql', ''), ('provider:microsoft-mssql', '')]","[{'comment_id': 2590789927, 'issue_id': 2787483155, 'author': 'dabla', 'body': ""@eladkal Would it hurt if some methods in Dialects are being renamed?  I don't think it's actually used yet by any released provider right?\r\n\r\nI'm thinking of renaming following 2 methods:\r\n\r\nescape_colmun_name -> escape_word\r\nremove_quotes -> unescape_word"", 'created_at': datetime.datetime(2025, 1, 14, 18, 23, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593195914, 'issue_id': 2787483155, 'author': 'eladkal', 'body': ""> @eladkal Would it hurt if some methods in Dialects are being renamed? I don't think it's actually used yet by any released provider right?\r\n> \r\n> I'm thinking of renaming following 2 methods:\r\n> \r\n> escape_colmun_name -> escape_word remove_quotes -> unescape_word\r\n\r\nDialects were not yet released so you can introduce changes. Once I cut a release you won't be able to introduce breaking changes without doing a major release"", 'created_at': datetime.datetime(2025, 1, 15, 15, 26, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593334047, 'issue_id': 2787483155, 'author': 'dabla', 'body': ""> > @eladkal Would it hurt if some methods in Dialects are being renamed? I don't think it's actually used yet by any released provider right?\r\n> > I'm thinking of renaming following 2 methods:\r\n> > escape_colmun_name -> escape_word remove_quotes -> unescape_word\r\n> \r\n> Dialects were not yet released so you can introduce changes. Once I cut a release you won't be able to introduce breaking changes without doing a major release\r\n\r\nOk if approved this one can we merged, I tested it locally and works as expected. Yesterday we encountered a new DAG which had to persist records to a table which name was a reserved word and had also column names as reserved words in MS SQL, the perfect test case 🤣"", 'created_at': datetime.datetime(2025, 1, 15, 16, 6, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2612198474, 'issue_id': 2787483155, 'author': 'eladkal', 'body': 'cc @potiuk any comments on this one? If not happy to merge it', 'created_at': datetime.datetime(2025, 1, 24, 10, 33, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614333914, 'issue_id': 2787483155, 'author': 'eladkal', 'body': '@dabla can you rebase and resolve conflicts? I will merge after', 'created_at': datetime.datetime(2025, 1, 26, 11, 26, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614341464, 'issue_id': 2787483155, 'author': 'dabla', 'body': '> @dabla can you rebase and resolve conflicts? I will merge after\r\n\r\njust rebased and merged with main', 'created_at': datetime.datetime(2025, 1, 26, 11, 50, 47, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2025-01-14 18:23:42 UTC): @eladkal Would it hurt if some methods in Dialects are being renamed?  I don't think it's actually used yet by any released provider right?

I'm thinking of renaming following 2 methods:

escape_colmun_name -> escape_word
remove_quotes -> unescape_word

eladkal on (2025-01-15 15:26:04 UTC): Dialects were not yet released so you can introduce changes. Once I cut a release you won't be able to introduce breaking changes without doing a major release

dabla (Issue Creator) on (2025-01-15 16:06:14 UTC): Ok if approved this one can we merged, I tested it locally and works as expected. Yesterday we encountered a new DAG which had to persist records to a table which name was a reserved word and had also column names as reserved words in MS SQL, the perfect test case 🤣

eladkal on (2025-01-24 10:33:40 UTC): cc @potiuk any comments on this one? If not happy to merge it

eladkal on (2025-01-26 11:26:13 UTC): @dabla can you rebase and resolve conflicts? I will merge after

dabla (Issue Creator) on (2025-01-26 11:50:47 UTC): just rebased and merged with main

"
2787165006,pull_request,closed,,chore: Update docstring for DatabaseInfo in OpenLineage provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
Some docstring updates to make it easier to understand.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2025-01-14 13:43:05+00:00,[],2025-01-15 07:21:27+00:00,2025-01-14 16:30:49+00:00,https://github.com/apache/airflow/pull/45638,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2787160250,pull_request,closed,,feat: Add OpenLineage support for MsSqlHook and MSSQLToGCSOperator,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for MS SQL Hook. Similar to MySqlHook, PostgresHook and others.
Also, it adds support for MSSQLToGCSOperator, similar to MySQLToGCSOperator, PostgresToGCSOperator and others.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2025-01-14 13:41:14+00:00,[],2025-01-16 14:02:10+00:00,2025-01-16 13:55:47+00:00,https://github.com/apache/airflow/pull/45637,"[('area:providers', ''), ('provider:microsoft-mssql', '')]",[],
2786934320,pull_request,closed,,Bump minimum version of psycopg2-binary to 2.9.7,"Seems that latest release of the Python Base image updated to latest debian bookworm release which stopped working with older releases of psycobg2-binary raising

```
_psycopg.cpython-311-x86_64-linux-gnu.so: undefined symbol: GENERAL_NAME_free
```

Bumoing minimum version to 2.9.7 should solve the problem.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-14 11:47:52+00:00,[],2025-01-14 14:28:13+00:00,2025-01-14 14:28:11+00:00,https://github.com/apache/airflow/pull/45635,"[('area:providers', ''), ('area:dev-tools', ''), ('provider:postgres', ''), ('canary', 'When set on PR running from apache repo - behave as canary run')]",[],
2786792207,pull_request,closed,,New Optional dbt Cloud Job Operator Params,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
### Summary
Allow triggering dbt Cloud jobs using ``project_name``, ``environment_name``, and ``job_name`` instead of ``job_id``.

It is not a breaking change, but optional, alternative way of triggering a job - both options will work:

```py
# regular job run by id
trigger_job_run1 = DbtCloudRunJobOperator(
    task_id=""trigger_job_run1"",
    job_id=48617,
    check_interval=10,
    timeout=300,
)

# equivalent job run by name
trigger_job_run3 = DbtCloudRunJobOperator(
    task_id=""trigger_job_run3"",
    project_name=""my_dbt_project"",
    environment_name=""prod"",
    job_name=""my_dbt_job"",
    check_interval=10,
    timeout=300,
)
```

This is beneficial in dynamically configured environments (e.g. managed by Infrastructure as Code) when ``job_id`` is not known upfront (or may change over time) and therefore hardcoding it is not convenient.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ginone,2025-01-14 10:34:08+00:00,[],2025-02-04 15:58:51+00:00,2025-02-04 15:58:47+00:00,https://github.com/apache/airflow/pull/45634,"[('area:providers', ''), ('kind:documentation', ''), ('provider:dbt-cloud', '')]","[{'comment_id': 2589560603, 'issue_id': 2786792207, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 14, 10, 34, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2590120392, 'issue_id': 2786792207, 'author': 'jaklan', 'body': '@joellabes another MR related to dbt Cloud Operator from our side - could you have a look if you are fine with the approach?', 'created_at': datetime.datetime(2025, 1, 14, 14, 46, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595680976, 'issue_id': 2786792207, 'author': 'pikachuev', 'body': 'Hi @ginone , great proposal and change. We use in our Airflow environment an own helper and retrieve job_ids by names. We figure out that in our case the payload from dbt Cloud REST API is quite big to retrieve it  for every dbt cloud job triggering. To reduce payload size we additionally filter rest api calls by filtering project name in API call, for example: \r\n project_url = (\r\n        f""{base_url_v3}accounts/{dbt_cloud_account_id}/projects/""\r\n        f""?account_id={dbt_cloud_account_id}""\r\n        **f""&name__icontains={project_name}**""\r\n    )\r\n\r\nor\r\njob_url = (\r\n        f""{base_url_v2}accounts/{dbt_cloud_account_id}/jobs/""\r\n        f""?account_id={dbt_cloud_account_id}""\r\n        f""&project_id={project_id}""\r\n        **f""&name__icontains={job_name}""**\r\n    )\r\nWhat do you think about such improvement?', 'created_at': datetime.datetime(2025, 1, 16, 13, 28, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595762377, 'issue_id': 2786792207, 'author': 'ginone', 'body': ""@pikachuev thanks for the feedback!\r\n\r\nIf you look at the code, `get_job_by_name` function specifically, you will notice there already is an optimization that works similarly to your suggestion. In order to minimize the response sizes, the process is done in 3 steps:\r\n1. `list_projects` using `project_name` as filter (`name__icontains={project_name}`)\r\n2. `list_environments ` using `project_id` as a filter\r\n3. `list_jobs` using both `project_id` & `environment_id` as filters\r\n\r\nI decided to only use `name__icontains` for first step to limit the response size as retrieving all projects would not make sense. In 2nd & 3rd stages my assumption was that it should not be necessary to use such filtering because there should be no more than a few environments in each project and a dozen or so jobs in each environment.\r\n\r\nNow that you mentioned it, I think it would make sense to use `name__icontains` at least also for retrieving jobs, as there may be use cases when there are 100+ jobs in a single environment, so I'll submit that change shortly."", 'created_at': datetime.datetime(2025, 1, 16, 13, 57, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609019669, 'issue_id': 2786792207, 'author': 'joellabes', 'body': "">could you have a look if you are fine with the approach?\n\nI'm sorry that it's necessary (and have linked this internally for us to work on a better strategy!) but I think it's a sensible workaround for now, and is a pattern we've seen customers use before 👍"", 'created_at': datetime.datetime(2025, 1, 23, 7, 9, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615279528, 'issue_id': 2786792207, 'author': 'ginone', 'body': '@josh-fell @Lee-W thank you for the code review, I\'ve addressed all feedback. Could you please look again?\r\n\r\nBTW. What do you think regarding @jaklan suggestion (https://github.com/apache/airflow/pull/45634#pullrequestreview-2557110660)? My thoughts:\r\n\r\n1. this (implicit argument types) feels wrong/confusing:\r\n```py\r\nself.job: str | int,\r\nself.project: str | int,\r\nself.environment: str | int,\r\n```\r\nI think the params should be explicit, so I would go with:\r\n```py\r\nself.job_id: int,\r\nself.project_id: int,\r\nself.environment_id: int,\r\nself.job_name: str,\r\nself.project_name: str,\r\nself.environment_name: str,\r\n```\r\n\r\n2. I see this as an enhancement that could allow more flexible setups, but I would prefer to release this PR ""as is"" and unblock using `project_name`, `environment_name`, and `job_name` ASAP. I would create a new PR with the suggested enhancements.', 'created_at': datetime.datetime(2025, 1, 27, 9, 47, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2619507526, 'issue_id': 2786792207, 'author': 'ginone', 'body': '> @josh-fell @Lee-W thank you for the code review, I\'ve addressed all feedback. Could you please look again?\r\n> \r\n> BTW. What do you think regarding @jaklan suggestion ([#45634 (review)](https://github.com/apache/airflow/pull/45634#pullrequestreview-2557110660))? My thoughts:\r\n> \r\n> 1. this (implicit argument types) feels wrong/confusing:\r\n> \r\n> ```python\r\n> self.job: str | int,\r\n> self.project: str | int,\r\n> self.environment: str | int,\r\n> ```\r\n> \r\n> I think the params should be explicit, so I would go with:\r\n> \r\n> ```python\r\n> self.job_id: int,\r\n> self.project_id: int,\r\n> self.environment_id: int,\r\n> self.job_name: str,\r\n> self.project_name: str,\r\n> self.environment_name: str,\r\n> ```\r\n> \r\n> 2. I see this as an enhancement that could allow more flexible setups, but I would prefer to release this PR ""as is"" and unblock using `project_name`, `environment_name`, and `job_name` ASAP. I would create a new PR with the suggested enhancements.\r\n\r\nNew PR that includes the changes described above: https://github.com/apache/airflow/pull/46184\r\n\r\nFeel free to select just one of my PRs and close the other one.', 'created_at': datetime.datetime(2025, 1, 28, 16, 34, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2630237786, 'issue_id': 2786792207, 'author': 'Lee-W', 'body': '> @josh-fell @Lee-W thank you for the code review, I\'ve addressed all feedback. Could you please look again?\r\n> \r\n> BTW. What do you think regarding @jaklan suggestion ([#45634 (review)](https://github.com/apache/airflow/pull/45634#pullrequestreview-2557110660))? My thoughts:\r\n> \r\n>     1. this (implicit argument types) feels wrong/confusing:\r\n> \r\n> \r\n> ```python\r\n> self.job: str | int,\r\n> self.project: str | int,\r\n> self.environment: str | int,\r\n> ```\r\n> \r\n> I think the params should be explicit, so I would go with:\r\n> \r\n> ```python\r\n> self.job_id: int,\r\n> self.project_id: int,\r\n> self.environment_id: int,\r\n> self.job_name: str,\r\n> self.project_name: str,\r\n> self.environment_name: str,\r\n> ```\r\n> \r\n>     2. I see this as an enhancement that could allow more flexible setups, but I would prefer to release this PR ""as is"" and unblock using `project_name`, `environment_name`, and `job_name` ASAP. I would create a new PR with the suggested enhancements.\r\n\r\nHi, sorry for the late reply. I prefer this idea more. It would be great if you could rebase from the main branch and resolve the conflict, then I\'ll review it again. Thanks a lot!', 'created_at': datetime.datetime(2025, 2, 3, 8, 11, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2633288207, 'issue_id': 2786792207, 'author': 'ginone', 'body': '@Lee-W rebasing is done, please have a look again. Thanks!', 'created_at': datetime.datetime(2025, 2, 4, 9, 7, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2633570050, 'issue_id': 2786792207, 'author': 'ginone', 'body': '> Looks good to me. Thanks for your prompt reply. I\'ll keep it open for one to two days so others can take a look.\r\n\r\n[Fixed one incorrect ""include"" path in docs](https://github.com/apache/airflow/pull/45634/commits/670aa4f3bccc34be6f956c54bf1d08a067973842). Checks should be all green now.\r\n\r\nThanks!', 'created_at': datetime.datetime(2025, 2, 4, 11, 2, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2634399656, 'issue_id': 2786792207, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 2, 4, 15, 58, 49, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-14 10:34:13 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

jaklan on (2025-01-14 14:46:38 UTC): @joellabes another MR related to dbt Cloud Operator from our side - could you have a look if you are fine with the approach?

pikachuev on (2025-01-16 13:28:04 UTC): Hi @ginone , great proposal and change. We use in our Airflow environment an own helper and retrieve job_ids by names. We figure out that in our case the payload from dbt Cloud REST API is quite big to retrieve it  for every dbt cloud job triggering. To reduce payload size we additionally filter rest api calls by filtering project name in API call, for example: 
 project_url = (
        f""{base_url_v3}accounts/{dbt_cloud_account_id}/projects/""
        f""?account_id={dbt_cloud_account_id}""
        **f""&name__icontains={project_name}**""
    )

or
job_url = (
        f""{base_url_v2}accounts/{dbt_cloud_account_id}/jobs/""
        f""?account_id={dbt_cloud_account_id}""
        f""&project_id={project_id}""
        **f""&name__icontains={job_name}""**
    )
What do you think about such improvement?

ginone (Issue Creator) on (2025-01-16 13:57:03 UTC): @pikachuev thanks for the feedback!

If you look at the code, `get_job_by_name` function specifically, you will notice there already is an optimization that works similarly to your suggestion. In order to minimize the response sizes, the process is done in 3 steps:
1. `list_projects` using `project_name` as filter (`name__icontains={project_name}`)
2. `list_environments ` using `project_id` as a filter
3. `list_jobs` using both `project_id` & `environment_id` as filters

I decided to only use `name__icontains` for first step to limit the response size as retrieving all projects would not make sense. In 2nd & 3rd stages my assumption was that it should not be necessary to use such filtering because there should be no more than a few environments in each project and a dozen or so jobs in each environment.

Now that you mentioned it, I think it would make sense to use `name__icontains` at least also for retrieving jobs, as there may be use cases when there are 100+ jobs in a single environment, so I'll submit that change shortly.

joellabes on (2025-01-23 07:09:31 UTC): I'm sorry that it's necessary (and have linked this internally for us to work on a better strategy!) but I think it's a sensible workaround for now, and is a pattern we've seen customers use before 👍

ginone (Issue Creator) on (2025-01-27 09:47:13 UTC): @josh-fell @Lee-W thank you for the code review, I've addressed all feedback. Could you please look again?

BTW. What do you think regarding @jaklan suggestion (https://github.com/apache/airflow/pull/45634#pullrequestreview-2557110660)? My thoughts:

1. this (implicit argument types) feels wrong/confusing:
```py
self.job: str | int,
self.project: str | int,
self.environment: str | int,
```
I think the params should be explicit, so I would go with:
```py
self.job_id: int,
self.project_id: int,
self.environment_id: int,
self.job_name: str,
self.project_name: str,
self.environment_name: str,
```

2. I see this as an enhancement that could allow more flexible setups, but I would prefer to release this PR ""as is"" and unblock using `project_name`, `environment_name`, and `job_name` ASAP. I would create a new PR with the suggested enhancements.

ginone (Issue Creator) on (2025-01-28 16:34:43 UTC): New PR that includes the changes described above: https://github.com/apache/airflow/pull/46184

Feel free to select just one of my PRs and close the other one.

Lee-W on (2025-02-03 08:11:09 UTC): Hi, sorry for the late reply. I prefer this idea more. It would be great if you could rebase from the main branch and resolve the conflict, then I'll review it again. Thanks a lot!

ginone (Issue Creator) on (2025-02-04 09:07:27 UTC): @Lee-W rebasing is done, please have a look again. Thanks!

ginone (Issue Creator) on (2025-02-04 11:02:37 UTC): [Fixed one incorrect ""include"" path in docs](https://github.com/apache/airflow/pull/45634/commits/670aa4f3bccc34be6f956c54bf1d08a067973842). Checks should be all green now.

Thanks!

boring-cyborg[bot] on (2025-02-04 15:58:49 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2785974658,pull_request,closed,,Fix `FileTaskHandler` only read from default executor,"closes: #45529

Also added `test_file_task_handler_with_multiple_executors` to verify that the correct `get_task_log` method of different executors is called.  

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2025-01-14 01:55:08+00:00,[],2025-01-27 12:58:42+00:00,2025-01-24 02:58:45+00:00,https://github.com/apache/airflow/pull/45631,"[('area:logging', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2590414172, 'issue_id': 2785974658, 'author': 'potiuk', 'body': 'cc: @o-nikolas', 'created_at': datetime.datetime(2025, 1, 14, 16, 19, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597415611, 'issue_id': 2785974658, 'author': 'jason810496', 'body': 'Hi @o-nikolas,  \nI ran the tests locally with Breeze, and they worked fine. However, the CI is failing mostly due to ""Unknown executor being loaded: <executor name>"" errors. Do you have any idea where I should look into this? (Could it be resolved by adding some additional configuration for Breeze tests or something similar?)  \n\nThanks!', 'created_at': datetime.datetime(2025, 1, 17, 4, 33, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598517505, 'issue_id': 2785974658, 'author': 'potiuk', 'body': 'Likely this is a side effect of some other test that does not clean-up after itself - you can repeat what CI is doing - i.e. run the `Core` test type:\r\n\r\n```\r\nbreeze testing core-tests --test-type Core\r\n```\r\n\r\nAnd they should run the tests in the same sequence the ""Core"" tests are run in CI in your PR (`Core` test type is the one that is failing. \r\n\r\nThe problem is that some of the earlier tests likely modify a state stored in memory (likely list of executors stored in memory) and do not restore it properly - and the failing tests do not set up the expected state properly.\r\n\r\nNow - it\'s a bit of guessing, art and eventually bisecting to see which tests are  causing it. In many cases you can guess - you know which tests you added so likely it is somehow related to your changes (but it might be that your tests simply ucovered it). What I often do in such cases is trying to bisect it - instead of runnin the whole test_type (""Core"") - I just enter breeze and try to run the same sequence of tests - simply individually rin the test packages/modulles that you see printed in the output - so for example from the above I try to run (there are some packages that are before that).\r\n\r\n```\r\npytest ... tests/models tests/ti_deps tests/utils \r\n```\r\n\r\nAnd see it fails\r\n\r\nNow if you run:\r\n\r\n```\r\npytest tests/ti_deps tests/utils \r\n```\r\n\r\nAnd it fails - then you know side effect comes from either ti_deps or earlier utils - then you can remove ti_deps and see if it fails, then if you see tha it comes from utils, you run tests from individual modules in ti_utils in the same sequence you see below and remove first half and see if it fails - and so on. \r\n\r\nThis is by far fastest way of narrowing down which test is creating the side-effect if you have no idea.\r\n\r\nHere is the example output.\r\n\r\n```\r\n  ....\r\n  tests/models/test_xcom_arg_map.py ...........                            [ 67%]\r\n  tests/ti_deps/deps/test_dag_ti_slots_available_dep.py ..                 [ 67%]\r\n  tests/ti_deps/deps/test_dag_unpaused_dep.py ..                           [ 67%]\r\n  tests/ti_deps/deps/test_dagrun_exists_dep.py ..                          [ 67%]\r\n  tests/ti_deps/deps/test_mapped_task_upstream_dep.py .................... [ 68%]\r\n  ......................................................ssssssssssss...... [ 70%]\r\n  ......                                                                   [ 71%]\r\n  tests/ti_deps/deps/test_not_in_retry_period_dep.py ...                   [ 71%]\r\n  tests/ti_deps/deps/test_not_previously_skipped_dep.py .....              [ 71%]\r\n  tests/ti_deps/deps/test_pool_slots_available_dep.py .....                [ 71%]\r\n  tests/ti_deps/deps/test_prev_dagrun_dep.py ...........                   [ 71%]\r\n  tests/ti_deps/deps/test_ready_to_reschedule_dep.py ................      [ 72%]\r\n  tests/ti_deps/deps/test_runnable_exec_date_dep.py .........              [ 72%]\r\n  tests/ti_deps/deps/test_task_concurrency.py ..........                   [ 73%]\r\n  tests/ti_deps/deps/test_task_not_running_dep.py ..                       [ 73%]\r\n  tests/ti_deps/deps/test_trigger_rule_dep.py ............................ [ 74%]\r\n  ........................................................................ [ 77%]\r\n  ..........................                                               [ 78%]\r\n  tests/ti_deps/deps/test_valid_state_dep.py ...                           [ 78%]\r\n  tests/utils/log/test_colored_log.py .                                    [ 78%]\r\n  tests/utils/log/test_file_processor_handler.py ssss                      [ 78%]\r\n  tests/utils/log/test_json_formatter.py sssss                             [ 78%]\r\n  tests/utils/log/test_log_reader.py ........                              [ 78%]\r\n  tests/utils/log/test_secrets_masker.py sssssssssssssssssssssssssssssssss [ 80%]\r\n  ssssssssssssssssssssssssss                                               [ 80%]\r\n  tests/utils/test_cli_util.py ..................                          [ 81%]\r\n  tests/utils/test_context.py ....sss                                      [ 81%]\r\n  tests/utils/test_dag_cycle.py sssssssss                                  [ 82%]\r\n  tests/utils/test_dataform.py ss                                          [ 82%]\r\n  tests/utils/test_db.py ...................                               [ 83%]\r\n  tests/utils/test_db_cleanup.py ......................................... [ 84%]\r\n  ...                                                                      [ 84%]\r\n  tests/utils/test_db_manager.py ........                                  [ 84%]\r\n  tests/utils/test_decorators.py ssssssssssssssssssssssss                  [ 85%]\r\n  tests/utils/test_docs.py ssss                                            [ 86%]\r\n  tests/utils/test_dot_renderer.py ......                                  [ 86%]\r\n  tests/utils/test_edgemodifier.py ssssssssssssss                          [ 86%]\r\n  tests/utils/test_email.py sssssssssss..............                      [ 87%]\r\n  tests/utils/test_entry_points.py s                                       [ 87%]\r\n  tests/utils/test_event_scheduler.py s                                    [ 87%]\r\n  tests/utils/test_file.py ssssssssssssssssssssss                          [ 88%]\r\n  tests/utils/test_helpers.py .sssssssssss.ssssssssssssssssssssssssssss    [ 90%]\r\n  tests/utils/test_json.py sssssssssssssssss                               [ 90%]\r\n  tests/utils/test_log_handlers.py ...FFF.......................           [ 91%]\r\n```', 'created_at': datetime.datetime(2025, 1, 17, 14, 42, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598674742, 'issue_id': 2785974658, 'author': 'jason810496', 'body': 'Thanks, @potiuk, for pointing out that the error might be caused by side effects from other tests and for providing the detailed guide to resolve it! I will try using the bisect approach to identify which test case is causing the side effect.  \r\n\r\nUpdate:\r\nLuckily, I found that it was caused by the `tests/ti_deps/` module after a few iterations!  \r\n> `tests/ti_deps/deps/test_ready_to_reschedule_dep.py`', 'created_at': datetime.datetime(2025, 1, 17, 16, 0, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2599741396, 'issue_id': 2785974658, 'author': 'jason810496', 'body': ""> Update:\r\n> Luckily, I found that it was caused by the tests/ti_deps/ module after a few iterations!\r\n> `tests/ti_deps/deps/test_ready_to_reschedule_dep.py`\r\n\r\nTL;DR:  \r\nThe global state in the `executor_loader` module can cause side effects in other test cases if not properly torn down.  \r\n\r\nThe issue is caused by the `executor_loader` module, as it stores some state in global variables:  \r\nhttps://github.com/apache/airflow/blob/main/airflow/executors/executor_loader.py#L48-L54  \r\nThis can lead to errors in `Executor.load_executor` or `Executor.get_default_executor` , as these methods rely on looking up `executor_name` in global variables. If a test interacts with `executor_loader` and doesn't clear the global variables, it may cause side effects in subsequent tests.  \r\n\r\n---\r\n\r\nIn other test cases that use the `executor_loader` module, `reload` is employed.\r\nHowever, in the current test case, we need to mock the `Executor.load_executor` and `Executor.get_default_executor` methods. Mixing `reload(executor_loader)` with mocks results in the mock object never being called, as the callable used during the test runtime bypasses the mock.  \r\n\r\nFrom my perspective, cleaning the global variables in `executor_loader` should suffice for tearing down the state. I will create another PR to investigate whether this approach is correct and to evaluate how much test speed can be improved by replacing all `reload(executor_loader)` calls with `clean_executor_loader()`."", 'created_at': datetime.datetime(2025, 1, 18, 14, 32, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2607772960, 'issue_id': 2785974658, 'author': 'jason810496', 'body': ""The CI failed due to https://github.com/apache/airflow/pull/45917. I'll wait for it to be merged, then rebase with the main branch, which should resolve the issue."", 'created_at': datetime.datetime(2025, 1, 22, 16, 56, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609151178, 'issue_id': 2785974658, 'author': 'jason810496', 'body': 'Resolved the issue, and the CI has successfully passed! 🎉\r\ncc @o-nikolas', 'created_at': datetime.datetime(2025, 1, 23, 8, 29, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610660237, 'issue_id': 2785974658, 'author': 'o-nikolas', 'body': '> Resolved the issue, and the CI has successfully passed! 🎉 cc @o-nikolas\r\n\r\nNice! LGTM, @Lee-W Has your feedback been addressed to your satisfaction?', 'created_at': datetime.datetime(2025, 1, 23, 18, 35, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611439421, 'issue_id': 2785974658, 'author': 'Lee-W', 'body': ""> > Resolved the issue, and the CI has successfully passed! 🎉 cc @o-nikolas\r\n> \r\n> Nice! LGTM, @Lee-W Has your feedback been addressed to your satisfaction?\r\n\r\nYep, looks good 🙂 let's merge it!"", 'created_at': datetime.datetime(2025, 1, 24, 2, 58, 40, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-14 16:19:12 UTC): cc: @o-nikolas

jason810496 (Issue Creator) on (2025-01-17 04:33:12 UTC): Hi @o-nikolas,  
I ran the tests locally with Breeze, and they worked fine. However, the CI is failing mostly due to ""Unknown executor being loaded: <executor name>"" errors. Do you have any idea where I should look into this? (Could it be resolved by adding some additional configuration for Breeze tests or something similar?)  

Thanks!

potiuk on (2025-01-17 14:42:01 UTC): Likely this is a side effect of some other test that does not clean-up after itself - you can repeat what CI is doing - i.e. run the `Core` test type:

```
breeze testing core-tests --test-type Core
```

And they should run the tests in the same sequence the ""Core"" tests are run in CI in your PR (`Core` test type is the one that is failing. 

The problem is that some of the earlier tests likely modify a state stored in memory (likely list of executors stored in memory) and do not restore it properly - and the failing tests do not set up the expected state properly.

Now - it's a bit of guessing, art and eventually bisecting to see which tests are  causing it. In many cases you can guess - you know which tests you added so likely it is somehow related to your changes (but it might be that your tests simply ucovered it). What I often do in such cases is trying to bisect it - instead of runnin the whole test_type (""Core"") - I just enter breeze and try to run the same sequence of tests - simply individually rin the test packages/modulles that you see printed in the output - so for example from the above I try to run (there are some packages that are before that).

```
pytest ... tests/models tests/ti_deps tests/utils 
```

And see it fails

Now if you run:

```
pytest tests/ti_deps tests/utils 
```

And it fails - then you know side effect comes from either ti_deps or earlier utils - then you can remove ti_deps and see if it fails, then if you see tha it comes from utils, you run tests from individual modules in ti_utils in the same sequence you see below and remove first half and see if it fails - and so on. 

This is by far fastest way of narrowing down which test is creating the side-effect if you have no idea.

Here is the example output.

```
  ....
  tests/models/test_xcom_arg_map.py ...........                            [ 67%]
  tests/ti_deps/deps/test_dag_ti_slots_available_dep.py ..                 [ 67%]
  tests/ti_deps/deps/test_dag_unpaused_dep.py ..                           [ 67%]
  tests/ti_deps/deps/test_dagrun_exists_dep.py ..                          [ 67%]
  tests/ti_deps/deps/test_mapped_task_upstream_dep.py .................... [ 68%]
  ......................................................ssssssssssss...... [ 70%]
  ......                                                                   [ 71%]
  tests/ti_deps/deps/test_not_in_retry_period_dep.py ...                   [ 71%]
  tests/ti_deps/deps/test_not_previously_skipped_dep.py .....              [ 71%]
  tests/ti_deps/deps/test_pool_slots_available_dep.py .....                [ 71%]
  tests/ti_deps/deps/test_prev_dagrun_dep.py ...........                   [ 71%]
  tests/ti_deps/deps/test_ready_to_reschedule_dep.py ................      [ 72%]
  tests/ti_deps/deps/test_runnable_exec_date_dep.py .........              [ 72%]
  tests/ti_deps/deps/test_task_concurrency.py ..........                   [ 73%]
  tests/ti_deps/deps/test_task_not_running_dep.py ..                       [ 73%]
  tests/ti_deps/deps/test_trigger_rule_dep.py ............................ [ 74%]
  ........................................................................ [ 77%]
  ..........................                                               [ 78%]
  tests/ti_deps/deps/test_valid_state_dep.py ...                           [ 78%]
  tests/utils/log/test_colored_log.py .                                    [ 78%]
  tests/utils/log/test_file_processor_handler.py ssss                      [ 78%]
  tests/utils/log/test_json_formatter.py sssss                             [ 78%]
  tests/utils/log/test_log_reader.py ........                              [ 78%]
  tests/utils/log/test_secrets_masker.py sssssssssssssssssssssssssssssssss [ 80%]
  ssssssssssssssssssssssssss                                               [ 80%]
  tests/utils/test_cli_util.py ..................                          [ 81%]
  tests/utils/test_context.py ....sss                                      [ 81%]
  tests/utils/test_dag_cycle.py sssssssss                                  [ 82%]
  tests/utils/test_dataform.py ss                                          [ 82%]
  tests/utils/test_db.py ...................                               [ 83%]
  tests/utils/test_db_cleanup.py ......................................... [ 84%]
  ...                                                                      [ 84%]
  tests/utils/test_db_manager.py ........                                  [ 84%]
  tests/utils/test_decorators.py ssssssssssssssssssssssss                  [ 85%]
  tests/utils/test_docs.py ssss                                            [ 86%]
  tests/utils/test_dot_renderer.py ......                                  [ 86%]
  tests/utils/test_edgemodifier.py ssssssssssssss                          [ 86%]
  tests/utils/test_email.py sssssssssss..............                      [ 87%]
  tests/utils/test_entry_points.py s                                       [ 87%]
  tests/utils/test_event_scheduler.py s                                    [ 87%]
  tests/utils/test_file.py ssssssssssssssssssssss                          [ 88%]
  tests/utils/test_helpers.py .sssssssssss.ssssssssssssssssssssssssssss    [ 90%]
  tests/utils/test_json.py sssssssssssssssss                               [ 90%]
  tests/utils/test_log_handlers.py ...FFF.......................           [ 91%]
```

jason810496 (Issue Creator) on (2025-01-17 16:00:16 UTC): Thanks, @potiuk, for pointing out that the error might be caused by side effects from other tests and for providing the detailed guide to resolve it! I will try using the bisect approach to identify which test case is causing the side effect.  

Update:
Luckily, I found that it was caused by the `tests/ti_deps/` module after a few iterations!

jason810496 (Issue Creator) on (2025-01-18 14:32:44 UTC): TL;DR:  
The global state in the `executor_loader` module can cause side effects in other test cases if not properly torn down.  

The issue is caused by the `executor_loader` module, as it stores some state in global variables:  
https://github.com/apache/airflow/blob/main/airflow/executors/executor_loader.py#L48-L54  
This can lead to errors in `Executor.load_executor` or `Executor.get_default_executor` , as these methods rely on looking up `executor_name` in global variables. If a test interacts with `executor_loader` and doesn't clear the global variables, it may cause side effects in subsequent tests.  

---

In other test cases that use the `executor_loader` module, `reload` is employed.
However, in the current test case, we need to mock the `Executor.load_executor` and `Executor.get_default_executor` methods. Mixing `reload(executor_loader)` with mocks results in the mock object never being called, as the callable used during the test runtime bypasses the mock.  

From my perspective, cleaning the global variables in `executor_loader` should suffice for tearing down the state. I will create another PR to investigate whether this approach is correct and to evaluate how much test speed can be improved by replacing all `reload(executor_loader)` calls with `clean_executor_loader()`.

jason810496 (Issue Creator) on (2025-01-22 16:56:02 UTC): The CI failed due to https://github.com/apache/airflow/pull/45917. I'll wait for it to be merged, then rebase with the main branch, which should resolve the issue.

jason810496 (Issue Creator) on (2025-01-23 08:29:23 UTC): Resolved the issue, and the CI has successfully passed! 🎉
cc @o-nikolas

o-nikolas on (2025-01-23 18:35:04 UTC): Nice! LGTM, @Lee-W Has your feedback been addressed to your satisfaction?

Lee-W on (2025-01-24 02:58:40 UTC): Yep, looks good 🙂 let's merge it!

"
2785825921,pull_request,closed,,(bugfix): replace `create_event`  with `send_event`  in `PagerdutyNotifier`,"Closes: https://github.com/apache/airflow/issues/45626
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #45626 
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---

As noted in the most recent change log, https://airflow.apache.org/docs/apache-airflow-providers-pagerduty/stable/changelog.html, switch the create_event method to send_event. This PR fixes the provider as it still uses the prior method.

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bshea5,2025-01-14 00:38:15+00:00,[],2025-01-16 12:25:03+00:00,2025-01-15 18:56:30+00:00,https://github.com/apache/airflow/pull/45630,"[('area:providers', ''), ('provider:pagerduty', '')]","[{'comment_id': 2588507750, 'issue_id': 2785825921, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 14, 0, 38, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2588509780, 'issue_id': 2785825921, 'author': 'bshea5', 'body': 'Covers issue #45630', 'created_at': datetime.datetime(2025, 1, 14, 0, 40, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593713645, 'issue_id': 2785825921, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 15, 18, 56, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2595443755, 'issue_id': 2785825921, 'author': 'potiuk', 'body': '> The fact that we didn\'t catch this when create_event was removed from the hook means that something is not working properly with the tests. Merging to unblock the notifier but would be cool if someone has the time to look into the tests\r\n\r\n.They were just mocking hook\'s methods not API methods. But the fact is that MyPy should detect it. For some reason it did not. The ""self.hook"" is clearly `PagerdutyEventsHook` and it does not have `create_event` so there should be `no attr_defined` or similar mypy error ... but you never know with MyPy. Sometimes it does not detect obvious things like that.\r\n\r\nPotentially we could mock `pdpyras.EventsAPISession(self.integration_key)` session usage rather than hook usage and it would be detected in the tests.', 'created_at': datetime.datetime(2025, 1, 16, 12, 25, 1, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-14 00:38:18 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

bshea5 (Issue Creator) on (2025-01-14 00:40:18 UTC): Covers issue #45630

boring-cyborg[bot] on (2025-01-15 18:56:32 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2025-01-16 12:25:01 UTC): .They were just mocking hook's methods not API methods. But the fact is that MyPy should detect it. For some reason it did not. The ""self.hook"" is clearly `PagerdutyEventsHook` and it does not have `create_event` so there should be `no attr_defined` or similar mypy error ... but you never know with MyPy. Sometimes it does not detect obvious things like that.

Potentially we could mock `pdpyras.EventsAPISession(self.integration_key)` session usage rather than hook usage and it would be detected in the tests.

"
2785461588,pull_request,closed,,Start porting mapped task to SDK,"This PR restructures the Mapped Operator and Mapped Task Group code to live in
the Task SDK at definition time.

The big thing this change _does not do_ is make it possible to execute mapped
tasks via the Task Execution API server etc -- that is up next (https://github.com/apache/airflow/issues/44360).

There were some un-avoidable changes to the scheduler/expansion part of mapped
tasks here. Of note:

`BaseOperator.get_mapped_ti_count` has moved from an instance method on
BaseOperator to be a class method. The reason for this was that with the move
of more and more of the ""definition time"" code into the TaskSDK BaseOperator
and AbstractOperator it is no longer possible to add DB-accessing code to a
base class and have it apply to the subclasses. (i.e.
`airflow.models.abstractoperator.AbstractOperator` is now _not always_ in the
MRO for tasks. Eventually that class will be deleted, but not yet)

On a similar vein XComArg's `get_task_map_length` is also moved to a single
dispatch class method on the TaskMap model since now the definition time
objects live in the TaskSDK, and there is no realistic way to get a per-type
subclass with DB logic (i.e. it's very complex to end up with a
PlainDBXComArg, a MapDBXComArg, etc. that we can attach the method too)

For those who aren't aware, singledispatch (and singledispatchmethod) are a
part of the standard library when the type of the first argument is used to
determine which implementation to call. If you are familiar with C++ or Java
this is very similar to method overloading, the one caveat is that it _only_
examines the type of the first argument, not the full signature.

The long term goal here is to have a clean separation between ""runtime/definition time"" behaviour (i.e. creating mapped tasks, or running a mapped task) and expanding a mapped task (which is a scheduling-time operation only)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2025-01-13 21:26:32+00:00,[],2025-01-21 11:09:45+00:00,2025-01-21 11:05:19+00:00,https://github.com/apache/airflow/pull/45627,"[('area:serialization', ''), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR'), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]","[{'comment_id': 2588279778, 'issue_id': 2785461588, 'author': 'ashb', 'body': 'Mypy is seriously unhappy. Oh well', 'created_at': datetime.datetime(2025, 1, 13, 21, 42, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2588390323, 'issue_id': 2785461588, 'author': 'ashb', 'body': ""Oh also singlediaptch and singledispathmethod don't play _great_ with type hints in 3.9. Worked around that easily enough now though."", 'created_at': datetime.datetime(2025, 1, 13, 22, 50, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604416363, 'issue_id': 2785461588, 'author': 'kaxil', 'body': '![](https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExMGNmNWRueGljc3Zic3pkMjdzMGticmZ0NG9iZHcyNzJuNjc5a2N5ZSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/145ttXPiU8q6E0286z/giphy.gif)\r\n\r\n🎉 🎉 🎉', 'created_at': datetime.datetime(2025, 1, 21, 11, 6, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604423461, 'issue_id': 2785461588, 'author': 'kaxil', 'body': '#protm', 'created_at': datetime.datetime(2025, 1, 21, 11, 9, 43, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2025-01-13 21:42:14 UTC): Mypy is seriously unhappy. Oh well

ashb (Issue Creator) on (2025-01-13 22:50:08 UTC): Oh also singlediaptch and singledispathmethod don't play _great_ with type hints in 3.9. Worked around that easily enough now though.

kaxil on (2025-01-21 11:06:30 UTC): ![](https://media4.giphy.com/media/v1.Y2lkPTc5MGI3NjExMGNmNWRueGljc3Zic3pkMjdzMGticmZ0NG9iZHcyNzJuNjc5a2N5ZSZlcD12MV9pbnRlcm5hbF9naWZfYnlfaWQmY3Q9Zw/145ttXPiU8q6E0286z/giphy.gif)

🎉 🎉 🎉

kaxil on (2025-01-21 11:09:43 UTC): #protm

"
2785209706,pull_request,closed,,Convert exceptions raised in Flask application to fastapi exceptions,"A small Flask application is embedded in fastapi application using `WSGIMiddleware`. This flask application can throw some exceptions. These exceptions are then propagated to the fastapi application. Since these exceptions are specific to Flask and not handled on the fastapi side, it results as a 500.

This PR does two things:
- On Flask side, it convert these exceptions to JSON so that fastapi can parse them and understand them
- On fastapi side, through a middleware, if I receive an exception as JSON, I convert it to a fastapi exception

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-13 19:53:17+00:00,[],2025-01-14 15:31:15+00:00,2025-01-14 15:31:13+00:00,https://github.com/apache/airflow/pull/45625,"[('area:providers', ''), ('provider:fab', '')]",[],
2784568997,pull_request,closed,,Support `timeout` in BatchOperator,"When using a deferrable BatchOperator, it is possible to specify the `max_retries` and `poll_interval`, but this does not appear to terminate the job once the task times out.

Having the ability to specify the timeout and letting the job be terminated will allow us to enforce strict timeouts on critical pipelines running on Fargate via AWS Batch.

This PR adds support to allow specifying `timeout` in the BatchOperator constructor:\
https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/batch/client/submit_job.html

> timeout (dict) –
>
> The timeout configuration for this SubmitJob operation. You can specify a timeout duration after which Batch terminates your jobs if they haven’t finished. If a job is terminated due to a timeout, it isn’t retried. The minimum value for the timeout is 60 seconds. This configuration overrides any timeout configuration specified in the job definition. For array jobs, child jobs have the same timeout configuration as the parent job. For more information, see [Job Timeouts](https://docs.aws.amazon.com/AmazonECS/latest/developerguide/job_timeouts.html) in the Amazon Elastic Container Service Developer Guide.
>
> - attemptDurationSeconds (integer) –
>
>    The job timeout time (in seconds) that’s measured from the job attempt’s startedAt timestamp. After this time passes, Batch terminates your jobs if they aren’t finished. The minimum value for the timeout is 60 seconds.
>
>    For array jobs, the timeout applies to the child jobs, not to the parent array job.
>
>    For multi-node parallel (MNP) jobs, the timeout applies to the whole job, not to the individual nodes.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",nrobinson-intelycare,2025-01-13 16:39:20+00:00,[],2025-01-15 00:26:58+00:00,2025-01-15 00:26:58+00:00,https://github.com/apache/airflow/pull/45619,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2587622916, 'issue_id': 2784568997, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 13, 16, 39, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2591146469, 'issue_id': 2784568997, 'author': 'nrobinson-intelycare', 'body': ""Something is up, I'll try to get the tests working locally"", 'created_at': datetime.datetime(2025, 1, 14, 21, 33, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2591380264, 'issue_id': 2784568997, 'author': 'nrobinson-intelycare', 'body': 'Moved to https://github.com/apache/airflow/pull/45660 to avoid merge commits', 'created_at': datetime.datetime(2025, 1, 15, 0, 26, 58, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-13 16:39:25 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

nrobinson-intelycare (Issue Creator) on (2025-01-14 21:33:51 UTC): Something is up, I'll try to get the tests working locally

nrobinson-intelycare (Issue Creator) on (2025-01-15 00:26:58 UTC): Moved to https://github.com/apache/airflow/pull/45660 to avoid merge commits

"
2784256478,pull_request,closed,,Move `list_py_file_paths` test to the right file (#45521),"This was reverted along with #45371, but that's back in main now so now is the time to bring this back too.",jedcunningham,2025-01-13 15:05:05+00:00,[],2025-01-13 16:04:55+00:00,2025-01-13 16:04:53+00:00,https://github.com/apache/airflow/pull/45617,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2784111123,pull_request,closed,,Replaced fail_stop to fail_fast successfully,"Rename 'fail_Stop' to 'fail_fast' for consistency

Replaced instances of 'fail_Stop' with 'fail_fast' to maintain naming consistency across the project. This change aligns with established conventions and improves readability in the codebase.
",ishi142005,2025-01-13 14:20:41+00:00,[],2025-01-13 14:28:16+00:00,2025-01-13 14:28:16+00:00,https://github.com/apache/airflow/pull/45616,"[('area:task-sdk', None)]","[{'comment_id': 2587233238, 'issue_id': 2784111123, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 13, 14, 20, 45, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-13 14:20:45 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2784096626,pull_request,closed,,include AirflowDagRunFacet in complete/failed OpenLineage events,"This ensures that AirflowDagRunFacet, currently only attached to `start` OpenLineage events, is also attached to `complete` or `failed`. 

This enables OpenLineage consumers easier access to DR-level information on job complete, being able, for example, to efficiently calculate the duration of a particular run. ",mobuchowski,2025-01-13 14:15:56+00:00,[],2025-01-13 15:07:38+00:00,2025-01-13 15:07:38+00:00,https://github.com/apache/airflow/pull/45615,"[('area:providers', ''), ('provider:openlineage', 'AIP-53')]",[],
2783686304,pull_request,closed,,[v2-10-test] Provide package write permissions to push-ci-image-cache job (#45573),"(cherry picked from commit 14f6622827c216a1091b24778e868598422ad9f1)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-13 11:21:40+00:00,[],2025-01-13 11:23:16+00:00,2025-01-13 11:23:14+00:00,https://github.com/apache/airflow/pull/45612,"[('area:dev-tools', '')]","[{'comment_id': 2586841219, 'issue_id': 2783686304, 'author': 'potiuk', 'body': 'That backport should fix pushing image cache in `v2-10-test` that is currently failing', 'created_at': datetime.datetime(2025, 1, 13, 11, 22, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2586842715, 'issue_id': 2783686304, 'author': 'potiuk', 'body': 'Failure here: https://github.com/apache/airflow/actions/runs/12742913151/job/35513738172', 'created_at': datetime.datetime(2025, 1, 13, 11, 23, 8, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-13 11:22:22 UTC): That backport should fix pushing image cache in `v2-10-test` that is currently failing

potiuk (Issue Creator) on (2025-01-13 11:23:08 UTC): Failure here: https://github.com/apache/airflow/actions/runs/12742913151/job/35513738172

"
2783669270,pull_request,closed,,Add missing methods in fab provider's AirflowAppBuilder class,"Adding missing method `add_permissions` in FAB's AirflowAppBuilder class which we started using in this [PR](https://github.com/apache/airflow/pull/45441/files).

more info - https://github.com/apache/airflow/pull/45441/files#r1910360144",utkarsharma2,2025-01-13 11:13:40+00:00,[],2025-01-14 18:10:00+00:00,2025-01-13 13:41:33+00:00,https://github.com/apache/airflow/pull/45611,"[('area:providers', ''), ('provider:fab', '')]",[],
2783659932,pull_request,closed,,BigQueryCreateExternalTableOperator pass schema_fields through if only it set explicitly,"Closes https://github.com/apache/airflow/issues/45512

This PR fixes the case when schema `autodetect` is used in `BigQueryCreateExternalTableOperator`. Currently, the table created in BigQuery can't be queried when empty `schema.fields` are passed to GCP. Simply omitting empty `schema.fields` to be passed in request body to GCP allows schema auto-detection flow to prosper.

This part of API is marked as deprecated, hence [unit tests](https://github.com/apache/airflow/commit/ffe09d62ed15bbc09aeba19ebd5d1b2a2cc8e0ed) I was able to come up with fail:
```
E   airflow.exceptions.AirflowProviderDeprecationWarning: Passing table parameters via keywords arguments will be deprecated. Please provide table definition using `table_resource` parameter.
```

I was able to run that test with `--disable-forbidden-warnings ` flag:
```
pytest --disable-forbidden-warnings providers/tests/google/cloud/operators/test_bigquery.py::TestBigQueryCreateExternalTableOperator
...

providers/tests/google/cloud/operators/test_bigquery.py::TestBigQueryCreateExternalTableOperator::test_execute_with_csv_format PASSED                                                                          [ 25%]
providers/tests/google/cloud/operators/test_bigquery.py::TestBigQueryCreateExternalTableOperator::test_execute_with_parquet_format PASSED                                                                      [ 50%]
providers/tests/google/cloud/operators/test_bigquery.py::TestBigQueryCreateExternalTableOperator::test_get_openlineage_facets_on_complete PASSED                                                               [ 75%]
providers/tests/google/cloud/operators/test_bigquery.py::TestBigQueryCreateExternalTableOperator::test_execute_with_schema_fields_not_set PASSED                                                               [100%]
...
============================================================================================ 4 passed, 1 warning in 1.83s ============================================================================================
```",EugeneYushin,2025-01-13 11:09:18+00:00,[],2025-02-05 15:08:45+00:00,2025-02-05 15:08:38+00:00,https://github.com/apache/airflow/pull/45610,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2586813833, 'issue_id': 2783659932, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 13, 11, 9, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2629456348, 'issue_id': 2783659932, 'author': 'VladaZakharova', 'body': ""> I'll be happy to approve and merge, after handling the unit test and the CI issue (probably merging from `main` shold help). @EugeneYushin - Could you please try @MaksYermak 's suggestion?\r\n\r\nHi! I am afraid we can't merge this code. We are working rn on actually deprecating both BigQueryCreateExternalTableOperator and BigQueryCreateEmptyTableOperator since there is a lot of misunderstanding because of those deprecations of parameters. So there will be a new BigQueryCreateTableOperator which will support current logic from both those operators"", 'created_at': datetime.datetime(2025, 2, 2, 16, 12, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2629521673, 'issue_id': 2783659932, 'author': 'EugeneYushin', 'body': ""> > I'll be happy to approve and merge, after handling the unit test and the CI issue (probably merging from `main` shold help). @EugeneYushin - Could you please try @MaksYermak 's suggestion?\r\n> \r\n> Hi! I am afraid we can't merge this code. We are working rn on actually deprecating both BigQueryCreateExternalTableOperator and BigQueryCreateEmptyTableOperator since there is a lot of misunderstanding because of those deprecations of parameters. So there will be a new BigQueryCreateTableOperator which will support current logic from both those operators\r\n\r\n@VladaZakharova What do you think would be the best way to handle this PR? Should I just close it with empty resolution?"", 'created_at': datetime.datetime(2025, 2, 2, 19, 21, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2630731893, 'issue_id': 2783659932, 'author': 'MaksYermak', 'body': ""> > > I'll be happy to approve and merge, after handling the unit test and the CI issue (probably merging from `main` shold help). @EugeneYushin - Could you please try @MaksYermak 's suggestion?\r\n> > \r\n> > \r\n> > Hi! I am afraid we can't merge this code. We are working rn on actually deprecating both BigQueryCreateExternalTableOperator and BigQueryCreateEmptyTableOperator since there is a lot of misunderstanding because of those deprecations of parameters. So there will be a new BigQueryCreateTableOperator which will support current logic from both those operators\r\n> \r\n> @VladaZakharova What do you think would be the best way to handle this PR? Should I just close it with empty resolution?\r\n\r\n@EugeneYushin it's better to close this PR, without resolution. Soon we will create a new operator `BigQueryCreateTableOperator` and deprecate `BigQueryCreateExternalTableOperator` and `BigQueryCreateEmptyTableOperator` operators. As a solution for `autodetect`'s  problem you can pass the `table_resource` parameter to the Operator as a `dict` or `Table` object."", 'created_at': datetime.datetime(2025, 2, 3, 11, 52, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2637130049, 'issue_id': 2783659932, 'author': 'potiuk', 'body': 'Closing', 'created_at': datetime.datetime(2025, 2, 5, 15, 8, 44, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-13 11:09:37 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

VladaZakharova on (2025-02-02 16:12:06 UTC): Hi! I am afraid we can't merge this code. We are working rn on actually deprecating both BigQueryCreateExternalTableOperator and BigQueryCreateEmptyTableOperator since there is a lot of misunderstanding because of those deprecations of parameters. So there will be a new BigQueryCreateTableOperator which will support current logic from both those operators

EugeneYushin (Issue Creator) on (2025-02-02 19:21:24 UTC): @VladaZakharova What do you think would be the best way to handle this PR? Should I just close it with empty resolution?

MaksYermak on (2025-02-03 11:52:14 UTC): @EugeneYushin it's better to close this PR, without resolution. Soon we will create a new operator `BigQueryCreateTableOperator` and deprecate `BigQueryCreateExternalTableOperator` and `BigQueryCreateEmptyTableOperator` operators. As a solution for `autodetect`'s  problem you can pass the `table_resource` parameter to the Operator as a `dict` or `Table` object.

potiuk on (2025-02-05 15:08:44 UTC): Closing

"
2783647671,pull_request,closed,,AIP-84 Log User Actions,"Related: https://github.com/apache/airflow/issues/44057

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2025-01-13 11:03:30+00:00,[],2025-01-27 14:09:25+00:00,2025-01-27 14:09:22+00:00,https://github.com/apache/airflow/pull/45609,[],"[{'comment_id': 2601318774, 'issue_id': 2783647671, 'author': 'vatsrahul1001', 'body': '@pierrejeambrun request your review on this', 'created_at': datetime.datetime(2025, 1, 20, 4, 36, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2615655180, 'issue_id': 2783647671, 'author': 'vatsrahul1001', 'body': ""> Looking for `public/connections` and `public/variables` is a good idea.\r\n> \r\n> In the current form it will not work because you remove `/` and replace them with `.` in the event name generation.\r\n> \r\n> I think we need to look for `public.connections` and `public.variables` **in** `event_name` (event_name contains `public.connections` or `public.variables`. Can you write a test to verify that the appropriate code is being called for connections and variables ? (You can provide a test dependency for`request` to give the appropriate route and mock `_mask_variable_fields` to verify that it's actually being called).\r\n\r\n@pierrejeambrun I have added a test. Also I am keeping event name with `/`"", 'created_at': datetime.datetime(2025, 1, 27, 12, 39, 58, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2025-01-20 04:36:33 UTC): @pierrejeambrun request your review on this

vatsrahul1001 (Issue Creator) on (2025-01-27 12:39:58 UTC): @pierrejeambrun I have added a test. Also I am keeping event name with `/`

"
2783339063,pull_request,closed,,Add tests for dag filtering in home page and dag documentation modal,"This adds basic tests to ensure filter buttons in dags list page works. This also adds tests for dag documentation button and modal opening flow on click.

* Create a router that has all the routes configured to a memory router. https://api.reactrouter.com/v7/functions/react_router.createMemoryRouter.html
* Create a wrapper that uses the configured router and also accepts `initialEntries` to load the tests in a given URL location for assertion. There were some issues in using existing `Wrapper.tsx` with the changes in existing tests so created using `AppWrapper.tsx` with the changes to keep them separate.
* vitest recommends using msw for mocking requests. https://vitest.dev/guide/mocking#requests
* Handlers structured as per best practices to mock endpoints : https://mswjs.io/docs/best-practices/structuring-handlers
* On each test create a server with the handlers so that the test data is used.",tirkarthi,2025-01-13 08:39:51+00:00,[],2025-01-27 12:53:45+00:00,2025-01-24 18:24:31+00:00,https://github.com/apache/airflow/pull/45607,"[('type:improvement', 'Changelog: Improvements'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2610910609, 'issue_id': 2783339063, 'author': 'bbovenzi', 'body': 'But it looks like we need a rebase', 'created_at': datetime.datetime(2025, 1, 23, 20, 4, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613093155, 'issue_id': 2783339063, 'author': 'tirkarthi', 'body': 'Rebased against main which had changes to markdown rendering components.', 'created_at': datetime.datetime(2025, 1, 24, 17, 56, 48, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2025-01-23 20:04:15 UTC): But it looks like we need a rebase

tirkarthi (Issue Creator) on (2025-01-24 17:56:48 UTC): Rebased against main which had changes to markdown rendering components.

"
2782754100,pull_request,closed,,Protect against missing .uv cache,"In v2-10-test for now we have no uv used to install static checks because we cannot use latest uv version and pre-commit-uv with python 3.8.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 23:32:23+00:00,[],2025-01-13 08:01:48+00:00,2025-01-13 08:01:47+00:00,https://github.com/apache/airflow/pull/45605,"[('area:dev-tools', ''), ('canary', 'When set on PR running from apache repo - behave as canary run')]","[{'comment_id': 2585964547, 'issue_id': 2782754100, 'author': 'potiuk', 'body': 'At this moment canary builds are failing in v2-10-test because of that.', 'created_at': datetime.datetime(2025, 1, 12, 23, 33, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585964745, 'issue_id': 2782754100, 'author': 'potiuk', 'body': 'https://github.com/apache/airflow/actions/runs/12737573988/job/35498983821', 'created_at': datetime.datetime(2025, 1, 12, 23, 34, 2, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-12 23:33:27 UTC): At this moment canary builds are failing in v2-10-test because of that.

potiuk (Issue Creator) on (2025-01-12 23:34:02 UTC): https://github.com/apache/airflow/actions/runs/12737573988/job/35498983821

"
2782752734,pull_request,closed,,[v2-10-test] Upgrade sphinx and related dependencies (#45563) (#45596),"
---------

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 23:28:46+00:00,[],2025-01-12 23:29:32+00:00,2025-01-12 23:29:32+00:00,https://github.com/apache/airflow/pull/45604,"[('area:dev-tools', ''), ('canary', 'When set on PR running from apache repo - behave as canary run')]",[],
2782744001,pull_request,closed,,Add missing newline on dbt Cloud conn string example,"The [Connecting to dbt Cloud](https://airflow.apache.org/docs/apache-airflow-providers-dbt-cloud/stable/connections.html) page has a code block which is not rendering correctly: 

<img width=""878"" alt=""Screenshot 2025-01-13 at 12 03 44 PM"" src=""https://github.com/user-attachments/assets/0a0f9917-6abe-4b59-97bf-2eafcb8f7edb"" />

This PR adds the missing newline so that it will be properly treated as a code block. 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",joellabes,2025-01-12 23:04:46+00:00,[],2025-01-13 17:19:34+00:00,2025-01-13 12:13:06+00:00,https://github.com/apache/airflow/pull/45603,"[('area:providers', ''), ('kind:documentation', ''), ('provider:dbt-cloud', '')]","[{'comment_id': 2585955178, 'issue_id': 2782744001, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 12, 23, 4, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2586944546, 'issue_id': 2782744001, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 13, 12, 13, 9, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-12 23:04:51 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2025-01-13 12:13:09 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2782664368,pull_request,closed,,Remove init File with the Wrong Name in Core API Services,"I haven't realised this is duplicated while working on the grid service and the other one autogenerated. Small cleanup.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2025-01-12 19:53:38+00:00,[],2025-01-14 11:31:00+00:00,2025-01-14 11:31:00+00:00,https://github.com/apache/airflow/pull/45602,[],[],
2782632394,pull_request,closed,,[v1-10-test] Remove workflow run from v1 10 stable,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 18:42:29+00:00,[],2025-01-12 18:52:14+00:00,2025-01-12 18:52:13+00:00,https://github.com/apache/airflow/pull/45600,"[('area:dev-tools', '')]","[{'comment_id': 2585867425, 'issue_id': 2782632394, 'author': 'potiuk', 'body': 'One more place where we had `workflow_run` rather than `pull_request_target` :)', 'created_at': datetime.datetime(2025, 1, 12, 18, 44, 48, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-12 18:44:48 UTC): One more place where we had `workflow_run` rather than `pull_request_target` :)

"
2782604998,pull_request,closed,,Make Python 3.9 default for v2-10-test branch,"Since we are switching to Sphinx7, we need to build docs using Python 3.9. We need to make sure that Python 3.9 is default image.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 17:45:16+00:00,[],2025-01-28 12:07:59+00:00,2025-01-12 20:45:21+00:00,https://github.com/apache/airflow/pull/45599,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2585847895, 'issue_id': 2782604998, 'author': 'potiuk', 'body': 'I think this should be as simple as that one line change @shahar1 :)', 'created_at': datetime.datetime(2025, 1, 12, 17, 45, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585849587, 'issue_id': 2782604998, 'author': 'potiuk', 'body': 'With some unit tests of course :)\r\n\r\nLet\'s see - but after removal of the ""pull_request_target"" - such changes are quite a bit simpler as we have only ""current"" workflow - not two workflows to synchronize - one from PR and one from branch.', 'created_at': datetime.datetime(2025, 1, 12, 17, 51, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585856423, 'issue_id': 2782604998, 'author': 'potiuk', 'body': 'OK. One more place where 3.8 had to be changed to 3.9 - we have static checks using it. Also some docs - just in case and error messages pointing to build 3.9 shoudl be updated. Will make @jscheffl 3.8-3.9 PR smaller :)', 'created_at': datetime.datetime(2025, 1, 12, 18, 14, 34, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-12 17:45:57 UTC): I think this should be as simple as that one line change @shahar1 :)

potiuk (Issue Creator) on (2025-01-12 17:51:57 UTC): With some unit tests of course :)

Let's see - but after removal of the ""pull_request_target"" - such changes are quite a bit simpler as we have only ""current"" workflow - not two workflows to synchronize - one from PR and one from branch.

potiuk (Issue Creator) on (2025-01-12 18:14:34 UTC): OK. One more place where 3.8 had to be changed to 3.9 - we have static checks using it. Also some docs - just in case and error messages pointing to build 3.9 shoudl be updated. Will make @jscheffl 3.8-3.9 PR smaller :)

"
2782529415,pull_request,closed,,[v2-10-test] Upgrade sphinx and related dependencies (#45563),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
backports: #45563


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2025-01-12 14:59:17+00:00,[],2025-01-28 12:08:06+00:00,2025-01-12 22:20:08+00:00,https://github.com/apache/airflow/pull/45596,"[('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2585850252, 'issue_id': 2782529415, 'author': 'potiuk', 'body': ""After #45599 -> this one have a chance to work @shahar1, but I think you will have to have conditional dependency - depending on python versions, otherwise python3.8 won't be installable / image won't be buildable."", 'created_at': datetime.datetime(2025, 1, 12, 17, 54, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585910993, 'issue_id': 2782529415, 'author': 'potiuk', 'body': 'OK. Rebased it after merging 3.9 as default - but I guess it might fail for Python 3.8 until the conditional sphinx /docutils for Python 3.9+', 'created_at': datetime.datetime(2025, 1, 12, 20, 47, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585921410, 'issue_id': 2782529415, 'author': 'potiuk', 'body': ""Yeah. That's what I thought. I added `; python_version >= '3.9'` to all doc dependencies and it should help with building 3.8 image."", 'created_at': datetime.datetime(2025, 1, 12, 21, 23, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585940620, 'issue_id': 2782529415, 'author': 'potiuk', 'body': 'HURRAY! FIRST STEP DONE :)', 'created_at': datetime.datetime(2025, 1, 12, 22, 20, 34, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-12 17:54:36 UTC): After #45599 -> this one have a chance to work @shahar1, but I think you will have to have conditional dependency - depending on python versions, otherwise python3.8 won't be installable / image won't be buildable.

potiuk on (2025-01-12 20:47:20 UTC): OK. Rebased it after merging 3.9 as default - but I guess it might fail for Python 3.8 until the conditional sphinx /docutils for Python 3.9+

potiuk on (2025-01-12 21:23:35 UTC): Yeah. That's what I thought. I added `; python_version >= '3.9'` to all doc dependencies and it should help with building 3.8 image.

potiuk on (2025-01-12 22:20:34 UTC): HURRAY! FIRST STEP DONE :)

"
2782524188,pull_request,closed,,"Revert ""Disable branch protection for old, inactive releases temporar…","…ily (#45592)""

This reverts commit a1fab3d69552d8cdf18ce33ee5ba2f57addb8a31.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 14:50:41+00:00,[],2025-01-12 16:11:35+00:00,2025-01-12 16:11:33+00:00,https://github.com/apache/airflow/pull/45594,"[('area:dev-tools', '')]",[],
2782523561,pull_request,closed,,"Revert ""Remove classes from `typing_compat` that can be imported dire…","…ctly (#45589)""

This reverts commit 6307a123d2c1bec99d671914cb18bc93c4c8933b.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 14:49:15+00:00,[],2025-01-12 14:49:38+00:00,2025-01-12 14:49:31+00:00,https://github.com/apache/airflow/pull/45593,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:providers', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('area:Triggerer', ''), ('provider:openlineage', 'AIP-53'), ('provider:dbt-cloud', '')]","[{'comment_id': 2585763847, 'issue_id': 2782523561, 'author': 'potiuk', 'body': 'Wrong one :)', 'created_at': datetime.datetime(2025, 1, 12, 14, 49, 37, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-12 14:49:37 UTC): Wrong one :)

"
2782515568,pull_request,closed,,"Disable branch protection for old, inactive releases temporarily","In order to remove ""pull_request_target"" from old branches it is easiest to remove branch protection from old branches.

It's not dangerous - since we do not use those branches any more for releases, but we should bring it back for extra safety after the removal is complete

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 14:31:34+00:00,[],2025-01-12 14:39:28+00:00,2025-01-12 14:39:27+00:00,https://github.com/apache/airflow/pull/45592,"[('area:dev-tools', '')]",[],
2782504270,pull_request,closed,,[providers-fab/v1-5] Synchronize build scripts with main,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 14:07:25+00:00,[],2025-01-12 22:08:11+00:00,2025-01-12 22:08:11+00:00,https://github.com/apache/airflow/pull/45591,"[('area:dev-tools', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2585749603, 'issue_id': 2782504270, 'author': 'potiuk', 'body': 'This one synchronizes ""pull_request_target"" workflow changes with tip of the `providers-fab/v1-5` branch', 'created_at': datetime.datetime(2025, 1, 12, 14, 8, 27, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585750651, 'issue_id': 2782504270, 'author': 'potiuk', 'body': 'Same story as for `v2-10-test` -> that `providers-fab/v1-5` branch also still has `pull-request-target` workflow and it needs to be removed.', 'created_at': datetime.datetime(2025, 1, 12, 14, 11, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585752694, 'issue_id': 2782504270, 'author': 'potiuk', 'body': '> Same as previous PR - but hoping that not (many/any) patch cycles on this branch are needed.\r\n\r\nYeah. That one should be WAY easier to get green.', 'created_at': datetime.datetime(2025, 1, 12, 14, 16, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585784225, 'issue_id': 2782504270, 'author': 'eladkal', 'body': ""Why do we need this change?\r\nWe don't have plans to cut another release feom this branch"", 'created_at': datetime.datetime(2025, 1, 12, 15, 42, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585793226, 'issue_id': 2782504270, 'author': 'potiuk', 'body': ""> We don't have plans to cut another release feom this branch\r\n\r\nWe might need to do it (because of security) - and I know of some security fixes that are coming to FAB.\r\nI prefer to do it now - when I know exactly how to fix issues, because I've just done it for v2-10-test - rather than trying to remember it 3 weeks from now."", 'created_at': datetime.datetime(2025, 1, 12, 16, 10, 2, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-12 14:08:27 UTC): This one synchronizes ""pull_request_target"" workflow changes with tip of the `providers-fab/v1-5` branch

potiuk (Issue Creator) on (2025-01-12 14:11:02 UTC): Same story as for `v2-10-test` -> that `providers-fab/v1-5` branch also still has `pull-request-target` workflow and it needs to be removed.

potiuk (Issue Creator) on (2025-01-12 14:16:40 UTC): Yeah. That one should be WAY easier to get green.

eladkal on (2025-01-12 15:42:39 UTC): Why do we need this change?
We don't have plans to cut another release feom this branch

potiuk (Issue Creator) on (2025-01-12 16:10:02 UTC): We might need to do it (because of security) - and I know of some security fixes that are coming to FAB.
I prefer to do it now - when I know exactly how to fix issues, because I've just done it for v2-10-test - rather than trying to remember it 3 weeks from now.

"
2782500421,pull_request,closed,,doc: breeze /files/dags in container,,raphaelauv,2025-01-12 13:59:28+00:00,[],2025-01-12 17:28:20+00:00,2025-01-12 17:27:42+00:00,https://github.com/apache/airflow/pull/45590,"[('area:dev-tools', '')]",[],
2782486133,pull_request,closed,,Remove classes from `typing_compat` that can be imported directly,"`Protocol`, `TypedDict` and `runtime_checkable` are directly importable from `typing` module for the Python versions supported by Airflow main and Providers.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-12 13:27:50+00:00,[],2025-01-12 14:48:21+00:00,2025-01-12 14:48:20+00:00,https://github.com/apache/airflow/pull/45589,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:CLI', ''), ('area:providers', ''), ('area:serialization', ''), ('area:API', ""Airflow's REST/HTTP API""), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('provider:openlineage', 'AIP-53'), ('provider:dbt-cloud', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]",[],
2782481628,pull_request,closed,,V2 10 test,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 13:17:18+00:00,[],2025-01-12 14:12:18+00:00,2025-01-12 14:12:17+00:00,https://github.com/apache/airflow/pull/45588,"[('area:dev-tools', '')]","[{'comment_id': 2585732175, 'issue_id': 2782481628, 'author': 'potiuk', 'body': 'We need to merge v2-10-test (with fast-forward) now - in order to remove last ""pull_request_target"" workflow from v2-10-stable. @kaxil @utkarsharma2 @jscheffl -> This means that we need to merge stable before preparing 2.10.5 or 2.11.0 -> so that might change a bit the process of releasing - but for security reasons, we should do it now.', 'created_at': datetime.datetime(2025, 1, 12, 13, 19, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585732903, 'issue_id': 2782481628, 'author': 'potiuk', 'body': 'I think our changelog preparation will work anyway - because it is based on tags not branches, so it should work same way as usual (and we can fix it if not).', 'created_at': datetime.datetime(2025, 1, 12, 13, 20, 53, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-12 13:19:17 UTC): We need to merge v2-10-test (with fast-forward) now - in order to remove last ""pull_request_target"" workflow from v2-10-stable. @kaxil @utkarsharma2 @jscheffl -> This means that we need to merge stable before preparing 2.10.5 or 2.11.0 -> so that might change a bit the process of releasing - but for security reasons, we should do it now.

potiuk (Issue Creator) on (2025-01-12 13:20:53 UTC): I think our changelog preparation will work anyway - because it is based on tags not branches, so it should work same way as usual (and we can fix it if not).

"
2782436945,pull_request,closed,,List Pools under the admin nav button,"Pools option:
<img width=""1725"" alt=""Screenshot 2025-01-12 at 4 01 30 PM"" src=""https://github.com/user-attachments/assets/58ca80c7-54d6-4323-a321-4f8c040f1393"" />

Deferred flag status:
<img width=""1725"" alt=""Screenshot 2025-01-12 at 4 36 30 PM"" src=""https://github.com/user-attachments/assets/f992f609-91ff-4c7b-b6ae-da751e2d47c9"" />

Different slots:
<img width=""1725"" alt=""Screenshot 2025-01-12 at 4 36 36 PM"" src=""https://github.com/user-attachments/assets/4a7370cd-a736-4819-a206-5ec9d7ec2f32"" />


related: #43706


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-12 11:31:00+00:00,[],2025-01-27 13:10:11+00:00,2025-01-21 23:26:21+00:00,https://github.com/apache/airflow/pull/45587,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2585699924, 'issue_id': 2782436945, 'author': 'shubhamraj-git', 'body': 'I have currently utilised the Run status colour which closely aligns with the pool slot options. Reason to that is, run status colours are used all over the UI from a single source of truth(airflow/ui/src/utils/stateColor.ts). Just to not confuse users I kept the same colours of that.\r\n\r\nThe stateColor currently used are:\r\n```\r\nexport const stateColor = {\r\n  deferred: ""mediumpurple"",\r\n  failed: ""red"",\r\n  null: ""lightblue"",\r\n  queued: ""gray"",\r\n  removed: ""lightgrey"",\r\n  restarting: ""violet"",\r\n  running: ""lime"",\r\n  scheduled: ""tan"",\r\n  skipped: ""hotpink"",\r\n  success: ""green"",\r\n  up_for_reschedule: ""turquoise"",\r\n  up_for_retry: ""gold"",\r\n  upstream_failed: ""orange"",\r\n};\r\n```\r\nOne advantage of this would be when users will personalise the status colours of runs (https://airflow.apache.org/docs/apache-airflow/1.10.13/howto/customize-state-colors-ui.html) these values will also change.\r\n\r\nIf we should have a fixed colour, we can  use the below options: (Open to discussion)\r\n```\r\nOpen Slots\t     Green\r\nScheduled Slots\t     Gray\t\r\nRunning Slots\t     Blue\t\r\nQueued Slots\t     Orange\r\nOccupied Slots\t     Yellow\t\r\nDeferred Slots\t     Red\t\r\n```\r\n\r\nWhich would look like\r\n<img width=""1725"" alt=""Screenshot 2025-01-12 at 4 01 20\u202fPM"" src=""https://github.com/user-attachments/assets/5fda2655-45d7-48ce-86b7-60f92620787e"" />', 'created_at': datetime.datetime(2025, 1, 12, 11, 44, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593420153, 'issue_id': 2782436945, 'author': 'shubhamraj-git', 'body': '@bbovenzi Also, regarding slots icons, let me think of something, will try something COOL in upcoming PRs!', 'created_at': datetime.datetime(2025, 1, 15, 16, 42, 52, tzinfo=datetime.timezone.utc)}]","shubhamraj-git (Issue Creator) on (2025-01-12 11:44:40 UTC): I have currently utilised the Run status colour which closely aligns with the pool slot options. Reason to that is, run status colours are used all over the UI from a single source of truth(airflow/ui/src/utils/stateColor.ts). Just to not confuse users I kept the same colours of that.

The stateColor currently used are:
```
export const stateColor = {
  deferred: ""mediumpurple"",
  failed: ""red"",
  null: ""lightblue"",
  queued: ""gray"",
  removed: ""lightgrey"",
  restarting: ""violet"",
  running: ""lime"",
  scheduled: ""tan"",
  skipped: ""hotpink"",
  success: ""green"",
  up_for_reschedule: ""turquoise"",
  up_for_retry: ""gold"",
  upstream_failed: ""orange"",
};
```
One advantage of this would be when users will personalise the status colours of runs (https://airflow.apache.org/docs/apache-airflow/1.10.13/howto/customize-state-colors-ui.html) these values will also change.

If we should have a fixed colour, we can  use the below options: (Open to discussion)
```
Open Slots	     Green
Scheduled Slots	     Gray	
Running Slots	     Blue	
Queued Slots	     Orange
Occupied Slots	     Yellow	
Deferred Slots	     Red	
```

Which would look like
<img width=""1725"" alt=""Screenshot 2025-01-12 at 4 01 20 PM"" src=""https://github.com/user-attachments/assets/5fda2655-45d7-48ce-86b7-60f92620787e"" />

shubhamraj-git (Issue Creator) on (2025-01-15 16:42:52 UTC): @bbovenzi Also, regarding slots icons, let me think of something, will try something COOL in upcoming PRs!

"
2782381857,pull_request,closed,,Limit sphinx-airlfow-theme in preparation to Sphinx 7 upgrade,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-12 09:57:25+00:00,[],2025-01-12 10:59:27+00:00,2025-01-12 10:59:26+00:00,https://github.com/apache/airflow/pull/45586,[],"[{'comment_id': 2585686205, 'issue_id': 2782381857, 'author': 'potiuk', 'body': 'Random K8s issues', 'created_at': datetime.datetime(2025, 1, 12, 10, 59, 24, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-12 10:59:24 UTC): Random K8s issues

"
2782352897,pull_request,closed,,Remove code for deprecation of Context keys,"We removed all the deprecated keys in https://github.com/apache/airflow/pull/43902 so we no longer need this code.

In preparation of https://github.com/apache/airflow/pull/45583, I want to simplify this code. We can always revert/re-add this later when we need to deprecate a key.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-12 08:37:52+00:00,[],2025-01-12 13:15:07+00:00,2025-01-12 13:15:06+00:00,https://github.com/apache/airflow/pull/45585,"[('area:providers', ''), ('provider:standard', '')]",[],
2782331192,pull_request,closed,,Fix Context Type hint,"PR removes now deprecated `AssetEventPydantic` & `DagRunPydantic`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-12 07:32:18+00:00,[],2025-01-12 09:08:06+00:00,2025-01-12 09:08:06+00:00,https://github.com/apache/airflow/pull/45584,[],[],
2782078024,pull_request,closed,,AIP-72: Support better type-hinting for Context dict in SDK ,"This PR adds a `Context` class that is used for Type hinting of the Context dictionary. It replaces Context in the Scheduler.

part of https://github.com/apache/airflow/issues/44481

Next PRs:

- [ ] Port remaining keys to Task SDK's Context dict
- [x] Change Typehint in providers while keeping support for 2.x
- [ ] Remove context dict duplication in the following code: https://github.com/apache/airflow/blob/1cf1d628404ab62f979d2b0d9936ca5af001f44f/airflow/models/taskinstance.py#L1009-L1051

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-11 18:51:13+00:00,[],2025-01-14 19:58:37+00:00,2025-01-14 19:58:35+00:00,https://github.com/apache/airflow/pull/45583,"[('area:providers', ''), ('area:dev-tools', ''), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow'), ('area:Executors-core', 'LocalExecutor & SequentialExecutor'), ('provider:standard', ''), ('area:task-sdk', None)]",[],
2782052415,pull_request,closed,,[v2-10-test] Update spelling wordlist (#45579),"(cherry picked from commit d53d07ccf277f2d567497e96394f361cee259de2)

(cherry picked from commit 13f5bd6d75f4707091dbeea89b59be9acdcfec87)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2025-01-11 18:17:51+00:00,[],2025-01-11 19:06:26+00:00,2025-01-11 19:06:25+00:00,https://github.com/apache/airflow/pull/45582,"[('kind:documentation', '')]",[],
2782042091,pull_request,closed,,[v2-10-test] Ensure teardown tasks are executed when DAG run is set to failed (#45530),"* Ensure teardown tasks are executed when DAG run is set to failed

* Also handle the case of setting DAG to success

* Add some documentation to behavior changes

* Add some documentation to behavior changes
(cherry picked from commit 1e8977a2ea24e989c6c57ee3cb8e7b6bc4cf6c56)

Co-authored-by: Jens Scheffler <95105677+jscheffl@users.noreply.github.com>",github-actions[bot],2025-01-11 17:52:08+00:00,[],2025-01-11 19:42:44+00:00,2025-01-11 19:27:50+00:00,https://github.com/apache/airflow/pull/45581,"[('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-52', 'Automatic setup and teardown tasks')]",[],
2782020328,pull_request,closed,,Update spelling wordlist,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
related: #45563

While working on upgrading Sphinx, it turned out that the spelling checks workflow failed due to unrecognized words*.
I'm not entirely sure that it's directly related to the upgrade - maybe the workflow didn't run in previous times or failures were overlooked. However, after updating the wordlist with the new words in this PR - the [workflow passed ](https://github.com/apache/airflow/actions/runs/12725611320/job/35473129180) without errors.
As the new words could be merged separately, I'd rather merge them in this PR.


\* -  And maybe other reasons, but I'm trying to separate variables.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2025-01-11 17:00:37+00:00,[],2025-01-11 18:07:41+00:00,2025-01-11 17:44:34+00:00,https://github.com/apache/airflow/pull/45579,"[('kind:documentation', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2585354628, 'issue_id': 2782020328, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12726319613\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/13f5bd6d75f4707091dbeea89b59be9acdcfec87""><img src=\'https://img.shields.io/badge/Commit-13f5bd6-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker 13f5bd6 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2025, 1, 11, 17, 45, 23, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-11 17:45:23 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12726319613'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/13f5bd6d75f4707091dbeea89b59be9acdcfec87""><img src='https://img.shields.io/badge/Commit-13f5bd6-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker 13f5bd6 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2781996789,pull_request,closed,,Minor improvements to TaskSDK's WatchedSubprocess,"Follow-up of https://github.com/apache/airflow/pull/45570 to add some Typehints so my editor (PyCharm) can find `_on_child_started`.

Added/Updated docstrings since `WatchedSubprocess` is now a Base class.

and removed redundant exception handling for `init_log_file`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-11 16:23:31+00:00,[],2025-01-11 16:54:02+00:00,2025-01-11 16:54:00+00:00,https://github.com/apache/airflow/pull/45578,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:task-sdk', None)]",[],
2781962404,pull_request,closed,,Add Bulk API  for Variables,"This brings up the bulk API for variables.
According to discussion: https://apache-airflow.slack.com/archives/C0809U4S1Q9/p1736418768381509

You can test the API here: http://localhost:29091/docs#/Variable/bulk_variables 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-11 15:23:56+00:00,[],2025-01-23 09:14:07+00:00,2025-01-14 19:55:53+00:00,https://github.com/apache/airflow/pull/45577,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2781718369,pull_request,closed,,Fix --from-pr feature for image load and stabilize help,"This is a follow-up after #45564 - it fixes the `--from-pr` and `--from-run` to work (it was failing with file does not exist).

Also found out that gettempdir might return different directory depending on which is your designated tmp directory (for example in MacOS this is is a longer path in /var/.....) - so we have to force the default during help generation to always return ""/tmp"" so that the --help images do not change depending on which system you are and what your tmp directory is.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-11 09:08:14+00:00,[],2025-01-11 10:17:00+00:00,2025-01-11 10:16:58+00:00,https://github.com/apache/airflow/pull/45575,"[('area:dev-tools', '')]",[],
2781715073,pull_request,closed,,Incorrect field rendering in DAG Params,closes #45290,rawwar,2025-01-11 08:59:20+00:00,[],2025-01-11 10:31:41+00:00,2025-01-11 10:31:41+00:00,https://github.com/apache/airflow/pull/45574,"[('area:webserver', 'Webserver related Issues'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR')]","[{'comment_id': 2585164214, 'issue_id': 2781715073, 'author': 'rawwar', 'body': 'Even after removing the condition, validations are happening.', 'created_at': datetime.datetime(2025, 1, 11, 9, 0, 56, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2025-01-11 09:00:56 UTC): Even after removing the condition, validations are happening.

"
2781600152,pull_request,closed,,Provide package write permissions to push-ci-image-cache and push-prod-image-cache job,"These permissions are required to push the cache, otherwise it throws 403 error.

See canary runs failed to push https://github.com/apache/airflow/actions/runs/12720115782/job/35462623467#step:7:1363

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-11 04:24:28+00:00,[],2025-01-11 09:20:10+00:00,2025-01-11 09:20:09+00:00,https://github.com/apache/airflow/pull/45573,"[('area:dev-tools', '')]",[],
2781351355,pull_request,closed,,Fix tests introduced in #45546,"This was merged without letting tests pass somehow. We have removed the
`root_dag` argument in Airflow 3.
",ashb,2025-01-10 22:50:35+00:00,[],2025-01-11 07:02:25+00:00,2025-01-10 23:16:33+00:00,https://github.com/apache/airflow/pull/45572,"[('area:API', ""Airflow's REST/HTTP API"")]",[],
2781316669,pull_request,closed,,fix: kpo async kube_config_path,"closes: #44325
",raphaelauv,2025-01-10 22:29:07+00:00,[],2025-02-07 14:24:02+00:00,2025-02-07 13:50:15+00:00,https://github.com/apache/airflow/pull/45571,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2597929018, 'issue_id': 2781316669, 'author': 'raphaelauv', 'body': '@romsharon98  @amoghrajesh gentle ping :)', 'created_at': datetime.datetime(2025, 1, 17, 10, 32, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2631945389, 'issue_id': 2781316669, 'author': 'raphaelauv', 'body': '@romsharon98 @amoghrajesh gentle ping :)', 'created_at': datetime.datetime(2025, 2, 3, 19, 58, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2642985573, 'issue_id': 2781316669, 'author': 'raphaelauv', 'body': 'hi @eladkal , could you pls review , thanks', 'created_at': datetime.datetime(2025, 2, 7, 13, 43, 55, tzinfo=datetime.timezone.utc)}]","raphaelauv (Issue Creator) on (2025-01-17 10:32:34 UTC): @romsharon98  @amoghrajesh gentle ping :)

raphaelauv (Issue Creator) on (2025-02-03 19:58:45 UTC): @romsharon98 @amoghrajesh gentle ping :)

raphaelauv (Issue Creator) on (2025-02-07 13:43:55 UTC): hi @eladkal , could you pls review , thanks

"
2781261794,pull_request,closed,,Improve subclassing of TaskSDK's WatchedSubprocess,"When I added the DagFileProcessorProcess I did some naughty things with
subclassing and lying to the type checker, and this is now stopping us easily
adding DAG bundles (because as it is structured right now we would have to
change both parsing and execution at the same time, or make the type checker
_even more unhappy_.)

This more correctly separates the two classes -- essentially anything that
used `self.client` couldn't have been called from a DagFileProcessorProcess
(as client was always None for those instances).

This PR fixes it by adding a new `ActivitySubprocess` which is the type used
at Execution time (the one that always has the client) and the base behaviour
kept in WatchedSubprocess.

Closes #45537 as it is an alternative implementation of addressing the same problem

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",ashb,2025-01-10 21:56:46+00:00,[],2025-01-10 22:51:45+00:00,2025-01-10 22:51:44+00:00,https://github.com/apache/airflow/pull/45570,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:task-sdk', None)]","[{'comment_id': 2584623251, 'issue_id': 2781261794, 'author': 'ashb', 'body': ""Tests are failing with this:\r\n\r\n```\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[backfill-failed] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[backfill-success] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[backfill-queued] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[scheduled-failed] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[scheduled-success] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[scheduled-queued] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[manual-failed] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[manual-success] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[manual-queued] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[asset_triggered-failed] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[asset_triggered-success] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\nFAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[asset_triggered-queued] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'\r\n```\r\n\r\nwhich I think main is suffering from too."", 'created_at': datetime.datetime(2025, 1, 10, 22, 45, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2584649254, 'issue_id': 2781261794, 'author': 'ashb', 'body': 'Yup, issue is unrelated, fix is #45572.\r\n\r\nMerging this', 'created_at': datetime.datetime(2025, 1, 10, 22, 51, 20, tzinfo=datetime.timezone.utc)}]","ashb (Issue Creator) on (2025-01-10 22:45:22 UTC): Tests are failing with this:

```
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[backfill-failed] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[backfill-success] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[backfill-queued] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[scheduled-failed] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[scheduled-success] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[scheduled-queued] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[manual-failed] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[manual-success] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[manual-queued] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[asset_triggered-failed] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[asset_triggered-success] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
FAILED tests/api_connexion/endpoints/test_dag_run_endpoint.py::TestPatchDagRunState::test_action_logging[asset_triggered-queued] - TypeError: bag_dag() got an unexpected keyword argument 'root_dag'
```

which I think main is suffering from too.

ashb (Issue Creator) on (2025-01-10 22:51:20 UTC): Yup, issue is unrelated, fix is #45572.

Merging this

"
2781225700,pull_request,closed,,[v2-10-test] Fix typo in README_RELEASE_AIRFLOW.md (#45568),"(cherry picked from commit a467fc386d1e39af3210eed7cdc53b3d142fbde1)

Co-authored-by: Shahar Epstein <60007259+shahar1@users.noreply.github.com>",github-actions[bot],2025-01-10 21:39:02+00:00,[],2025-01-11 19:42:42+00:00,2025-01-10 21:40:58+00:00,https://github.com/apache/airflow/pull/45569,"[('area:dev-tools', '')]","[{'comment_id': 2584342977, 'issue_id': 2781225700, 'author': 'jedcunningham', 'body': ""This doesn't need to be backported. These docs really only live in main."", 'created_at': datetime.datetime(2025, 1, 10, 21, 40, 58, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2025-01-10 21:40:58 UTC): This doesn't need to be backported. These docs really only live in main.

"
2781211263,pull_request,closed,,Fix typo in README_RELEASE_AIRFLOW.md,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2025-01-10 21:31:03+00:00,[],2025-01-10 21:41:22+00:00,2025-01-10 21:38:13+00:00,https://github.com/apache/airflow/pull/45568,"[('area:dev-tools', '')]","[{'comment_id': 2584334297, 'issue_id': 2781211263, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45569""><img src=""https://img.shields.io/badge/PR-45569-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2025, 1, 10, 21, 39, 4, tzinfo=datetime.timezone.utc)}]","github-actions[bot] on (2025-01-10 21:39:04 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45569""><img src=""https://img.shields.io/badge/PR-45569-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2781192482,pull_request,closed,,Fix log_action decorator when content type is None,Fixes broken main. Sometimes content type is None.,dstandish,2025-01-10 21:22:18+00:00,[],2025-01-10 21:42:03+00:00,2025-01-10 21:42:01+00:00,https://github.com/apache/airflow/pull/45567,"[('area:webserver', 'Webserver related Issues')]","[{'comment_id': 2584266950, 'issue_id': 2781192482, 'author': 'jedcunningham', 'body': 'This was broken in #45546.', 'created_at': datetime.datetime(2025, 1, 10, 21, 23, 21, tzinfo=datetime.timezone.utc)}]","jedcunningham on (2025-01-10 21:23:21 UTC): This was broken in #45546.

"
2781047552,pull_request,closed,,Reserve the 'example_dags' bundle name,"Users can enable example dags with config, so we will reserve the bundle name, as it's added automatically based on that config.",jedcunningham,2025-01-10 20:11:23+00:00,[],2025-01-10 21:37:49+00:00,2025-01-10 21:37:48+00:00,https://github.com/apache/airflow/pull/45566,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2584328514, 'issue_id': 2781047552, 'author': 'jedcunningham', 'body': 'Failures are unrelated and will be fixed in #45567.', 'created_at': datetime.datetime(2025, 1, 10, 21, 37, 44, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2025-01-10 21:37:44 UTC): Failures are unrelated and will be fixed in #45567.

"
2780977808,pull_request,closed,,Add optional --image-file-dir to store loaded files elsewhere,"While backorting the ""pull_request_target"" removal to v2-10-test branches it turned out that there is not enough disk space on Public runner to load all 5 images and keep the file dump at the same time in the same filesystem. This PR allows to choose where the load/save files will be stored and in the github runner environment we store the files in ""/mnt"" wnich is a separate folder with 40GB free.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-10 19:39:41+00:00,[],2025-01-11 06:50:32+00:00,2025-01-11 06:50:30+00:00,https://github.com/apache/airflow/pull/45564,"[('area:dev-tools', '')]",[],
2780855345,pull_request,closed,,Upgrade sphinx and related dependencies,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
closes: #31963
related: #39449

This PR update the following dependencies:
- `sphinx` to v7+ (there's already v8, but it is supported only for Python 3.10)
- `docutils` to v0.21+ (haven't encountered any `<section>` tags as mentioned in the deleted inline comment)
- `sphinx-autoapi` to v3+ and `astroid` to v3+ (possible now that `sphinx` is v7+)
- `sphinxcontrib-serializinghtml` to v1.1.5+ (pinning it causes dependency conflicts)

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shahar1,2025-01-10 18:43:27+00:00,[],2025-01-12 14:50:36+00:00,2025-01-12 14:49:50+00:00,https://github.com/apache/airflow/pull/45563,"[('kind:documentation', ''), ('area:CI', ""Airflow's tests and continious integration""), ('area:dependencies', 'Issues related to dependencies problems'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2583607553, 'issue_id': 2780855345, 'author': 'shahar1', 'body': 'Drafting, weirdly on `v2-10-test` it worked fine but here there are errors', 'created_at': datetime.datetime(2025, 1, 10, 18, 58, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2584045630, 'issue_id': 2780855345, 'author': 'potiuk', 'body': 'one more thing - last time when we tried to upgrade sphinx and docutils, the documentation looked ....weird .... lots of extra whitespace', 'created_at': datetime.datetime(2025, 1, 10, 20, 32, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585187198, 'issue_id': 2780855345, 'author': 'shahar1', 'body': ""Apparently it is a quite a tough task, here are some insights:\r\n- A requirement for upgrading Sphinx to v7 is to merge https://github.com/apache/airflow-site/pull/1103 and create a new version for `sphinx_airflow_theme` (`0.1.0`). I struggled with mounting the changes locally, so for now, I made a workaround by injecting the contents of the file that was modified via `Dockerfile.ci` (created an [issue](https://github.com/apache/airflow/issues/45576) for anyone who wants to tackle it in the future).\r\n\r\n- When running only the build docs workflow, locally and on GitHub Actions, using `breeze build-docs apache-airflow docker-stack --docs-only --clean-build`, the build succeeds without any errors (see [GitHub Action workflow](https://github.com/apache/airflow/actions/runs/12722412749/job/35466510483)). When running the docs server locally, the extra spaces issue indeed persists - we need to find out how to modify the related CSS (no success with it so far). \r\n![image](https://github.com/user-attachments/assets/158c938d-5120-4e43-b066-27f4838f8357)\r\n\r\n- When running only the spellchecks workflow, locally and on GitHub Actions, using `breeze build-docs apache-airflow docker-stack --spellchecks-only --clean-build` (see raw [logs](https://productionresultssa15.blob.core.windows.net/actions-results/150f2642-909d-4db9-9c5d-8fbcbdac4d97/workflow-job-run-d861e44f-2bbb-5cfa-a1f8-37f87cf3d990/logs/job/job-logs.txt?rsct=text%2Fplain&se=2025-01-11T08%3A50%3A51Z&sig=VqIwiRSbgJv4DXcHviF0uu1tQNPJiaXCgdLlVnQ7eOM%3D&ske=2025-01-11T17%3A27%3A16Z&skoid=ca7593d4-ee42-46cd-af88-8b886a2f84eb&sks=b&skt=2025-01-11T05%3A27%3A16Z&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skv=2024-11-04&sp=r&spr=https&sr=b&st=2025-01-11T08%3A40%3A46Z&sv=2024-11-04) - BIG FILE warning) - we get a lot of weird errors. If you take a look at the logs, it often fails when parsing from `/opt/airflow/providers/src/airflow/providers/amazon/aws/hooks/ssm.py::SsmHook:: get_parameter_value`. **Edit:** it happened due to missing words in the spellcheck wordlist (see #45579) - now it should be fine.\r\n\r\n- When running the workflow for building docs and spelling **altogether** (`breeze build-docs apache-airflow docker-stack --clean-build`), the build fails due to a large number of implicit errors (which might be related to the failure of the spelling checks?).\r\n\r\n- The [MyPy workflow](https://github.com/apache/airflow/actions/runs/12722412749/job/35466520027) fails, but it doesn't seem too bad - in the worst case we just ignore it.\r\n\r\nI'll be happy for some help in solving some of the riddles above, it will gets us closer to upgrading to Sphinx 7 :)"", 'created_at': datetime.datetime(2025, 1, 11, 9, 50, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585393127, 'issue_id': 2780855345, 'author': 'potiuk', 'body': '#protm', 'created_at': datetime.datetime(2025, 1, 11, 20, 5, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585689346, 'issue_id': 2780855345, 'author': 'potiuk', 'body': 'It needs conflict resolution though :)', 'created_at': datetime.datetime(2025, 1, 12, 11, 9, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585711499, 'issue_id': 2780855345, 'author': 'kaxil', 'body': 'Merge conflicts on `hatch_build.py` @shahar1 and then hopefully we are good 🤞', 'created_at': datetime.datetime(2025, 1, 12, 12, 19, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585740175, 'issue_id': 2780855345, 'author': 'shahar1', 'body': ""> Merge conflicts on `hatch_build.py` @shahar1 and then hopefully we are good 🤞 \n\n\nResolved conclicts, I'd be happy if @potiuk could review before merging :)"", 'created_at': datetime.datetime(2025, 1, 12, 13, 41, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585751520, 'issue_id': 2780855345, 'author': 'potiuk', 'body': 'LGTM ! 🎉 🎉 🎉 🎉 🎉 🎉 🎉 🎉 🎉', 'created_at': datetime.datetime(2025, 1, 12, 14, 13, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585764159, 'issue_id': 2780855345, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12734537509\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/a51ebe43780afc7ba95453a46fd3b8bfae450540""><img src=\'https://img.shields.io/badge/Commit-a51ebe4-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker a51ebe4 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2025, 1, 12, 14, 50, 35, tzinfo=datetime.timezone.utc)}]","shahar1 (Issue Creator) on (2025-01-10 18:58:11 UTC): Drafting, weirdly on `v2-10-test` it worked fine but here there are errors

potiuk on (2025-01-10 20:32:24 UTC): one more thing - last time when we tried to upgrade sphinx and docutils, the documentation looked ....weird .... lots of extra whitespace

shahar1 (Issue Creator) on (2025-01-11 09:50:46 UTC): Apparently it is a quite a tough task, here are some insights:
- A requirement for upgrading Sphinx to v7 is to merge https://github.com/apache/airflow-site/pull/1103 and create a new version for `sphinx_airflow_theme` (`0.1.0`). I struggled with mounting the changes locally, so for now, I made a workaround by injecting the contents of the file that was modified via `Dockerfile.ci` (created an [issue](https://github.com/apache/airflow/issues/45576) for anyone who wants to tackle it in the future).

- When running only the build docs workflow, locally and on GitHub Actions, using `breeze build-docs apache-airflow docker-stack --docs-only --clean-build`, the build succeeds without any errors (see [GitHub Action workflow](https://github.com/apache/airflow/actions/runs/12722412749/job/35466510483)). When running the docs server locally, the extra spaces issue indeed persists - we need to find out how to modify the related CSS (no success with it so far). 
![image](https://github.com/user-attachments/assets/158c938d-5120-4e43-b066-27f4838f8357)

- When running only the spellchecks workflow, locally and on GitHub Actions, using `breeze build-docs apache-airflow docker-stack --spellchecks-only --clean-build` (see raw [logs](https://productionresultssa15.blob.core.windows.net/actions-results/150f2642-909d-4db9-9c5d-8fbcbdac4d97/workflow-job-run-d861e44f-2bbb-5cfa-a1f8-37f87cf3d990/logs/job/job-logs.txt?rsct=text%2Fplain&se=2025-01-11T08%3A50%3A51Z&sig=VqIwiRSbgJv4DXcHviF0uu1tQNPJiaXCgdLlVnQ7eOM%3D&ske=2025-01-11T17%3A27%3A16Z&skoid=ca7593d4-ee42-46cd-af88-8b886a2f84eb&sks=b&skt=2025-01-11T05%3A27%3A16Z&sktid=398a6654-997b-47e9-b12b-9515b896b4de&skv=2024-11-04&sp=r&spr=https&sr=b&st=2025-01-11T08%3A40%3A46Z&sv=2024-11-04) - BIG FILE warning) - we get a lot of weird errors. If you take a look at the logs, it often fails when parsing from `/opt/airflow/providers/src/airflow/providers/amazon/aws/hooks/ssm.py::SsmHook:: get_parameter_value`. **Edit:** it happened due to missing words in the spellcheck wordlist (see #45579) - now it should be fine.

- When running the workflow for building docs and spelling **altogether** (`breeze build-docs apache-airflow docker-stack --clean-build`), the build fails due to a large number of implicit errors (which might be related to the failure of the spelling checks?).

- The [MyPy workflow](https://github.com/apache/airflow/actions/runs/12722412749/job/35466520027) fails, but it doesn't seem too bad - in the worst case we just ignore it.

I'll be happy for some help in solving some of the riddles above, it will gets us closer to upgrading to Sphinx 7 :)

potiuk on (2025-01-11 20:05:28 UTC): #protm

potiuk on (2025-01-12 11:09:24 UTC): It needs conflict resolution though :)

kaxil on (2025-01-12 12:19:09 UTC): Merge conflicts on `hatch_build.py` @shahar1 and then hopefully we are good 🤞

shahar1 (Issue Creator) on (2025-01-12 13:41:31 UTC): Resolved conclicts, I'd be happy if @potiuk could review before merging :)

potiuk on (2025-01-12 14:13:21 UTC): LGTM ! 🎉 🎉 🎉 🎉 🎉 🎉 🎉 🎉 🎉

github-actions[bot] on (2025-01-12 14:50:35 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12734537509'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/a51ebe43780afc7ba95453a46fd3b8bfae450540""><img src='https://img.shields.io/badge/Commit-a51ebe4-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker a51ebe4 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

"
2780854253,pull_request,closed,,AIP-82 Handle trigger serialization,"Handle serialization of triggers in DAGs as part of AIP-82. With AIP-82 (External event driven scheduling in Airflow) you can define DAGs as below:

```
trigger = FileTrigger(....)
asset = Asset(""<my_queue>"", watchers=[AssetWatcher(name=""my_file_watcher"", trigger=trigger)])
 
with DAG(
    dag_id=DAG_ID,
    schedule=asset,
):
    empty_task = EmptyOperator(task_id=""empty_task"")
 
    chain(empty_task)
```

Triggers can be instantiated as part of a DAG. As such, we need to serialize them.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-10 18:42:51+00:00,[],2025-01-31 23:57:23+00:00,2025-01-31 23:57:21+00:00,https://github.com/apache/airflow/pull/45562,"[('area:serialization', '')]","[{'comment_id': 2598489688, 'issue_id': 2780854253, 'author': 'vincbeck', 'body': 'I addressed your comments but I also added something new. It was actually a suggestion from @dstandish that I think is a great idea! I introduced the concept of `AssetWatcher` that is a thin wrapper around trigger. Explanations:\r\n\r\nInstead of having:\r\n\r\n```\r\ntrigger = FileTrigger(....)\r\nasset = Asset(""<my_queue>"", watchers=[trigger])\r\n```\r\n\r\nNow it is:\r\n\r\n```\r\ntrigger = FileTrigger(....)\r\nasset = Asset(""<my_queue>"", watchers=[AssetWatcher(name=""my_queue_watcher"", trigger=trigger)])\r\n```\r\n\r\n`AssetWatcher` does not add much besides just a name, but I think it is important because, in the future, we might want to surface the relations between assets and triggers in the graph view in the UI. Representing a trigger in the graph can be tricky because triggers have 2 pieces of information: `classpath` and `kwargs`. None of them are very suitable for displaying purposes. `classpath` is debatable but it is anyway not representable of the trigger. Example: you might have an asset with 2 watchers: each one uses the trigger `FileTrigger` to monitor a different file. Having only the classpath displayed will not help the user to understand which one is which. Hence the name.', 'created_at': datetime.datetime(2025, 1, 17, 14, 28, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2604987283, 'issue_id': 2780854253, 'author': 'vincbeck', 'body': '@uranusjr @ashb what do you guys think?', 'created_at': datetime.datetime(2025, 1, 21, 15, 6, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605063606, 'issue_id': 2780854253, 'author': 'ashb', 'body': ""I'll take another look today or tomorrow."", 'created_at': datetime.datetime(2025, 1, 21, 15, 35, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622616228, 'issue_id': 2780854253, 'author': 'vincbeck', 'body': 'Other questions/concerns? :)', 'created_at': datetime.datetime(2025, 1, 29, 19, 14, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2625637538, 'issue_id': 2780854253, 'author': 'vincbeck', 'body': ""@ashb Are you okay with these changes? I'll make the changes related to the discussion we had on Slack (creating the interface `BaseEventTrigger`) in a separate PR."", 'created_at': datetime.datetime(2025, 1, 30, 21, 30, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2627074548, 'issue_id': 2780854253, 'author': 'ashb', 'body': 'All good, thanks @vincbeck', 'created_at': datetime.datetime(2025, 1, 31, 12, 17, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2628587999, 'issue_id': 2780854253, 'author': 'vincbeck', 'body': ""> All good, thanks @vincbeck\r\n\r\nThank you for thorough review! I like very much the changes made thanks to your feedbacks ans @uranusjr's as well!"", 'created_at': datetime.datetime(2025, 1, 31, 23, 57, 12, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2025-01-17 14:28:17 UTC): I addressed your comments but I also added something new. It was actually a suggestion from @dstandish that I think is a great idea! I introduced the concept of `AssetWatcher` that is a thin wrapper around trigger. Explanations:

Instead of having:

```
trigger = FileTrigger(....)
asset = Asset(""<my_queue>"", watchers=[trigger])
```

Now it is:

```
trigger = FileTrigger(....)
asset = Asset(""<my_queue>"", watchers=[AssetWatcher(name=""my_queue_watcher"", trigger=trigger)])
```

`AssetWatcher` does not add much besides just a name, but I think it is important because, in the future, we might want to surface the relations between assets and triggers in the graph view in the UI. Representing a trigger in the graph can be tricky because triggers have 2 pieces of information: `classpath` and `kwargs`. None of them are very suitable for displaying purposes. `classpath` is debatable but it is anyway not representable of the trigger. Example: you might have an asset with 2 watchers: each one uses the trigger `FileTrigger` to monitor a different file. Having only the classpath displayed will not help the user to understand which one is which. Hence the name.

vincbeck (Issue Creator) on (2025-01-21 15:06:33 UTC): @uranusjr @ashb what do you guys think?

ashb on (2025-01-21 15:35:23 UTC): I'll take another look today or tomorrow.

vincbeck (Issue Creator) on (2025-01-29 19:14:46 UTC): Other questions/concerns? :)

vincbeck (Issue Creator) on (2025-01-30 21:30:49 UTC): @ashb Are you okay with these changes? I'll make the changes related to the discussion we had on Slack (creating the interface `BaseEventTrigger`) in a separate PR.

ashb on (2025-01-31 12:17:54 UTC): All good, thanks @vincbeck

vincbeck (Issue Creator) on (2025-01-31 23:57:12 UTC): Thank you for thorough review! I like very much the changes made thanks to your feedbacks ans @uranusjr's as well!

"
2780667802,pull_request,closed,,Bump trove-classifiers from 2025.1.7.14 to 2025.1.10.15,"Bumps [trove-classifiers](https://github.com/pypa/trove-classifiers) from 2025.1.7.14 to 2025.1.10.15.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/trove-classifiers/commit/28d3e615a2b449f2fc0eabcf4d4578db7dbe0dc8""><code>28d3e61</code></a> Remove unused and &quot;Voluntarily retired&quot; licenses (<a href=""https://redirect.github.com/pypa/trove-classifiers/issues/202"">#202</a>)</li>
<li>See full diff in <a href=""https://github.com/pypa/trove-classifiers/compare/2025.1.7.14...2025.1.10.15"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=trove-classifiers&package-manager=pip&previous-version=2025.1.7.14&new-version=2025.1.10.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2025-01-10 17:04:10+00:00,[],2025-01-10 17:18:10+00:00,2025-01-10 17:18:00+00:00,https://github.com/apache/airflow/pull/45561,"[('area:dependencies', 'Issues related to dependencies problems')]",[],
2780521571,pull_request,closed,,fix: log action get the correct request body (#45546),"(cherry picked from commit bae4bb1d549f20a54a2e8c27c57377a0207f393b)

(cherry picked from commit 46304d8d7e5e0d47e3829ae51401e8a4b9bfc4ae)

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",pierrejeambrun,2025-01-10 16:02:17+00:00,[],2025-01-13 19:16:06+00:00,2025-01-13 18:46:53+00:00,https://github.com/apache/airflow/pull/45560,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes')]","[{'comment_id': 2583299021, 'issue_id': 2780521571, 'author': 'potiuk', 'body': 'Some tests are failing though :(', 'created_at': datetime.datetime(2025, 1, 10, 17, 17, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2584271291, 'issue_id': 2780521571, 'author': 'jedcunningham', 'body': ""@pierrejeambrun you'll also want the fix in #45567 :)"", 'created_at': datetime.datetime(2025, 1, 10, 21, 24, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585753767, 'issue_id': 2780521571, 'author': 'pierrejeambrun', 'body': 'Thanks', 'created_at': datetime.datetime(2025, 1, 12, 14, 19, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2586464334, 'issue_id': 2780521571, 'author': 'pierrejeambrun', 'body': 'I’m on holidays this week.\r\n\r\nill try to find time to add the mentionned commit and update the PR.\r\n\r\nFeel free to update as needed.', 'created_at': datetime.datetime(2025, 1, 13, 8, 20, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2587335754, 'issue_id': 2780521571, 'author': 'pierrejeambrun', 'body': 'Updated', 'created_at': datetime.datetime(2025, 1, 13, 14, 58, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2587469526, 'issue_id': 2780521571, 'author': 'pierrejeambrun', 'body': 'CI is looking better. Thanks.', 'created_at': datetime.datetime(2025, 1, 13, 15, 42, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2587932313, 'issue_id': 2780521571, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2025, 1, 13, 18, 47, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-10 17:17:29 UTC): Some tests are failing though :(

jedcunningham on (2025-01-10 21:24:22 UTC): @pierrejeambrun you'll also want the fix in #45567 :)

pierrejeambrun (Issue Creator) on (2025-01-12 14:19:44 UTC): Thanks

pierrejeambrun (Issue Creator) on (2025-01-13 08:20:26 UTC): I’m on holidays this week.

ill try to find time to add the mentionned commit and update the PR.

Feel free to update as needed.

pierrejeambrun (Issue Creator) on (2025-01-13 14:58:45 UTC): Updated

pierrejeambrun (Issue Creator) on (2025-01-13 15:42:01 UTC): CI is looking better. Thanks.

potiuk on (2025-01-13 18:47:01 UTC): Nice!

"
2780475220,pull_request,closed,,AIP-38 Clear Tasks,"Close: https://github.com/apache/airflow/issues/44860

Add the clear task feature and the action button in the Task Instance list. Also takes care of:
- Factorizing the code with the Clear Dag Run feature
- Rework the `SegmentedControl` component to allow multiple selected values.
- Simplifies state management overall

Clear DagRun is still working as before. Clear Task Instances screenshots:

![Screenshot 2025-01-10 at 16 39 24](https://github.com/user-attachments/assets/a8b33dc6-c52f-428e-b847-0283e1470841)
![Screenshot 2025-01-10 at 16 39 53](https://github.com/user-attachments/assets/54b17877-4ddc-466a-8583-48ef258dd538)
![Screenshot 2025-01-10 at 16 40 01](https://github.com/user-attachments/assets/d603d5ea-7c44-4c4f-b7be-f3222173b481)
![Screenshot 2025-01-10 at 16 42 26](https://github.com/user-attachments/assets/7fd8a5c7-4703-4195-930a-193631e13bb1)
![Screenshot 2025-01-10 at 16 42 44](https://github.com/user-attachments/assets/dfbb7669-1e1b-4783-ad65-343cb93855bd)
![Screenshot 2025-01-10 at 16 43 39](https://github.com/user-attachments/assets/5462a3b0-d511-43ad-884f-977d1557b649)


",pierrejeambrun,2025-01-10 15:44:56+00:00,['pierrejeambrun'],2025-01-11 23:56:19+00:00,2025-01-11 23:56:17+00:00,https://github.com/apache/airflow/pull/45559,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]",[],
2780377401,pull_request,closed,,Remove contents: write permission from generate-constraints,"The write permission cannot be set for PRs from forks in the call workflow - so we have to come back to implicit permissions and make explicit permissions passing a bit differently.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-10 14:56:11+00:00,[],2025-01-10 15:24:35+00:00,2025-01-10 15:24:33+00:00,https://github.com/apache/airflow/pull/45558,"[('area:dev-tools', '')]","[{'comment_id': 2582942592, 'issue_id': 2780377401, 'author': 'gopidesupavan', 'body': 'Ah I see', 'created_at': datetime.datetime(2025, 1, 10, 15, 18, 53, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2025-01-10 15:18:53 UTC): Ah I see

"
2780363022,pull_request,closed,,"Revert ""Pin pnpm action to hash commit following best GH Action pract…","…ices (#45547)""

This reverts commit 378e3581f31dfcc6dfa4661d07643ea07b2406bb.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-10 14:49:15+00:00,[],2025-01-10 15:24:24+00:00,2025-01-10 15:24:22+00:00,https://github.com/apache/airflow/pull/45557,"[('area:dev-tools', '')]","[{'comment_id': 2582941080, 'issue_id': 2780363022, 'author': 'gopidesupavan', 'body': 'Just back to home', 'created_at': datetime.datetime(2025, 1, 10, 15, 18, 7, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2025-01-10 15:18:07 UTC): Just back to home

"
2780362755,pull_request,closed,,Add support for missing columns in GCSToBigQueryOperator,"Problem:
Currently, the GCSToBigQueryOperator fails with a schema compatibility error when a column defined in the BigQuery schema is missing from the source file. Even if the missing column in BigQuery is configured to allow NULL values, the operator does not handle the missing column gracefully. Instead, it interrupts the pipeline, requiring additional preprocessing steps, such as manually editing the source file to include the missing column, which increases processing overhead and reduces pipeline efficiency.

Use Case:
For example, when loading data from an Avro file into BigQuery, if a column present in BigQuery is absent from the Avro file, BigQuery itself can handle this scenario by inserting NULL values. However, the operator does not pass this flexibility to BigQuery, resulting in a schema mismatch error and pipeline failure.

Solution:
This Pull Request introduces a new parameter, insert_null_for_missing_columns, to the GCSToBigQueryOperator. When this parameter is set to True, the operator includes the allowMissingFields configuration in the BigQuery load job. This allows BigQuery to insert NULL values for any missing columns in the source file, avoiding schema compatibility errors and ensuring smoother pipeline execution.

This change is backward-compatible, as the default behavior (raising a schema compatibility error) is maintained unless the new parameter is explicitly set to True.",maiconcGringo,2025-01-10 14:49:07+00:00,[],2025-01-10 16:31:34+00:00,2025-01-10 16:31:34+00:00,https://github.com/apache/airflow/pull/45556,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2582881527, 'issue_id': 2780362755, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 10, 14, 49, 11, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-10 14:49:11 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2780328930,pull_request,closed,,Improve google credentials error message,"- Add details to the error message, to track what exact values were provided.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2025-01-10 14:33:17+00:00,[],2025-01-13 18:49:22+00:00,2025-01-13 18:49:22+00:00,https://github.com/apache/airflow/pull/45553,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2587605352, 'issue_id': 2780328930, 'author': 'olegkachur-e', 'body': '> This is bad idea. You are about to reveal keyfile_dict which contains private key in the log.\r\n\r\nGood point! There definitely was an another way to improve. The code is updated', 'created_at': datetime.datetime(2025, 1, 13, 16, 32, 53, tzinfo=datetime.timezone.utc)}]","olegkachur-e (Issue Creator) on (2025-01-13 16:32:53 UTC): Good point! There definitely was an another way to improve. The code is updated

"
2780162529,pull_request,closed,,[v2-10-test] fix code indent in modified docker-compose.yaml for PyCharm (#45545),"(cherry picked from commit fcef600a7e60bcd625977cbc4e4546a7c4f799b0)

Co-authored-by: Park Jiwon <57484954+david-parkk@users.noreply.github.com>",github-actions[bot],2025-01-10 13:12:12+00:00,[],2025-01-28 12:07:45+00:00,2025-01-10 13:33:06+00:00,https://github.com/apache/airflow/pull/45552,"[('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only')]",[],
2780136815,pull_request,closed,,Sagemaker Operator Character limit fix ,"… SageMaker 64 character length constraint

SageMakerProcessingJobs have a hard limit of 64 characters for the ProcessingJobName.
In the SageMakerBaseOperator there is a check for uniqueness for the name. 
In the case that a name is not unique it adds a timestamp to prevent a potential collision, however there is no check to prevent the updated <jobname>-<timestamp> from exceeding 64 characters. This causes the creation of the SageMakerProcessingJob to fail. 

In the SageMaker Pipelines SDK they truncate the base name before adding the timestamp, therefor we took a similar approach for consistency purposes. 

Closes: #45550 


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dirkrkotzeml,2025-01-10 12:59:56+00:00,[],2025-01-15 17:47:31+00:00,2025-01-15 17:47:27+00:00,https://github.com/apache/airflow/pull/45551,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2582657293, 'issue_id': 2780136815, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 10, 13, 0, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589877618, 'issue_id': 2780136815, 'author': 'dirkrkotzeml', 'body': '> Could you add a unit test to cover that?\r\n\r\n@ferruzzi  @vincbeck  We have updated the prior unit tests and added two of our own, the provider tests all pass.\r\n\r\nJust a small note the previous mock for time_ns was using an incorrect format that the time_ns() function would not return.\r\nWe updated the unit tests to use a representative integer for the tests.\r\n\r\nIn our updated function we limit the returned timestamp to 10 characters to capture only the date time up to the seconds as this is all that is needed.', 'created_at': datetime.datetime(2025, 1, 14, 13, 12, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589892315, 'issue_id': 2780136815, 'author': 'Rudolf07688', 'body': '@dirkrkotzeml @eladkal @o-nikolas \r\nUnit tests passing after latest commit.\r\n\r\n<img width=""852"" alt=""Screenshot 2025-01-14 at 15 07 12"" src=""https://github.com/user-attachments/assets/5f1d48fb-0311-4288-901e-b5ca8ae47b54"" />', 'created_at': datetime.datetime(2025, 1, 14, 13, 19, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2591257813, 'issue_id': 2780136815, 'author': 'ferruzzi', 'body': 'Looks like you just need to run your static checks.  running  `breeze static-checks`  should fix the formatting issues that the CI is crying about.', 'created_at': datetime.datetime(2025, 1, 14, 22, 42, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2592157413, 'issue_id': 2780136815, 'author': 'Rudolf07688', 'body': '> Looks like you just need to run your static checks. running `breeze static-checks` should fix the formatting issues that the CI is crying about.\r\n\r\nRan the checks now and pushed changes. Thanks @ferruzzi', 'created_at': datetime.datetime(2025, 1, 15, 9, 49, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593577974, 'issue_id': 2780136815, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 15, 17, 47, 29, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-10 13:00:02 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

dirkrkotzeml (Issue Creator) on (2025-01-14 13:12:02 UTC): @ferruzzi  @vincbeck  We have updated the prior unit tests and added two of our own, the provider tests all pass.

Just a small note the previous mock for time_ns was using an incorrect format that the time_ns() function would not return.
We updated the unit tests to use a representative integer for the tests.

In our updated function we limit the returned timestamp to 10 characters to capture only the date time up to the seconds as this is all that is needed.

Rudolf07688 on (2025-01-14 13:19:12 UTC): @dirkrkotzeml @eladkal @o-nikolas 
Unit tests passing after latest commit.

<img width=""852"" alt=""Screenshot 2025-01-14 at 15 07 12"" src=""https://github.com/user-attachments/assets/5f1d48fb-0311-4288-901e-b5ca8ae47b54"" />

ferruzzi on (2025-01-14 22:42:46 UTC): Looks like you just need to run your static checks.  running  `breeze static-checks`  should fix the formatting issues that the CI is crying about.

Rudolf07688 on (2025-01-15 09:49:01 UTC): Ran the checks now and pushed changes. Thanks @ferruzzi

boring-cyborg[bot] on (2025-01-15 17:47:29 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2779853797,pull_request,closed,,Add explicit permissions for all workflow-run workflows,"Those workflows inherit permissions from the calling workflows but it's good to add explicit permissions to indicate what is needed and in case we will also use the workflows for other purposes in the future - default permissions for older repos might be write so it's best to be explicit about the permissions.

Found by CodeQL scanning

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-10 10:37:34+00:00,[],2025-01-10 15:26:43+00:00,2025-01-10 11:41:54+00:00,https://github.com/apache/airflow/pull/45548,"[('area:dev-tools', ''), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2582958863, 'issue_id': 2779853797, 'author': 'gopidesupavan', 'body': 'Cool :)', 'created_at': datetime.datetime(2025, 1, 10, 15, 26, 41, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2025-01-10 15:26:41 UTC): Cool :)

"
2779810338,pull_request,closed,,Pin npm action to hash commit following best GH Action practices,"This was found by the CodeQL Actions scanning

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-10 10:17:49+00:00,[],2025-01-10 10:19:14+00:00,2025-01-10 10:19:12+00:00,https://github.com/apache/airflow/pull/45547,"[('area:dev-tools', '')]",[],
2779787326,pull_request,closed,,fix: log action get the correct request body,"### Apache Airflow version
main (development)

### How to reproduce
POST request with `content-type` as `application/json; charset=utf-8`
```
curl -X 'PATCH' \
  'https://you_host_com/api/v1/dags/dag_id/dagRuns/run_id' \
  -H 'accept: application/json' \
  -H 'Content-Type: application/json; charset=utf-8' \
  -d '{
  ""state"": ""success""
}'
```

### Problem Description
When an API call is made, if the API has the `@action_logging` annotation, the event will be recorded in the db `log` table as follows
![image](https://github.com/user-attachments/assets/4f82db26-96e4-4085-a4e7-3b0f75f880c1)

### Related Code
Currently, whether the current request contains json_body is determined by judging whether `request.headers.get(""content-type"")` is equal to `application/json`. The relevant code is as follows
![image](https://github.com/user-attachments/assets/f67c9a58-44b7-4582-be66-f4b7ace23fbc)


But in many cases, the `content-type` contains other information besides `application/json`, such as `application/json; charset=utf-8`. In this case, the database will not record valid information.
![image](https://github.com/user-attachments/assets/a3637f3d-5536-415b-933b-d3b31752ab46)

### Solution
So the judgment condition should be changed to include",luoyuliuyin,2025-01-10 10:06:48+00:00,[],2025-01-10 16:02:35+00:00,2025-01-10 15:52:11+00:00,https://github.com/apache/airflow/pull/45546,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2582660432, 'issue_id': 2779787326, 'author': 'luoyuliuyin', 'body': '> NIce.\r\n> \r\n> Small nits before merging, but looking good.\r\n\r\nThank you for the suggestion. Please check the latest commit.', 'created_at': datetime.datetime(2025, 1, 10, 13, 1, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2583028895, 'issue_id': 2779787326, 'author': 'github-actions[bot]', 'body': '### Backport failed to create: v2-10-test. View the failure log <a href=\'https://github.com/apache/airflow/actions/runs/12712770597\'> Run details </a>\n\n<table>\n    <tr>\n        <th>Status</th>\n        <th>Branch</th>\n        <th>Result</th>\n    </tr>\n    <tr>\n        <td>❌</td>\n        <td>v2-10-test</td>\n        <td><a href=""https://github.com/apache/airflow/commit/bae4bb1d549f20a54a2e8c27c57377a0207f393b""><img src=\'https://img.shields.io/badge/Commit-bae4bb1-red\' alt=\'Commit Link\'></a></td>\n    </tr>\n</table>\n\nYou can attempt to backport this manually by running:\n\n```bash\ncherry_picker bae4bb1 v2-10-test\n```\n\nThis should apply the commit to the v2-10-test branch and leave the commit in conflict state marking\nthe files that need manual conflict resolution.\n\nAfter you have resolved the conflicts, you can continue the backport process by running:\n\n```bash\ncherry_picker --continue\n```', 'created_at': datetime.datetime(2025, 1, 10, 15, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2583069991, 'issue_id': 2779787326, 'author': 'pierrejeambrun', 'body': 'cherry pick PR here:\r\nhttps://github.com/apache/airflow/pull/45560', 'created_at': datetime.datetime(2025, 1, 10, 16, 2, 33, tzinfo=datetime.timezone.utc)}]","luoyuliuyin (Issue Creator) on (2025-01-10 13:01:06 UTC): Thank you for the suggestion. Please check the latest commit.

github-actions[bot] on (2025-01-10 15:53:00 UTC): ### Backport failed to create: v2-10-test. View the failure log <a href='https://github.com/apache/airflow/actions/runs/12712770597'> Run details </a>

<table>
    <tr>
        <th>Status</th>
        <th>Branch</th>
        <th>Result</th>
    </tr>
    <tr>
        <td>❌</td>
        <td>v2-10-test</td>
        <td><a href=""https://github.com/apache/airflow/commit/bae4bb1d549f20a54a2e8c27c57377a0207f393b""><img src='https://img.shields.io/badge/Commit-bae4bb1-red' alt='Commit Link'></a></td>
    </tr>
</table>

You can attempt to backport this manually by running:

```bash
cherry_picker bae4bb1 v2-10-test
```

This should apply the commit to the v2-10-test branch and leave the commit in conflict state marking
the files that need manual conflict resolution.

After you have resolved the conflicts, you can continue the backport process by running:

```bash
cherry_picker --continue
```

pierrejeambrun on (2025-01-10 16:02:33 UTC): cherry pick PR here:
https://github.com/apache/airflow/pull/45560

"
2779770763,pull_request,closed,,fix code indent in modified docker-compose.yaml for PyCharm,"fix code indent in documentation(debugging docker compose in PyCharm)
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",david-parkk,2025-01-10 09:58:46+00:00,[],2025-01-30 14:35:21+00:00,2025-01-10 13:11:22+00:00,https://github.com/apache/airflow/pull/45545,"[('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2582683849, 'issue_id': 2779770763, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 10, 13, 11, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582685651, 'issue_id': 2779770763, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45552""><img src=""https://img.shields.io/badge/PR-45552-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2025, 1, 10, 13, 12, 14, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-10 13:11:25 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

github-actions[bot] on (2025-01-10 13:12:14 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45552""><img src=""https://img.shields.io/badge/PR-45552-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2779760296,pull_request,closed,,fix code indent in modified docker-compose.yaml for PyCharm,"fix code indent in documentation(debugging docker compose in PyCharm)
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",david-parkk,2025-01-10 09:54:28+00:00,[],2025-01-10 09:54:58+00:00,2025-01-10 09:54:58+00:00,https://github.com/apache/airflow/pull/45544,"[('kind:documentation', '')]","[{'comment_id': 2582240271, 'issue_id': 2779760296, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 10, 9, 54, 32, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-10 09:54:32 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2779641094,pull_request,closed,,Upgrade pgBouncer version to 1.24.0,"As of version 1.23.0, pgBouncer introduced [support for rolling restarts](https://www.pgbouncer.org/changelog.html#pgbouncer-123x) and version 1.24.0 is also introduced with several improvements and fixes. This feature allows users to seamlessly restart PgBouncer instances without disrupting active connections. For Airflow users managing PgBouncer on Kubernetes, this enhancement simplifies maintenance and upgrades, ensuring high availability and minimal downtime for critical workflows.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",goktugkose,2025-01-10 09:01:13+00:00,[],2025-01-10 13:35:55+00:00,2025-01-10 13:12:46+00:00,https://github.com/apache/airflow/pull/45542,"[('area:helm-chart', 'Airflow Helm Chart'), ('full tests needed', 'We need to run full set of tests for this PR to merge')]","[{'comment_id': 2582107948, 'issue_id': 2779641094, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 10, 9, 1, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582481895, 'issue_id': 2779641094, 'author': 'potiuk', 'body': 'I built and pushed the image, running the tests to make sure it works in our K8S tests', 'created_at': datetime.datetime(2025, 1, 10, 11, 25, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582482249, 'issue_id': 2779641094, 'author': 'potiuk', 'body': 'Thanks for creating the PR @goktugkose', 'created_at': datetime.datetime(2025, 1, 10, 11, 25, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582686200, 'issue_id': 2779641094, 'author': 'potiuk', 'body': 'Random unrelated test failing. Merging. Thanks for the PR.', 'created_at': datetime.datetime(2025, 1, 10, 13, 12, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582686771, 'issue_id': 2779641094, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 10, 13, 12, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582729141, 'issue_id': 2779641094, 'author': 'goktugkose', 'body': ""@potiuk Thank you so much for the quick response! I hope this contribution proves useful for the community. It's always great to collaborate and improve together ❤️"", 'created_at': datetime.datetime(2025, 1, 10, 13, 35, 54, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-10 09:01:18 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

potiuk on (2025-01-10 11:25:04 UTC): I built and pushed the image, running the tests to make sure it works in our K8S tests

potiuk on (2025-01-10 11:25:17 UTC): Thanks for creating the PR @goktugkose

potiuk on (2025-01-10 13:12:31 UTC): Random unrelated test failing. Merging. Thanks for the PR.

boring-cyborg[bot] on (2025-01-10 13:12:49 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

goktugkose (Issue Creator) on (2025-01-10 13:35:54 UTC): @potiuk Thank you so much for the quick response! I hope this contribution proves useful for the community. It's always great to collaborate and improve together ❤️

"
2779640351,pull_request,closed,,CodeQL scanning can run always on all code,"The CodeQL scannig is fast and having custom configuration to select which scanning to run should be run makes it unnecessarily complex

We can just run all CodeQL scans always.

This has been suggested by actions codeql scan itself.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-10 09:00:50+00:00,[],2025-01-10 10:19:32+00:00,2025-01-10 10:19:30+00:00,https://github.com/apache/airflow/pull/45541,"[('area:dev-tools', '')]",[],
2779471992,pull_request,closed,,[v2-10-test] Cease using ``InventoryFileReader`` (#45391),"(cherry picked from commit 57be0631223c8a04bec8966f257c62cff9be2095)

Co-authored-by: Adam Turner <9087854+AA-Turner@users.noreply.github.com>",github-actions[bot],2025-01-10 07:20:54+00:00,[],2025-01-10 07:31:44+00:00,2025-01-10 07:31:41+00:00,https://github.com/apache/airflow/pull/45538,"[('kind:documentation', '')]",[],
2779415452,pull_request,closed,,Ensure that WatchedSubprocess inheritors have consistent method signatures,"The `start` and `_on_child_started` methods have inconsistent signatures for the dag processor subclass.

This PR resolves that.

Why bother?  Well, I need to change the path handling a little bit to pass rel path and bundle info separately.  And we should get rid of the dags folder concept.  And when I tried to make these changes in the execution context, it broke dag parsing, because of this signature issue.
",dstandish,2025-01-10 06:42:41+00:00,[],2025-01-10 22:51:45+00:00,2025-01-10 22:51:44+00:00,https://github.com/apache/airflow/pull/45537,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:task-sdk', None)]","[{'comment_id': 2583313628, 'issue_id': 2779415452, 'author': 'dstandish', 'body': ""> I think by having this as two subclasses (for a total of three classes) also means we can keep the public signature as it is taking `ActivitySubprocess.start(dag_path, ti, client=client, logger=logger)`, and that could then pass the right things on to `child_started_kwargs` in the super call etc?\r\n\r\nThe dag processor does not pass a TI -- it only passes (optionally) a callback list.  \r\nI'll look into whether this can be further improved by having a base class but, i think if nothing else, this PR does not make the situation worse and just makes explicit and clear all the shenanigans that were sorta hidden before"", 'created_at': datetime.datetime(2025, 1, 10, 17, 26, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2583337764, 'issue_id': 2779415452, 'author': 'ashb', 'body': 'By having a separate subclass for execution we get rid of the need to have `if TYPE_CEHCKING: assert self.client` which feels nicer', 'created_at': datetime.datetime(2025, 1, 10, 17, 42, 3, tzinfo=datetime.timezone.utc)}]","dstandish (Issue Creator) on (2025-01-10 17:26:44 UTC): The dag processor does not pass a TI -- it only passes (optionally) a callback list.  
I'll look into whether this can be further improved by having a base class but, i think if nothing else, this PR does not make the situation worse and just makes explicit and clear all the shenanigans that were sorta hidden before

ashb on (2025-01-10 17:42:03 UTC): By having a separate subclass for execution we get rid of the need to have `if TYPE_CEHCKING: assert self.client` which feels nicer

"
2779041118,pull_request,closed,,AIP-38 List providers,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE


How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

related: #43708

<img width=""511"" alt=""Screenshot 2025-01-09 at 4 45 15 PM"" src=""https://github.com/user-attachments/assets/83407ea6-f0a3-42bd-ab8e-41317540e8bb"" />


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dauinh,2025-01-10 00:49:05+00:00,[],2025-01-31 09:34:13+00:00,2025-01-31 09:34:13+00:00,https://github.com/apache/airflow/pull/45535,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]","[{'comment_id': 2613265027, 'issue_id': 2779041118, 'author': 'bbovenzi', 'body': 'Could you run `pnpm lint && pnpm format` locally? Looks like static checks are failing.', 'created_at': datetime.datetime(2025, 1, 24, 19, 46, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613288775, 'issue_id': 2779041118, 'author': 'dauinh', 'body': ""I just did! Thank you for your reviews! I simplified the code by changing the URL into a link component. I couldn't figure out how to work with `replace` or other JS functions, so I kept `embedLinks`. If you have any suggestion, please let me know. \r\n\r\nI couldn't reproduce the key prop error either, but I did have key prop for each table row. I hope that works!"", 'created_at': datetime.datetime(2025, 1, 24, 20, 2, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2622477172, 'issue_id': 2779041118, 'author': 'dauinh', 'body': 'I have rebased my branch to the most updated `main` branch. Thank you for your time and guidance!', 'created_at': datetime.datetime(2025, 1, 29, 18, 8, 38, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2025-01-24 19:46:47 UTC): Could you run `pnpm lint && pnpm format` locally? Looks like static checks are failing.

dauinh (Issue Creator) on (2025-01-24 20:02:36 UTC): I just did! Thank you for your reviews! I simplified the code by changing the URL into a link component. I couldn't figure out how to work with `replace` or other JS functions, so I kept `embedLinks`. If you have any suggestion, please let me know. 

I couldn't reproduce the key prop error either, but I did have key prop for each table row. I hope that works!

dauinh (Issue Creator) on (2025-01-29 18:08:38 UTC): I have rebased my branch to the most updated `main` branch. Thank you for your time and guidance!

"
2779011897,pull_request,closed,,Add actions in codeql workflows to scan github workflow actions,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-10 00:13:42+00:00,[],2025-01-11 04:32:21+00:00,2025-01-10 08:25:24+00:00,https://github.com/apache/airflow/pull/45534,"[('area:dev-tools', '')]","[{'comment_id': 2581488193, 'issue_id': 2779011897, 'author': 'github-advanced-security[bot]', 'body': ""This pull request sets up GitHub code scanning for this repository. Once the scans have completed and the checks have passed, the analysis results for this pull request branch will appear on [this overview](/apache/airflow/security/code-scanning?query=pr%3A45534+is%3Aopen). Once you merge this pull request, the 'Security' tab will show more code scanning analysis results (for example, for the default branch). Depending on your configuration and choice of analysis tool, future pull requests will be annotated with code scanning analysis results. For more information about GitHub code scanning, check out [the documentation](https://docs.github.com/code-security/code-scanning/introduction-to-code-scanning/about-code-scanning)."", 'created_at': datetime.datetime(2025, 1, 10, 0, 15, 15, tzinfo=datetime.timezone.utc)}]","github-advanced-security[bot] on (2025-01-10 00:15:15 UTC): This pull request sets up GitHub code scanning for this repository. Once the scans have completed and the checks have passed, the analysis results for this pull request branch will appear on [this overview](/apache/airflow/security/code-scanning?query=pr%3A45534+is%3Aopen). Once you merge this pull request, the 'Security' tab will show more code scanning analysis results (for example, for the default branch). Depending on your configuration and choice of analysis tool, future pull requests will be annotated with code scanning analysis results. For more information about GitHub code scanning, check out [the documentation](https://docs.github.com/code-security/code-scanning/introduction-to-code-scanning/about-code-scanning).

"
2779000623,pull_request,closed,,Add a bundle for example dags when enabled,"Once we start parsing from bundles, we will have a separate bundle to represent the example dags, instead of simply adding them to the list of files from the dags folder like we do today.

(This is split out of  #45532)",jedcunningham,2025-01-10 00:03:01+00:00,[],2025-01-10 20:11:57+00:00,2025-01-10 19:43:21+00:00,https://github.com/apache/airflow/pull/45533,"[('AIP-66: DAG Bundle/Manifest', '')]",[],
2778970070,pull_request,closed,,AIP-66: Add support for parsing DAG bundles ,"This is #45371, which had to be reverted.

Let's start parsing DAG bundles! This moves us away from parsing a
single local directory to being able to parse many different bundles,
including optional support for versioning.

This is just the basics - it keeps the parsing loop largely untouched.
We still have a single list of ""dag files"" to parse, and queue of them.
However, instead of just a path, this list and queue now contain
`DagFilePath`s, which hold both a local path and the bundle its from.

There are a number of things that are not fully functional at this
stage, like versioned callbacks. These will be refactored later. There
is enough churn with the basics (particularly with the number of test
changes).",jedcunningham,2025-01-09 23:35:29+00:00,[],2025-01-13 11:50:21+00:00,2025-01-13 11:50:19+00:00,https://github.com/apache/airflow/pull/45532,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('full tests needed', 'We need to run full set of tests for this PR to merge'), ('provider:openlineage', 'AIP-53'), ('provider:fab', ''), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2778868375,pull_request,closed,,AIP-66: Revert bundle parsing,"We need to revert #45371 and #45521 (this is a small followup - nothing really wrong in this one).

#45371 seems to have made some tests pretty flaky, and there may also be issues with multiprocessing and sqlalchemy.",jedcunningham,2025-01-09 22:30:15+00:00,[],2025-01-09 23:31:19+00:00,2025-01-09 23:31:17+00:00,https://github.com/apache/airflow/pull/45531,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('provider:openlineage', 'AIP-53'), ('provider:fab', ''), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2778864345,pull_request,closed,,Ensure teardown tasks are executed when DAG run is set to failed,"Related to Slack topic: https://apache-airflow.slack.com/archives/CCR6P6JRL/p1736440079894049

We noticed that if a DAG run is set to failed, all tasks are either set to failed or skipped. But if Teardown Tasks are used in a DAG, they are not executed. This could lead to infrastructure or external dependencies not properly cleaned-up.

This PR changes the behavior and does NOT fail/skip teardown tasks if a DAG is set to failed.
A side effect as consequence might be that the DAG is after the call NOT failed, else if it would set it to failed, then any teardown task (even if not skipped/failed) will not scheduled anymore.",jscheffl,2025-01-09 22:27:32+00:00,[],2025-01-14 20:20:18+00:00,2025-01-11 17:51:21+00:00,https://github.com/apache/airflow/pull/45530,"[('area:API', ""Airflow's REST/HTTP API""), ('type:bug-fix', 'Changelog: Bug Fixes'), ('AIP-52', 'Automatic setup and teardown tasks'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2585344164, 'issue_id': 2778864345, 'author': 'jscheffl', 'body': ""> Nice catch! One edge case that I thought about though* - what if the corresponding setup task hasn't finished running yet? (if such exists ofc) For example: ![image](https://private-user-images.githubusercontent.com/60007259/401885485-e41019c0-1788-4f1e-9745-48e0ede7ad07.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MzY1Mzk1OTEsIm5iZiI6MTczNjUzOTI5MSwicGF0aCI6Ii82MDAwNzI1OS80MDE4ODU0ODUtZTQxMDE5YzAtMTc4OC00ZjFlLTk3NDUtNDhlMGVkZTdhZDA3LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTAxMTAlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwMTEwVDIwMDEzMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU1MTQyOTFjNjQ5NmRhMDQ4NmZjMGJkYmI4N2Y4YmQyYjI3ZGI3NDY4N2I2NzliNTRjYjA2YWU3MmM4ZGQ4MWQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.uZ8ztTGGj75LBIpfubeTOCLsEZmUhLSXLYs7i6f4x7M) If you set the DAG run to `failed` before the cluster was created, the `delete_cluster` should be skipped.\r\n> \r\n> * Maybe the current architecture already handles, but it's worth checking before merging this PR.\r\n\r\nOh, yeah. Tested this explicitly. And actually the Scheduler had this feature before (added this to docs as well, was also new to me): If the setup task is skipped (which is the state when you mark as failed and it was not running) then the teardown is also skipped,"", 'created_at': datetime.datetime(2025, 1, 11, 17, 8, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585344311, 'issue_id': 2778864345, 'author': 'jscheffl', 'body': 'Added some docs as I thought about that slightly the behavior changes - to ensure it is properly documented.', 'created_at': datetime.datetime(2025, 1, 11, 17, 9, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585356465, 'issue_id': 2778864345, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45581""><img src=""https://img.shields.io/badge/PR-45581-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2025, 1, 11, 17, 52, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2588463039, 'issue_id': 2778864345, 'author': 'Lee-W', 'body': ""just notice this could potentially be a breaking change, but doesn't look like something we need a migration rule 🤔 would like to confirm whether we might want to have such a rule?"", 'created_at': datetime.datetime(2025, 1, 13, 23, 37, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2590403975, 'issue_id': 2778864345, 'author': 'potiuk', 'body': '> just notice this could potentially be a breaking change, but doesn\'t look like something we need a migration rule 🤔 would like to confirm whether we might want to have such a rule?\r\n\r\nI\'d say it\'s a bugfix. Not all ""change behaviour"" is ""breaking change"". Every bugfix is a ""behavioural change"" in essence, the important thing is what is the feature intention and whether the change is ""fixing"" things or ""changing intention on how things should work"". SemVer is all about **intentions** and not about whether behaviour changes or not - see https://semver.org/ \r\n\r\nIn this case it seems reasonable to assume that this behaviour was intention of the ""teardown"" behaviour - so technically it\'s a bugfix (and it\'s been already backported to 2.10 it seems.\r\n\r\nIt might require a newsfragment, but IMHO - that\'s more than enough.', 'created_at': datetime.datetime(2025, 1, 14, 16, 15, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2591027043, 'issue_id': 2778864345, 'author': 'jscheffl', 'body': '> just notice this could potentially be a breaking change, but doesn\'t look like something we need a migration rule 🤔 would like to confirm whether we might want to have such a rule?\r\n\r\nFor sure it does not need migration rules. No code change needed.\r\n\r\nYeah and thought also a bit about if it is breaking, asked in #random / Slack for feedback and nobody except @dstandish was responding. Then after passing... I think it is really in the intend for why we have Setup/Teardown. Behaviour change is ""just"" because of the side effect that the DAG is not immediately failed if you set it to failed as Teardown need to be scheduled.', 'created_at': datetime.datetime(2025, 1, 14, 20, 20, 17, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2025-01-11 17:08:48 UTC): Oh, yeah. Tested this explicitly. And actually the Scheduler had this feature before (added this to docs as well, was also new to me): If the setup task is skipped (which is the state when you mark as failed and it was not running) then the teardown is also skipped,

jscheffl (Issue Creator) on (2025-01-11 17:09:14 UTC): Added some docs as I thought about that slightly the behavior changes - to ensure it is properly documented.

github-actions[bot] on (2025-01-11 17:52:11 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45581""><img src=""https://img.shields.io/badge/PR-45581-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

Lee-W on (2025-01-13 23:37:02 UTC): just notice this could potentially be a breaking change, but doesn't look like something we need a migration rule 🤔 would like to confirm whether we might want to have such a rule?

potiuk on (2025-01-14 16:15:50 UTC): I'd say it's a bugfix. Not all ""change behaviour"" is ""breaking change"". Every bugfix is a ""behavioural change"" in essence, the important thing is what is the feature intention and whether the change is ""fixing"" things or ""changing intention on how things should work"". SemVer is all about **intentions** and not about whether behaviour changes or not - see https://semver.org/ 

In this case it seems reasonable to assume that this behaviour was intention of the ""teardown"" behaviour - so technically it's a bugfix (and it's been already backported to 2.10 it seems.

It might require a newsfragment, but IMHO - that's more than enough.

jscheffl (Issue Creator) on (2025-01-14 20:20:17 UTC): For sure it does not need migration rules. No code change needed.

Yeah and thought also a bit about if it is breaking, asked in #random / Slack for feedback and nobody except @dstandish was responding. Then after passing... I think it is really in the intend for why we have Setup/Teardown. Behaviour change is ""just"" because of the side effect that the DAG is not immediately failed if you set it to failed as Teardown need to be scheduled.

"
2778722422,pull_request,closed,,Fix kubernetes executor watcher kube_client_request_args shadowing,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
Fix KubernetesJobWatcher shadowing kube client timeouts arguments 

Provided change allows to have previously established defaults in KubernetesJobWatcher for client timeouts to not hang on events reading, but also do not overwrite them if they were provided in specific configuration option by user.

closes: #45517 

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",insomnes,2025-01-09 20:45:50+00:00,[],2025-01-13 17:01:54+00:00,2025-01-13 16:56:35+00:00,https://github.com/apache/airflow/pull/45528,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2581214730, 'issue_id': 2778722422, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 9, 20, 45, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582991206, 'issue_id': 2778722422, 'author': 'insomnes', 'body': ""I've checked failed tests in previous checks run\r\nhttps://github.com/apache/airflow/actions/runs/12698225501\r\n\r\nAnd I can't find any reason for my changes to interfere with them. So I've rebased branch again"", 'created_at': datetime.datetime(2025, 1, 10, 15, 42, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585146276, 'issue_id': 2778722422, 'author': 'insomnes', 'body': 'Added as suggested. I am not familiar with code standards, so I was trying to minimize my ""invasion"".\n\nThank you!', 'created_at': datetime.datetime(2025, 1, 11, 8, 27, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2587666577, 'issue_id': 2778722422, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 13, 16, 56, 38, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-09 20:45:56 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

insomnes (Issue Creator) on (2025-01-10 15:42:02 UTC): I've checked failed tests in previous checks run
https://github.com/apache/airflow/actions/runs/12698225501

And I can't find any reason for my changes to interfere with them. So I've rebased branch again

insomnes (Issue Creator) on (2025-01-11 08:27:33 UTC): Added as suggested. I am not familiar with code standards, so I was trying to minimize my ""invasion"".

Thank you!

boring-cyborg[bot] on (2025-01-13 16:56:38 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2778722042,pull_request,closed,,[v2-10-test] Backport pull_request_target removal,"This is a bulk change that synchronizes dev/ci scripts for v2-10-test branch with main #45266 - including follow-ups.

Rather than cherry-picking relevant PRs, this one gets the latest version of the scripts from main and updates the branch with some changes to adapt them to v2-10-test (such as bringing back python 3.8 support, removing some providers checks after the bulk move of providers and making sure all tests are passing.

This is far easier than cherry-picking the changes, because for the v2-10-test we stopped cherry-picking CI changes which was deemed unnecessary (we used to do it for all previous branches) but this made it far more difficult (if not impossible) to cherry-pick individual changes.

Fortunately, the CI scripts are maintained in the way that their latest version **should** in principle work for a v2-* branch and hopefully after just a few adjustments we should be able to synchronize the changes from main by updating all relevant CI/DEV scripts, dockerfile images, workflows, pre-commits etc.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-09 20:45:36+00:00,[],2025-01-28 12:07:53+00:00,2025-01-12 12:00:06+00:00,https://github.com/apache/airflow/pull/45527,"[('area:dev-tools', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2585381090, 'issue_id': 2778722042, 'author': 'potiuk', 'body': 'Hey here. I know this one is huge and difficult to review, but this was the easiest way I could bring the  ""pull_request_target"" removal to `v2-10-test`  branch. \r\n\r\nSince we stopped cherry-picking breeze changes to `v2-10-test` and made a LOT of chenges in main (removing Python 3.8, moving providers, adding test_sdk and so on -  cherry-picking individual commits was not an option. So I choose a different path - I copuied the latest `breeze`, `ci_scripts`, `Dockerfiles` and `.pre-commits` and adapted them to`v2-10-test` - mostly removing stuff that was not needed in v2-10-test (providers, charts, new api etc. etc., adding back Python 3.8). \r\n\r\nAll other changes were results of fixing the tests.\r\n\r\nI think the easiest way to review it is two-fold:\r\n\r\n1) you can compare all the breeze/ci stuff with `main` - and see the differences (mostly removals of the things above) \r\n2) then you can compare ""airflow"" and ""tests"" with `v2-10-test` and see that they only changed to accomodate to some tests scripts changes. \r\n\r\nI know I am asking a lot, but this is the easiest way we can remove last remnants of `pull_request_target"" - which is still a potential security issue.', 'created_at': datetime.datetime(2025, 1, 11, 19, 16, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585452337, 'issue_id': 2778722042, 'author': 'potiuk', 'body': 'Yeah - some test failure fixes needed :(', 'created_at': datetime.datetime(2025, 1, 11, 21, 32, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585704333, 'issue_id': 2778722042, 'author': 'potiuk', 'body': 'All problems solved. I also applied latest version of sphinx-theme limit and compared produced .whl files for airflow and the differences are pretty much as expected:\r\n\r\n> diff ./old ./new -r\r\n\r\n```diff\r\ndiff -r ./old/airflow/api/common/mark_tasks.py ./new/airflow/api/common/mark_tasks.py\r\n413a414,417\r\n>\r\n>     # Mark all task instances of the dag run to success - except for teardown as they need to complete work.\r\n>     normal_tasks = [task for task in dag.tasks if not task.is_teardown]\r\n>\r\n415c419\r\n<     if commit:\r\n---\r\n>     if commit and len(normal_tasks) == len(dag.tasks):\r\n418,419c422\r\n<     # Mark all task instances of the dag run to success.\r\n<     for task in dag.tasks:\r\n---\r\n>     for task in normal_tasks:\r\n422c425\r\n<         tasks=dag.tasks,\r\n---\r\n>         tasks=normal_tasks,\r\n469,472d471\r\n<     # Mark the dag run to failed.\r\n<     if commit:\r\n<         _set_dag_run_state(dag.dag_id, run_id, DagRunState.FAILED, session)\r\n<\r\n481c480\r\n<     tis = session.scalars(\r\n---\r\n>     running_tis: list[TaskInstance] = session.scalars(\r\n488c487\r\n<     )\r\n---\r\n>     ).all()\r\n490c489,490\r\n<     task_ids_of_running_tis = [task_instance.task_id for task_instance in tis]\r\n---\r\n>     # Do not kill teardown tasks\r\n>     task_ids_of_running_tis = [ti.task_id for ti in running_tis if not dag.task_dict[ti.task_id].is_teardown]\r\n492c492\r\n<     tasks = []\r\n---\r\n>     running_tasks = []\r\n496c496\r\n<             tasks.append(task)\r\n---\r\n>             running_tasks.append(task)\r\n499c499\r\n<     tis = session.scalars(\r\n---\r\n>     pending_tis: list[TaskInstance] = session.scalars(\r\n512a513,515\r\n>     # Do not skip teardown tasks\r\n>     pending_normal_tis = [ti for ti in pending_tis if not dag.task_dict[ti.task_id].is_teardown]\r\n>\r\n514c517\r\n<         for ti in tis:\r\n---\r\n>         for ti in pending_normal_tis:\r\n517,518c520,525\r\n<     return tis + set_state(\r\n<         tasks=tasks,\r\n---\r\n>         # Mark the dag run to failed if there is no pending teardown (else this would not be scheduled later).\r\n>         if not any(dag.task_dict[ti.task_id].is_teardown for ti in (running_tis + pending_tis)):\r\n>             _set_dag_run_state(dag.dag_id, run_id, DagRunState.FAILED, session)\r\n>\r\n>     return pending_normal_tis + set_state(\r\n>         tasks=running_tasks,\r\ndiff -r ./old/airflow/api_connexion/openapi/v1.yaml ./new/airflow/api_connexion/openapi/v1.yaml\r\n5735a5736\r\n>         format: path\r\ndiff -r ./old/airflow/cli/cli_config.py ./new/airflow/cli/cli_config.py\r\n67c67\r\n<         """"""Override error and use print_instead of print_usage.""""""\r\n---\r\n>         """"""Override error and use print_help instead of print_usage.""""""\r\ndiff -r ./old/airflow/datasets/metadata.py ./new/airflow/datasets/metadata.py\r\n19a20\r\n> import warnings\r\n40a42,50\r\n>         if isinstance(target, str):\r\n>             warnings.warn(\r\n>                 (\r\n>                     ""Accessing outlet_events using string is deprecated and will be removed in Airflow 3. ""\r\n>                     ""Please use the Dataset or DatasetAlias object (renamed as Asset and AssetAlias in Airflow 3) directly""\r\n>                 ),\r\n>                 DeprecationWarning,\r\n>                 stacklevel=2,\r\n>             )\r\n45a56,63\r\n>             warnings.warn(\r\n>                 (\r\n>                     ""Emitting dataset events using string is deprecated and will be removed in Airflow 3. ""\r\n>                     ""Please use the Dataset object (renamed as Asset in Airflow 3) directly""\r\n>                 ),\r\n>                 DeprecationWarning,\r\n>                 stacklevel=2,\r\n>             )\r\ndiff -r ./old/airflow/executors/executor_loader.py ./new/airflow/executors/executor_loader.py\r\n340c340\r\n<         if engine.dialect.name == ""sqlite"":\r\n---\r\n>         if engine and engine.dialect.name == ""sqlite"":\r\ndiff -r ./old/airflow/git_version ./new/airflow/git_version\r\n1c1\r\n< .release:c083e456fa02c6cb32cdbe0c9ed3c3b2380beccd\r\n\\ No newline at end of file\r\n---\r\n> .release:a9fe36219cd537af06708c9ed2efba86e3449f81\r\n\\ No newline at end of file\r\ndiff -r ./old/airflow/models/baseoperator.py ./new/airflow/models/baseoperator.py\r\n968d967\r\n<         validate_key(task_id)\r\n973a973,975\r\n>\r\n>         validate_key(self.task_id)\r\n>\r\ndiff -r ./old/airflow/models/mappedoperator.py ./new/airflow/models/mappedoperator.py\r\n832a833,834\r\n>             op.downstream_task_ids = self.downstream_task_ids\r\n>             op.upstream_task_ids = self.upstream_task_ids\r\ndiff -r ./old/airflow/models/skipmixin.py ./new/airflow/models/skipmixin.py\r\n164,165d163\r\n<         SkipMixin._set_state_to_skipped(dag_run, task_ids_list, session)\r\n<         session.commit()\r\n166a165,169\r\n>         # The following could be applied only for non-mapped tasks\r\n>         if map_index == -1:\r\n>             SkipMixin._set_state_to_skipped(dag_run, task_ids_list, session)\r\n>             session.commit()\r\n>\r\n179a183\r\n>     @staticmethod\r\n181d184\r\n<         self,\r\ndiff -r ./old/airflow/models/taskinstance.py ./new/airflow/models/taskinstance.py\r\n28a29\r\n> import traceback\r\n249c250\r\n<         TaskInstance.save_to_db(ti=ti, session=session)\r\n---\r\n>         TaskInstance.save_to_db(ti=ti, session=session, refresh_dag=False)\r\n1243c1244\r\n<         TaskInstance.save_to_db(failure_context[""ti""], session)\r\n---\r\n>         TaskInstance.save_to_db(task_instance, session)\r\n3093a3095\r\n>             self.log.error(""Stacktrace: \\n%s"", """".join(traceback.format_stack()))\r\n3396c3398,3402\r\n<     def save_to_db(ti: TaskInstance | TaskInstancePydantic, session: Session = NEW_SESSION):\r\n---\r\n>     def save_to_db(\r\n>         ti: TaskInstance | TaskInstancePydantic, session: Session = NEW_SESSION, refresh_dag: bool = True\r\n>     ):\r\n>         if refresh_dag and isinstance(ti, TaskInstance):\r\n>             ti.get_dagrun().refresh_from_db()\r\ndiff -r ./old/airflow/providers_manager.py ./new/airflow/providers_manager.py\r\n534d533\r\n<     @provider_info_cache(""hook_lineage_writers"")\r\ndiff -r ./old/airflow/reproducible_build.yaml ./new/airflow/reproducible_build.yaml\r\n1,2c1,2\r\n< release-notes-hash: 0867869dba7304e7ead28dd0800c5c4b\r\n< source-date-epoch: 1733822937\r\n---\r\n> release-notes-hash: 7be47e2ddbbe1bfbd0d3f572d2b7800a\r\n> source-date-epoch: 1736532824\r\ndiff -r ./old/airflow/sensors/base.py ./new/airflow/sensors/base.py\r\n109c109,112\r\n<             TaskReschedule.try_number == try_number,\r\n---\r\n>             # If the first try\'s record was not saved due to the Exception occurred and the following\r\n>             # transaction rollback, the next available attempt should be taken\r\n>             # to prevent falling in the endless rescheduling\r\n>             TaskReschedule.try_number >= try_number,\r\n256c259\r\n<             # first execution of the task, or the first execution after the task was cleared.)\r\n---\r\n>             # first execution of the task, or the first execution after the task was cleared).\r\ndiff -r ./old/airflow/ti_deps/deps/not_previously_skipped_dep.py ./new/airflow/ti_deps/deps/not_previously_skipped_dep.py\r\n21a22\r\n> from airflow.utils.db import LazySelectSequence\r\n41d41\r\n<             SkipMixin,\r\n52,55c52,54\r\n<             if isinstance(parent, SkipMixin):\r\n<                 if parent.task_id not in finished_task_ids:\r\n<                     # This can happen if the parent task has not yet run.\r\n<                     continue\r\n---\r\n>             if parent.task_id not in finished_task_ids:\r\n>                 # This can happen if the parent task has not yet run.\r\n>                 continue\r\n57c56,58\r\n<                 prev_result = ti.xcom_pull(task_ids=parent.task_id, key=XCOM_SKIPMIXIN_KEY, session=session)\r\n---\r\n>             prev_result = ti.xcom_pull(\r\n>                 task_ids=parent.task_id, key=XCOM_SKIPMIXIN_KEY, session=session, map_indexes=ti.map_index\r\n>             )\r\n59,61c60,61\r\n<                 if prev_result is None:\r\n<                     # This can happen if the parent task has not yet run.\r\n<                     continue\r\n---\r\n>             if isinstance(prev_result, LazySelectSequence):\r\n>                 prev_result = next(iter(prev_result))\r\n63,75c63,65\r\n<                 should_skip = False\r\n<                 if (\r\n<                     XCOM_SKIPMIXIN_FOLLOWED in prev_result\r\n<                     and ti.task_id not in prev_result[XCOM_SKIPMIXIN_FOLLOWED]\r\n<                 ):\r\n<                     # Skip any tasks that are not in ""followed""\r\n<                     should_skip = True\r\n<                 elif (\r\n<                     XCOM_SKIPMIXIN_SKIPPED in prev_result\r\n<                     and ti.task_id in prev_result[XCOM_SKIPMIXIN_SKIPPED]\r\n<                 ):\r\n<                     # Skip any tasks that are in ""skipped""\r\n<                     should_skip = True\r\n---\r\n>             if prev_result is None:\r\n>                 # This can happen if the parent task has not yet run.\r\n>                 continue\r\n77,92c67,84\r\n<                 if should_skip:\r\n<                     # If the parent SkipMixin has run, and the XCom result stored indicates this\r\n<                     # ti should be skipped, set ti.state to SKIPPED and fail the rule so that the\r\n<                     # ti does not execute.\r\n<                     if dep_context.wait_for_past_depends_before_skipping:\r\n<                         past_depends_met = ti.xcom_pull(\r\n<                             task_ids=ti.task_id, key=PAST_DEPENDS_MET, session=session, default=False\r\n<                         )\r\n<                         if not past_depends_met:\r\n<                             yield self._failing_status(\r\n<                                 reason=(""Task should be skipped but the past depends are not met"")\r\n<                             )\r\n<                             return\r\n<                     ti.set_state(TaskInstanceState.SKIPPED, session)\r\n<                     yield self._failing_status(\r\n<                         reason=f""Skipping because of previous XCom result from parent task {parent.task_id}""\r\n---\r\n>             should_skip = False\r\n>             if (\r\n>                 XCOM_SKIPMIXIN_FOLLOWED in prev_result\r\n>                 and ti.task_id not in prev_result[XCOM_SKIPMIXIN_FOLLOWED]\r\n>             ):\r\n>                 # Skip any tasks that are not in ""followed""\r\n>                 should_skip = True\r\n>             elif XCOM_SKIPMIXIN_SKIPPED in prev_result and ti.task_id in prev_result[XCOM_SKIPMIXIN_SKIPPED]:\r\n>                 # Skip any tasks that are in ""skipped""\r\n>                 should_skip = True\r\n>\r\n>             if should_skip:\r\n>                 # If the parent SkipMixin has run, and the XCom result stored indicates this\r\n>                 # ti should be skipped, set ti.state to SKIPPED and fail the rule so that the\r\n>                 # ti does not execute.\r\n>                 if dep_context.wait_for_past_depends_before_skipping:\r\n>                     past_depends_met = ti.xcom_pull(\r\n>                         task_ids=ti.task_id, key=PAST_DEPENDS_MET, session=session, default=False\r\n94c86,95\r\n<                     return\r\n---\r\n>                     if not past_depends_met:\r\n>                         yield self._failing_status(\r\n>                             reason=""Task should be skipped but the past depends are not met""\r\n>                         )\r\n>                         return\r\n>                 ti.set_state(TaskInstanceState.SKIPPED, session)\r\n>                 yield self._failing_status(\r\n>                     reason=f""Skipping because of previous XCom result from parent task {parent.task_id}""\r\n>                 )\r\n>                 return\r\ndiff -r ./old/airflow/ti_deps/deps/trigger_rule_dep.py ./new/airflow/ti_deps/deps/trigger_rule_dep.py\r\n29a30\r\n> from airflow.utils.task_group import MappedTaskGroup\r\n66,67c67\r\n<         :param ti: the ti that we want to calculate deps for\r\n<         :param finished_tis: all the finished tasks of the dag_run\r\n---\r\n>         :param finished_upstreams: all the finished upstreams of the dag_run\r\n145a146,158\r\n>         def _iter_expansion_dependencies(task_group: MappedTaskGroup) -> Iterator[str]:\r\n>             from airflow.models.mappedoperator import MappedOperator\r\n>\r\n>             if isinstance(ti.task, MappedOperator):\r\n>                 for op in ti.task.iter_mapped_dependencies():\r\n>                     yield op.task_id\r\n>             if task_group and task_group.iter_mapped_task_groups():\r\n>                 yield from (\r\n>                     op.task_id\r\n>                     for tg in task_group.iter_mapped_task_groups()\r\n>                     for op in tg.iter_mapped_dependencies()\r\n>                 )\r\n>\r\n158a172,178\r\n>             if isinstance(ti.task.task_group, MappedTaskGroup):\r\n>                 is_fast_triggered = ti.task.trigger_rule in (TR.ONE_SUCCESS, TR.ONE_FAILED, TR.ONE_DONE)\r\n>                 if is_fast_triggered and upstream_id not in set(\r\n>                     _iter_expansion_dependencies(task_group=ti.task.task_group)\r\n>                 ):\r\n>                     return None\r\n>\r\n220c240\r\n<                     yield (TaskInstance.task_id == upstream_id)\r\n---\r\n>                     yield TaskInstance.task_id == upstream_id\r\n240c260\r\n<             Evaluate whether ``ti``\'s trigger rule was met.\r\n---\r\n>             Evaluate whether ``ti``\'s trigger rule was met as part of the setup constraint.\r\n242,244c262\r\n<             :param ti: Task instance to evaluate the trigger rule of.\r\n<             :param dep_context: The current dependency context.\r\n<             :param session: Database session.\r\n---\r\n>             :param relevant_setups: Relevant setups for the current task instance.\r\n330,336c348\r\n<             """"""\r\n<             Evaluate whether ``ti``\'s trigger rule was met.\r\n<\r\n<             :param ti: Task instance to evaluate the trigger rule of.\r\n<             :param dep_context: The current dependency context.\r\n<             :param session: Database session.\r\n<             """"""\r\n---\r\n>             """"""Evaluate whether ``ti``\'s trigger rule in direct relatives was met.""""""\r\n436c448\r\n<                             reason=(""Task should be skipped but the past depends are not met"")\r\n---\r\n>                             reason=""Task should be skipped but the past depends are not met""\r\ndiff -r ./old/airflow/utils/context.py ./new/airflow/utils/context.py\r\n361a362\r\n>         ""conf"": [],\r\ndiff -r ./old/airflow/utils/sqlalchemy.py ./new/airflow/utils/sqlalchemy.py\r\n112a113,114\r\n>     should_evaluate_none = True\r\n>\r\nOnly in ./old/airflow/www/static/dist: clusterActivity.2ecf4759427048c07368.js\r\nOnly in ./old/airflow/www/static/dist: clusterActivity.2ecf4759427048c07368.js.LICENSE.txt\r\nOnly in ./new/airflow/www/static/dist: clusterActivity.fff5d3527b4c5eedb340.js\r\nOnly in ./new/airflow/www/static/dist: clusterActivity.fff5d3527b4c5eedb340.js.LICENSE.txt\r\nOnly in ./old/airflow/www/static/dist: dags.2b495ee52ff9e3b5160e.css\r\nOnly in ./old/airflow/www/static/dist: dags.2b495ee52ff9e3b5160e.js\r\nOnly in ./old/airflow/www/static/dist: dags.2b495ee52ff9e3b5160e.js.LICENSE.txt\r\nOnly in ./new/airflow/www/static/dist: dags.4cb7043334f0e3173c4c.css\r\nOnly in ./new/airflow/www/static/dist: dags.4cb7043334f0e3173c4c.js\r\nOnly in ./new/airflow/www/static/dist: dags.4cb7043334f0e3173c4c.js.LICENSE.txt\r\nOnly in ./new/airflow/www/static/dist: datasets.0bc892295c97e7bfe58d.js\r\nOnly in ./new/airflow/www/static/dist: datasets.0bc892295c97e7bfe58d.js.LICENSE.txt\r\nOnly in ./old/airflow/www/static/dist: datasets.9af23983e71a1ebcbd80.js\r\nOnly in ./old/airflow/www/static/dist: datasets.9af23983e71a1ebcbd80.js.LICENSE.txt\r\nOnly in ./old/airflow/www/static/dist: grid.70939cd423edfd7d6e08.js\r\nOnly in ./old/airflow/www/static/dist: grid.70939cd423edfd7d6e08.js.LICENSE.txt\r\nOnly in ./new/airflow/www/static/dist: grid.9dfc288c631a1f964c7a.js\r\nOnly in ./new/airflow/www/static/dist: grid.9dfc288c631a1f964c7a.js.LICENSE.txt\r\nOnly in ./old/airflow/www/static/dist: main.8461584ab30f513901c2.css\r\nOnly in ./old/airflow/www/static/dist: main.8461584ab30f513901c2.js\r\nOnly in ./old/airflow/www/static/dist: main.8461584ab30f513901c2.js.LICENSE.txt\r\nOnly in ./new/airflow/www/static/dist: main.fb487bd34c7cd20f02bc.css\r\nOnly in ./new/airflow/www/static/dist: main.fb487bd34c7cd20f02bc.js\r\nOnly in ./new/airflow/www/static/dist: main.fb487bd34c7cd20f02bc.js.LICENSE.txt\r\ndiff -r ./old/airflow/www/static/dist/manifest.json ./new/airflow/www/static/dist/manifest.json\r\n9,10c9,10\r\n<   ""dags.css"": ""dags.2b495ee52ff9e3b5160e.css"",\r\n<   ""dags.js"": ""dags.2b495ee52ff9e3b5160e.js"",\r\n---\r\n>   ""dags.css"": ""dags.4cb7043334f0e3173c4c.css"",\r\n>   ""dags.js"": ""dags.4cb7043334f0e3173c4c.js"",\r\n17,18c17,18\r\n<   ""main.css"": ""main.8461584ab30f513901c2.css"",\r\n<   ""main.js"": ""main.8461584ab30f513901c2.js"",\r\n---\r\n>   ""main.css"": ""main.fb487bd34c7cd20f02bc.css"",\r\n>   ""main.js"": ""main.fb487bd34c7cd20f02bc.js"",\r\n25c25\r\n<   ""taskInstances.js"": ""taskInstances.a65435400ad9c5e928c1.js"",\r\n---\r\n>   ""taskInstances.js"": ""taskInstances.7a19b383b09d370fe8a0.js"",\r\n28,31c28,31\r\n<   ""grid.js"": ""grid.70939cd423edfd7d6e08.js"",\r\n<   ""clusterActivity.js"": ""clusterActivity.2ecf4759427048c07368.js"",\r\n<   ""datasets.js"": ""datasets.9af23983e71a1ebcbd80.js"",\r\n<   ""trigger.js"": ""trigger.d972e04a6a32368ffc7e.js"",\r\n---\r\n>   ""grid.js"": ""grid.9dfc288c631a1f964c7a.js"",\r\n>   ""clusterActivity.js"": ""clusterActivity.fff5d3527b4c5eedb340.js"",\r\n>   ""datasets.js"": ""datasets.0bc892295c97e7bfe58d.js"",\r\n>   ""trigger.js"": ""trigger.cef24b4966646f363d5a.js"",\r\nOnly in ./new/airflow/www/static/dist: taskInstances.7a19b383b09d370fe8a0.js\r\nOnly in ./new/airflow/www/static/dist: taskInstances.7a19b383b09d370fe8a0.js.LICENSE.txt\r\nOnly in ./old/airflow/www/static/dist: taskInstances.a65435400ad9c5e928c1.js\r\nOnly in ./old/airflow/www/static/dist: taskInstances.a65435400ad9c5e928c1.js.LICENSE.txt\r\nOnly in ./new/airflow/www/static/dist: trigger.cef24b4966646f363d5a.js\r\nOnly in ./new/airflow/www/static/dist: trigger.cef24b4966646f363d5a.js.LICENSE.txt\r\nOnly in ./old/airflow/www/static/dist: trigger.d972e04a6a32368ffc7e.js\r\nOnly in ./old/airflow/www/static/dist: trigger.d972e04a6a32368ffc7e.js.LICENSE.txt\r\ndiff -r ./old/airflow/www/static/js/api/useTaskXcom.ts ./new/airflow/www/static/js/api/useTaskXcom.ts\r\n60,67c60,69\r\n<     () =>\r\n<       axios.get<AxiosResponse, API.XCom>(\r\n<         getMetaValue(""task_xcom_entry_api"")\r\n<           .replace(""_DAG_RUN_ID_"", dagRunId)\r\n<           .replace(""_TASK_ID_"", taskId)\r\n<           .replace(""_XCOM_KEY_"", xcomKey),\r\n<         { params: { map_index: mapIndex, stringify: false } }\r\n<       ),\r\n---\r\n>     () => {\r\n>       const taskXcomEntryApiUrl = getMetaValue(""task_xcom_entry_api"")\r\n>         .replace(""_DAG_RUN_ID_"", dagRunId)\r\n>         .replace(""_TASK_ID_"", taskId)\r\n>         .replace(""_XCOM_KEY_"", encodeURIComponent(xcomKey));\r\n>\r\n>       return axios.get<AxiosResponse, API.XCom>(taskXcomEntryApiUrl, {\r\n>         params: { map_index: mapIndex, stringify: false },\r\n>       });\r\n>     },\r\ndiff -r ./old/airflow/www/static/js/dag/details/taskInstance/ExtraLinks.tsx ./new/airflow/www/static/js/dag/details/taskInstance/ExtraLinks.tsx\r\n60,61c60,67\r\n<     const urlRegex = /^(https?:)/i;\r\n<     return urlRegex.test(url);\r\n---\r\n>     const path = new URL(url, ""http://localhost"");\r\n>     // Allow Absolute/Relative URL and prevent javascript:() from executing when passed as path.\r\n>     // Example - `javascript:alert(""Hi"");`. Protocol for absolute and relative urls will either be `http:`/`https:`.\r\n>     // Where as for javascript it will be `javascript:`.\r\n>     if (path.protocol === ""http:"" || path.protocol === ""https:"") {\r\n>       return true; // Absolute/Relative URLs are allowed\r\n>     }\r\n>     return false;\r\ndiff -r ./old/airflow/www/static/js/main.js ./new/airflow/www/static/js/main.js\r\n288a289,292\r\n>\r\n>   // Turn off autocomplete for login form\r\n>   $(""#username:input"")[0].autocomplete = ""off"";\r\n>   $(""#password:input"")[0].autocomplete = ""off"";\r\ndiff -r ./old/airflow/www/static/js/trigger.js ./new/airflow/www/static/js/trigger.js\r\n62,63d61\r\n<       } else if (elements[i].value.length === 0) {\r\n<         params[keyName] = null;\r\n83a82,83\r\n>       } else if (elements[i].value.length === 0) {\r\n>         params[keyName] = null;\r\ndiff -r ./old/airflow/www/templates/airflow/trigger.html ./new/airflow/www/templates/airflow/trigger.html\r\n123c123,125\r\n<         {{- form_details.value | tojson() -}}\r\n---\r\n>         {%- if form_details.value %}\r\n>           {{- form_details.value | tojson() -}}\r\n>         {% endif -%}\r\ndiff -r ./old/airflow/www/views.py ./new/airflow/www/views.py\r\n5358a5359\r\n>         ""rendered_map_index"",\r\ndiff -r ./old/airflow/www/yarn.lock ./new/airflow/www/yarn.lock\r\n9021,9023c9021,9023\r\n<   version ""3.3.7""\r\n<   resolved ""https://registry.yarnpkg.com/nanoid/-/nanoid-3.3.7.tgz#d0c301a691bc8d54efa0a2226ccf3fe2fd656bd8""\r\n<   integrity sha512-eSRppjcPIatRIMC1U6UngP8XFcz8MQWGQdt1MTBQ7NaAmvXDfvNxbvWV3x2y6CdEUciCSsDHDQZbhYaB8QEo2g==\r\n---\r\n>   version ""3.3.8""\r\n>   resolved ""https://registry.yarnpkg.com/nanoid/-/nanoid-3.3.8.tgz#b1be3030bee36aaff18bacb375e5cce521684baf""\r\n>   integrity sha512-WNLf5Sd8oZxOm+TzppcYk8gVOgP+l58xNy58D0nbUnOxOWRWvlcCV4kUF7ltmI6PsrLl/BgKEyS4mqsGChFN0w==\r\ndiff -r ./old/apache_airflow-2.10.4.dist-info/METADATA ./new/apache_airflow-2.10.4.dist-info/METADATA\r\n1c1\r\n< Metadata-Version: 2.3\r\n---\r\n> Metadata-Version: 2.4\r\n14c14,17\r\n< Project-URL: Twitter, https://twitter.com/ApacheAirflow\r\n---\r\n> Project-URL: X, https://x.com/ApacheAirflow\r\n> Project-URL: LinkedIn, https://www.linkedin.com/company/apache-airflow/\r\n> Project-URL: Mastodon, https://fosstodon.org/@airflow\r\n> Project-URL: Bluesky, https://bsky.app/profile/apache-airflow.bsky.social\r\n17a21,39\r\n> License-File: 3rd-party-licenses/LICENSE-bootstrap.txt\r\n> License-File: 3rd-party-licenses/LICENSE-bootstrap3-typeahead.txt\r\n> License-File: 3rd-party-licenses/LICENSE-d3-shape.txt\r\n> License-File: 3rd-party-licenses/LICENSE-d3-tip.txt\r\n> License-File: 3rd-party-licenses/LICENSE-d3js.txt\r\n> License-File: 3rd-party-licenses/LICENSE-dagre-d3.txt\r\n> License-File: 3rd-party-licenses/LICENSE-datatables.txt\r\n> License-File: 3rd-party-licenses/LICENSE-elasticmock.txt\r\n> License-File: 3rd-party-licenses/LICENSE-eonasdan-bootstrap-datetimepicker.txt\r\n> License-File: 3rd-party-licenses/LICENSE-flask-kerberos.txt\r\n> License-File: 3rd-party-licenses/LICENSE-hue.txt\r\n> License-File: 3rd-party-licenses/LICENSE-jqclock.txt\r\n> License-File: 3rd-party-licenses/LICENSE-jquery.txt\r\n> License-File: 3rd-party-licenses/LICENSE-moment.txt\r\n> License-File: 3rd-party-licenses/LICENSE-normalize.txt\r\n> License-File: 3rd-party-licenses/LICENSE-pytest-capture-warnings.txt\r\n> License-File: 3rd-party-licenses/LICENSE-reproducible.txt\r\n> License-File: 3rd-party-licenses/LICENSES-ui.txt\r\n> License-File: LICENSE\r\n610c632\r\n< Requires-Dist: sphinx-airflow-theme>=0.0.12; extra == \'devel-ci\'\r\n---\r\n> Requires-Dist: sphinx-airflow-theme>=0.0.12,<0.1.0; extra == \'devel-ci\'\r\ndiff -r ./old/apache_airflow-2.10.4.dist-info/RECORD ./new/apache_airflow-2.10.4.dist-info/RECORD\r\n8c8\r\n< airflow/git_version,sha256=6E3ZBkweW8VFYORN0DNUo8SZM3cAFT0_U0GDmbh1IqE,49\r\n---\r\n> airflow/git_version,sha256=rEn9yIg5n9gUvutSQdG_ngYFd65U0CLp7im84nC_Myo,49\r\n14c14\r\n< airflow/providers_manager.py,sha256=YOfMooQ4scNetaIF0QjutJF8E-hUnRIazU4EGalU9G4,60758\r\n---\r\n> airflow/providers_manager.py,sha256=MvLoakmAbgmrx1uhd-6FFwgW3HCVzDHRrPeakyp4aCU,60709\r\n16c16\r\n< airflow/reproducible_build.yaml,sha256=ZRd7HP66q8TdyVowicdDmugQlzopFTwZcRCYc6m_RdY,83\r\n---\r\n> airflow/reproducible_build.yaml,sha256=x1Y9ilxTlN-x0qa3BFSKRVoTPjL9N7U5rOgykhIDjY4,83\r\n41c41\r\n< airflow/api/common/mark_tasks.py,sha256=SWbzRsKPbt7GUjz1Gcy3bbSTgSfSBjEzRMNyfdDhjlQ,21676\r\n---\r\n> airflow/api/common/mark_tasks.py,sha256=fnk9ufUA6Z8Dh-o_-CuipyD3q18wKKAg8l8Pb0UpLgA,22322\r\n85c85\r\n< airflow/api_connexion/openapi/v1.yaml,sha256=9VycODYcWWFeIxs7ORfgoUwbRHZfT63nPruAalePP0I,185018\r\n---\r\n> airflow/api_connexion/openapi/v1.yaml,sha256=jNu8ahNGZQ3Qcpy2gykobmLC2oqUb-Ks0dKt5abMv1Q,185039\r\n145c145\r\n< airflow/cli/cli_config.py,sha256=GZr5cRH2QriI6igFDDqcPFCtSVyc5MbMukSO2D1arzU,74368\r\n---\r\n> airflow/cli/cli_config.py,sha256=dgktdDrK6ZKOSYxp-7P-KveRlstElP1ffJmeIKJIRF0,74373\r\n198c198\r\n< airflow/datasets/metadata.py,sha256=yUj3_yKabKrthkRA35oQHlmQk0Of0HdELY3jpFkBWrE,1503\r\n---\r\n> airflow/datasets/metadata.py,sha256=rWgsJn1m6AGE9K1fgEUWt1CBe5gPsSa90cHyYK3S0Gk,2276\r\n282c282\r\n< airflow/executors/executor_loader.py,sha256=YrbbpCMPOdzc6cNCxWS_3CD1YlZzsmCEPI7KFBZJBKw,15858\r\n---\r\n> airflow/executors/executor_loader.py,sha256=ZjuG9Gt5kXGSu1C7wuDEChjx5baPG_j6rvt2ew6pQNA,15869\r\n497c497\r\n< airflow/models/baseoperator.py,sha256=MRHmOJYNOFFQrvRxMwSPclXEiOLhgKco6bLBSHLvXRA,84364\r\n---\r\n> airflow/models/baseoperator.py,sha256=oJTH5qcr1BsqxzbXjGyQQhT8eJeobh5iZrTlCM98k4c,84371\r\n513c513\r\n< airflow/models/mappedoperator.py,sha256=qUjnblFhnJkDDUJ6TCGVGAIRy_TvTb-b7peeylEE6TU,36299\r\n---\r\n> airflow/models/mappedoperator.py,sha256=XWQM-eLsm-NLC1yC9vcaJY0NwY-8CY72ounznSRXPbA,36419\r\n519c519\r\n< airflow/models/skipmixin.py,sha256=rg0ME6-44vZabNCroMY5NfxKVyIVOIbhbWgYgIMlIu4,11195\r\n---\r\n> airflow/models/skipmixin.py,sha256=e9mSCLo5tCJRwKr9Qhi0tdek-0hFsr3PoeIougauHnU,11303\r\n522c522\r\n< airflow/models/taskinstance.py,sha256=wS61gKGC15ybUAUaBHkgBeag3Nfoq9X14CXNAcqTfVM,164929\r\n---\r\n> airflow/models/taskinstance.py,sha256=ZanEQ7x-bTR2bs60LzYEJWgmNhdbL69wZnEv3jfUkp8,165182\r\n561c561\r\n< airflow/sensors/base.py,sha256=YjzOnEWNiPIkFpecL33Hq_B8B3SBpwxuGtpztb6vVpM,19422\r\n---\r\n> airflow/sensors/base.py,sha256=6OKk8O9P3G2eevTESzErCHqGOP8KGfGF5POM6UgudVc,19664\r\n618c618\r\n< airflow/ti_deps/deps/not_previously_skipped_dep.py,sha256=naCUyduB7LovCt8KaM2xv2cOeztzvzSOnGXZKI6nj60,3905\r\n---\r\n> airflow/ti_deps/deps/not_previously_skipped_dep.py,sha256=rczgk5AvMDX9Hmq2nKu5tLa4Zjj43xVMX-8wKz0z2wE,3853\r\n625c625\r\n< airflow/ti_deps/deps/trigger_rule_dep.py,sha256=wN_QwBATJFoJbGWxEKhWprU-VdLhmwUIE6erIFmEuRA,27306\r\n---\r\n> airflow/ti_deps/deps/trigger_rule_dep.py,sha256=4fNNN3lW86tLqvGD22B0CxPNHw33xmjAkgZInZQUcsU,28001\r\n652c652\r\n< airflow/utils/context.py,sha256=YWHQchFhHxJe5Qi8tXzdlM5c94q04c9AGAErmE2gSmo,16795\r\n---\r\n> airflow/utils/context.py,sha256=v59xFD7N1QQiV52SoPmTLkMmR1_sJhj-5fb2rZEG8Y4,16815\r\n693c693\r\n< airflow/utils/sqlalchemy.py,sha256=VSjv1HclQSsC5oajvBMVJ95hqkWVIzXvOkKoPu-H-XQ,18499\r\n---\r\n> airflow/utils/sqlalchemy.py,sha256=BvF8UWAYTe3ZdUmBouXrMZ8IRBNeaD5sDFdtEFDvDOg,18532\r\n749c749\r\n< airflow/www/views.py,sha256=psdMP4jCt7VAipAP6DdAvhkdbybUCR89ZlGc0Q-FcvM,226234\r\n---\r\n> airflow/www/views.py,sha256=3Vuikb3pvD8R_xURIqcmxNGhpZHcD_F70ILGt_dVCFk,226264\r\n752c752\r\n< airflow/www/yarn.lock,sha256=xqaLeeDPyrio6vkva3mejgYeIEYUE8fLAm5j1QrfZDY,558144\r\n---\r\n> airflow/www/yarn.lock,sha256=tre3GeiFoWlf-eBw91q3cjwG465l5TXnzcVezBlIrB4,558144\r\n801,802c801,802\r\n< airflow/www/static/dist/clusterActivity.2ecf4759427048c07368.js,sha256=Y1qL_8VihWr3X0H97W8Mye1oNa-_JmE5lCjdlpZKVMY,2998266\r\n< airflow/www/static/dist/clusterActivity.2ecf4759427048c07368.js.LICENSE.txt,sha256=8IF0e7cOf2GdyUFCB0faQVO0wWE3K69GmL9yWX_ouLw,3335\r\n---\r\n> airflow/www/static/dist/clusterActivity.fff5d3527b4c5eedb340.js,sha256=j1FzBv7oRMbZ4rYil1m1vLjo2tT6D-jYwk2r7Zi7Tn4,2998266\r\n> airflow/www/static/dist/clusterActivity.fff5d3527b4c5eedb340.js.LICENSE.txt,sha256=8IF0e7cOf2GdyUFCB0faQVO0wWE3K69GmL9yWX_ouLw,3335\r\n822,826c822,826\r\n< airflow/www/static/dist/dags.2b495ee52ff9e3b5160e.css,sha256=K0nVsWcO_k4EvzAkoH6KBbouNA6_wymJXYhMdwQSSU0,2728\r\n< airflow/www/static/dist/dags.2b495ee52ff9e3b5160e.js,sha256=INoxfCJ-XrElFrn9EuKJ9wDKWNa_F21xzCoU0JaC8oA,94990\r\n< airflow/www/static/dist/dags.2b495ee52ff9e3b5160e.js.LICENSE.txt,sha256=AXbnnahJ1YVvF7cQaDFWtahoDOz70YRel1q39jKviR8,1384\r\n< airflow/www/static/dist/datasets.9af23983e71a1ebcbd80.js,sha256=mOWNxUu98wL-ZbOzbgIWDiFDMlkaxC6HEPW-6hsPkBg,2508113\r\n< airflow/www/static/dist/datasets.9af23983e71a1ebcbd80.js.LICENSE.txt,sha256=SmF_cYmqkr47iujpTjFXSkaqdVDp9pTuQDbPN-GKUZc,4280\r\n---\r\n> airflow/www/static/dist/dags.4cb7043334f0e3173c4c.css,sha256=K0nVsWcO_k4EvzAkoH6KBbouNA6_wymJXYhMdwQSSU0,2728\r\n> airflow/www/static/dist/dags.4cb7043334f0e3173c4c.js,sha256=ocPyMPpTONv5Jm0WCW_CXt3ZwQhnSOR9131N33XLEtg,95076\r\n> airflow/www/static/dist/dags.4cb7043334f0e3173c4c.js.LICENSE.txt,sha256=AXbnnahJ1YVvF7cQaDFWtahoDOz70YRel1q39jKviR8,1384\r\n> airflow/www/static/dist/datasets.0bc892295c97e7bfe58d.js,sha256=g-qNenzwqj9S0s49SkrH9r4-4wl3HXYUxvYgiiefN-A,2508113\r\n> airflow/www/static/dist/datasets.0bc892295c97e7bfe58d.js.LICENSE.txt,sha256=SmF_cYmqkr47iujpTjFXSkaqdVDp9pTuQDbPN-GKUZc,4280\r\n831,832c831,832\r\n< airflow/www/static/dist/grid.70939cd423edfd7d6e08.js,sha256=S_M57tluGp6L_9QDNwR78XCXNss_-eD1gJ2tPGYDEb8,3967483\r\n< airflow/www/static/dist/grid.70939cd423edfd7d6e08.js.LICENSE.txt,sha256=sQtXf7GfCo89PP-yECRigR0zh4q51Ul0rglmaW4nDqs,5245\r\n---\r\n> airflow/www/static/dist/grid.9dfc288c631a1f964c7a.js,sha256=hT5Qwi8bzeMUKcuOKpdLHYVA9MUloqLficGjzpeGiwg,3967582\r\n> airflow/www/static/dist/grid.9dfc288c631a1f964c7a.js.LICENSE.txt,sha256=sQtXf7GfCo89PP-yECRigR0zh4q51Ul0rglmaW4nDqs,5245\r\n843,846c843,846\r\n< airflow/www/static/dist/main.8461584ab30f513901c2.css,sha256=oXiTMwdpRp556KBwH0NCOO_L5H4OIt5EapaujfpXqws,7304\r\n< airflow/www/static/dist/main.8461584ab30f513901c2.js,sha256=Jtgg3qTAAwOpG-EbaDVeqJL2bZIjA-uDF0ZAg4yhq_M,5366\r\n< airflow/www/static/dist/main.8461584ab30f513901c2.js.LICENSE.txt,sha256=FX9Q5lmXWsdQeuAN5eIQlag1BKUFTx3rpUftXrj5Et4,809\r\n< airflow/www/static/dist/manifest.json,sha256=PF2FtfzT9gRPoEwpqdOW_BXmTgUDGjb5vlwtVg3bljI,4419\r\n---\r\n> airflow/www/static/dist/main.fb487bd34c7cd20f02bc.css,sha256=oXiTMwdpRp556KBwH0NCOO_L5H4OIt5EapaujfpXqws,7304\r\n> airflow/www/static/dist/main.fb487bd34c7cd20f02bc.js,sha256=ZjQdt94DGbnkMxJ-EssgDrlNe3KC0SORzgagX85uoVs,5452\r\n> airflow/www/static/dist/main.fb487bd34c7cd20f02bc.js.LICENSE.txt,sha256=FX9Q5lmXWsdQeuAN5eIQlag1BKUFTx3rpUftXrj5Et4,809\r\n> airflow/www/static/dist/manifest.json,sha256=NLyXgQkYDEKMEH8xezZTiFF6w6hMmoFD0s6RBmgMarw,4419\r\n859,860c859,860\r\n< airflow/www/static/dist/taskInstances.a65435400ad9c5e928c1.js,sha256=iM6DYjtsw9vuqc28swtZSJgwn_6zigt1kSLz1j0SSm8,86420\r\n< airflow/www/static/dist/taskInstances.a65435400ad9c5e928c1.js.LICENSE.txt,sha256=AXbnnahJ1YVvF7cQaDFWtahoDOz70YRel1q39jKviR8,1384\r\n---\r\n> airflow/www/static/dist/taskInstances.7a19b383b09d370fe8a0.js,sha256=OdY9NgfXl7nVrAwvcjMlqHnXF2xMotXhiJTOP8aybUU,86506\r\n> airflow/www/static/dist/taskInstances.7a19b383b09d370fe8a0.js.LICENSE.txt,sha256=AXbnnahJ1YVvF7cQaDFWtahoDOz70YRel1q39jKviR8,1384\r\n865,866c865,866\r\n< airflow/www/static/dist/trigger.d972e04a6a32368ffc7e.js,sha256=wvnRSPCc-YLqqcq4lN6xfyC9D8LguDzxd6MDy4RGjAs,4215\r\n< airflow/www/static/dist/trigger.d972e04a6a32368ffc7e.js.LICENSE.txt,sha256=FX9Q5lmXWsdQeuAN5eIQlag1BKUFTx3rpUftXrj5Et4,809\r\n---\r\n> airflow/www/static/dist/trigger.cef24b4966646f363d5a.js,sha256=am6cJ3g7X95X5ePUM4tEkdie7fnUdHR1XCKh9Vo2HDo,4207\r\n> airflow/www/static/dist/trigger.cef24b4966646f363d5a.js.LICENSE.txt,sha256=FX9Q5lmXWsdQeuAN5eIQlag1BKUFTx3rpUftXrj5Et4,809\r\n908c908\r\n< airflow/www/static/js/main.js,sha256=Q2sJr4Hm8p0kmJXRx2yeprSb92Q0tt5TSQvTnJyWpEI,7953\r\n---\r\n> airflow/www/static/js/main.js,sha256=QhBmPQb391AItfUnuPVVv0NTZ_09AGTRH-kBsKsPInQ,8092\r\n914c914\r\n< airflow/www/static/js/trigger.js,sha256=mtoIGCTm5t5DOkrS1wYMfRhf4Sk_jlbFGlz_b2jECjQ,9730\r\n---\r\n> airflow/www/static/js/trigger.js,sha256=GPz9Me2-MpFdriQ7-BOaHhky7c4K_dBiSdcc6rumhHI,9730\r\n955c955\r\n< airflow/www/static/js/api/useTaskXcom.ts,sha256=TEhpgznfJpjsGX2mhYXwq1zbc7hNatu552-R3ijcVBE,2270\r\n---\r\n> airflow/www/static/js/api/useTaskXcom.ts,sha256=UHwS1RUmrdO4YvZFlciZhovbbn76ABfkXRYag4Gbq20,2347\r\n1055c1055\r\n< airflow/www/static/js/dag/details/taskInstance/ExtraLinks.tsx,sha256=GMha9M50_25hpOsOrIChwd2Hmy1HLhKmuvn2up3bWME,2256\r\n---\r\n> airflow/www/static/js/dag/details/taskInstance/ExtraLinks.tsx,sha256=jtmJ_8CWZjMdbHnoZ2ThHOkY_JGmPyDjuGP_kzvqMYM,2659\r\n1142c1142\r\n< airflow/www/templates/airflow/trigger.html,sha256=zM9o5RMnv-L5f6B7-Kqca_nKFVC08wo1pMb_T3fPB0Q,17073\r\n---\r\n> airflow/www/templates/airflow/trigger.html,sha256=bOntLWS6Itsx27H9NNKT4IUwxQPNih2W6aRcYYemgQE,17133\r\n1161,1162c1161,1162\r\n< apache_airflow-2.10.4.dist-info/METADATA,sha256=eu4fno5zrcRyup713uEJ0ykjC9UHcRiY1QDuFAX1ANM,43527\r\n< apache_airflow-2.10.4.dist-info/WHEEL,sha256=C2FUgwZgiLbznR-k0b_5k3Ai_1aASOXDss3lzCUsUug,87\r\n---\r\n> apache_airflow-2.10.4.dist-info/METADATA,sha256=vMGaVysA0MXf5ftvq2Qt72rDbBqm73bpDBPVGWgbc90,44764\r\n> apache_airflow-2.10.4.dist-info/WHEEL,sha256=qtCwoSJWgHk21S1Kb4ihdzI2rlJ1ZKaIurTj_ngOhyQ,87\r\ndiff -r ./old/apache_airflow-2.10.4.dist-info/WHEEL ./new/apache_airflow-2.10.4.dist-info/WHEEL\r\n2c2\r\n< Generator: hatchling 1.26.3\r\n---\r\n> Generator: hatchling 1.27.0\r\n```', 'created_at': datetime.datetime(2025, 1, 12, 11, 59, 22, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-11 19:16:57 UTC): Hey here. I know this one is huge and difficult to review, but this was the easiest way I could bring the  ""pull_request_target"" removal to `v2-10-test`  branch. 

Since we stopped cherry-picking breeze changes to `v2-10-test` and made a LOT of chenges in main (removing Python 3.8, moving providers, adding test_sdk and so on -  cherry-picking individual commits was not an option. So I choose a different path - I copuied the latest `breeze`, `ci_scripts`, `Dockerfiles` and `.pre-commits` and adapted them to`v2-10-test` - mostly removing stuff that was not needed in v2-10-test (providers, charts, new api etc. etc., adding back Python 3.8). 

All other changes were results of fixing the tests.

I think the easiest way to review it is two-fold:

1) you can compare all the breeze/ci stuff with `main` - and see the differences (mostly removals of the things above) 
2) then you can compare ""airflow"" and ""tests"" with `v2-10-test` and see that they only changed to accomodate to some tests scripts changes. 

I know I am asking a lot, but this is the easiest way we can remove last remnants of `pull_request_target"" - which is still a potential security issue.

potiuk (Issue Creator) on (2025-01-11 21:32:20 UTC): Yeah - some test failure fixes needed :(

potiuk (Issue Creator) on (2025-01-12 11:59:22 UTC): All problems solved. I also applied latest version of sphinx-theme limit and compared produced .whl files for airflow and the differences are pretty much as expected:


```diff
diff -r ./old/airflow/api/common/mark_tasks.py ./new/airflow/api/common/mark_tasks.py
413a414,417
415c419
<     if commit:
---
418,419c422
<     # Mark all task instances of the dag run to success.
<     for task in dag.tasks:
---
422c425
<         tasks=dag.tasks,
---
469,472d471
<     # Mark the dag run to failed.
<     if commit:
<         _set_dag_run_state(dag.dag_id, run_id, DagRunState.FAILED, session)
<
481c480
<     tis = session.scalars(
---
488c487
<     )
---
490c489,490
<     task_ids_of_running_tis = [task_instance.task_id for task_instance in tis]
---
492c492
<     tasks = []
---
496c496
<             tasks.append(task)
---
499c499
<     tis = session.scalars(
---
512a513,515
514c517
<         for ti in tis:
---
517,518c520,525
<     return tis + set_state(
<         tasks=tasks,
---
diff -r ./old/airflow/api_connexion/openapi/v1.yaml ./new/airflow/api_connexion/openapi/v1.yaml
5735a5736
diff -r ./old/airflow/cli/cli_config.py ./new/airflow/cli/cli_config.py
67c67
<         """"""Override error and use print_instead of print_usage.""""""
---
diff -r ./old/airflow/datasets/metadata.py ./new/airflow/datasets/metadata.py
19a20
40a42,50
45a56,63
diff -r ./old/airflow/executors/executor_loader.py ./new/airflow/executors/executor_loader.py
340c340
<         if engine.dialect.name == ""sqlite"":
---
diff -r ./old/airflow/git_version ./new/airflow/git_version
1c1
< .release:c083e456fa02c6cb32cdbe0c9ed3c3b2380beccd
\ No newline at end of file
---
\ No newline at end of file
diff -r ./old/airflow/models/baseoperator.py ./new/airflow/models/baseoperator.py
968d967
<         validate_key(task_id)
973a973,975
diff -r ./old/airflow/models/mappedoperator.py ./new/airflow/models/mappedoperator.py
832a833,834
diff -r ./old/airflow/models/skipmixin.py ./new/airflow/models/skipmixin.py
164,165d163
<         SkipMixin._set_state_to_skipped(dag_run, task_ids_list, session)
<         session.commit()
166a165,169
179a183
181d184
<         self,
diff -r ./old/airflow/models/taskinstance.py ./new/airflow/models/taskinstance.py
28a29
249c250
<         TaskInstance.save_to_db(ti=ti, session=session)
---
1243c1244
<         TaskInstance.save_to_db(failure_context[""ti""], session)
---
3093a3095
3396c3398,3402
<     def save_to_db(ti: TaskInstance | TaskInstancePydantic, session: Session = NEW_SESSION):
---
diff -r ./old/airflow/providers_manager.py ./new/airflow/providers_manager.py
534d533
<     @provider_info_cache(""hook_lineage_writers"")
diff -r ./old/airflow/reproducible_build.yaml ./new/airflow/reproducible_build.yaml
1,2c1,2
< release-notes-hash: 0867869dba7304e7ead28dd0800c5c4b
< source-date-epoch: 1733822937
---
diff -r ./old/airflow/sensors/base.py ./new/airflow/sensors/base.py
109c109,112
<             TaskReschedule.try_number == try_number,
---
256c259
<             # first execution of the task, or the first execution after the task was cleared.)
---
diff -r ./old/airflow/ti_deps/deps/not_previously_skipped_dep.py ./new/airflow/ti_deps/deps/not_previously_skipped_dep.py
21a22
41d41
<             SkipMixin,
52,55c52,54
<             if isinstance(parent, SkipMixin):
<                 if parent.task_id not in finished_task_ids:
<                     # This can happen if the parent task has not yet run.
<                     continue
---
57c56,58
<                 prev_result = ti.xcom_pull(task_ids=parent.task_id, key=XCOM_SKIPMIXIN_KEY, session=session)
---
59,61c60,61
<                 if prev_result is None:
<                     # This can happen if the parent task has not yet run.
<                     continue
---
63,75c63,65
<                 should_skip = False
<                 if (
<                     XCOM_SKIPMIXIN_FOLLOWED in prev_result
<                     and ti.task_id not in prev_result[XCOM_SKIPMIXIN_FOLLOWED]
<                 ):
<                     # Skip any tasks that are not in ""followed""
<                     should_skip = True
<                 elif (
<                     XCOM_SKIPMIXIN_SKIPPED in prev_result
<                     and ti.task_id in prev_result[XCOM_SKIPMIXIN_SKIPPED]
<                 ):
<                     # Skip any tasks that are in ""skipped""
<                     should_skip = True
---
77,92c67,84
<                 if should_skip:
<                     # If the parent SkipMixin has run, and the XCom result stored indicates this
<                     # ti should be skipped, set ti.state to SKIPPED and fail the rule so that the
<                     # ti does not execute.
<                     if dep_context.wait_for_past_depends_before_skipping:
<                         past_depends_met = ti.xcom_pull(
<                             task_ids=ti.task_id, key=PAST_DEPENDS_MET, session=session, default=False
<                         )
<                         if not past_depends_met:
<                             yield self._failing_status(
<                                 reason=(""Task should be skipped but the past depends are not met"")
<                             )
<                             return
<                     ti.set_state(TaskInstanceState.SKIPPED, session)
<                     yield self._failing_status(
<                         reason=f""Skipping because of previous XCom result from parent task {parent.task_id}""
---
94c86,95
<                     return
---
diff -r ./old/airflow/ti_deps/deps/trigger_rule_dep.py ./new/airflow/ti_deps/deps/trigger_rule_dep.py
29a30
66,67c67
<         :param ti: the ti that we want to calculate deps for
<         :param finished_tis: all the finished tasks of the dag_run
---
145a146,158
158a172,178
220c240
<                     yield (TaskInstance.task_id == upstream_id)
---
240c260
<             Evaluate whether ``ti``'s trigger rule was met.
---
242,244c262
<             :param ti: Task instance to evaluate the trigger rule of.
<             :param dep_context: The current dependency context.
<             :param session: Database session.
---
330,336c348
<             """"""
<             Evaluate whether ``ti``'s trigger rule was met.
<
<             :param ti: Task instance to evaluate the trigger rule of.
<             :param dep_context: The current dependency context.
<             :param session: Database session.
<             """"""
---
436c448
<                             reason=(""Task should be skipped but the past depends are not met"")
---
diff -r ./old/airflow/utils/context.py ./new/airflow/utils/context.py
361a362
diff -r ./old/airflow/utils/sqlalchemy.py ./new/airflow/utils/sqlalchemy.py
112a113,114
Only in ./old/airflow/www/static/dist: clusterActivity.2ecf4759427048c07368.js
Only in ./old/airflow/www/static/dist: clusterActivity.2ecf4759427048c07368.js.LICENSE.txt
Only in ./new/airflow/www/static/dist: clusterActivity.fff5d3527b4c5eedb340.js
Only in ./new/airflow/www/static/dist: clusterActivity.fff5d3527b4c5eedb340.js.LICENSE.txt
Only in ./old/airflow/www/static/dist: dags.2b495ee52ff9e3b5160e.css
Only in ./old/airflow/www/static/dist: dags.2b495ee52ff9e3b5160e.js
Only in ./old/airflow/www/static/dist: dags.2b495ee52ff9e3b5160e.js.LICENSE.txt
Only in ./new/airflow/www/static/dist: dags.4cb7043334f0e3173c4c.css
Only in ./new/airflow/www/static/dist: dags.4cb7043334f0e3173c4c.js
Only in ./new/airflow/www/static/dist: dags.4cb7043334f0e3173c4c.js.LICENSE.txt
Only in ./new/airflow/www/static/dist: datasets.0bc892295c97e7bfe58d.js
Only in ./new/airflow/www/static/dist: datasets.0bc892295c97e7bfe58d.js.LICENSE.txt
Only in ./old/airflow/www/static/dist: datasets.9af23983e71a1ebcbd80.js
Only in ./old/airflow/www/static/dist: datasets.9af23983e71a1ebcbd80.js.LICENSE.txt
Only in ./old/airflow/www/static/dist: grid.70939cd423edfd7d6e08.js
Only in ./old/airflow/www/static/dist: grid.70939cd423edfd7d6e08.js.LICENSE.txt
Only in ./new/airflow/www/static/dist: grid.9dfc288c631a1f964c7a.js
Only in ./new/airflow/www/static/dist: grid.9dfc288c631a1f964c7a.js.LICENSE.txt
Only in ./old/airflow/www/static/dist: main.8461584ab30f513901c2.css
Only in ./old/airflow/www/static/dist: main.8461584ab30f513901c2.js
Only in ./old/airflow/www/static/dist: main.8461584ab30f513901c2.js.LICENSE.txt
Only in ./new/airflow/www/static/dist: main.fb487bd34c7cd20f02bc.css
Only in ./new/airflow/www/static/dist: main.fb487bd34c7cd20f02bc.js
Only in ./new/airflow/www/static/dist: main.fb487bd34c7cd20f02bc.js.LICENSE.txt
diff -r ./old/airflow/www/static/dist/manifest.json ./new/airflow/www/static/dist/manifest.json
9,10c9,10
<   ""dags.css"": ""dags.2b495ee52ff9e3b5160e.css"",
<   ""dags.js"": ""dags.2b495ee52ff9e3b5160e.js"",
---
17,18c17,18
<   ""main.css"": ""main.8461584ab30f513901c2.css"",
<   ""main.js"": ""main.8461584ab30f513901c2.js"",
---
25c25
<   ""taskInstances.js"": ""taskInstances.a65435400ad9c5e928c1.js"",
---
28,31c28,31
<   ""grid.js"": ""grid.70939cd423edfd7d6e08.js"",
<   ""clusterActivity.js"": ""clusterActivity.2ecf4759427048c07368.js"",
<   ""datasets.js"": ""datasets.9af23983e71a1ebcbd80.js"",
<   ""trigger.js"": ""trigger.d972e04a6a32368ffc7e.js"",
---
Only in ./new/airflow/www/static/dist: taskInstances.7a19b383b09d370fe8a0.js
Only in ./new/airflow/www/static/dist: taskInstances.7a19b383b09d370fe8a0.js.LICENSE.txt
Only in ./old/airflow/www/static/dist: taskInstances.a65435400ad9c5e928c1.js
Only in ./old/airflow/www/static/dist: taskInstances.a65435400ad9c5e928c1.js.LICENSE.txt
Only in ./new/airflow/www/static/dist: trigger.cef24b4966646f363d5a.js
Only in ./new/airflow/www/static/dist: trigger.cef24b4966646f363d5a.js.LICENSE.txt
Only in ./old/airflow/www/static/dist: trigger.d972e04a6a32368ffc7e.js
Only in ./old/airflow/www/static/dist: trigger.d972e04a6a32368ffc7e.js.LICENSE.txt
diff -r ./old/airflow/www/static/js/api/useTaskXcom.ts ./new/airflow/www/static/js/api/useTaskXcom.ts
60,67c60,69
<     () =>
<       axios.get<AxiosResponse, API.XCom>(
<         getMetaValue(""task_xcom_entry_api"")
<           .replace(""_DAG_RUN_ID_"", dagRunId)
<           .replace(""_TASK_ID_"", taskId)
<           .replace(""_XCOM_KEY_"", xcomKey),
<         { params: { map_index: mapIndex, stringify: false } }
<       ),
---
diff -r ./old/airflow/www/static/js/dag/details/taskInstance/ExtraLinks.tsx ./new/airflow/www/static/js/dag/details/taskInstance/ExtraLinks.tsx
60,61c60,67
<     const urlRegex = /^(https?:)/i;
<     return urlRegex.test(url);
---
diff -r ./old/airflow/www/static/js/main.js ./new/airflow/www/static/js/main.js
288a289,292
diff -r ./old/airflow/www/static/js/trigger.js ./new/airflow/www/static/js/trigger.js
62,63d61
<       } else if (elements[i].value.length === 0) {
<         params[keyName] = null;
83a82,83
diff -r ./old/airflow/www/templates/airflow/trigger.html ./new/airflow/www/templates/airflow/trigger.html
123c123,125
<         {{- form_details.value | tojson() -}}
---
diff -r ./old/airflow/www/views.py ./new/airflow/www/views.py
5358a5359
diff -r ./old/airflow/www/yarn.lock ./new/airflow/www/yarn.lock
9021,9023c9021,9023
<   version ""3.3.7""
<   resolved ""https://registry.yarnpkg.com/nanoid/-/nanoid-3.3.7.tgz#d0c301a691bc8d54efa0a2226ccf3fe2fd656bd8""
<   integrity sha512-eSRppjcPIatRIMC1U6UngP8XFcz8MQWGQdt1MTBQ7NaAmvXDfvNxbvWV3x2y6CdEUciCSsDHDQZbhYaB8QEo2g==
---
diff -r ./old/apache_airflow-2.10.4.dist-info/METADATA ./new/apache_airflow-2.10.4.dist-info/METADATA
1c1
< Metadata-Version: 2.3
---
14c14,17
< Project-URL: Twitter, https://twitter.com/ApacheAirflow
---
17a21,39
610c632
< Requires-Dist: sphinx-airflow-theme>=0.0.12; extra == 'devel-ci'
---
diff -r ./old/apache_airflow-2.10.4.dist-info/RECORD ./new/apache_airflow-2.10.4.dist-info/RECORD
8c8
< airflow/git_version,sha256=6E3ZBkweW8VFYORN0DNUo8SZM3cAFT0_U0GDmbh1IqE,49
---
14c14
< airflow/providers_manager.py,sha256=YOfMooQ4scNetaIF0QjutJF8E-hUnRIazU4EGalU9G4,60758
---
16c16
< airflow/reproducible_build.yaml,sha256=ZRd7HP66q8TdyVowicdDmugQlzopFTwZcRCYc6m_RdY,83
---
41c41
< airflow/api/common/mark_tasks.py,sha256=SWbzRsKPbt7GUjz1Gcy3bbSTgSfSBjEzRMNyfdDhjlQ,21676
---
85c85
< airflow/api_connexion/openapi/v1.yaml,sha256=9VycODYcWWFeIxs7ORfgoUwbRHZfT63nPruAalePP0I,185018
---
145c145
< airflow/cli/cli_config.py,sha256=GZr5cRH2QriI6igFDDqcPFCtSVyc5MbMukSO2D1arzU,74368
---
198c198
< airflow/datasets/metadata.py,sha256=yUj3_yKabKrthkRA35oQHlmQk0Of0HdELY3jpFkBWrE,1503
---
282c282
< airflow/executors/executor_loader.py,sha256=YrbbpCMPOdzc6cNCxWS_3CD1YlZzsmCEPI7KFBZJBKw,15858
---
497c497
< airflow/models/baseoperator.py,sha256=MRHmOJYNOFFQrvRxMwSPclXEiOLhgKco6bLBSHLvXRA,84364
---
513c513
< airflow/models/mappedoperator.py,sha256=qUjnblFhnJkDDUJ6TCGVGAIRy_TvTb-b7peeylEE6TU,36299
---
519c519
< airflow/models/skipmixin.py,sha256=rg0ME6-44vZabNCroMY5NfxKVyIVOIbhbWgYgIMlIu4,11195
---
522c522
< airflow/models/taskinstance.py,sha256=wS61gKGC15ybUAUaBHkgBeag3Nfoq9X14CXNAcqTfVM,164929
---
561c561
< airflow/sensors/base.py,sha256=YjzOnEWNiPIkFpecL33Hq_B8B3SBpwxuGtpztb6vVpM,19422
---
618c618
< airflow/ti_deps/deps/not_previously_skipped_dep.py,sha256=naCUyduB7LovCt8KaM2xv2cOeztzvzSOnGXZKI6nj60,3905
---
625c625
< airflow/ti_deps/deps/trigger_rule_dep.py,sha256=wN_QwBATJFoJbGWxEKhWprU-VdLhmwUIE6erIFmEuRA,27306
---
652c652
< airflow/utils/context.py,sha256=YWHQchFhHxJe5Qi8tXzdlM5c94q04c9AGAErmE2gSmo,16795
---
693c693
< airflow/utils/sqlalchemy.py,sha256=VSjv1HclQSsC5oajvBMVJ95hqkWVIzXvOkKoPu-H-XQ,18499
---
749c749
< airflow/www/views.py,sha256=psdMP4jCt7VAipAP6DdAvhkdbybUCR89ZlGc0Q-FcvM,226234
---
752c752
< airflow/www/yarn.lock,sha256=xqaLeeDPyrio6vkva3mejgYeIEYUE8fLAm5j1QrfZDY,558144
---
801,802c801,802
< airflow/www/static/dist/clusterActivity.2ecf4759427048c07368.js,sha256=Y1qL_8VihWr3X0H97W8Mye1oNa-_JmE5lCjdlpZKVMY,2998266
< airflow/www/static/dist/clusterActivity.2ecf4759427048c07368.js.LICENSE.txt,sha256=8IF0e7cOf2GdyUFCB0faQVO0wWE3K69GmL9yWX_ouLw,3335
---
822,826c822,826
< airflow/www/static/dist/dags.2b495ee52ff9e3b5160e.css,sha256=K0nVsWcO_k4EvzAkoH6KBbouNA6_wymJXYhMdwQSSU0,2728
< airflow/www/static/dist/dags.2b495ee52ff9e3b5160e.js,sha256=INoxfCJ-XrElFrn9EuKJ9wDKWNa_F21xzCoU0JaC8oA,94990
< airflow/www/static/dist/dags.2b495ee52ff9e3b5160e.js.LICENSE.txt,sha256=AXbnnahJ1YVvF7cQaDFWtahoDOz70YRel1q39jKviR8,1384
< airflow/www/static/dist/datasets.9af23983e71a1ebcbd80.js,sha256=mOWNxUu98wL-ZbOzbgIWDiFDMlkaxC6HEPW-6hsPkBg,2508113
< airflow/www/static/dist/datasets.9af23983e71a1ebcbd80.js.LICENSE.txt,sha256=SmF_cYmqkr47iujpTjFXSkaqdVDp9pTuQDbPN-GKUZc,4280
---
831,832c831,832
< airflow/www/static/dist/grid.70939cd423edfd7d6e08.js,sha256=S_M57tluGp6L_9QDNwR78XCXNss_-eD1gJ2tPGYDEb8,3967483
< airflow/www/static/dist/grid.70939cd423edfd7d6e08.js.LICENSE.txt,sha256=sQtXf7GfCo89PP-yECRigR0zh4q51Ul0rglmaW4nDqs,5245
---
843,846c843,846
< airflow/www/static/dist/main.8461584ab30f513901c2.css,sha256=oXiTMwdpRp556KBwH0NCOO_L5H4OIt5EapaujfpXqws,7304
< airflow/www/static/dist/main.8461584ab30f513901c2.js,sha256=Jtgg3qTAAwOpG-EbaDVeqJL2bZIjA-uDF0ZAg4yhq_M,5366
< airflow/www/static/dist/main.8461584ab30f513901c2.js.LICENSE.txt,sha256=FX9Q5lmXWsdQeuAN5eIQlag1BKUFTx3rpUftXrj5Et4,809
< airflow/www/static/dist/manifest.json,sha256=PF2FtfzT9gRPoEwpqdOW_BXmTgUDGjb5vlwtVg3bljI,4419
---
859,860c859,860
< airflow/www/static/dist/taskInstances.a65435400ad9c5e928c1.js,sha256=iM6DYjtsw9vuqc28swtZSJgwn_6zigt1kSLz1j0SSm8,86420
< airflow/www/static/dist/taskInstances.a65435400ad9c5e928c1.js.LICENSE.txt,sha256=AXbnnahJ1YVvF7cQaDFWtahoDOz70YRel1q39jKviR8,1384
---
865,866c865,866
< airflow/www/static/dist/trigger.d972e04a6a32368ffc7e.js,sha256=wvnRSPCc-YLqqcq4lN6xfyC9D8LguDzxd6MDy4RGjAs,4215
< airflow/www/static/dist/trigger.d972e04a6a32368ffc7e.js.LICENSE.txt,sha256=FX9Q5lmXWsdQeuAN5eIQlag1BKUFTx3rpUftXrj5Et4,809
---
908c908
< airflow/www/static/js/main.js,sha256=Q2sJr4Hm8p0kmJXRx2yeprSb92Q0tt5TSQvTnJyWpEI,7953
---
914c914
< airflow/www/static/js/trigger.js,sha256=mtoIGCTm5t5DOkrS1wYMfRhf4Sk_jlbFGlz_b2jECjQ,9730
---
955c955
< airflow/www/static/js/api/useTaskXcom.ts,sha256=TEhpgznfJpjsGX2mhYXwq1zbc7hNatu552-R3ijcVBE,2270
---
1055c1055
< airflow/www/static/js/dag/details/taskInstance/ExtraLinks.tsx,sha256=GMha9M50_25hpOsOrIChwd2Hmy1HLhKmuvn2up3bWME,2256
---
1142c1142
< airflow/www/templates/airflow/trigger.html,sha256=zM9o5RMnv-L5f6B7-Kqca_nKFVC08wo1pMb_T3fPB0Q,17073
---
1161,1162c1161,1162
< apache_airflow-2.10.4.dist-info/METADATA,sha256=eu4fno5zrcRyup713uEJ0ykjC9UHcRiY1QDuFAX1ANM,43527
< apache_airflow-2.10.4.dist-info/WHEEL,sha256=C2FUgwZgiLbznR-k0b_5k3Ai_1aASOXDss3lzCUsUug,87
---
diff -r ./old/apache_airflow-2.10.4.dist-info/WHEEL ./new/apache_airflow-2.10.4.dist-info/WHEEL
2c2
< Generator: hatchling 1.26.3
---
```

"
2778702165,pull_request,closed,,"Revert ""Fix fetch_access_token_for_cluster in EKS hook""","Revert #45469 and #45520.

#45469 introduced a bug. All EKS system tests are failing because of that bug. I tried to fix it as part of #45520 but no luck, even though it is working on my laptop. Reverting for now to avoid regressions in the Amazon provider package.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-09 20:31:28+00:00,[],2025-01-10 23:42:25+00:00,2025-01-09 22:09:48+00:00,https://github.com/apache/airflow/pull/45526,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2778547351,pull_request,closed,,AIP-72: Add tests for `xcom_pull`,"This test was missed and will help https://github.com/apache/airflow/pull/45509

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-09 18:52:13+00:00,[],2025-01-09 19:29:19+00:00,2025-01-09 19:29:17+00:00,https://github.com/apache/airflow/pull/45523,"[('area:task-sdk', None)]",[],
2778356953,pull_request,closed,,Move `list_py_file_paths` test to the right file,,jedcunningham,2025-01-09 17:13:28+00:00,[],2025-01-09 21:15:00+00:00,2025-01-09 21:14:59+00:00,https://github.com/apache/airflow/pull/45521,"[('area:Scheduler', 'including HA (high availability) scheduler')]",[],
2778287988,pull_request,closed,,Fix the way to get STS endpoint in EKS hook,"#45469 introduced a bug and made [EKS system test executions](https://aws-mwaa.github.io/#/open-source/system-tests/dashboard.html) fail. The way to get the STS Boto3 client was wrong, instead we should use the hook in order to do that.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-09 16:38:49+00:00,[],2025-01-09 18:20:15+00:00,2025-01-09 18:20:13+00:00,https://github.com/apache/airflow/pull/45520,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]",[],
2778233469,pull_request,closed,,AIP-38 Fix TaskInstance Icon Warnings,"Fix warnings for unknown props

![Screenshot 2025-01-09 at 17 10 52](https://github.com/user-attachments/assets/7727102f-2b4e-4f5f-9a57-c0a49982dba9)
",pierrejeambrun,2025-01-09 16:11:06+00:00,['pierrejeambrun'],2025-01-09 20:33:41+00:00,2025-01-09 20:33:39+00:00,https://github.com/apache/airflow/pull/45518,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]",[],
2778078898,pull_request,closed,,AIP-72: Move non-user facing code to `_internal`,"Anything within `_internal` module is not a user-facing code, this makes it clearer! It won't be covered by Semantic versioning and can have breaking changes even in patch versions. A user should never use anything in `airflow/sdk/definitions/_internal`.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-09 15:05:34+00:00,[],2025-01-09 16:03:53+00:00,2025-01-09 16:03:50+00:00,https://github.com/apache/airflow/pull/45515,"[('area:providers', ''), ('area:dev-tools', ''), ('area:serialization', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:standard', ''), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2778038052,pull_request,closed,,AIP-84 Clear Task Instance improve response,"Update the response for the `clearTaskInstances` endpoint to return a more complete information regarding the task instances.

Today:
&nbsp;&nbsp; Only returns a list of: `task_id, dag_run_id, dag_id` objects.

Now:
&nbsp;&nbsp; Returns a list of standard `TaskInstanceResponse` serialized representation of a task instance. This will be useful to know the state, dates and additional information of cleared task insta
nces. Especially to be able to display that in the front-end when running the `dry-run` mode.

> Note: The old response is still fully contained in the new one. That's not a breaking change.

Legacy UI were using a custom private endpoints, therefore had more information available to display:
![Screenshot 2025-01-09 at 15 51 05](https://github.com/user-attachments/assets/7d01156c-0a6e-457d-a691-ae11b086bd00)",pierrejeambrun,2025-01-09 14:48:26+00:00,['pierrejeambrun'],2025-01-10 10:48:25+00:00,2025-01-10 10:48:23+00:00,https://github.com/apache/airflow/pull/45514,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2778002593,pull_request,closed,,Fixed retry of PowerBIDatasetRefreshOperator when dataset refresh wasn't directly available,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

Fixes: https://github.com/apache/airflow/issues/44618

## Changes

This PR adds 2 changes:
- a retry mechanism on the API request to get the refresh status, to fix the bug when the API is not yet up-to-date with the triggered `refreshId`
- a new separation between the refresh trigger and the status polling

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Ohashiro,2025-01-09 14:33:27+00:00,[],2025-01-27 12:38:43+00:00,2025-01-26 17:42:43+00:00,https://github.com/apache/airflow/pull/45513,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2582096167, 'issue_id': 2778002593, 'author': 'dabla', 'body': '@Ohashiro really nice work here well done!', 'created_at': datetime.datetime(2025, 1, 10, 8, 55, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589433454, 'issue_id': 2778002593, 'author': 'dabla', 'body': '@Ohashiro If you have time to apply changes from comments, then I think you could remove the draft en we merge this PR.', 'created_at': datetime.datetime(2025, 1, 14, 9, 34, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589558396, 'issue_id': 2778002593, 'author': 'Ohashiro', 'body': 'Thanks for all your feedbacks and your review!\r\nBefore merging, I just wanted to test the behavior of the `xcom_push` for the key `powerbi_dataset_refresh_status`. I think that we push this message only when the refresh is successful but I think that we should also push when the refresh fails', 'created_at': datetime.datetime(2025, 1, 14, 10, 33, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589566742, 'issue_id': 2778002593, 'author': 'dabla', 'body': ""> Thanks for all your feedbacks and your review! Before merging, I just wanted to test the behavior of the `xcom_push` for the key `powerbi_dataset_refresh_status`. I think that we push this message only when the refresh is successful but I think that we should also push when the refresh fails\r\n\r\nThen it's more safe to put it back to draft, and set it back to ready once you've done the testing."", 'created_at': datetime.datetime(2025, 1, 14, 10, 37, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2589674130, 'issue_id': 2778002593, 'author': 'Ohashiro', 'body': 'Hi @dabla I made a quick change to push the `powerbi_dataset_refresh_status` even when the refresh fails. Should I let you review this commit before setting the PR as ""Ready for review""?', 'created_at': datetime.datetime(2025, 1, 14, 11, 30, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593731579, 'issue_id': 2778002593, 'author': 'dabla', 'body': '@Ohashiro do not forget to remove the draft option', 'created_at': datetime.datetime(2025, 1, 15, 19, 6, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593737831, 'issue_id': 2778002593, 'author': 'Ohashiro', 'body': 'Sorry, where is the ""draft option""? I thought it was ""ready"" as is', 'created_at': datetime.datetime(2025, 1, 15, 19, 10, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593747382, 'issue_id': 2778002593, 'author': 'dabla', 'body': '> Sorry, where is the ""draft option""? I thought it was ""ready"" as is\r\n\r\nIt should be somewhere at the bottom, I cannot see it unfortunately.  It\'s indeed the ""Ready for review"" button at bottom, now your PR is still marked as ""Draft"".', 'created_at': datetime.datetime(2025, 1, 15, 19, 16, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593756508, 'issue_id': 2778002593, 'author': 'Ohashiro', 'body': 'I don\'t know, there might be a bug somewhere, I clicked on the ""Ready for review"" button a few hours ago and the PR appears ""Open"" to me.\r\n\r\nI rebased main to see if it refreshes something and solves the display issue', 'created_at': datetime.datetime(2025, 1, 15, 19, 21, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593774556, 'issue_id': 2778002593, 'author': 'dabla', 'body': '> I don\'t know, there might be a bug somewhere, I clicked on the ""Ready for review"" button a few hours ago and the PR appears ""Open"" to me.\r\n> \r\n> I rebased main to see if it refreshes something and solves the display issue\r\n\r\nNow it\'s fine.\r\n\r\n@potiuk or @eladkal I\'ve just reviewed this PR, if approved by you guys could it be merged when you have time as this fixes an issue with the PowerBIDatasetRefreshOperator.', 'created_at': datetime.datetime(2025, 1, 15, 19, 32, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593776941, 'issue_id': 2778002593, 'author': 'dabla', 'body': '@Ohashiro Could you rename the title of the PR into something like:\r\n\r\n""Fixed retry of PowerBIDatasetRefreshOperator when dataset refresh wasn\'t directly available""', 'created_at': datetime.datetime(2025, 1, 15, 19, 33, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613040940, 'issue_id': 2778002593, 'author': 'Ohashiro', 'body': ""Hi @dabla ! Do you know if there's something missing on this PR?"", 'created_at': datetime.datetime(2025, 1, 24, 17, 25, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2613227164, 'issue_id': 2778002593, 'author': 'dabla', 'body': ""> Hi @dabla ! Do you know if there's something missing on this PR?\r\n\r\nNo I just think they are being busy working on Airflow 3. Could @potiuk or @eladkal look to merge this please, it’s a bugfix which I already reviewed."", 'created_at': datetime.datetime(2025, 1, 24, 19, 21, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614523483, 'issue_id': 2778002593, 'author': 'Ohashiro', 'body': 'OK I understand, thank you very much!', 'created_at': datetime.datetime(2025, 1, 26, 17, 46, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614544747, 'issue_id': 2778002593, 'author': 'dabla', 'body': '> OK I understand, thank you very much!\r\n\r\nThank you @Ohashiro for fixing this issue.', 'created_at': datetime.datetime(2025, 1, 26, 18, 46, 2, tzinfo=datetime.timezone.utc)}]","dabla on (2025-01-10 08:55:55 UTC): @Ohashiro really nice work here well done!

dabla on (2025-01-14 09:34:17 UTC): @Ohashiro If you have time to apply changes from comments, then I think you could remove the draft en we merge this PR.

Ohashiro (Issue Creator) on (2025-01-14 10:33:10 UTC): Thanks for all your feedbacks and your review!
Before merging, I just wanted to test the behavior of the `xcom_push` for the key `powerbi_dataset_refresh_status`. I think that we push this message only when the refresh is successful but I think that we should also push when the refresh fails

dabla on (2025-01-14 10:37:18 UTC): Then it's more safe to put it back to draft, and set it back to ready once you've done the testing.

Ohashiro (Issue Creator) on (2025-01-14 11:30:51 UTC): Hi @dabla I made a quick change to push the `powerbi_dataset_refresh_status` even when the refresh fails. Should I let you review this commit before setting the PR as ""Ready for review""?

dabla on (2025-01-15 19:06:31 UTC): @Ohashiro do not forget to remove the draft option

Ohashiro (Issue Creator) on (2025-01-15 19:10:14 UTC): Sorry, where is the ""draft option""? I thought it was ""ready"" as is

dabla on (2025-01-15 19:16:14 UTC): It should be somewhere at the bottom, I cannot see it unfortunately.  It's indeed the ""Ready for review"" button at bottom, now your PR is still marked as ""Draft"".

Ohashiro (Issue Creator) on (2025-01-15 19:21:37 UTC): I don't know, there might be a bug somewhere, I clicked on the ""Ready for review"" button a few hours ago and the PR appears ""Open"" to me.

I rebased main to see if it refreshes something and solves the display issue

dabla on (2025-01-15 19:32:04 UTC): Now it's fine.

@potiuk or @eladkal I've just reviewed this PR, if approved by you guys could it be merged when you have time as this fixes an issue with the PowerBIDatasetRefreshOperator.

dabla on (2025-01-15 19:33:30 UTC): @Ohashiro Could you rename the title of the PR into something like:

""Fixed retry of PowerBIDatasetRefreshOperator when dataset refresh wasn't directly available""

Ohashiro (Issue Creator) on (2025-01-24 17:25:43 UTC): Hi @dabla ! Do you know if there's something missing on this PR?

dabla on (2025-01-24 19:21:46 UTC): No I just think they are being busy working on Airflow 3. Could @potiuk or @eladkal look to merge this please, it’s a bugfix which I already reviewed.

Ohashiro (Issue Creator) on (2025-01-26 17:46:34 UTC): OK I understand, thank you very much!

dabla on (2025-01-26 18:46:02 UTC): Thank you @Ohashiro for fixing this issue.

"
2777714615,pull_request,closed,,AIP-72: Use `create_runtime_ti` fixture more widely,"I had added `create_runtime_ti` in https://github.com/apache/airflow/pull/45486, this PR modifies the fixture a little bit and uses it more broadly.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-09 12:34:39+00:00,[],2025-01-09 12:58:48+00:00,2025-01-09 12:58:46+00:00,https://github.com/apache/airflow/pull/45510,"[('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('area:task-sdk', None)]",[],
2777682695,pull_request,closed,,AIP-72: Supporting Pulling multiple XCOM values,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/45243

We can just handle xcoms for multiple task ids in the client directly by reusing the same task runner machinery.

DAG:
```
from airflow import DAG
from airflow.providers.standard.operators.python import PythonOperator

def push_to_xcom(**kwargs):
    value = ""Hello, XCom!""
    return value

def push_to_xcom2(**kwargs):
    value = ""Hello, XCom2!""
    return value

def pull_from_xcom(**kwargs):
    ti = kwargs['ti']
    xcom_value = ti.xcom_pull(task_ids=[""push_xcom_task"", ""push_xcom_task2""])
    print(f""Retrieved XCom Value: {xcom_value}"")


with DAG(
    'xcom_example',
    schedule=None,
    catchup=False,
) as dag:

    push_xcom_task = PythonOperator(
        task_id='push_xcom_task',
        python_callable=push_to_xcom,
    )

    push_xcom_task2 = PythonOperator(
        task_id='push_xcom_task2',
        python_callable=push_to_xcom2,
    )

    pull_xcom_task = PythonOperator(
        task_id='pull_xcom_task',
        python_callable=pull_from_xcom,
    )

    push_xcom_task >> push_xcom_task2 >> pull_xcom_task

```

Task1:
![image](https://github.com/user-attachments/assets/04b38cdd-fe9f-4995-9aac-6eb472a94ec1)

Task2:
![image](https://github.com/user-attachments/assets/c2809825-fba7-4169-9438-27b2bc4a68e3)

Task3: (gets xcoms pushed by 1 and 2)
![image](https://github.com/user-attachments/assets/a5166296-0fba-41ac-8205-5e7891949195)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-09 12:21:48+00:00,[],2025-01-20 06:36:37+00:00,2025-01-10 12:57:34+00:00,https://github.com/apache/airflow/pull/45509,"[('area:task-sdk', None)]","[{'comment_id': 2580025762, 'issue_id': 2777682695, 'author': 'amoghrajesh', 'body': 'Not too sure where to add the tests for this.', 'created_at': datetime.datetime(2025, 1, 9, 12, 22, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582654789, 'issue_id': 2777682695, 'author': 'kaxil', 'body': '@amoghrajesh I merged this to tick off items :) -- but feel free to change anything in follow-up', 'created_at': datetime.datetime(2025, 1, 10, 12, 58, 43, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2025-01-09 12:22:34 UTC): Not too sure where to add the tests for this.

kaxil on (2025-01-10 12:58:43 UTC): @amoghrajesh I merged this to tick off items :) -- but feel free to change anything in follow-up

"
2777567232,pull_request,closed,,AIP-38 Fix log width,"Small PR to fix the log width:
## Before
![Screenshot 2025-01-09 at 12 30 00](https://github.com/user-attachments/assets/1cd790f4-c7bc-4ae4-8d5b-8114f7d19691)

## After
![Screenshot 2025-01-09 at 12 29 45](https://github.com/user-attachments/assets/b9ec0909-78b4-4edc-9c20-ee75648f92d4)
",pierrejeambrun,2025-01-09 11:30:22+00:00,['pierrejeambrun'],2025-01-09 14:21:07+00:00,2025-01-09 14:21:04+00:00,https://github.com/apache/airflow/pull/45508,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]",[],
2777535322,pull_request,closed,,Update `dags reserialize` command to work with DAG bundle,"This PR also changed the `--subdir` arg to --bundle-name.

Closes: https://github.com/apache/airflow/issues/45336",ephraimbuddy,2025-01-09 11:15:18+00:00,['ephraimbuddy'],2025-01-16 20:19:38+00:00,2025-01-14 12:28:18+00:00,https://github.com/apache/airflow/pull/45507,"[('area:CLI', ''), ('AIP-66: DAG Bundle/Manifest', '')]",[],
2777405694,pull_request,closed,,AIP-72: Handle clearing of XComs when task starts execution,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


closes: https://github.com/apache/airflow/issues/45419

XComs have to be cleared when a task starts execution. We are handling this in the `run` endpoint as this endpoint marks ""execution"" for a task instance.

Few points:
- Do not clear XComs for cases when ""next_method"" is set - for deferrable and reschedule tasks
- Clear Xcoms for other regular tasks
- Ported unit tests from `test_taskinstance.py` - only `test_xcom_pull_different_logical_date` is pending.


### Testing

#### Normal DAG
Steps:
1. Create a normal DAG like this that doesn't push an xcom
```
from airflow import DAG
from airflow.providers.standard.operators.bash import BashOperator
from datetime import datetime, timedelta

dag = DAG(
    'hello_world_dag',
    schedule=None,
    catchup=False,
)

hello_task = BashOperator(
    task_id='say_hello',
    bash_command='echo ""Hello World from Airflow!""',
    dag=dag,
    do_xcom_push=False
)

hello_task
```

2. Directly hit the API in fast api to set an xcom for the task instance to stage an older Xcom being present
![image](https://github.com/user-attachments/assets/dc4499d0-d105-43fc-8047-23180cdafc28)

<img width=""1233"" alt=""image"" src=""https://github.com/user-attachments/assets/09cd72a5-f77e-40de-b8de-4d102d11f344"" />


3. Run the dag again, the xcom will get cleared
<img width=""1233"" alt=""image"" src=""https://github.com/user-attachments/assets/fa2d3690-b1e4-43f9-ab2e-65e3abf00068"" />



#### DAG with a deferred Task

DAG:
```
from datetime import datetime, timedelta
from airflow import DAG
from airflow.models import BaseOperator
from airflow.providers.standard.triggers.temporal import TimeDeltaTrigger


class XComPushDeferOperator(BaseOperator):
    def execute(self, context):
        context[""ti""].xcom_push(""test"", ""test_value"")

        self.defer(
            trigger=TimeDeltaTrigger(delta=timedelta(seconds=10)),
            method_name=""next"",
        )

    def next(self, context, event=None):
        pass


with DAG(
    ""xcom_clear"", schedule=None, start_date=datetime(2025, 1, 8),
) as dag:
    XComPushDeferOperator(task_id=""xcom_push"")

``` (ref from https://github.com/apache/airflow/issues/22931)

Steps:
1. Run the dag:
<img width=""1725"" alt=""image"" src=""https://github.com/user-attachments/assets/4f6932c0-2df5-412a-a091-9594094684ae"" />

2. XComs aren't cleared, still present
<img width=""1725"" alt=""image"" src=""https://github.com/user-attachments/assets/c4b741a2-6356-4fae-888b-eb65d6dc0a80"" />

3. Triggers running
![image](https://github.com/user-attachments/assets/50f3fd7e-2a31-43f0-9571-c6bca5b497d7)




<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-09 10:17:30+00:00,[],2025-01-09 11:08:04+00:00,2025-01-09 11:08:02+00:00,https://github.com/apache/airflow/pull/45506,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK')]",[],
2777400286,pull_request,closed,,AIP-72: Remove redundant handling of `AirflowException`,"This is already handled in the code below:
https://github.com/apache/airflow/blob/9de80ab8f76798e0d3daedf6565832bc36650961/task_sdk/src/airflow/sdk/execution_time/task_runner.py#L485-L492

So it will never reach

https://github.com/apache/airflow/blob/9de80ab8f76798e0d3daedf6565832bc36650961/task_sdk/src/airflow/sdk/execution_time/task_runner.py#L493-L499

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-09 10:14:54+00:00,[],2025-01-09 10:30:19+00:00,2025-01-09 10:30:17+00:00,https://github.com/apache/airflow/pull/45505,"[('area:task-sdk', None)]",[],
2777026933,pull_request,closed,,AIP-72: Add logging for exception in Task Runner,"Currently, when a task fails there are no log which makes it very difficult to debug.

**Before**:

<img width=""1723"" alt=""image"" src=""https://github.com/user-attachments/assets/71f81767-ec1b-410f-a78a-d27a8a3bd5cf"" />


```json
{""file"":""/files/dags/get_context.py"",""timestamp"":""2025-01-09T07:17:10.066994"",""logger"":""task"",""event"":""DAG file parsed"",""level"":""debug""}
{""json"":""{\""rendered_fields\"":{\""templates_dict\"":null,\""op_args\"":\""()\"",\""op_kwargs\"":{}},\""type\"":\""SetRenderedFields\""}\n"",""timestamp"":""2025-01-09T07:17:10.067242"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""json"":""{\""state\"":\""failed\"",\""end_date\"":\""2025-01-09T07:17:10.071585Z\"",\""type\"":\""TaskState\""}\n"",""timestamp"":""2025-01-09T07:17:10.071638"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
```

**After**:

<img width=""1704"" alt=""image"" src=""https://github.com/user-attachments/assets/204cf49e-c2db-4cb8-8ac3-9663e6c4223f"" />


```json
{""file"":""/files/dags/get_context.py"",""timestamp"":""2025-01-09T07:17:10.066994"",""logger"":""task"",""event"":""DAG file parsed"",""level"":""debug""}
{""json"":""{\""rendered_fields\"":{\""templates_dict\"":null,\""op_args\"":\""()\"",\""op_kwargs\"":{}},\""type\"":\""SetRenderedFields\""}\n"",""timestamp"":""2025-01-09T07:17:10.067242"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""timestamp"":""2025-01-09T07:17:10.071412"",""logger"":""task"",""error_detail"":[{""exc_type"":""AirflowException"",""exc_value"":""Current context was requested but no context was found! Are you running within an airflow task?"",""syntax_error"":null,""is_cause"":false,""frames"":[{""filename"":""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/task_runner.py"",""lineno"":457,""name"":""run""},{""filename"":""/opt/airflow/airflow/models/baseoperator.py"",""lineno"":376,""name"":""wrapper""},{""filename"":""/opt/airflow/airflow/decorators/base.py"",""lineno"":261,""name"":""execute""},{""filename"":""/opt/airflow/airflow/models/baseoperator.py"",""lineno"":376,""name"":""wrapper""},{""filename"":""/opt/airflow/providers/src/airflow/providers/standard/operators/python.py"",""lineno"":196,""name"":""execute""},{""filename"":""/opt/airflow/providers/src/airflow/providers/standard/operators/python.py"",""lineno"":222,""name"":""execute_callable""},{""filename"":""/opt/airflow/airflow/utils/operator_helpers.py"",""lineno"":269,""name"":""run""},{""filename"":""/files/dags/get_context.py"",""lineno"":16,""name"":""template_test""},{""filename"":""/opt/airflow/providers/src/airflow/providers/standard/operators/python.py"",""lineno"":1153,""name"":""get_current_context""}]}],""event"":""Task failed with exception"",""level"":""error""}
{""json"":""{\""state\"":\""failed\"",\""end_date\"":\""2025-01-09T07:17:10.071585Z\"",\""type\"":\""TaskState\""}\n"",""timestamp"":""2025-01-09T07:17:10.071638"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
```

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-09 07:23:51+00:00,[],2025-01-09 07:58:38+00:00,2025-01-09 07:58:36+00:00,https://github.com/apache/airflow/pull/45502,"[('area:task-sdk', None)]",[],
2776945988,pull_request,closed,,Don't display table/card header and pagination when no rows are present.,"If there are no rows to display the current table component displays the header and pagination with no rows message in between. The header and pagination can be hidden when there are no rows.

main

![image](https://github.com/user-attachments/assets/4e23c0bd-eecd-4885-a9c0-3dd75e7614e9)

After PR

![image](https://github.com/user-attachments/assets/b26ee134-3907-4f4d-b82d-057c127d0307)

",tirkarthi,2025-01-09 06:34:34+00:00,[],2025-01-10 15:41:27+00:00,2025-01-10 15:41:27+00:00,https://github.com/apache/airflow/pull/45501,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2776919453,pull_request,closed,,Use setSearchParams after setTableURLState to ensure updates are not overriden by setTableURLState.,"Ref : https://github.com/apache/airflow/pull/45095#issuecomment-2561957593

It seems `setTableURLState` also uses `setSearchParams` and the updates to `setSearchParams` before `setTableURLState` get overridden inside the `setTableURLState` call. This looks similar to a reported issue where multiple calls to `setSearchParams` seem to be not safe  https://github.com/remix-run/react-router/issues/9757 .",tirkarthi,2025-01-09 06:13:36+00:00,[],2025-01-09 16:46:28+00:00,2025-01-09 16:46:27+00:00,https://github.com/apache/airflow/pull/45500,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2579261739, 'issue_id': 2776919453, 'author': 'Mizokuiam', 'body': ""Thank you for raising this issue! I'll look into it and try to help if I can."", 'created_at': datetime.datetime(2025, 1, 9, 6, 20, 5, tzinfo=datetime.timezone.utc)}]","Mizokuiam on (2025-01-09 06:20:05 UTC): Thank you for raising this issue! I'll look into it and try to help if I can.

"
2776412530,pull_request,closed,,Remove marshmallow version restriction; update deprecated usages,"This reverts #45442, since [marshmallow 3.24.2](https://github.com/marshmallow-code/marshmallow/blob/dev/CHANGELOG.rst#3242-2025-01-08) obviates it. As of 3.24.2, marshmallow can be upgraded without upgrading marshmallow-sqlalchemy (need to wait until https://github.com/dpgaspar/Flask-AppBuilder/pull/2298 is merged and released for that).

This also updates deprecated field usages to avoid warnings and future-proof for marshmallow 4.",sloria,2025-01-08 21:48:20+00:00,[],2025-01-09 17:03:02+00:00,2025-01-09 00:27:23+00:00,https://github.com/apache/airflow/pull/45499,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2578731781, 'issue_id': 2776412530, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 8, 21, 48, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578943574, 'issue_id': 2776412530, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 9, 0, 27, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578943696, 'issue_id': 2776412530, 'author': 'potiuk', 'body': 'Nice. All was green !', 'created_at': datetime.datetime(2025, 1, 9, 0, 27, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578944015, 'issue_id': 2776412530, 'author': 'potiuk', 'body': 'Thanks a lot for that one @sloria !', 'created_at': datetime.datetime(2025, 1, 9, 0, 27, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2580828299, 'issue_id': 2776412530, 'author': 'gopidesupavan', 'body': '@sloria thats awesome , thank you so much for making changes. :)', 'created_at': datetime.datetime(2025, 1, 9, 17, 2, 59, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-08 21:48:25 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2025-01-09 00:27:26 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

potiuk on (2025-01-09 00:27:32 UTC): Nice. All was green !

potiuk on (2025-01-09 00:27:52 UTC): Thanks a lot for that one @sloria !

gopidesupavan on (2025-01-09 17:02:59 UTC): @sloria thats awesome , thank you so much for making changes. :)

"
2776275119,pull_request,closed,,Add Grid View to new UI,"Add an initial Grid View to the new UI.

Features:
- expand and collapse task groups
- expand and collapse all task groups (including in graph view)
- basic title to show run_id/task_name and state
- Click on a dag run, task name, or task instance to select
- hover on a dag run, task name or task instance to see your position
- All clickable areas are keyboard accessible
- duration and date axes for the dag run bar graph
- paginate dag runs by increments of 10 even though the limit is 25. I'm open to change this.

Not included:
- Full tooltips. There is an issue with Chakra v3 that tooltips in particular are much slower and so a large grid view would grind to a halt: https://github.com/chakra-ui/chakra-ui/discussions/9488
- Accessible state colors. Will be another PR
- AutoRefresh and detecting new dag runs
- Detecting selected dag run from the url and shifting the grid base date to match
- Filtering by run state or type
- Hovering to highlight different task states
- Task name search

<img width=""1100"" alt=""Screenshot 2025-01-23 at 1 58 13 PM"" src=""https://github.com/user-attachments/assets/dcb22939-970a-4135-8ab2-fb32e2c2f634"" />
<img width=""1101"" alt=""Screenshot 2025-01-23 at 1 58 23 PM"" src=""https://github.com/user-attachments/assets/7314dbc1-3f87-4979-a079-4a5ebeb7c568"" />


I think there's still too many magic numbers to make the layout work. Which I'm happy to work on as well as performance once we confirm that we want to use the grid view in this full page modal.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2025-01-08 20:24:53+00:00,[],2025-01-27 12:48:55+00:00,2025-01-25 16:03:07+00:00,https://github.com/apache/airflow/pull/45497,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2610835193, 'issue_id': 2776275119, 'author': 'jscheffl', 'body': 'Did a small ""smoke test"" - if you select a mapped task and close the grid, the selected task navigation throws an error:\r\n![image](https://github.com/user-attachments/assets/dde3a00b-57b6-40f6-a021-49cd7adb3941)', 'created_at': datetime.datetime(2025, 1, 23, 19, 24, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610845678, 'issue_id': 2776275119, 'author': 'jscheffl', 'body': 'Also second had ""strange"" results in the example task group, when I selected tasks in a group my browser (Firefox, Ubuntu 24.04 LTS) was sorting the runs and selecting the first execution if I clicked on the task of second/third run:\r\n![image](https://github.com/user-attachments/assets/412ada86-fb8e-4734-9ac7-6f87068a5c01)', 'created_at': datetime.datetime(2025, 1, 23, 19, 30, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611176628, 'issue_id': 2776275119, 'author': 'bbovenzi', 'body': ""Good call on the mapped task stuff. I made an issue for it here: https://github.com/apache/airflow/issues/45990\r\n\r\nWould you be able to make a gif or video of the second behavior you described? I am having a hard time understanding or I can't replicate it yet locally"", 'created_at': datetime.datetime(2025, 1, 23, 22, 50, 58, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614095717, 'issue_id': 2776275119, 'author': 'jscheffl', 'body': ""> Good call on the mapped task stuff. I made an issue for it here: #45990\r\n> \r\n> Would you be able to make a gif or video of the second behavior you described? I am having a hard time understanding or I can't replicate it yet locally\r\n\r\nSorry for the delay, coming back post merge now.\r\n\r\nhttps://github.com/user-attachments/assets/76de8570-cee0-4260-9f71-56e4bef47aa3\r\n\r\nAttached please find the recording. Just tested post merge on current main. Clicks are not visual but whenever I click a task cell you see the runs are getting re-sorted by the length of the bars of DAG runs."", 'created_at': datetime.datetime(2025, 1, 25, 20, 50, 27, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-23 19:24:47 UTC): Did a small ""smoke test"" - if you select a mapped task and close the grid, the selected task navigation throws an error:
![image](https://github.com/user-attachments/assets/dde3a00b-57b6-40f6-a021-49cd7adb3941)

jscheffl on (2025-01-23 19:30:36 UTC): Also second had ""strange"" results in the example task group, when I selected tasks in a group my browser (Firefox, Ubuntu 24.04 LTS) was sorting the runs and selecting the first execution if I clicked on the task of second/third run:
![image](https://github.com/user-attachments/assets/412ada86-fb8e-4734-9ac7-6f87068a5c01)

bbovenzi (Issue Creator) on (2025-01-23 22:50:58 UTC): Good call on the mapped task stuff. I made an issue for it here: https://github.com/apache/airflow/issues/45990

Would you be able to make a gif or video of the second behavior you described? I am having a hard time understanding or I can't replicate it yet locally

jscheffl on (2025-01-25 20:50:27 UTC): Sorry for the delay, coming back post merge now.

https://github.com/user-attachments/assets/76de8570-cee0-4260-9f71-56e4bef47aa3

Attached please find the recording. Just tested post merge on current main. Clicks are not visual but whenever I click a task cell you see the runs are getting re-sorted by the length of the bars of DAG runs.

"
2775790283,pull_request,closed,,AIP-38 Activate sort select on table dags view,Allow dags sorting on the `table` display too.,pierrejeambrun,2025-01-08 16:15:46+00:00,['pierrejeambrun'],2025-01-08 16:34:47+00:00,2025-01-08 16:34:25+00:00,https://github.com/apache/airflow/pull/45490,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]","[{'comment_id': 2578113210, 'issue_id': 2775790283, 'author': 'bbovenzi', 'body': 'So, a user can always sort by the dropdown but on the table view can also click on the column headers?', 'created_at': datetime.datetime(2025, 1, 8, 16, 32, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578116904, 'issue_id': 2775790283, 'author': 'pierrejeambrun', 'body': 'I realized later that table header do exactly that. Closing.', 'created_at': datetime.datetime(2025, 1, 8, 16, 34, 46, tzinfo=datetime.timezone.utc)}]","bbovenzi on (2025-01-08 16:32:53 UTC): So, a user can always sort by the dropdown but on the table view can also click on the column headers?

pierrejeambrun (Issue Creator) on (2025-01-08 16:34:46 UTC): I realized later that table header do exactly that. Closing.

"
2775770227,pull_request,closed,,Rename Try Number to Attempt,"Try Number is fine as the column entry. But I think ""Attempt"" is a more intuitive name for users.


---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2025-01-08 16:06:38+00:00,[],2025-01-14 15:33:40+00:00,2025-01-14 15:30:24+00:00,https://github.com/apache/airflow/pull/45489,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2578447997, 'issue_id': 2775770227, 'author': 'eladkal', 'body': '> Try Number is fine as the column entry. But I think ""Attempt"" is a more intuitive name for users.\r\n\r\nTry number is very well received term. I suggest to consider the implications...\r\nI find it easier when the UI speaks the same language as the code. try number is something that all airflow users are aware of and familiar with - changing the terminology just in the ui might cause confusion.\r\n\r\nI don\'t feel strongly about this so if others are fine with it lets merge.', 'created_at': datetime.datetime(2025, 1, 8, 19, 20, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578594419, 'issue_id': 2775770227, 'author': 'jscheffl', 'body': ""I'd also rather recommend to keep it the same name - and stronger opinion is to have it consistent. If we change the name in UI then we should also change the name in DB and API/Code consistenly, else this is very confusing"", 'created_at': datetime.datetime(2025, 1, 8, 20, 27, 55, tzinfo=datetime.timezone.utc)}]","eladkal on (2025-01-08 19:20:51 UTC): Try number is very well received term. I suggest to consider the implications...
I find it easier when the UI speaks the same language as the code. try number is something that all airflow users are aware of and familiar with - changing the terminology just in the ui might cause confusion.

I don't feel strongly about this so if others are fine with it lets merge.

jscheffl on (2025-01-08 20:27:55 UTC): I'd also rather recommend to keep it the same name - and stronger opinion is to have it consistent. If we change the name in UI then we should also change the name in DB and API/Code consistenly, else this is very confusing

"
2775595738,pull_request,closed,,FIX: add case of aarch64 environments for cloud-sql-proxy binaries,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
This PR addresses an edge case when running airflow in linux on an arm64 machine and trying to use the cloud sql proxy. Linux declares its `os.uname().machine` as `aarch64` but the binary that is built and available for download is called `arm64`. This adds a simple check to return the proper name of the binary.

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",mdering,2025-01-08 14:52:07+00:00,[],2025-01-08 22:41:35+00:00,2025-01-08 22:41:35+00:00,https://github.com/apache/airflow/pull/45488,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2775435982,pull_request,closed,,AIP-72: Add support for `get_current_context` in Task SDK,"closes https://github.com/apache/airflow/issues/45234

I am putting the logic for `set_current_context` in `execution_time/context.py`. I didn't want to put `_CURRENT_CONTEXT` in `task_sdk/src/airflow/sdk/definitions/contextmanager.py` to avoid execution logic in a user-facing module but I couldn't think of another way to store it from execution & allow retrieving (via `get_current_context` in the Standard Provider) in their Task.

Upcoming PRs:
- Move most of the internal stuff in Task SDK to a separate module.
- Use `create_runtime_ti` fixture more widely in tests

---

Tested with the following DAG:

```py
import pendulum

from airflow.decorators import dag, task
from airflow.providers.standard.operators.python import get_current_context

@dag(
    schedule=None,
    start_date=pendulum.datetime(2021, 1, 1, tz=""UTC""),
    catchup=False,
)
def x_get_context():
    @task
    def template_test(data_interval_end):
        context = get_current_context()

        # Will print `2024-10-10 00:00:00+00:00`.
        # Note how we didn't pass this value when calling the task. Instead
        # it was passed by the decorator from the context
        print(f""data_interval_end: {data_interval_end}"")

        # Will print the full context dict
        print(f""context: {context}"")

    template_test()

x_get_context()

```
<img width=""1703"" alt=""image"" src=""https://github.com/user-attachments/assets/2763963a-d299-412f-bee3-3b20904ca7c8"" />





<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-08 13:45:04+00:00,[],2025-01-09 13:52:22+00:00,2025-01-09 07:15:54+00:00,https://github.com/apache/airflow/pull/45486,"[('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2775395793,pull_request,closed,,feat: Add OpenLineage support for transfer operators between GCS and SFTP,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for SFTPToGCSOperator and GCSToSFTPOperator.


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2025-01-08 13:26:38+00:00,[],2025-01-09 08:08:31+00:00,2025-01-08 22:55:53+00:00,https://github.com/apache/airflow/pull/45485,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2775368051,pull_request,open,,RENAMED fail_stop to fail_fast,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",richochetclementine1315,2025-01-08 13:13:42+00:00,[],2025-01-08 13:13:47+00:00,,https://github.com/apache/airflow/pull/45484,[],"[{'comment_id': 2577643952, 'issue_id': 2775368051, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 8, 13, 13, 46, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-08 13:13:46 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2775335451,pull_request,open,,Pass specific env vars to logGroomerSideCar,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
In our deployment we need to pass specific environment variables to logGroomerSidecar in both scheduler and triggered versions. This is a proposal to add them using envFrom.

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",mrestivill,2025-01-08 12:57:57+00:00,[],2025-02-03 07:08:51+00:00,,https://github.com/apache/airflow/pull/45483,"[('area:helm-chart', 'Airflow Helm Chart')]","[{'comment_id': 2577612637, 'issue_id': 2775335451, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 8, 12, 58, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593349187, 'issue_id': 2775335451, 'author': 'romsharon98', 'body': 'Can you add it to other logGroomer we have, and add tests [here](https://github.com/apache/airflow/blob/03349014513114f1eaa413a9831b0027e4fbfa67/tests/charts/log_groomer.py)?', 'created_at': datetime.datetime(2025, 1, 15, 16, 12, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2630136744, 'issue_id': 2775335451, 'author': 'eladkal', 'body': 'Do we still need this PR after https://github.com/apache/airflow/pull/46003 was merged?', 'created_at': datetime.datetime(2025, 2, 3, 7, 8, 50, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-08 12:58:02 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

romsharon98 on (2025-01-15 16:12:29 UTC): Can you add it to other logGroomer we have, and add tests [here](https://github.com/apache/airflow/blob/03349014513114f1eaa413a9831b0027e4fbfa67/tests/charts/log_groomer.py)?

eladkal on (2025-02-03 07:08:50 UTC): Do we still need this PR after https://github.com/apache/airflow/pull/46003 was merged?

"
2775185782,pull_request,closed,,do not instantiate raw CallbackRequest,"This fixes main (after https://github.com/apache/airflow/pull/45305), as CallbackRequest is not an instantiable class now.",mobuchowski,2025-01-08 11:45:01+00:00,[],2025-01-08 13:42:48+00:00,2025-01-08 13:42:48+00:00,https://github.com/apache/airflow/pull/45482,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:celery', '')]",[],
2775112355,pull_request,closed,,Add bundle_name to ParseImportError,"This PR adds bundle_name to ParseImportError. Future work would make
the filename relative to the bundle path and that means we need to include
bundle_name as part of the ParseImportError so that if two DAG files are
having the same filename, we could differentiate them by the bundle they belong.


Depends on https://github.com/apache/airflow/pull/45371

Closes: #45474",ephraimbuddy,2025-01-08 11:08:39+00:00,[],2025-01-15 23:09:46+00:00,2025-01-15 23:09:44+00:00,https://github.com/apache/airflow/pull/45480,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:providers', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('provider:openlineage', 'AIP-53'), ('provider:fab', ''), ('area:db-migrations', 'PRs with DB migration'), ('AIP-66: DAG Bundle/Manifest', ''), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2591101758, 'issue_id': 2775112355, 'author': 'ephraimbuddy', 'body': '> Do we need to make any changes to the new FastAPI endpoint?\r\n\r\nYes. Added the needed changes now', 'created_at': datetime.datetime(2025, 1, 14, 21, 5, 41, tzinfo=datetime.timezone.utc)}]","ephraimbuddy (Issue Creator) on (2025-01-14 21:05:41 UTC): Yes. Added the needed changes now

"
2774947552,pull_request,closed,,Moved test functions from azure provider to tests_common package for reusability in other providers,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: [#44809](https://github.com/apache/airflow/pull/44809)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Moved test functions from azure provider to tests_common package for reusability in other providers.

This is to split the other [PR](https://github.com/apache/airflow/pull/44809) related to the deferred pagination mode in the GenericTransfer operator, so the PR doesn't become too big as that one will also need those test helper functions to be able to test deferred operators.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2025-01-08 10:10:58+00:00,[],2025-01-27 12:36:41+00:00,2025-01-26 21:31:05+00:00,https://github.com/apache/airflow/pull/45478,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]","[{'comment_id': 2593225553, 'issue_id': 2774947552, 'author': 'dabla', 'body': ""@potiuk @eladkal Could this PR be merged as this will help make this [PR ](https://github.com/apache/airflow/pull/44809) to be smaller, it's a split of that one."", 'created_at': datetime.datetime(2025, 1, 15, 15, 32, 23, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2025-01-15 15:32:23 UTC): @potiuk @eladkal Could this PR be merged as this will help make this [PR ](https://github.com/apache/airflow/pull/44809) to be smaller, it's a split of that one.

"
2774829612,pull_request,closed,,Prevent new pytest-asyncio from failing our tests,"Changes in recent pytest-asyncio uncovered some issues with the way we use asyncio event loop in our tests. Until we fix the tests we limit pytest-asyncio.

See https://github.com/apache/airflow/issues/45355

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-08 09:33:28+00:00,[],2025-01-08 16:49:02+00:00,2025-01-08 16:49:01+00:00,https://github.com/apache/airflow/pull/45477,[],[],
2773637119,pull_request,closed,,Do not use core Airflow Flask related resources in FAB provider (package `api_connexion`),"Follow-up of #45441.

The Flask application in FAB provider should not use any Flask related resources from core Airflow. Otherwise, deleting the main Flask application in core Airflow when the legacy Airflow 2 is gone will be impossible.

This PR focus on the package `airflow.api_connexion`.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-07 20:02:12+00:00,[],2025-01-08 15:59:57+00:00,2025-01-08 15:59:54+00:00,https://github.com/apache/airflow/pull/45473,"[('area:providers', ''), ('provider:fab', '')]",[],
2773567353,pull_request,closed,,Do not use core Airflow Flask related resources in FAB provider (tests of `www`),"Follow-up of #45441.

In #45441 I forgot to apply the changes in tests as well. This PR solves that.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-07 19:21:13+00:00,[],2025-01-28 17:30:49+00:00,2025-01-13 14:48:28+00:00,https://github.com/apache/airflow/pull/45472,"[('area:providers', ''), ('provider:fab', '')]","[{'comment_id': 2587307413, 'issue_id': 2773567353, 'author': 'vincbeck', 'body': 'Closing this PR since I actually do not think this is needed. All these tests will be deleted when the Airflow 2 UI is deleted', 'created_at': datetime.datetime(2025, 1, 13, 14, 48, 28, tzinfo=datetime.timezone.utc)}]","vincbeck (Issue Creator) on (2025-01-13 14:48:28 UTC): Closing this PR since I actually do not think this is needed. All these tests will be deleted when the Airflow 2 UI is deleted

"
2773540738,pull_request,closed,,Do not use core Airflow Flask related resources in FAB provider (package `security`),"Follow-up of #45441.

The Flask application in FAB provider should not use any Flask related resources from core Airflow. Otherwise, deleting the main Flask application in core Airflow when the legacy Airflow 2 is gone will be impossible.

This PR focus on the package `airflow.security`.


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-07 19:04:19+00:00,[],2025-01-08 17:58:01+00:00,2025-01-08 17:57:59+00:00,https://github.com/apache/airflow/pull/45471,"[('area:providers', ''), ('provider:fab', '')]",[],
2773535689,pull_request,closed,,Fixing return type for azure hook 'run_query',"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

New release of https://github.com/Azure/azure-kusto-python couldve introduced this. Tried my hand at a fix for CI failure: https://github.com/apache/airflow/actions/runs/12652631045


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-07 19:01:04+00:00,[],2025-01-08 19:41:38+00:00,2025-01-08 05:20:32+00:00,https://github.com/apache/airflow/pull/45470,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2576332585, 'issue_id': 2773535689, 'author': 'jscheffl', 'body': 'Sorry for the failed attempts :-( Sometimes I hate spell-checking :-(', 'created_at': datetime.datetime(2025, 1, 7, 22, 15, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576572307, 'issue_id': 2773535689, 'author': 'amoghrajesh', 'body': '@jscheffl it was slightly late for me, I slept! Will check now. Thanks though', 'created_at': datetime.datetime(2025, 1, 8, 2, 18, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576776253, 'issue_id': 2773535689, 'author': 'amoghrajesh', 'body': '@jscheffl it took me a few tries to fix spellcheck too!\r\nIt was the wordlist that needed update:\r\n```\r\n""""""\r\nThis module contains Azure Data Explorer hook.\r\n\r\n.. spelling:word-list::\r\n\r\n    KustoResponseDataSet\r\n    kusto\r\n""""""\r\n****\r\n```', 'created_at': datetime.datetime(2025, 1, 8, 5, 19, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576994095, 'issue_id': 2773535689, 'author': 'potiuk', 'body': 'Nice :)', 'created_at': datetime.datetime(2025, 1, 8, 8, 5, 24, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-07 22:15:21 UTC): Sorry for the failed attempts :-( Sometimes I hate spell-checking :-(

amoghrajesh (Issue Creator) on (2025-01-08 02:18:43 UTC): @jscheffl it was slightly late for me, I slept! Will check now. Thanks though

amoghrajesh (Issue Creator) on (2025-01-08 05:19:50 UTC): @jscheffl it took me a few tries to fix spellcheck too!
It was the wordlist that needed update:
```
""""""
This module contains Azure Data Explorer hook.

.. spelling:word-list::

    KustoResponseDataSet
    kusto
""""""
****
```

potiuk on (2025-01-08 08:05:24 UTC): Nice :)

"
2773306185,pull_request,closed,,Fix `fetch_access_token_for_cluster` in EKS hook,"Resolves #45368.

Some users in China reported an issue when integrating EKS with Airflow. The customer could not use the workflow under global account after migrating it to China. Their dag script to connect to EKS cluster using `EksPodOperator` returned 401 .

Error:

```
[2024-12-31, 08:47:19 UTC] {taskinstance.py:3310} ERROR - Task failed with exception
Traceback (most recent call last):
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py"", line 767, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/models/taskinstance.py"", line 733, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/utils/operator_helpers.py"", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py"", line 406, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/providers/amazon/aws/operators/eks.py"", line 1103, in execute
    return super().execute(context)
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/models/baseoperator.py"", line 406, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/providers/cncf/kubernetes/operators/pod.py"", line 593, in execute
    return self.execute_sync(context)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/providers/cncf/kubernetes/operators/pod.py"", line 603, in execute_sync
    self.pod = self.get_or_create_pod(  # must set `self.pod` for `on_kill`
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/providers/cncf/kubernetes/operators/pod.py"", line 561, in get_or_create_pod
    pod = self.find_pod(self.namespace or pod_request_obj.metadata.namespace, context=context)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/airflow/providers/cncf/kubernetes/operators/pod.py"", line 534, in find_pod
    pod_list = self.client.list_namespaced_pod(
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/kubernetes/client/api/core_v1_api.py"", line 15823, in list_namespaced_pod
    return self.list_namespaced_pod_with_http_info(namespace, **kwargs)  # noqa: E501
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/kubernetes/client/api/core_v1_api.py"", line 15942, in list_namespaced_pod_with_http_info
    return self.api_client.call_api(
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/kubernetes/client/api_client.py"", line 348, in call_api
    return self.__call_api(resource_path, method,
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/kubernetes/client/api_client.py"", line 180, in __call_api
    response_data = self.request(
                    ^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/kubernetes/client/api_client.py"", line 373, in request
    return self.rest_client.GET(url,
           ^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/kubernetes/client/rest.py"", line 244, in GET
    return self.request(""GET"", url,
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/usr/local/airflow/.local/lib/python3.11/site-packages/kubernetes/client/rest.py"", line 238, in request
    raise ApiException(http_resp=r)
kubernetes.client.exceptions.ApiException: (401)
Reason: Unauthorized
```

The root cause is the address to access STS here points to the global address, not the China STS service address. So the eks token obtained cannot be used in China. The sts_url that should be used in China is `https://sts/.{session.region_name}.[amazonaws.com.cn/?Action=GetCallerIdentity&Version=2011-06-15`

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-07 16:49:03+00:00,[],2025-01-08 15:31:40+00:00,2025-01-08 15:31:39+00:00,https://github.com/apache/airflow/pull/45469,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2575890909, 'issue_id': 2773306185, 'author': 'o-nikolas', 'body': 'Looks like some of the existing tests need updating first as well', 'created_at': datetime.datetime(2025, 1, 7, 17, 45, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575959243, 'issue_id': 2773306185, 'author': 'eladkal', 'body': 'Does this fix solve https://github.com/apache/airflow/issues/45368 ?', 'created_at': datetime.datetime(2025, 1, 7, 18, 23, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575976201, 'issue_id': 2773306185, 'author': 'vincbeck', 'body': '> Does this fix solve #45368 ?\r\n\r\nOh yeah! I did not know there was a ticket for it. I updated the description to mention it', 'created_at': datetime.datetime(2025, 1, 7, 18, 33, 54, tzinfo=datetime.timezone.utc)}]","o-nikolas on (2025-01-07 17:45:53 UTC): Looks like some of the existing tests need updating first as well

eladkal on (2025-01-07 18:23:33 UTC): Does this fix solve https://github.com/apache/airflow/issues/45368 ?

vincbeck (Issue Creator) on (2025-01-07 18:33:54 UTC): Oh yeah! I did not know there was a ticket for it. I updated the description to mention it

"
2773279669,pull_request,closed,,Default tooltips to showArrow,"Tooltips in the new UI to show an arrow by default

Based on conversation [here](https://github.com/apache/airflow/pull/44854#discussion_r1905481009)

<img width=""338"" alt=""Screenshot 2025-01-07 at 11 35 36 AM"" src=""https://github.com/user-attachments/assets/badf010a-3ea7-4d53-b987-e259cc1f3c07"" />

---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bbovenzi,2025-01-07 16:36:07+00:00,[],2025-01-07 17:20:24+00:00,2025-01-07 17:20:22+00:00,https://github.com/apache/airflow/pull/45468,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2773244490,pull_request,closed,,Bump trove-classifiers from 2025.1.6.15 to 2025.1.7.14,"Bumps [trove-classifiers](https://github.com/pypa/trove-classifiers) from 2025.1.6.15 to 2025.1.7.14.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/trove-classifiers/commit/c79c976dd1f3ca8cbd1f462d59823df61db7e259""><code>c79c976</code></a> Add upcoming django CMS version (<a href=""https://redirect.github.com/pypa/trove-classifiers/issues/198"">#198</a>)</li>
<li>See full diff in <a href=""https://github.com/pypa/trove-classifiers/compare/2025.1.6.15...2025.1.7.14"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=trove-classifiers&package-manager=pip&previous-version=2025.1.6.15&new-version=2025.1.7.14)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2025-01-07 16:20:28+00:00,[],2025-01-07 23:15:19+00:00,2025-01-07 23:15:11+00:00,https://github.com/apache/airflow/pull/45467,"[('area:dependencies', 'Issues related to dependencies problems')]",[],
2773203665,pull_request,open,,Add Parameters to SqlToS3Operator template fields. ,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


Adds parameters to the template_fields for the SqlToS3Operator.

Team was writing some basic automations and we came across some use cases where we want to dynamically run some reports with parameters and the thought of direct replacement inside the SQL instead of using SQL parameters is irking. 

An example of what we currently need todo. 
```
SqlToS3Operator(
        task_id=""export_sql_to_s3"",
        sql_conn_id=""trino_chart_retrieval_ro_id"",
        query=""""""select * from foo where date > {{ params.date}}"""""",
        s3_bucket=""{{params.s3bucket}}"",
        s3_key=""{{params.filepath }}"" + ""/"" + ""{{params.filename}}"",
        pd_kwargs={""index"": False, ""quoting"": csv.QUOTE_ALL},
        file_format=""csv"",
        aws_conn_id=""aws_conn_id"",
        replace=True,
    )
```

vs with the parameters field being templated.  
```
SqlToS3Operator(
        task_id=""export_sql_to_s3"",
        sql_conn_id=""trino_chart_retrieval_ro_id"",
        query=""""""select * from foo where date > %s"""""",
        parameters=({{params.date}},),
        s3_bucket=""{{params.s3bucket}}"",
        s3_key=""{{params.filepath }}"" + ""/"" + ""{{params.filename}}"",
        pd_kwargs={""index"": False, ""quoting"": csv.QUOTE_ALL},
        file_format=""csv"",
        aws_conn_id=""aws_conn_id"",
        replace=True,
    )
```


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",tkeller-moxe,2025-01-07 16:05:49+00:00,[],2025-01-07 17:35:25+00:00,,https://github.com/apache/airflow/pull/45466,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:providers', '')]","[{'comment_id': 2575667805, 'issue_id': 2773203665, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 7, 16, 5, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575675852, 'issue_id': 2773203665, 'author': 'eladkal', 'body': ""I think your example doesn't make sense. You are not using `parameters` anywhere.\r\nI don't think `parameters` needs to be templated. Correct me if i am wrong here but you are confusing `params` with `parameters`:\r\n\r\nhttps://stackoverflow.com/a/72246305/14624409\r\n\r\nIt doesn't make sense to template `parameters` given how it's being used.\r\nIf I miss something please explain"", 'created_at': datetime.datetime(2025, 1, 7, 16, 8, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575680563, 'issue_id': 2773203665, 'author': 'tkeller-moxe', 'body': 'I made some edits for clarity, Thanks for the quick response!\r\n\r\n---\r\nEdit let me edit/read your stackoverflow a bit more.', 'created_at': datetime.datetime(2025, 1, 7, 16, 10, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575703438, 'issue_id': 2773203665, 'author': 'tkeller-moxe', 'body': 'So I may be confused a little as well. \r\n\r\nAre the DAG Params when rendered in SQL, eg my first example, properly SQL escaped? If so that does alleviate our concern.  The team is worried about a future state where SQL injection might be possible. My assumption is that they are not and its mostly just a string insertion. \r\n\r\nPart of what might be confusing me is the [SQLExecuteQueryOperator](https://airflow.apache.org/docs/apache-airflow-providers-common-sql/stable/_api/airflow/providers/common/sql/operators/sql/index.html#airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator.template_fields) does have parameters in the `template_fields` which is leading to some inconsistency. \r\n\r\nThe second example I wrote is using the parameters option to allow SQLAlchemy to render the `select * from foo where date > %s` as a parameterized SQL statement passing in the values of `{{ params.date }}` as an argument instead of directly inline with the query.', 'created_at': datetime.datetime(2025, 1, 7, 16, 18, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575720791, 'issue_id': 2773203665, 'author': 'eladkal', 'body': '> Part of what might be confusing me is the [SQLExecuteQueryOperator](https://airflow.apache.org/docs/apache-airflow-providers-common-sql/stable/_api/airflow/providers/common/sql/operators/sql/index.html#airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator.template_fields) does have parameters in the template_fields which is leading to some inconsistency.\r\n\r\nTo my perspective it\'s wrong but that ship has saild.\r\n\r\nI don\'t really mind adding it as template filed here as you requested but the example you shared doesn\'t reflect using `parameters` at all and if we do add it as template fields it will confuse others even more. I think what you really need is:\r\n\r\n```\r\nSqlToS3Operator(\r\n        ...\r\n        query=""""""select * from foo where date > {{ params.date }} """""",\r\n        params={""date"": my_date}\r\n    )\r\n```\r\n\r\ntemplated fields is going to have massive refactor in Airflow 3', 'created_at': datetime.datetime(2025, 1, 7, 16, 23, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575787072, 'issue_id': 2773203665, 'author': 'tkeller-moxe', 'body': 'I\'ll be honest I\'m even more confused now. \r\nMy goal is to be able to use a DAG/UI enterable parameter to drive changes in this SQL statement. \r\n\r\nThe task level params do not show up when you go to manually trigger a DAG. \r\n\r\nNot included in the example, which might be the issue, is the DAG definition which looks like such\r\nThis is an example of the end state with parameters. \r\n```python\r\nwith DAG(\r\n    ...\r\n    dag_id=""demo"",\r\n    schedule=None,\r\n    catchup=False,\r\n    params={\r\n        ...\r\n        ""date"": ""2024-01-01"",\r\n    },\r\n) as dag:\r\n  SqlToS3Operator(\r\n          task_id=""export_sql_to_s3"",\r\n          sql_conn_id=""trino_chart_retrieval_ro_id"",\r\n          query=""""""select * from foo where date > %s"""""",\r\n          parameters=({{params.date}},),\r\n          ...\r\n      )\r\n```\r\n\r\nI gave a try using the task level params, as you gave an example, sadly I could not get them to show up in the Trigger Dag UI. Is there a pattern or documentation I\'m missing here?', 'created_at': datetime.datetime(2025, 1, 7, 16, 53, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575843675, 'issue_id': 2773203665, 'author': 'konradish', 'body': '> > Part of what might be confusing me is the [SQLExecuteQueryOperator](https://airflow.apache.org/docs/apache-airflow-providers-common-sql/stable/_api/airflow/providers/common/sql/operators/sql/index.html#airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator.template_fields) does have parameters in the template_fields which is leading to some inconsistency.\r\n> \r\n> To my perspective it\'s wrong but that ship has saild.\r\n> \r\n> I don\'t really mind adding it as template filed here as you requested but the example you shared doesn\'t reflect using `parameters` at all and if we do add it as template fields it will confuse others even more. I think what you really need is:\r\n> \r\n> ```\r\n> SqlToS3Operator(\r\n>         ...\r\n>         query=""""""select * from foo where date > {{ params.date }} """""",\r\n>         params={""date"": my_date}\r\n>     )\r\n> ```\r\n> \r\n> templated fields is going to have massive refactor in Airflow 3\r\n\r\nIsn\'t that templated string vulnerable to SQL injection? Passing params will go through SQLAlchemy and avoid that vulnerability. Is my understanding correct?', 'created_at': datetime.datetime(2025, 1, 7, 17, 20, 55, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-07 16:05:56 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

eladkal on (2025-01-07 16:08:51 UTC): I think your example doesn't make sense. You are not using `parameters` anywhere.
I don't think `parameters` needs to be templated. Correct me if i am wrong here but you are confusing `params` with `parameters`:

https://stackoverflow.com/a/72246305/14624409

It doesn't make sense to template `parameters` given how it's being used.
If I miss something please explain

tkeller-moxe (Issue Creator) on (2025-01-07 16:10:42 UTC): I made some edits for clarity, Thanks for the quick response!

---
Edit let me edit/read your stackoverflow a bit more.

tkeller-moxe (Issue Creator) on (2025-01-07 16:18:16 UTC): So I may be confused a little as well. 

Are the DAG Params when rendered in SQL, eg my first example, properly SQL escaped? If so that does alleviate our concern.  The team is worried about a future state where SQL injection might be possible. My assumption is that they are not and its mostly just a string insertion. 

Part of what might be confusing me is the [SQLExecuteQueryOperator](https://airflow.apache.org/docs/apache-airflow-providers-common-sql/stable/_api/airflow/providers/common/sql/operators/sql/index.html#airflow.providers.common.sql.operators.sql.SQLExecuteQueryOperator.template_fields) does have parameters in the `template_fields` which is leading to some inconsistency. 

The second example I wrote is using the parameters option to allow SQLAlchemy to render the `select * from foo where date > %s` as a parameterized SQL statement passing in the values of `{{ params.date }}` as an argument instead of directly inline with the query.

eladkal on (2025-01-07 16:23:53 UTC): To my perspective it's wrong but that ship has saild.

I don't really mind adding it as template filed here as you requested but the example you shared doesn't reflect using `parameters` at all and if we do add it as template fields it will confuse others even more. I think what you really need is:

```
SqlToS3Operator(
        ...
        query=""""""select * from foo where date > {{ params.date }} """""",
        params={""date"": my_date}
    )
```

templated fields is going to have massive refactor in Airflow 3

tkeller-moxe (Issue Creator) on (2025-01-07 16:53:25 UTC): I'll be honest I'm even more confused now. 
My goal is to be able to use a DAG/UI enterable parameter to drive changes in this SQL statement. 

The task level params do not show up when you go to manually trigger a DAG. 

Not included in the example, which might be the issue, is the DAG definition which looks like such
This is an example of the end state with parameters. 
```python
with DAG(
    ...
    dag_id=""demo"",
    schedule=None,
    catchup=False,
    params={
        ...
        ""date"": ""2024-01-01"",
    },
) as dag:
  SqlToS3Operator(
          task_id=""export_sql_to_s3"",
          sql_conn_id=""trino_chart_retrieval_ro_id"",
          query=""""""select * from foo where date > %s"""""",
          parameters=({{params.date}},),
          ...
      )
```

I gave a try using the task level params, as you gave an example, sadly I could not get them to show up in the Trigger Dag UI. Is there a pattern or documentation I'm missing here?

konradish on (2025-01-07 17:20:55 UTC): Isn't that templated string vulnerable to SQL injection? Passing params will go through SQLAlchemy and avoid that vulnerability. Is my understanding correct?

"
2773038250,pull_request,closed,,Adding holiday_region parameter  to create_auto_ml_forecasting_training_job in AutoMl hook,"https://cloud.google.com/vertex-ai/docs/tabular-data/forecasting/train-model#:~:text=Learn%20more.-,HOLIDAY_REGIONS,-%3A%20(Optional)%20You%20can",vinay2242g,2025-01-07 14:52:59+00:00,[],2025-01-10 14:16:36+00:00,2025-01-10 07:31:07+00:00,https://github.com/apache/airflow/pull/45465,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2773000980,pull_request,closed,,Updated instantiation of httpx AsyncClient in KiotaRequestAdapterHook to be httpx 0.28.x compliant,"From httpx 0.28.0 and higher, the deprecated 'proxies' parameter of the AsyncClient won't be available anymore and has been replaced with the 'mounts' parameter.  At the moment this isn't an issue yet as Airflow is still using 0.27.x but could become a problem in the future once Airflow would start using httpx 0.28.0 or higher.

The httpx AsyncClient is being used by the KiotaRequestAdapterHook in the Microsoft Azure provider, so to avoid any upgrade issues in the future I've fixed the instantiation of the AsyncClient.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2025-01-07 14:36:32+00:00,[],2025-01-08 09:06:38+00:00,2025-01-08 05:35:50+00:00,https://github.com/apache/airflow/pull/45464,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]","[{'comment_id': 2577148287, 'issue_id': 2773000980, 'author': 'dabla', 'body': 'Thanks @eladkal', 'created_at': datetime.datetime(2025, 1, 8, 9, 6, 37, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2025-01-08 09:06:37 UTC): Thanks @eladkal

"
2772904079,pull_request,closed,,adding holiday region parameter,"adding holiday region parameter

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vinay2242g,2025-01-07 13:51:41+00:00,[],2025-01-07 13:57:55+00:00,2025-01-07 13:57:55+00:00,https://github.com/apache/airflow/pull/45463,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2772466650,pull_request,closed,,Minor query fix changing session.execute to session.scalars,"Since this query no longer looks at two columns, we should use scalars. Using execute returns a tuple ('4q4qw4',), for example, and IDE complains because we used serialized_dag.dag_hash to access the tuple. With scalars, it's now just the dag_hash that is returned

",ephraimbuddy,2025-01-07 10:26:25+00:00,[],2025-01-07 11:36:55+00:00,2025-01-07 11:36:53+00:00,https://github.com/apache/airflow/pull/45460,"[('area:serialization', '')]",[],
2772452592,pull_request,closed,,AIP-38 Better markdown rendering,"Only the last commit is relevant. Depends on https://github.com/apache/airflow/pull/45434

This fixes the markdown rendering. Due to the ChakraUI CSS reset (good practice), native elements have no styling. We need to remap html tags to Chakra components in the markdown renderer. Example of the css reset, those are correctly h1, ul, li tags, but no style are applied (CSS reset):
![Screenshot 2025-01-07 at 11 18 25](https://github.com/user-attachments/assets/0af6477c-4fa0-4394-a67e-55d1a9cb6b56)
 


## Before:
![Screenshot 2025-01-07 at 11 17 04](https://github.com/user-attachments/assets/eb005aa0-a54f-4a48-9c34-fd36b14bf64b)
![Screenshot 2025-01-07 at 11 17 23](https://github.com/user-attachments/assets/e1acf82d-445c-4181-bd2f-35bd58a5ac18)
![Screenshot 2025-01-07 at 11 17 34](https://github.com/user-attachments/assets/3f8e1475-7fab-476c-a048-7ac302c5f940)

## After:
![Screenshot 2025-01-07 at 11 15 44](https://github.com/user-attachments/assets/aff61e55-ba61-4d91-9f46-ebad9003938a)
![Screenshot 2025-01-07 at 11 16 03](https://github.com/user-attachments/assets/3cc03115-c3e8-4b38-920e-70f57823114f)
![Screenshot 2025-01-07 at 11 16 29](https://github.com/user-attachments/assets/603faef7-9a99-4781-a93a-f0f90b505ae4)
",pierrejeambrun,2025-01-07 10:19:52+00:00,['pierrejeambrun'],2025-01-08 16:13:39+00:00,2025-01-08 16:13:37+00:00,https://github.com/apache/airflow/pull/45459,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]",[],
2772402586,pull_request,open,,AIP-72: Add support to get Variables in task SDK to author tasks,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: https://github.com/apache/airflow/issues/45449

### Intent

With AIP 72 coming in and for extending the task sdk to be able to write ""complete"" dags, we need to be able to interact with Airflow Variables: https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/variables.html

Historically, this was done like this:
```
from airflow.models import Variable

# Normal call style
foo = Variable.get(""foo"")

# Auto-deserializes a JSON value
bar = Variable.get(""bar"", deserialize_json=True)

# Returns the value of default_var (None) if the variable is not set
baz = Variable.get(""baz"", default_var=None)
```

Either at the task level or at the DAG level. Note that ""airflow.models"" is used - which is what we are removing for Airflow 3 so that user code doesn't directly interact with DB models, preventing any potential hazard to the Airflow metadata DB. Instead, some user facing interfaces will be exposed to interact with Airflow entities so that we can provide a better DAG writing experience as well as be secure and reduce any risks.

The aim here is to be able to write dags with `from airflow.sdk import Variable`

### Key changes in the PR
- In `definitions/variable.py` user facing interface, a ""get"" method has been introduced to fetch variables.
- This ""get"" method piggybacks on` _get_variable(key)` which was introduced in https://github.com/apache/airflow/pull/45431
- In `_get_variable`, we perform a hypothesis check, we try to import ""airflow.sdk.execution_time.task_runner import SUPERVISOR_COMMS"", if import is possible, that means we are in execution context of a task, but if it fails, we are in execution context of a dag, so we attempt to import ""airflow.dag_processing.processor import COMMS_DECODER"" instead.
- There is effectively a supervisor in DAG processing too, since we extend on the same machinery for dag processing as introduced in #44972. We rely on this machinery and play around with the `_handle_requests` to pass around the VariableResult to the dag processing process. 
- In the dag processor's handle_requests, we interact with the DB directly without using execution API and the client, this is the core package and can freely interact with DB. The advantage this brings in is that we won't need an exeuction API server when testing DAG level stuff. Like getting variables at DAG level.

### Testing

#### Variable.get at dag level
DAG:
```
from __future__ import annotations

from airflow.models.baseoperator import BaseOperator
from airflow import DAG
from airflow.sdk import Variable

value = Variable.get(key=""my_var"")

class CustomOperator(BaseOperator):
    def execute(self, context):
        print(f""Variable defined at top level of dag has value: {value}"")


with DAG(""example_get_variable_using_task_sdk"", schedule=None, catchup=False) as dag:
    CustomOperator(task_id=""print_top_level_variable"")
```

Variable:
![image](https://github.com/user-attachments/assets/632a71be-e7f5-4afc-88d5-b0e47fba2aab)



When variable is present:
![image](https://github.com/user-attachments/assets/9cef5026-08d2-44d5-99e5-9b05e3f5d917)


When variable isn't present (scheduler doesn't crash)
```
C[2025-01-08T14:46:40.831+0000] {scheduler_job_runner.py:244} INFO - Exiting gracefully upon receiving signal 2
[2025-01-08 14:46:40 +0000] [449] [INFO] Handling signal: int
2025-01-08 14:46:40 [error    ] Variable: my_var does not exist [supervisor]
╭─────────────────────────────── Traceback (most recent call last) ────────────────────────────────╮
│ /opt/airflow/airflow/dag_processing/processor.py:252 in _handle_request                          │
│                                                                                                  │
│   249 │   │   │   try:                                                                           │
│   250 │   │   │   │   value = Variable.get(key)                                                  │
│   251 │   │   │   except KeyError:                                                               │
│ ❱ 252 │   │   │   │   log.exception(""Variable: %s does not exist"", key)                          │
│   253 │   │   │   │   raise                                                                      │
│   254 │   │   │   var_result = VariableResult.from_variable_response(VariableResponse(key=key,   │
│   255 │   │   │   resp = var_result.model_dump_json(exclude_unset=True).encode()                 │
│                                                                                                  │
│ ╭─────────────────────────────────────────── locals ───────────────────────────────────────────╮ │
│ │  key = 'my_var'                                                                              │ │
│ │  log = <BoundLoggerLazyProxy(logger=None, wrapper_class=None, processors=None,               │ │
│ │        context_class=None, initial_values={'logger_name': 'supervisor'},                     │ │
│ │        logger_factory_args=())>                                                              │ │
│ │  msg = GetVariable(key='my_var', type='GetVariable')                                         │ │
│ │ self = <DagFileProcessorProcess id=UUID('01944661-c7a1-7733-a5e5-54e427b6db66') pid=7181>    │ │
│ ╰──────────────────────────────────────────────────────────────────────────────────────────────╯ │
│                                                                                                  │
│ /opt/airflow/airflow/models/variable.py:144 in get                                               │
│                                                                                                  │
│   141 │   │   │   if default_var is not cls.__NO_DEFAULT_SENTINEL:                               │
│   142 │   │   │   │   return default_var                                                         │
│   143 │   │   │   else:                                                                          │
│ ❱ 144 │   │   │   │   raise KeyError(f""Variable {key} does not exist"")                           │
│   145 │   │   else:                                                                              │
│   146 │   │   │   if deserialize_json:                                                           │
│   147 │   │   │   │   obj = json.loads(var_val)                                                  │
│                                                                                                  │
│ ╭─────────────────────── locals ───────────────────────╮                                         │
│ │      default_var = <object object at 0xffff7fe99af0> │                                         │
│ │ deserialize_json = False                             │                                         │
│ │              key = 'my_var'                          │                                         │
│ │          var_val = None                              │                                         │
│ ╰──────────────────────────────────────────────────────╯                                         │
╰──────────────────────────────────────────────────────────────────────────────────────────────────╯
KeyError: 'Variable my_var does not exist'

Process ForkProcess-12:
Traceback (most recent call last):
  File ""/usr/local/lib/python3.9/multiprocessing/process.py"", line 315, in _bootstrap
    self.run()
  File ""/usr/local/lib/python3.9/multiprocessing/process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)
  File ""/opt/airflow/airflow/dag_processing/manager.py"", line 192, in _run_processor_manager
    processor_manager.run()
  File ""/opt/airflow/airflow/dag_processing/manager.py"", line 404, in run
    return self._run_parsing_loop()
  File ""/opt/airflow/airflow/dag_processing/manager.py"", line 492, in _run_parsing_loop
    self._service_processor_sockets(timeout=poll_time)
  File ""/opt/airflow/airflow/dag_processing/manager.py"", line 550, in _service_processor_sockets
    need_more = socket_handler(key.fileobj)
  File ""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/supervisor.py"", line 789, in cb
    gen.send(line)
  File ""/opt/airflow/airflow/dag_processing/processor.py"", line 243, in handle_requests
    def _handle_request(self, msg: ToParent, log: FilteringBoundLogger) -> None:  # type: ignore[override]
  File ""/opt/airflow/airflow/dag_processing/processor.py"", line 252, in _handle_request
    log.exception(""Variable: %s does not exist"", key)
  File ""/opt/airflow/airflow/models/variable.py"", line 144, in get
    raise KeyError(f""Variable {key} does not exist"")
KeyError: 'Variable my_var does not exist'
[2025-01-08 14:46:40 +0000] [450] [INFO] Worker exiting (pid: 450)
[2025-01-08 14:46:40 +0000] [451] [INFO] Worker exiting (pid: 451)
[2025-01-08 14:46:41 +0000] [449] [INFO] Shutting down: Master    
```


#### Variable.get at task level
DAG:
```
from __future__ import annotations

from airflow.models.baseoperator import BaseOperator
from airflow import DAG
from airflow.sdk import Variable



class CustomOperator(BaseOperator):
    def execute(self, context):
        value = Variable.get(key=""my_var"")
        print(f""Variable defined at task level has value: {value}"")


with DAG(""example_get_variable_using_task_sdk"", schedule=None, catchup=False) as dag:
    CustomOperator(task_id=""print_top_level_variable"")

```

Variable present:
![image](https://github.com/user-attachments/assets/a6883927-1789-4906-84db-86b8fa115400)


Variable not present:
![image](https://github.com/user-attachments/assets/b2ba9058-59e2-46ac-894f-25adfc909df3)



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-07 09:58:05+00:00,[],2025-01-09 07:40:53+00:00,,https://github.com/apache/airflow/pull/45458,"[('area:task-sdk', None)]","[{'comment_id': 2574921771, 'issue_id': 2772402586, 'author': 'amoghrajesh', 'body': 'This allows me to test something like:\r\n```\r\nfrom __future__ import annotations\r\n\r\nfrom airflow.models.baseoperator import BaseOperator\r\nfrom airflow.sdk import dag\r\nfrom airflow.sdk import Variable\r\n\r\n\r\nclass CustomOperator(BaseOperator):\r\n    def execute(self, context):\r\n        value = Variable.get(key=""my_var"")\r\n        print(f""The variable value is: {value}"")\r\n\r\n\r\n@dag()\r\ndef var_from_defn():\r\n    CustomOperator(task_id=""hello"")\r\n\r\n\r\nvar_from_defn()\r\n\r\n```\r\n\r\n\r\nAdvantage is that now this can be used at task level as well at DAG parsing level.\r\n\r\nThe PR is pre mature, will add edge cases etc once we are OK with the general direction.', 'created_at': datetime.datetime(2025, 1, 7, 10, 23, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2574962142, 'issue_id': 2772402586, 'author': 'amoghrajesh', 'body': ""Some ideas:\r\n1. `_get_variable` and `_get_connection` are really nice utilities and it will be nice if we can use those in definitions as well as in context, but they shouldn't be housed there at all. They should probably move to something slightly upper level - that can be used both by SDK as well as the execution_time. Something common to both.\r\n2. Or we just duplicate that code in the `Variable` class - but simpler, but that could soon become spaghetti code imo."", 'created_at': datetime.datetime(2025, 1, 7, 10, 43, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576908018, 'issue_id': 2772402586, 'author': 'amoghrajesh', 'body': 'Tested it out, and yes that won\'t be possible because of us depending on execution time. So implementation will have to change:\r\n```\r\nBroken DAG: [/files/dags/get-variable-from-sdk.py]\r\nTraceback (most recent call last):\r\n  File ""/opt/airflow/task_sdk/src/airflow/sdk/definitions/variable.py"", line 48, in get\r\n    return _get_variable(key).value\r\n  File ""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/context.py"", line 76, in _get_variable\r\n    from airflow.sdk.execution_time.task_runner import SUPERVISOR_COMMS\r\nImportError: cannot import name \'SUPERVISOR_COMMS\' from \'airflow.sdk.execution_time.task_runner\' (/opt/airflow/task_sdk/src/airflow/sdk/execution_time/task_runner.py)\r\n```', 'created_at': datetime.datetime(2025, 1, 8, 7, 16, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577152995, 'issue_id': 2772402586, 'author': 'amoghrajesh', 'body': 'New update:\r\n\r\nWhy don\'t we just use the SDK client instead? We don\'t really have a need to rely on supervisor here as variables can be retrieved at the top level too. We should also be able to add some level of control at the API level to return / reject API requests as forbidden.\n\nWhen we integrate the token mechanism, we can generate one long running token for such arbitrary requests. \r\n\r\nTesting:\r\n\r\n1. `Variable.get` at dag level\r\n```\r\nfrom __future__ import annotations\r\n\r\nfrom airflow.models.baseoperator import BaseOperator\r\nfrom airflow.sdk import dag\r\nfrom airflow.sdk import Variable\r\n\r\nvalue = Variable.get(key=""my_var"")\r\n\r\nclass CustomOperator(BaseOperator):\r\n    def execute(self, context):\r\n        print(f""The variable from top level dag is: {value}"")\r\n\r\n\r\n@dag()\r\ndef var_from_defn():\r\n    CustomOperator(task_id=""hello"")\r\n\r\n\r\nvar_from_defn()\r\n```\r\n\r\n![image](https://github.com/user-attachments/assets/ae44bfcc-cec2-47ec-b906-08ea1a566a7c)\r\n\r\n\r\n2. `Variable.get` inside task\r\n```\r\nfrom __future__ import annotations\r\n\r\nfrom airflow.models.baseoperator import BaseOperator\r\nfrom airflow.sdk import dag\r\nfrom airflow.sdk import Variable\r\n\r\n\r\nclass CustomOperator(BaseOperator):\r\n    def execute(self, context):\r\n        value = Variable.get(key=""my_var"")\r\n        print(f""The variable from top level dag is: {value}"")\r\n\r\n\r\n@dag()\r\ndef var_from_defn():\r\n    CustomOperator(task_id=""hello"")\r\n\r\n\r\nvar_from_defn()\r\n```\r\n\r\n\r\n![image](https://github.com/user-attachments/assets/077d9a88-94e2-444c-8fd6-bcf711b18441)', 'created_at': datetime.datetime(2025, 1, 8, 9, 8, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578171060, 'issue_id': 2772402586, 'author': 'amoghrajesh', 'body': 'Interesting that I cannot reproduce the failures locally.', 'created_at': datetime.datetime(2025, 1, 8, 16, 59, 26, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2025-01-07 10:23:31 UTC): This allows me to test something like:
```
from __future__ import annotations

from airflow.models.baseoperator import BaseOperator
from airflow.sdk import dag
from airflow.sdk import Variable


class CustomOperator(BaseOperator):
    def execute(self, context):
        value = Variable.get(key=""my_var"")
        print(f""The variable value is: {value}"")


@dag()
def var_from_defn():
    CustomOperator(task_id=""hello"")


var_from_defn()

```


Advantage is that now this can be used at task level as well at DAG parsing level.

The PR is pre mature, will add edge cases etc once we are OK with the general direction.

amoghrajesh (Issue Creator) on (2025-01-07 10:43:06 UTC): Some ideas:
1. `_get_variable` and `_get_connection` are really nice utilities and it will be nice if we can use those in definitions as well as in context, but they shouldn't be housed there at all. They should probably move to something slightly upper level - that can be used both by SDK as well as the execution_time. Something common to both.
2. Or we just duplicate that code in the `Variable` class - but simpler, but that could soon become spaghetti code imo.

amoghrajesh (Issue Creator) on (2025-01-08 07:16:10 UTC): Tested it out, and yes that won't be possible because of us depending on execution time. So implementation will have to change:
```
Broken DAG: [/files/dags/get-variable-from-sdk.py]
Traceback (most recent call last):
  File ""/opt/airflow/task_sdk/src/airflow/sdk/definitions/variable.py"", line 48, in get
    return _get_variable(key).value
  File ""/opt/airflow/task_sdk/src/airflow/sdk/execution_time/context.py"", line 76, in _get_variable
    from airflow.sdk.execution_time.task_runner import SUPERVISOR_COMMS
ImportError: cannot import name 'SUPERVISOR_COMMS' from 'airflow.sdk.execution_time.task_runner' (/opt/airflow/task_sdk/src/airflow/sdk/execution_time/task_runner.py)
```

amoghrajesh (Issue Creator) on (2025-01-08 09:08:45 UTC): New update:

Why don't we just use the SDK client instead? We don't really have a need to rely on supervisor here as variables can be retrieved at the top level too. We should also be able to add some level of control at the API level to return / reject API requests as forbidden.

When we integrate the token mechanism, we can generate one long running token for such arbitrary requests. 

Testing:

1. `Variable.get` at dag level
```
from __future__ import annotations

from airflow.models.baseoperator import BaseOperator
from airflow.sdk import dag
from airflow.sdk import Variable

value = Variable.get(key=""my_var"")

class CustomOperator(BaseOperator):
    def execute(self, context):
        print(f""The variable from top level dag is: {value}"")


@dag()
def var_from_defn():
    CustomOperator(task_id=""hello"")


var_from_defn()
```

![image](https://github.com/user-attachments/assets/ae44bfcc-cec2-47ec-b906-08ea1a566a7c)


2. `Variable.get` inside task
```
from __future__ import annotations

from airflow.models.baseoperator import BaseOperator
from airflow.sdk import dag
from airflow.sdk import Variable


class CustomOperator(BaseOperator):
    def execute(self, context):
        value = Variable.get(key=""my_var"")
        print(f""The variable from top level dag is: {value}"")


@dag()
def var_from_defn():
    CustomOperator(task_id=""hello"")


var_from_defn()
```


![image](https://github.com/user-attachments/assets/077d9a88-94e2-444c-8fd6-bcf711b18441)

amoghrajesh (Issue Creator) on (2025-01-08 16:59:26 UTC): Interesting that I cannot reproduce the failures locally.

"
2772378642,pull_request,closed,,Fix gcp auth in hashicorp vault provider.,,fpopic,2025-01-07 09:46:26+00:00,[],2025-01-07 09:51:37+00:00,2025-01-07 09:51:37+00:00,https://github.com/apache/airflow/pull/45457,[],[],
2772334847,pull_request,closed,,Added ADR document describing why the notion of dialects was introduced in the common sql provider,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: [#41327](https://github.com/apache/airflow/pull/41327)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Added ADR document describing why the notion of dialects was introduced in the common sql provider.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2025-01-07 09:25:45+00:00,[],2025-01-27 12:55:45+00:00,2025-01-24 08:45:27+00:00,https://github.com/apache/airflow/pull/45456,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:common-sql', '')]","[{'comment_id': 2574792606, 'issue_id': 2772334847, 'author': 'dabla', 'body': '@potiuk @jscheffl As promised a document describing the dialects in common sql provider.  If any remarks or improvements are necessary please let me know.', 'created_at': datetime.datetime(2025, 1, 7, 9, 26, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2574906432, 'issue_id': 2772334847, 'author': 'eladkal', 'body': ""NIce! I think we are also missing user facing docs about what dialects are and how to use them (ADR is for Airflow developers to document our design choices but it's not really a user facing doc)"", 'created_at': datetime.datetime(2025, 1, 7, 10, 16, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575030319, 'issue_id': 2772334847, 'author': 'dabla', 'body': ""> NIce! I think we are also missing user facing docs about what dialects are and how to use them (ADR is for Airflow developers to document our design choices but it's not really a user facing doc)\r\n\r\nWhere should I put those user facing docs?  Is that under docs/apache-airflow-providers-common-sql?  Should I create a new dialects.rst document?"", 'created_at': datetime.datetime(2025, 1, 7, 11, 17, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575552411, 'issue_id': 2772334847, 'author': 'eladkal', 'body': '> Where should I put those user facing docs? Is that under docs/apache-airflow-providers-common-sql? Should I create a new dialects.rst document?\r\n\r\nYes. You dont have to create new .rst \r\nDepends on the scope of what you write. If its 1-2 pargraphs it might fit in the current rst we have.\r\nHowever you may want to mention in the providers we have dedicated dialect how to use it and link to the doc in common.sql so there may be need for doc changea in several providers', 'created_at': datetime.datetime(2025, 1, 7, 15, 16, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582244947, 'issue_id': 2772334847, 'author': 'eladkal', 'body': '@dabla do you intend to add the docs in this PR?', 'created_at': datetime.datetime(2025, 1, 10, 9, 56, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2582273539, 'issue_id': 2772334847, 'author': 'dabla', 'body': '> @dabla do you intend to add the docs in this PR?\r\n\r\nI just [committed ](https://github.com/apache/airflow/pull/45456/commits/3b78ec318097f90f03d65ea3ebe5d0ae1a3a8e5f) a new dialects.rst and adapted the index.rst this morning, what do you think about it?', 'created_at': datetime.datetime(2025, 1, 10, 10, 9, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593116034, 'issue_id': 2772334847, 'author': 'dabla', 'body': '> Sorry, ""late to the party"" now digging through my backlog... wanted to review earlier.\r\n> \r\n> I really like this and the description.\r\n> \r\n> For the docs build problem I see two options: (1) [not sure if this really works] outside the TOC create a small RST just with the heading and pointing to the other doctree - or (2) if you want to have exactly the same doc in each provider then use a symlink in GIT such that the RST is maintained in one place and each doctree has the same. (As long as we not move the providers the symlink is working in Sphinx)\r\n> \r\n> Can you add some example the the `dialects.rst` or is this already contained in the implementation PR?\r\n\r\nWill look into it.  I also opened another [PR](https://github.com/apache/airflow/pull/45640) related to this which fixes an issue with reserved words and special characters using the dialects.', 'created_at': datetime.datetime(2025, 1, 15, 15, 8, 45, tzinfo=datetime.timezone.utc)}, {'comment_id': 2593313183, 'issue_id': 2772334847, 'author': 'dabla', 'body': '> Sorry, ""late to the party"" now digging through my backlog... wanted to review earlier.\r\n> \r\n> I really like this and the description.\r\n> \r\n> For the docs build problem I see two options: (1) [not sure if this really works] outside the TOC create a small RST just with the heading and pointing to the other doctree - or (2) if you want to have exactly the same doc in each provider then use a symlink in GIT such that the RST is maintained in one place and each doctree has the same. (As long as we not move the providers the symlink is working in Sphinx)\r\n> \r\n> Can you add some example the the `dialects.rst` or is this already contained in the implementation PR?\r\n\r\nNot that found of symlinks, dunno how git will handle those.  Aren\'t http references an option?  I saw it\'s also used within rst.\r\n\r\nFor example (won\'t exist atm ofc):\r\n\r\n<https://airflow.apache.org/docs/apache-airflow-providers-common-sql/stable/dialects.html>', 'created_at': datetime.datetime(2025, 1, 15, 15, 57, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611789814, 'issue_id': 2772334847, 'author': 'dabla', 'body': ""@eladkal I've duplicated the dialects document in each provider, we can sort it out later as you mentioned"", 'created_at': datetime.datetime(2025, 1, 24, 7, 26, 54, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2025-01-07 09:26:44 UTC): @potiuk @jscheffl As promised a document describing the dialects in common sql provider.  If any remarks or improvements are necessary please let me know.

eladkal on (2025-01-07 10:16:43 UTC): NIce! I think we are also missing user facing docs about what dialects are and how to use them (ADR is for Airflow developers to document our design choices but it's not really a user facing doc)

dabla (Issue Creator) on (2025-01-07 11:17:44 UTC): Where should I put those user facing docs?  Is that under docs/apache-airflow-providers-common-sql?  Should I create a new dialects.rst document?

eladkal on (2025-01-07 15:16:57 UTC): Yes. You dont have to create new .rst 
Depends on the scope of what you write. If its 1-2 pargraphs it might fit in the current rst we have.
However you may want to mention in the providers we have dedicated dialect how to use it and link to the doc in common.sql so there may be need for doc changea in several providers

eladkal on (2025-01-10 09:56:55 UTC): @dabla do you intend to add the docs in this PR?

dabla (Issue Creator) on (2025-01-10 10:09:31 UTC): I just [committed ](https://github.com/apache/airflow/pull/45456/commits/3b78ec318097f90f03d65ea3ebe5d0ae1a3a8e5f) a new dialects.rst and adapted the index.rst this morning, what do you think about it?

dabla (Issue Creator) on (2025-01-15 15:08:45 UTC): Will look into it.  I also opened another [PR](https://github.com/apache/airflow/pull/45640) related to this which fixes an issue with reserved words and special characters using the dialects.

dabla (Issue Creator) on (2025-01-15 15:57:46 UTC): Not that found of symlinks, dunno how git will handle those.  Aren't http references an option?  I saw it's also used within rst.

For example (won't exist atm ofc):

<https://airflow.apache.org/docs/apache-airflow-providers-common-sql/stable/dialects.html>

dabla (Issue Creator) on (2025-01-24 07:26:54 UTC): @eladkal I've duplicated the dialects document in each provider, we can sort it out later as you mentioned

"
2772272779,pull_request,closed,,fix(cncf-kubernetes): correctly shutdown xcom after job is complete,"closes: #45452
related: #45053

I fixed a regression we encountered when upgrading to the latest cncf-kubernetes provider `10.1.0`

I got the following logs when using the original statement

```
docker run -u 1000 -it alpine sh # alpine container seems to be run under uid 1000 in kubernetes
sh -c trap ""exit 0"" INT; while true; do sleep 1; done;
````

```
kill -2 $(pgrep -u $(whoami) -f 'trap')
```

```
whoami
whoami: unknown uid 1000
```

```
pgrep -f 'trap' # returns no processes
```

instead with:

```
kill -2 $(pgrep -u $(id -u) -f 'sh')
```

it stops the processes as it should.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #45452
related: #45053

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kjuulh,2025-01-07 09:00:41+00:00,[],2025-01-27 13:01:40+00:00,2025-01-23 14:27:42+00:00,https://github.com/apache/airflow/pull/45455,"[('area:providers', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)'), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2574739853, 'issue_id': 2772272779, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 7, 9, 0, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2609953453, 'issue_id': 2772272779, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 23, 14, 28, 3, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-07 09:00:46 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

boring-cyborg[bot] on (2025-01-23 14:28:03 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2772249203,pull_request,closed,,AIP-84: update reset_dag_runs default value to true in clearTaskInstances endpoint request body,"While Testing `clearTaskInstances` endpoint in FastAPI I noticed after clearing tasks are in no status.

![image](https://github.com/user-attachments/assets/f82c48fe-942d-48b1-a871-bfc1c4238c29)



This was because `reset_dag_runs` in request body default value is set as False in FastAPI, however in Legacy API it is True.

LeagcyAPI
![image](https://github.com/user-attachments/assets/0d15b41e-97c3-4fae-af4e-f8b488fca2d8)

FastAPI
![image](https://github.com/user-attachments/assets/fbce23fd-27d3-4acf-8836-cd1a077ea786)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2025-01-07 08:51:18+00:00,[],2025-01-08 15:35:37+00:00,2025-01-08 15:35:34+00:00,https://github.com/apache/airflow/pull/45453,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2577920533, 'issue_id': 2772249203, 'author': 'vatsrahul1001', 'body': ""> I don't think that's the issue.\r\n> \r\n> If we look at the legacy schema => `ClearTaskInstanceFormSchema`, `reset_dag_runs = fields.Boolean(load_default=False)` default is `False`.\r\n> \r\n> The legacy specification file `v1.yaml` does not mention the default value (wrongly, it should), and therefore the example payload shows `True` as an example. This is confusing because that does not mean that the default value is `True` it's just an 'example value', for boolean it's `True` when there is no default.\r\n> \r\n> That being said. The difference you observe is coming from the fact that the legacy UI is not calling the public API (clearTaskInstances), but the private `clear` endpoint which works differently.\r\n\r\n@pierrejeambrun ok, however, I feel like it is better to use default as true instead of false because some users might just use an example request like I did which might result in this behaviour in which task are in no run state"", 'created_at': datetime.datetime(2025, 1, 8, 15, 14, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577972554, 'issue_id': 2772249203, 'author': 'pierrejeambrun', 'body': 'Of course, we can definitely update that if this feels more natural.\r\n\r\n\r\n> Note to myself: Add an entry to the breaking change list when merging that.', 'created_at': datetime.datetime(2025, 1, 8, 15, 34, 5, tzinfo=datetime.timezone.utc)}]","vatsrahul1001 (Issue Creator) on (2025-01-08 15:14:01 UTC): @pierrejeambrun ok, however, I feel like it is better to use default as true instead of false because some users might just use an example request like I did which might result in this behaviour in which task are in no run state

pierrejeambrun on (2025-01-08 15:34:05 UTC): Of course, we can definitely update that if this feels more natural.

"
2772205208,pull_request,open,,Allow check_response to be defined in extra_options of HTTP connection,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: [#45237](https://github.com/apache/airflow/issues/45237)
related: [#45237](https://github.com/apache/airflow/issues/45237)

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

This PR allows you to define the check_response option in the extra options fields of the HTTP connection so that you can disable the check globally for that connection instead of always having to pass it to each HttpOperator using that same connection id.

I also took the opportunity to refactor the get_conn method of the HttpHook so you can easily override the default host and default headers in the specialized hooks so those subclasses (e.g. LivyHook or DingdingHook) don't need to override the get_conn method anymore, otherwise as the signature has changed (e.g. added extra_options parameter) those has to be changed also and the exisiting solution wasn't DRY also, now it is.

In the past if you want to disable the response_check in the HttpHook through the HtpOperator, you had to define the HttpOperator like this:

```
validate_custom_fields_task = HttpOperator(
    task_id=""get_data"",
    method=""GET"",
    http_conn_id=""http_conn_id"",
    endpoint=""/endpoint"",
    headers={},
    response_check=response_check,
    extra_options={""check_response"": False},  # allows you to use the custom response_check instead of the HttpHook buildin check
    dag=dag,
)
```

Now thanks to this PR, you can define the check_response globally in the extra_options of the connection, so it will be applied to each HttpOperator using that connection.

![image](https://github.com/user-attachments/assets/d3941a28-f681-424a-96c2-907d207fe7b2)


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dabla,2025-01-07 08:30:24+00:00,[],2025-02-07 07:05:02+00:00,,https://github.com/apache/airflow/pull/45451,"[('area:providers', ''), ('provider:http', '')]","[{'comment_id': 2590071474, 'issue_id': 2772205208, 'author': 'dabla', 'body': ""@potiuk or @eladkal Could any of you have a look and check if this MR can be merged please?  It's a fix for issue [#45237](https://github.com/apache/airflow/issues/45237)"", 'created_at': datetime.datetime(2025, 1, 14, 14, 29, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2590610479, 'issue_id': 2772205208, 'author': 'potiuk', 'body': 'You will need to bump HTTP provider version to new minor and make the other providers depend on it, otherwise someone can install old version of HTTP provider and new version of (say) livy and it wil not work.', 'created_at': datetime.datetime(2025, 1, 14, 17, 16, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2592131290, 'issue_id': 2772205208, 'author': 'dabla', 'body': '> You will need to bump HTTP provider version to new minor and make the other providers depend on it, otherwise someone can install old version of HTTP provider and new version of (say) livy and it wil not work.\r\n\r\nOk thx @potiuk  bumped the version of the http, livy and dingding provider and made them dependent on version 5.0.1 of http provider.', 'created_at': datetime.datetime(2025, 1, 15, 9, 37, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2598148496, 'issue_id': 2772205208, 'author': 'dabla', 'body': '> You will need to bump HTTP provider version to new minor and make the other providers depend on it, otherwise someone can install old version of HTTP provider and new version of (say) livy and it wil not work.\r\n\r\nI\'ve bumped the http provider (in provider.yaml) but is it normal I have to modify the version manually in module as well?\r\n\r\n```\r\n@@ -29,7 +29,7 @@ from airflow import __version__ as airflow_version\r\n \r\n __all__ = [""__version__""]\r\n \r\n-__version__ = ""5.0.0""\r\n+__version__ = ""5.0.1""\r\n```\r\n\r\nMaybe it\'s because I can\'t use the pre-commits on my Windows machine.', 'created_at': datetime.datetime(2025, 1, 17, 11, 24, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2631671650, 'issue_id': 2772205208, 'author': 'pierrejeambrun', 'body': 'I think something went wrong with the branch. Maybe a bad rebase or something, can you check and clean the branch please ?', 'created_at': datetime.datetime(2025, 2, 3, 17, 48, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2636348657, 'issue_id': 2772205208, 'author': 'eladkal', 'body': 'Note on the [error message](https://github.com/apache/airflow/actions/runs/13155177849/job/36710627700?pr=45451#step:10:198) in the CI:\r\n\r\n> There is a need to regenerate /home/runner/work/airflow/airflow/generated/provider_dependencies.json\r\n> You need to run the following command locally and commit generated generated/provider_dependencies.json file:\r\n> \r\n> breeze static-checks --type update-providers-dependencies --all-files\r\n> \r\n\r\n\r\nThere should be changes also to the `provider_dependencies.json` which breeze do automatically and it should be committed as part of your PR.', 'created_at': datetime.datetime(2025, 2, 5, 10, 33, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2636535624, 'issue_id': 2772205208, 'author': 'dabla', 'body': ""> Note on the [error message](https://github.com/apache/airflow/actions/runs/13155177849/job/36710627700?pr=45451#step:10:198) in the CI:\r\n> \r\n> > There is a need to regenerate /home/runner/work/airflow/airflow/generated/provider_dependencies.json\r\n> > You need to run the following command locally and commit generated generated/provider_dependencies.json file:\r\n> > breeze static-checks --type update-providers-dependencies --all-files\r\n> \r\n> There should be changes also to the `provider_dependencies.json` which breeze do automatically and it should be committed as part of your PR.\r\n\r\nYes I know but cannot run breeze directly from my Windows machine, so I have to switch to generate it, I'll try to do it asap ;-)"", 'created_at': datetime.datetime(2025, 2, 5, 12, 0, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2642098292, 'issue_id': 2772205208, 'author': 'eladkal', 'body': 'Tests are failing\r\n```\r\nFAILED providers/http/tests/provider_tests/http/sensors/test_http.py::TestHttpOpSensor::test_get - airflow.exceptions.AirflowException: 404:NOT FOUND\r\nFAILED providers/http/tests/provider_tests/http/sensors/test_http.py::TestHttpOpSensor::test_get_response_check - airflow.exceptions.AirflowException: 404:NOT FOUND\r\nFAILED providers/http/tests/provider_tests/http/sensors/test_http.py::TestHttpOpSensor::test_sensor - airflow.exceptions.AirflowSensorTimeout: Sensor has timed out; run duration of 15.730223178863525 seconds exceeds the specified timeout of 15.0.\r\n```', 'created_at': datetime.datetime(2025, 2, 7, 7, 5, 1, tzinfo=datetime.timezone.utc)}]","dabla (Issue Creator) on (2025-01-14 14:29:21 UTC): @potiuk or @eladkal Could any of you have a look and check if this MR can be merged please?  It's a fix for issue [#45237](https://github.com/apache/airflow/issues/45237)

potiuk on (2025-01-14 17:16:10 UTC): You will need to bump HTTP provider version to new minor and make the other providers depend on it, otherwise someone can install old version of HTTP provider and new version of (say) livy and it wil not work.

dabla (Issue Creator) on (2025-01-15 09:37:29 UTC): Ok thx @potiuk  bumped the version of the http, livy and dingding provider and made them dependent on version 5.0.1 of http provider.

dabla (Issue Creator) on (2025-01-17 11:24:17 UTC): I've bumped the http provider (in provider.yaml) but is it normal I have to modify the version manually in module as well?

```
@@ -29,7 +29,7 @@ from airflow import __version__ as airflow_version
 
 __all__ = [""__version__""]
 
-__version__ = ""5.0.0""
+__version__ = ""5.0.1""
```

Maybe it's because I can't use the pre-commits on my Windows machine.

pierrejeambrun on (2025-02-03 17:48:22 UTC): I think something went wrong with the branch. Maybe a bad rebase or something, can you check and clean the branch please ?

eladkal on (2025-02-05 10:33:39 UTC): Note on the [error message](https://github.com/apache/airflow/actions/runs/13155177849/job/36710627700?pr=45451#step:10:198) in the CI:



There should be changes also to the `provider_dependencies.json` which breeze do automatically and it should be committed as part of your PR.

dabla (Issue Creator) on (2025-02-05 12:00:36 UTC): Yes I know but cannot run breeze directly from my Windows machine, so I have to switch to generate it, I'll try to do it asap ;-)

eladkal on (2025-02-07 07:05:01 UTC): Tests are failing
```
FAILED providers/http/tests/provider_tests/http/sensors/test_http.py::TestHttpOpSensor::test_get - airflow.exceptions.AirflowException: 404:NOT FOUND
FAILED providers/http/tests/provider_tests/http/sensors/test_http.py::TestHttpOpSensor::test_get_response_check - airflow.exceptions.AirflowException: 404:NOT FOUND
FAILED providers/http/tests/provider_tests/http/sensors/test_http.py::TestHttpOpSensor::test_sensor - airflow.exceptions.AirflowSensorTimeout: Sensor has timed out; run duration of 15.730223178863525 seconds exceeds the specified timeout of 15.0.
```

"
2772044934,pull_request,closed,,AIP-72: Exposing 'extra_dejson' on Connection definition,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


closes: https://github.com/apache/airflow/issues/45443

Connection model supports `extra_dejson` which is a deserialised value of `extra` as a python dictionary: https://airflow.apache.org/docs/apache-airflow/stable/templates-ref.html#airflow-connections-in-templates

For AIP 72 and enablement of multi language support, we should have this lie in the task sdk side, so that the API client and server cleanly only communicate in JSON strings and the responsibility of deserialising and serialising lies on the client whilst sending to task sdk.

### Testing

DAG:
```
from __future__ import annotations

from airflow.models.baseoperator import BaseOperator
from airflow.models.dag import dag


class CustomOperator(BaseOperator):
    def execute(self, context):
        import os
        task_id = context[""task_instance""].task_id
        print(f""Hello World {task_id}!"")
        print(context)
        print(context[""conn""].airflow_db)
        print(context[""conn""].airflow_db.extra_dejson)



@dag()
def super_basic_run():
    CustomOperator(task_id=""hello"")


super_basic_run()

```

Steps:
1. In the existing connections, edited the `airflow_db` to add extra: 
![image](https://github.com/user-attachments/assets/cf2ce5b4-f4fe-4778-86b0-dba7c50c16b5)

2. Added `extra` as:
```
{
  ""extra-key"": ""value""
}
```

3. Ran the DAG to see results
![image](https://github.com/user-attachments/assets/d8859a70-ea5c-43a4-910c-b322c0e1e8bc)


4. Logs:
```
92aebea29925
 ▶ Log message source details
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2025-01-07T04:30:47.832247"",""event"":""Filling up the DagBag from /files/dags/conn_from_context.py"",""level"":""info""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2025-01-07T04:30:47.832785"",""event"":""Importing /files/dags/conn_from_context.py"",""level"":""debug""}
{""logger"":""airflow.models.dagbag.DagBag"",""timestamp"":""2025-01-07T04:30:47.835806"",""event"":""Loaded DAG <DAG: super_basic_run>"",""level"":""debug""}
{""file"":""/files/dags/conn_from_context.py"",""timestamp"":""2025-01-07T04:30:47.835971"",""logger"":""task"",""event"":""DAG file parsed"",""level"":""debug""}
{""logger"":""airflow.task.operators.unusual_prefix_0743271d82731f02d7e57e687278453c55c78854_conn_from_context.CustomOperator"",""timestamp"":""2025-01-07T04:30:47.860640"",""event"":""CustomOperator.execute cannot be called outside TaskInstance!"",""level"":""warning""}
{""json"":""{\""conn_id\"":\""airflow_db\"",\""type\"":\""GetConnection\""}\n"",""timestamp"":""2025-01-07T04:30:47.860845"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""chan"":""stdout"",""event"":""Hello World hello!"",""timestamp"":""2025-01-07T04:30:47.861110Z"",""level"":""info"",""logger"":""task""}
{""chan"":""stdout"",""event"":""{'dag': <DAG: super_basic_run>, 'inlets': [], 'map_index_template': None, 'outlets': [], 'run_id': 'manual__2025-01-07T04:30:47.499291+00:00', 'task': <Task(CustomOperator): hello>, 'task_instance': RuntimeTaskInstance(id=UUID('01943f07-8edc-7c2b-8de6-9a0a8e9c9129'), task_id='hello', dag_id='super_basic_run', run_id='manual__2025-01-07T04:30:47.499291+00:00', try_number=1, map_index=-1, task=<Task(CustomOperator): hello>), 'ti': RuntimeTaskInstance(id=UUID('01943f07-8edc-7c2b-8de6-9a0a8e9c9129'), task_id='hello', dag_id='super_basic_run', run_id='manual__2025-01-07T04:30:47.499291+00:00', try_number=1, map_index=-1, task=<Task(CustomOperator): hello>), 'conn': <ConnectionAccessor (dynamic access)>, 'dag_run': DagRun(dag_id='super_basic_run', run_id='manual__2025-01-07T04:30:47.499291+00:00', logical_date=datetime.datetime(2025, 1, 7, 4, 30, 47, 499291, tzinfo=TzInfo(UTC)), data_interval_start=datetime.datetime(2025, 1, 7, 4, 30, 47, 499291, tzinfo=TzInfo(UTC)), data_interval_end=datetime.datetime(2025, 1, 7, 4, 30, 47, 499291, tzinfo=TzInfo(UTC)), start_date=datetime.datetime(2025, 1, 7, 4, 30, 47, 669611, tzinfo=TzInfo(UTC)), end_date=None, run_type=<DagRunType.MANUAL: 'manual'>, conf={}), 'data_interval_end': datetime.datetime(2025, 1, 7, 4, 30, 47, 499291, tzinfo=TzInfo(UTC)), 'data_interval_start': datetime.datetime(2025, 1, 7, 4, 30, 47, 499291, tzinfo=TzInfo(UTC)), 'logical_date': datetime.datetime(2025, 1, 7, 4, 30, 47, 499291, tzinfo=TzInfo(UTC)), 'ds': '2025-01-07', 'ds_nodash': '20250107', 'task_instance_key_str': 'super_basic_run__hello__20250107', 'ts': '2025-01-07T04:30:47.499291+00:00', 'ts_nodash': '20250107T043047', 'ts_nodash_with_tz': '20250107T043047.499291+0000'}"",""timestamp"":""2025-01-07T04:30:47.861187Z"",""level"":""info"",""logger"":""task""}
{""chan"":""stdout"",""event"":""Connection(conn_id='airflow_db', conn_type='mysql', description=None, host='mysql', schema=None, login='root', password=None, port=None, extra='{\""extra-key\"": \""value\""}')"",""timestamp"":""2025-01-07T04:30:47.870231Z"",""level"":""info"",""logger"":""task""}
{""json"":""{\""conn_id\"":\""airflow_db\"",\""type\"":\""GetConnection\""}\n"",""timestamp"":""2025-01-07T04:30:47.870365"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
{""chan"":""stdout"",""event"":""{'extra-key': 'value'}"",""timestamp"":""2025-01-07T04:30:47.875280Z"",""level"":""info"",""logger"":""task""}
{""json"":""{\""state\"":\""success\"",\""end_date\"":\""2025-01-07T04:30:47.874890Z\"",\""type\"":\""TaskState\""}\n"",""timestamp"":""2025-01-07T04:30:47.874957"",""logger"":""task"",""event"":""Sending request"",""level"":""debug""}
```


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-07 06:57:49+00:00,['amoghrajesh'],2025-01-07 16:59:38+00:00,2025-01-07 16:59:35+00:00,https://github.com/apache/airflow/pull/45448,"[('area:task-sdk', None)]","[{'comment_id': 2575500718, 'issue_id': 2772044934, 'author': 'amoghrajesh', 'body': 'The failure was due to a timeout. Retriggering', 'created_at': datetime.datetime(2025, 1, 7, 14, 55, 11, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2025-01-07 14:55:11 UTC): The failure was due to a timeout. Retriggering

"
2771683369,pull_request,closed,,Added ability to pass namespace to hashicorp vault,"Adding the ability to pass a namespace from backend kwargs to the vault client.

Closes : #45413 

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",davidsharp7,2025-01-07 00:47:45+00:00,[],2025-01-07 09:00:11+00:00,2025-01-07 09:00:11+00:00,https://github.com/apache/airflow/pull/45445,"[('area:providers', ''), ('provider:hashicorp', 'Hashicorp provider related issues')]","[{'comment_id': 2574182469, 'issue_id': 2771683369, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 7, 0, 47, 49, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-07 00:47:49 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

"
2771605484,pull_request,closed,,AIP-72: Add Taskflow API support & template rendering in Task SDK,"closes https://github.com/apache/airflow/issues/45232
part of https://github.com/apache/airflow/issues/44481

The Templater class has been moved to the Task SDK to align with the language-specific aspects of template rendering. Templating logic is inherently tied to Python constructs. By keeping the Templater class within the Task SDK, we ensure that the core templating logic remains coupled with language-specific implementations.

Options I had were keeping it on the Schdeuler or the Execution side of Task SDK, neither of which is ideal as we would want to change the code in definition like DAG, Operator alongwith how it renders.

With [`tutorial_taskflow_api`](https://github.com/apache/airflow/blob/5581e65fd5575364fbf2c0e5c8cf4f4afe2b841b/airflow/example_dags/tutorial_taskflow_api.py#L38):

<img width=""1705"" alt=""image"" src=""https://github.com/user-attachments/assets/c84327ed-5956-4f48-ab32-97a77ae44016"" />

---
With [`example_xcom_args`](https://github.com/apache/airflow/blob/5581e65fd5575364fbf2c0e5c8cf4f4afe2b841b/airflow/example_dags/example_xcomargs.py):

<img width=""1720"" alt=""image"" src=""https://github.com/user-attachments/assets/f9e0190f-1030-437d-ab6b-8247a5f8cdb0"" />


<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kaxil,2025-01-06 23:19:08+00:00,[],2025-01-07 09:38:20+00:00,2025-01-07 09:38:19+00:00,https://github.com/apache/airflow/pull/45444,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues'), ('provider:standard', ''), ('area:task-execution-interface-aip72', 'AIP-72: Task Execution Interface (TEI) aka Task SDK'), ('area:task-sdk', None)]",[],
2771593787,pull_request,closed,,Restrict marshmallow==3.23,"It looks like marshmallow==3.24 introduced the breaking changes to 
https://github.com/marshmallow-code/marshmallow/blob/dev/CHANGELOG.rst#3240-2025-01-06

`Field <marshmallow.fields.Field>, Mapping <marshmallow.fields.Mapping>, and Number <marshmallow.fields.Number> should no longer be used as fields within schemas. Use their subclasses instead.`
Likely this PR https://github.com/marshmallow-code/marshmallow/pull/2723 

We use  <marshmallow.fields.Number>  in https://github.com/apache/airflow/blob/main/airflow/api_connexion/schemas/task_schema.py#L51. Likely these updates required? 


CI is failing https://github.com/apache/airflow/actions/runs/12639019672/job/35217178280#step:6:4004
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-06 23:06:33+00:00,[],2025-01-08 23:29:02+00:00,2025-01-07 03:39:02+00:00,https://github.com/apache/airflow/pull/45442,[],"[{'comment_id': 2574245619, 'issue_id': 2771593787, 'author': 'amoghrajesh', 'body': 'The failure seems to be due to flakiness, retriggered.', 'created_at': datetime.datetime(2025, 1, 7, 1, 58, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2574683564, 'issue_id': 2771593787, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2025, 1, 7, 8, 35, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2576779839, 'issue_id': 2771593787, 'author': 'emorikawa', 'body': ""@gopidesupavan thank you for finding and fixing this. The effect of marshmallow's breaking change was significant for me\r\n\r\nSince this does schema validation, this effectively caused all of my Airflow API requests to suddenly start 400'ing on my next deploy (deploys re pip-install things when the container is rebuilt).\r\n\r\nI have business critical functions that depend on programatically launching DAGs. All of those broke suddenly."", 'created_at': datetime.datetime(2025, 1, 8, 5, 23, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578324005, 'issue_id': 2771593787, 'author': 'sloria', 'body': ""marshmallow 3.24 doesn't actually have a breaking change: it only raises warnings for usages that are changed or removed in 4.0.\r\n\r\nThe issue is that marshmallow-sqlalchemy (a dependency of Flask-AppBuilder) needs to be upgraded to version 1.1.1 to work correctly with marshmallow. So I think this should be fixed by relaxing the version constraint here: https://github.com/dpgaspar/Flask-AppBuilder/blob/418ab8a93907669be4ccbb99d7aefa5283f3e013/setup.py#L61 \r\n\r\nOnce I get my Flask-AppBuilder dev environment set up, I can send a PR with that change"", 'created_at': datetime.datetime(2025, 1, 8, 18, 14, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578832490, 'issue_id': 2771593787, 'author': 'potiuk', 'body': '> The issue is that marshmallow-sqlalchemy (a dependency of Flask-AppBuilder) needs to be upgraded to version 1.1.1 to work correctly with marshmallow. So I think this should be fixed by relaxing the version constraint here: https://github.com/dpgaspar/Flask-AppBuilder/blob/418ab8a93907669be4ccbb99d7aefa5283f3e013/setup.py#L61\r\n\r\nNice find . Thanks for following it up!', 'created_at': datetime.datetime(2025, 1, 8, 22, 53, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578861812, 'issue_id': 2771593787, 'author': 'sloria', 'body': ""i just released marshmallow 3.24.2, which fixes compatibility with older marshmallow-sqlalchemy. so we no longer need to wait for Flask-AppBuilder. https://github.com/apache/airflow/pull/45499 reverts this as it's no longer be necessary to pin marshmallow"", 'created_at': datetime.datetime(2025, 1, 8, 23, 17, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2578873375, 'issue_id': 2771593787, 'author': 'potiuk', 'body': ""> i just released marshmallow 3.24.2, which fixes compatibility with older marshmallow-sqlalchemy. so we no longer need to wait for Flask-AppBuilder. #45499 reverts this as it's no longer be necessary to pin marshmallow\r\n\r\nCool. I rebased the PR and added legacy api label - let's see if all tests pass :)"", 'created_at': datetime.datetime(2025, 1, 8, 23, 29, 1, tzinfo=datetime.timezone.utc)}]","amoghrajesh on (2025-01-07 01:58:51 UTC): The failure seems to be due to flakiness, retriggered.

potiuk on (2025-01-07 08:35:12 UTC): Nice!

emorikawa on (2025-01-08 05:23:38 UTC): @gopidesupavan thank you for finding and fixing this. The effect of marshmallow's breaking change was significant for me

Since this does schema validation, this effectively caused all of my Airflow API requests to suddenly start 400'ing on my next deploy (deploys re pip-install things when the container is rebuilt).

I have business critical functions that depend on programatically launching DAGs. All of those broke suddenly.

sloria on (2025-01-08 18:14:44 UTC): marshmallow 3.24 doesn't actually have a breaking change: it only raises warnings for usages that are changed or removed in 4.0.

The issue is that marshmallow-sqlalchemy (a dependency of Flask-AppBuilder) needs to be upgraded to version 1.1.1 to work correctly with marshmallow. So I think this should be fixed by relaxing the version constraint here: https://github.com/dpgaspar/Flask-AppBuilder/blob/418ab8a93907669be4ccbb99d7aefa5283f3e013/setup.py#L61 

Once I get my Flask-AppBuilder dev environment set up, I can send a PR with that change

potiuk on (2025-01-08 22:53:10 UTC): Nice find . Thanks for following it up!

sloria on (2025-01-08 23:17:38 UTC): i just released marshmallow 3.24.2, which fixes compatibility with older marshmallow-sqlalchemy. so we no longer need to wait for Flask-AppBuilder. https://github.com/apache/airflow/pull/45499 reverts this as it's no longer be necessary to pin marshmallow

potiuk on (2025-01-08 23:29:01 UTC): Cool. I rebased the PR and added legacy api label - let's see if all tests pass :)

"
2771349528,pull_request,closed,,Do not use core Airflow Flask related resources in FAB provider,"As part of AIP-79.

The Flask application in FAB provider should not use any Flask related resources from core Airflow. Otherwise, deleting the main Flask application in core Airflow when the legacy Airflow 2 is gone will be impossible.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vincbeck,2025-01-06 20:01:14+00:00,[],2025-01-13 11:14:33+00:00,2025-01-07 16:00:49+00:00,https://github.com/apache/airflow/pull/45441,"[('area:webserver', 'Webserver related Issues'), ('area:providers', ''), ('provider:fab', '')]",[],
2771029800,pull_request,closed,,Bump trove-classifiers from 2024.10.21.16 to 2025.1.6.15,"Bumps [trove-classifiers](https://github.com/pypa/trove-classifiers) from 2024.10.21.16 to 2025.1.6.15.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/pypa/trove-classifiers/commit/82307b3772085ca434c4e5cf13192ea6aaac21b5""><code>82307b3</code></a> Add term for quantum computing (<a href=""https://redirect.github.com/pypa/trove-classifiers/issues/201"">#201</a>)</li>
<li>See full diff in <a href=""https://github.com/pypa/trove-classifiers/compare/2024.10.21.16...2025.1.6.15"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=trove-classifiers&package-manager=pip&previous-version=2024.10.21.16&new-version=2025.1.6.15)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2025-01-06 16:40:37+00:00,[],2025-01-06 17:52:11+00:00,2025-01-06 17:52:01+00:00,https://github.com/apache/airflow/pull/45439,"[('area:dependencies', 'Issues related to dependencies problems')]",[],
2770681443,pull_request,closed,,AIP-38 Improve clear dagrun table display for long task display names,"Long task display name are an issue because they overflow-x the table and make other columns wrap, which isn't great for the display. Also it doesn't bring much because that column is already a 'link' so we can just click on it to land on the full task instance detail page.

Before:
![Screenshot 2025-01-06 at 14 33 41](https://github.com/user-attachments/assets/d8f7f5ae-0269-4f62-9e4e-53034e7a24c9)

After:
![Screenshot 2025-01-06 at 16 29 38](https://github.com/user-attachments/assets/bfd9f665-0003-41ef-b463-45e885c537e2)
",pierrejeambrun,2025-01-06 13:37:30+00:00,['pierrejeambrun'],2025-01-06 16:31:47+00:00,2025-01-06 16:31:45+00:00,https://github.com/apache/airflow/pull/45437,"[('AIP-38', 'Modern Web Application')]",[],
2770654521,pull_request,closed,,AIP-38 Ability to update note when clearing a DagRun,"related to: https://github.com/apache/airflow/issues/44859

Adds the ability to write/update the note of the DagRun that is being cleared.

![Screenshot 2025-01-06 at 14 21 51](https://github.com/user-attachments/assets/a3c8cf18-a8ef-497e-982f-34910c6801bd)
![Screenshot 2025-01-06 at 14 24 26](https://github.com/user-attachments/assets/ddf64569-4686-42c2-9772-238247d30689)

![Screenshot 2025-01-06 at 14 22 28](https://github.com/user-attachments/assets/6e7343d3-e2c7-4eb7-810b-7ed965138a8c)
![Screenshot 2025-01-06 at 14 22 38](https://github.com/user-attachments/assets/aba6863f-ef99-4e78-8dfe-4494e9fff7f3)
![Screenshot 2025-01-06 at 14 22 57](https://github.com/user-attachments/assets/7567fbb1-d9af-4bb8-a615-71b4fbd6c9ff)


",pierrejeambrun,2025-01-06 13:23:05+00:00,['pierrejeambrun'],2025-01-07 12:10:34+00:00,2025-01-07 12:10:32+00:00,https://github.com/apache/airflow/pull/45434,"[('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-38', 'Modern Web Application')]","[{'comment_id': 2573108917, 'issue_id': 2770654521, 'author': 'pierrejeambrun', 'body': ""As a follow up I will:\r\n- Fix the markdown rendering. Because of the ChakraUI CSS reset, things are not rendered properly, i.e\r\n![Screenshot 2025-01-06 at 14 25 52](https://github.com/user-attachments/assets/702a19a9-b770-417b-8182-4ad805b044f8)\r\n- Fix the header of the task instance to not display directly the note but a button to show it in a full modal, because long markdown notes won't display nicely in the header.\r\n![Screenshot 2025-01-06 at 14 27 10](https://github.com/user-attachments/assets/12ca92e9-70f3-466b-8c88-b6b546ebdcc1)"", 'created_at': datetime.datetime(2025, 1, 6, 13, 26, 33, tzinfo=datetime.timezone.utc)}]","pierrejeambrun (Issue Creator) on (2025-01-06 13:26:33 UTC): As a follow up I will:
- Fix the markdown rendering. Because of the ChakraUI CSS reset, things are not rendered properly, i.e
![Screenshot 2025-01-06 at 14 25 52](https://github.com/user-attachments/assets/702a19a9-b770-417b-8182-4ad805b044f8)
- Fix the header of the task instance to not display directly the note but a button to show it in a full modal, because long markdown notes won't display nicely in the header.
![Screenshot 2025-01-06 at 14 27 10](https://github.com/user-attachments/assets/12ca92e9-70f3-466b-8c88-b6b546ebdcc1)

"
2770631179,pull_request,open,,remove unnecessary if statement because weight rule cannot be none,"
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",romsharon98,2025-01-06 13:10:33+00:00,[],2025-01-06 13:39:48+00:00,,https://github.com/apache/airflow/pull/45433,[],[],
2770575533,pull_request,closed,,AIP-72: Allow retrieving Variable from Task Context,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #45421

### Summary of changes

1. Added a minimal `Variable` user-facing definition which will be used in DAG files by DAG authors
2. Added logic to get Variables in the context - both in ""value"" and ""json"" format
- ""value"" is the raw form
- ""json"" is the deserialised json form, we are trying to keep the contract between SDK and API server simple, they interact only in strings and the responsibility of serialising + deserialising lies on the client before sending it to the task sdk, not on the API server. This will enable multi language support too.

#### Object Glossary
-`VariableResponse` is auto-generated and tightly coupled with the API schema.
-`VariableResult` is runtime-specific and meant for internal communication between Supervisor & Task Runner.
-`Variable` class here is where the public-facing, user-relevant aspects are exposed, hiding internal details.


### Testing
DAG:
```
from __future__ import annotations

from airflow.models.baseoperator import BaseOperator
from airflow.models.dag import dag


class CustomOperator(BaseOperator):
    def execute(self, context):
        import os
        os.environ[""AIRFLOW_VAR_HI_MESSAGE""] = ""hello_world""
        os.environ[""AIRFLOW_VAR_JSON_VAR""] = ""{\r\n  \""key1\"": \""value1\"",\r\n  \""key2\"": \""value2\"",\r\n  \""enabled\"": true,\r\n  \""threshold\"": 42\r\n}""
        task_id = context[""task_instance""].task_id
        print(f""Hello World {task_id}!"")
        print(context)
        print(context[""var""][""value""].hi_message)
        print(context[""var""][""json""].json_var)


@dag()
def var_from_context():
    CustomOperator(task_id=""hello"")


var_from_context()

```

This dag tests both the scenarios of a regular `value` context as well as `json`.

#### Case1: Variables found
![image](https://github.com/user-attachments/assets/ba946112-4682-414d-a2ad-99a985193c7a)


Logs:
```
2c27ff9a5949
 ▶ Log message source details
2025-01-06 12:37:34.612546 [info     ] Filling up the DagBag from /files/dags/var_from_context.py [airflow.models.dagbag.DagBag]
2025-01-06 12:37:34.613168 [debug    ] Importing /files/dags/var_from_context.py [airflow.models.dagbag.DagBag]
2025-01-06 12:37:34.616934 [debug    ] Loaded DAG <DAG: var_from_context> [airflow.models.dagbag.DagBag]
2025-01-06 12:37:34.617131 [debug    ] DAG file parsed                [task] file=/files/dags/var_from_context.py
2025-01-06 12:37:34.641905 [warning  ] CustomOperator.execute cannot be called outside TaskInstance! [airflow.task.operators.unusual_prefix_c6632fd34e048ff55a9057c21ee5a54c16b99828_var_from_context.CustomOperator]
2025-01-06 12:37:34.642284 [info     ] Hello World hello!             [task] chan=stdout
2025-01-06 12:37:34.642393 [info     ] {'dag': <DAG: var_from_context>, 'inlets': [], 'map_index_template': None, 'outlets': [], 'run_id': 'manual__2025-01-06T12:37:34.037857+00:00', 'task': <Task(CustomOperator): hello>, 'task_instance': RuntimeTaskInstance(id=UUID('01943b9e-dadf-72eb-a47b-6c36e0fea3b7'), task_id='hello', dag_id='var_from_context', run_id='manual__2025-01-06T12:37:34.037857+00:00', try_number=1, map_index=-1, task=<Task(CustomOperator): hello>), 'ti': RuntimeTaskInstance(id=UUID('01943b9e-dadf-72eb-a47b-6c36e0fea3b7'), task_id='hello', dag_id='var_from_context', run_id='manual__2025-01-06T12:37:34.037857+00:00', try_number=1, map_index=-1, task=<Task(CustomOperator): hello>), 'var': {'json': <VariableAccessor (dynamic access)>, 'value': <VariableAccessor (dynamic access)>}, 'conn': <ConnectionAccessor (dynamic access)>, 'dag_run': DagRun(dag_id='var_from_context', run_id='manual__2025-01-06T12:37:34.037857+00:00', logical_date=datetime.datetime(2025, 1, 6, 12, 37, 34, 37857, tzinfo=TzInfo(UTC)), data_interval_start=datetime.datetime(2025, 1, 6, 12, 37, 34, 37857, tzinfo=TzInfo(UTC)), data_interval_end=datetime.datetime(2025, 1, 6, 12, 37, 34, 37857, tzinfo=TzInfo(UTC)), start_date=datetime.datetime(2025, 1, 6, 12, 37, 34, 492777, tzinfo=TzInfo(UTC)), end_date=None, run_type=<DagRunType.MANUAL: 'manual'>, conf={}), 'data_interval_end': datetime.datetime(2025, 1, 6, 12, 37, 34, 37857, tzinfo=TzInfo(UTC)), 'data_interval_start': datetime.datetime(2025, 1, 6, 12, 37, 34, 37857, tzinfo=TzInfo(UTC)), 'logical_date': datetime.datetime(2025, 1, 6, 12, 37, 34, 37857, tzinfo=TzInfo(UTC)), 'ds': '2025-01-06', 'ds_nodash': '20250106', 'task_instance_key_str': 'var_from_context__hello__20250106', 'ts': '2025-01-06T12:37:34.037857+00:00', 'ts_nodash': '20250106T123734', 'ts_nodash_with_tz': '20250106T123734.037857+0000'} [task] chan=stdout
2025-01-06 12:37:34.642268 [debug    ] Sending request                [task] json={""key"":""hi_message"",""type"":""GetVariable""}

2025-01-06 12:37:34.648998 [info     ] Variable(key='hi_message', value='hello_world', description=None) [task] chan=stdout
2025-01-06 12:37:34.649000 [debug    ] Sending request                [task] json={""key"":""json_var"",""type"":""GetVariable""}

2025-01-06 12:37:34.652506 [warning  ] Pydantic serializer warnings:
  Expected `str` but got `dict` with value `{'api_key': '12345', 'region': 'us-east-1'}` - serialized value may not be as expected [py.warnings] category=UserWarning filename=/usr/local/lib/python3.9/site-packages/pydantic/main.py lineno=426
2025-01-06 12:37:34.652586 [debug    ] Sending request                [task] json={""state"":""success"",""end_date"":""2025-01-06T12:37:34.652550Z"",""type"":""TaskState""}

2025-01-06 12:37:34.652845 [info     ] Variable(key='json_var', value={'api_key': '12345', 'region': 'us-east-1'}, description=None) [task] chan=stdout
```

#### Case 2: Variable not found
![image](https://github.com/user-attachments/assets/a400b1ea-7679-428d-8d23-3b266e2aa704)


Logs:
```
2c27ff9a5949
 ▶ Log message source details
2025-01-06 12:34:57.712062 [info     ] Filling up the DagBag from /files/dags/var_from_context.py [airflow.models.dagbag.DagBag]
2025-01-06 12:34:57.712579 [debug    ] Importing /files/dags/var_from_context.py [airflow.models.dagbag.DagBag]
2025-01-06 12:34:57.717120 [debug    ] Loaded DAG <DAG: var_from_context> [airflow.models.dagbag.DagBag]
2025-01-06 12:34:57.717434 [debug    ] DAG file parsed                [task] file=/files/dags/var_from_context.py
2025-01-06 12:34:57.743903 [warning  ] CustomOperator.execute cannot be called outside TaskInstance! [airflow.task.operators.unusual_prefix_c6632fd34e048ff55a9057c21ee5a54c16b99828_var_from_context.CustomOperator]
2025-01-06 12:34:57.744163 [info     ] Hello World hello!             [task] chan=stdout
2025-01-06 12:34:57.744270 [info     ] {'dag': <DAG: var_from_context>, 'inlets': [], 'map_index_template': None, 'outlets': [], 'run_id': 'manual__2025-01-06T12:34:56.856856+00:00', 'task': <Task(CustomOperator): hello>, 'task_instance': RuntimeTaskInstance(id=UUID('01943b9c-74e4-7b93-ba7e-7401dde98944'), task_id='hello', dag_id='var_from_context', run_id='manual__2025-01-06T12:34:56.856856+00:00', try_number=1, map_index=-1, task=<Task(CustomOperator): hello>), 'ti': RuntimeTaskInstance(id=UUID('01943b9c-74e4-7b93-ba7e-7401dde98944'), task_id='hello', dag_id='var_from_context', run_id='manual__2025-01-06T12:34:56.856856+00:00', try_number=1, map_index=-1, task=<Task(CustomOperator): hello>), 'var': {'json': <VariableAccessor (dynamic access)>, 'value': <VariableAccessor (dynamic access)>}, 'conn': <ConnectionAccessor (dynamic access)>, 'dag_run': DagRun(dag_id='var_from_context', run_id='manual__2025-01-06T12:34:56.856856+00:00', logical_date=datetime.datetime(2025, 1, 6, 12, 34, 56, 856856, tzinfo=TzInfo(UTC)), data_interval_start=datetime.datetime(2025, 1, 6, 12, 34, 56, 856856, tzinfo=TzInfo(UTC)), data_interval_end=datetime.datetime(2025, 1, 6, 12, 34, 56, 856856, tzinfo=TzInfo(UTC)), start_date=datetime.datetime(2025, 1, 6, 12, 34, 57, 589490, tzinfo=TzInfo(UTC)), end_date=None, run_type=<DagRunType.MANUAL: 'manual'>, conf={}), 'data_interval_end': datetime.datetime(2025, 1, 6, 12, 34, 56, 856856, tzinfo=TzInfo(UTC)), 'data_interval_start': datetime.datetime(2025, 1, 6, 12, 34, 56, 856856, tzinfo=TzInfo(UTC)), 'logical_date': datetime.datetime(2025, 1, 6, 12, 34, 56, 856856, tzinfo=TzInfo(UTC)), 'ds': '2025-01-06', 'ds_nodash': '20250106', 'task_instance_key_str': 'var_from_context__hello__20250106', 'ts': '2025-01-06T12:34:56.856856+00:00', 'ts_nodash': '20250106T123456', 'ts_nodash_with_tz': '20250106T123456.856856+0000'} [task] chan=stdout
2025-01-06 12:34:57.744177 [debug    ] Sending request                [task] json={""key"":""hi_message"",""type"":""GetVariable""}

2025-01-06 12:34:57.749149 [debug    ] Sending request                [task] json={""state"":""failed"",""end_date"":""2025-01-06T12:34:57.749108Z"",""type"":""TaskState""}

```


TODO:
- [x] Writing variables from task SDK


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-06 12:39:19+00:00,[],2025-01-07 06:05:45+00:00,2025-01-07 06:05:43+00:00,https://github.com/apache/airflow/pull/45431,"[('area:task-sdk', None)]","[{'comment_id': 2573748917, 'issue_id': 2770575533, 'author': 'amoghrajesh', 'body': 'Unrelated failure. Merging.', 'created_at': datetime.datetime(2025, 1, 6, 19, 14, 35, tzinfo=datetime.timezone.utc)}]","amoghrajesh (Issue Creator) on (2025-01-06 19:14:35 UTC): Unrelated failure. Merging.

"
2770429967,pull_request,closed,,feat: Add OpenLineage support for some BQ operators,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->
This PR adds OpenLineage support for the following BQ operators:

- BigQueryUpdateTableOperator;
- BigQueryDeleteTableOperator;
- BigQueryUpsertTableOperator;
- BigQueryUpdateTableSchemaOperator;


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",kacpermuda,2025-01-06 11:14:07+00:00,[],2025-01-07 19:43:33+00:00,2025-01-07 18:55:27+00:00,https://github.com/apache/airflow/pull/45422,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]",[],
2770331248,pull_request,closed,,AIP-84 List DAGs endpoint new features (2/2) Advanced,"Closes: [#42467](https://github.com/apache/airflow/issues/42467)

Added:
- Filter on any/all combinations of tags
- List DAGs with a dag run within a particular date range
- List DAGs with a running dagrun",prabhusneha,2025-01-06 10:19:08+00:00,[],2025-01-27 13:09:22+00:00,2025-01-22 04:04:28+00:00,https://github.com/apache/airflow/pull/45420,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]",[],
2770214054,pull_request,closed,,[v2-10-test] docs: clarify which fields are masked in the UI (#45417),"The word 'contains' was used slightly confusingly here: it was meant to mean
'the name field contains any of these strings', but you could also read it as
'the name itself contains any of these strings'. This removes any
ambiguity.
(cherry picked from commit f03b1d4d996cf2b3f62c21f8c6a38aa53ba1e3be)

Co-authored-by: Arnout Engelen <arnout@bzzt.net>",github-actions[bot],2025-01-06 09:19:58+00:00,[],2025-01-28 12:07:38+00:00,2025-01-06 09:58:38+00:00,https://github.com/apache/airflow/pull/45418,"[('area:secrets', ''), ('kind:documentation', ''), ('changelog:skip', 'Changes that should be skipped from the changelog (CI, tests, etc..)')]",[],
2770181352,pull_request,closed,,docs: clarify which fields are masked in the UI,"The word 'contains' was used slightly confusingly here: it was meant to mean 'the name field contains any of these strings', but you could also read it as 'the name itself contains any of these strings'. This removes any ambiguity.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",raboof,2025-01-06 09:01:00+00:00,[],2025-01-06 09:20:03+00:00,2025-01-06 09:19:11+00:00,https://github.com/apache/airflow/pull/45417,"[('area:secrets', ''), ('kind:documentation', ''), ('type:doc-only', 'Changelog: Doc Only'), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2572629353, 'issue_id': 2770181352, 'author': 'potiuk', 'body': 'Nice! Thanks @raboof !', 'created_at': datetime.datetime(2025, 1, 6, 9, 5, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572652867, 'issue_id': 2770181352, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45418""><img src=""https://img.shields.io/badge/PR-45418-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2025, 1, 6, 9, 20, 1, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-06 09:05:37 UTC): Nice! Thanks @raboof !

github-actions[bot] on (2025-01-06 09:20:01 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45418""><img src=""https://img.shields.io/badge/PR-45418-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2770084261,pull_request,closed,,testing pygments fix,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-06 08:07:23+00:00,[],2025-01-06 09:03:15+00:00,2025-01-06 09:02:58+00:00,https://github.com/apache/airflow/pull/45416,[],"[{'comment_id': 2572625384, 'issue_id': 2770084261, 'author': 'potiuk', 'body': 'Closing - the fix aimed for 2.19.1 seems to work.', 'created_at': datetime.datetime(2025, 1, 6, 9, 3, 14, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-06 09:03:14 UTC): Closing - the fix aimed for 2.19.1 seems to work.

"
2769489596,pull_request,closed,,Limits Pygments to exclude 2.19.0,"Pygments 2.19.0 fails to properly render .ini examples with dictionaries.

This is tracked in https://github.com/pygments/pygments/issues/2834

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-05 22:56:53+00:00,[],2025-01-06 07:34:25+00:00,2025-01-05 23:07:45+00:00,https://github.com/apache/airflow/pull/45412,[],"[{'comment_id': 2571779371, 'issue_id': 2769489596, 'author': 'potiuk', 'body': 'Should fix docs-build in `canary`', 'created_at': datetime.datetime(2025, 1, 5, 22, 58, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572469087, 'issue_id': 2769489596, 'author': 'potiuk', 'body': 'FYI: The issue is scheduled to be fixed in 2.19.1', 'created_at': datetime.datetime(2025, 1, 6, 7, 34, 24, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-05 22:58:14 UTC): Should fix docs-build in `canary`

potiuk (Issue Creator) on (2025-01-06 07:34:24 UTC): FYI: The issue is scheduled to be fixed in 2.19.1

"
2769436555,pull_request,closed,,Set only ci-image-build condition for generate-constraints,"Remove added condition part of this https://github.com/apache/airflow/pull/45409 
and removing `only-new-ui-files` check we dont need it for CI, https://github.com/apache/airflow/pull/45409#discussion_r1903331886
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-05 20:27:26+00:00,[],2025-01-05 20:31:48+00:00,2025-01-05 20:31:15+00:00,https://github.com/apache/airflow/pull/45411,"[('area:dev-tools', '')]","[{'comment_id': 2571742821, 'issue_id': 2769436555, 'author': 'gopidesupavan', 'body': 'closing in favour of https://github.com/apache/airflow/pull/45410', 'created_at': datetime.datetime(2025, 1, 5, 20, 31, 12, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2025-01-05 20:31:12 UTC): closing in favour of https://github.com/apache/airflow/pull/45410

"
2769432021,pull_request,closed,,Simplify the condition for generate-constraints,"Constraints generation needs ci-image - so we should base it's running on the need to whether to create the images.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-05 20:14:07+00:00,[],2025-01-05 20:31:21+00:00,2025-01-05 20:31:19+00:00,https://github.com/apache/airflow/pull/45410,"[('area:dev-tools', '')]",[],
2769399057,pull_request,closed,,Fix generate-constraints job condition in canary run,"One more interesting thing :).

generate-constraints job skipped when UI only changes, this fine for normal PR builds, but for canary run we should trigger this job, this skip causes further dependent jobs skipped :) 

https://github.com/apache/airflow/actions/runs/12619970959/job/35165290069

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-05 18:39:39+00:00,[],2025-01-05 20:28:03+00:00,2025-01-05 20:00:06+00:00,https://github.com/apache/airflow/pull/45409,"[('area:dev-tools', '')]","[{'comment_id': 2571735238, 'issue_id': 2769399057, 'author': 'gopidesupavan', 'body': 'Merging now, one test failed not related to this, it seems test related to auth manager. will look into separate.', 'created_at': datetime.datetime(2025, 1, 5, 20, 0, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571735522, 'issue_id': 2769399057, 'author': 'gopidesupavan', 'body': '> Good catch! Our CI seems to be full of surprises the more you look into it :-D\r\n\r\nYeah good that the skipped jobs are visible in UI :)', 'created_at': datetime.datetime(2025, 1, 5, 20, 1, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571738071, 'issue_id': 2769399057, 'author': 'potiuk', 'body': '> Good catch! Our CI seems to be full of surprises the more you look into it :-D\r\n\r\nIt is (or should be) very simple - we should strongly avoid complex conditions in the yaml files - and do all the logic calculation in selective_checks - they are unit testable and ""python""  :).', 'created_at': datetime.datetime(2025, 1, 5, 20, 10, 42, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2025-01-05 20:00:00 UTC): Merging now, one test failed not related to this, it seems test related to auth manager. will look into separate.

gopidesupavan (Issue Creator) on (2025-01-05 20:01:04 UTC): Yeah good that the skipped jobs are visible in UI :)

potiuk on (2025-01-05 20:10:42 UTC): It is (or should be) very simple - we should strongly avoid complex conditions in the yaml files - and do all the logic calculation in selective_checks - they are unit testable and ""python""  :).

"
2769269053,pull_request,closed,,Apply zizmor findings,"We have nice tool available to find issues in github workflows/actions files.
https://woodruffw.github.io/zizmor/

Thanks to zizmor and @assignUser for sharing the details 
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-05 13:12:27+00:00,[],2025-01-06 06:22:03+00:00,2025-01-05 15:52:39+00:00,https://github.com/apache/airflow/pull/45408,"[('area:dev-tools', ''), ('canary', 'When set on PR running from apache repo - behave as canary run'), ('all versions', 'If set, the CI build will be forced to use all versions of Python/K8S/DBs')]","[{'comment_id': 2571622863, 'issue_id': 2769269053, 'author': 'gopidesupavan', 'body': 'going to run for all combinations just to make sure syntax are working :)', 'created_at': datetime.datetime(2025, 1, 5, 13, 13, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571626584, 'issue_id': 2769269053, 'author': 'gopidesupavan', 'body': 'Oops will update all the quotes :)', 'created_at': datetime.datetime(2025, 1, 5, 13, 26, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571670347, 'issue_id': 2769269053, 'author': 'potiuk', 'body': '> Nice one!\r\n\r\nIndeed :)', 'created_at': datetime.datetime(2025, 1, 5, 15, 53, tzinfo=datetime.timezone.utc)}]","gopidesupavan (Issue Creator) on (2025-01-05 13:13:13 UTC): going to run for all combinations just to make sure syntax are working :)

gopidesupavan (Issue Creator) on (2025-01-05 13:26:28 UTC): Oops will update all the quotes :)

potiuk on (2025-01-05 15:53:00 UTC): Indeed :)

"
2769267039,pull_request,closed,,Remove `--use-uv` from `breeze setup config`.,"While this config worked to setup uv/no-uv, it has never been really used. Instead in all places where `use-uv` parameter is used, the option determines the default rather than config on breeze setup level.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-05 13:07:17+00:00,[],2025-01-06 06:17:28+00:00,2025-01-05 15:15:29+00:00,https://github.com/apache/airflow/pull/45407,"[('area:dev-tools', '')]","[{'comment_id': 2571621796, 'issue_id': 2769267039, 'author': 'potiuk', 'body': 'Small cleanup of unused functionality', 'created_at': datetime.datetime(2025, 1, 5, 13, 9, 51, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-05 13:09:51 UTC): Small cleanup of unused functionality

"
2769162082,pull_request,closed,,Update providers metadata 2025-01-05,,eladkal,2025-01-05 08:02:42+00:00,[],2025-01-05 09:14:06+00:00,2025-01-05 08:46:28+00:00,https://github.com/apache/airflow/pull/45404,[],[],
2769045274,pull_request,closed,,Document deployment of Edge Worker on Windows,"So far I had only a bit of scribble and test setups to launch the EdgeWorker on Windows.

This PR now adds the notes into the docs.

Also it includes 2 example DAGs which can run with Windows.

If you want to try it, with Airflow 2.10.4 it is working with the changes applied following the docs.
To start Airflow 2.10.4 from this branch use `breeze down && rm dist/* && breeze release-management prepare-provider-packages --include-not-ready-providers edge && breeze start-airflow --python 3.12 --load-example-dags --backend postgres --executor EdgeExecutor --answer y --use-airflow-version 2.10.4 --use-packages-from-dist` and follow the steps in the RST to make it working.",jscheffl,2025-01-04 23:58:31+00:00,[],2025-01-05 21:58:40+00:00,2025-01-05 21:58:40+00:00,https://github.com/apache/airflow/pull/45403,"[('area:providers', ''), ('area:dev-tools', ''), ('kind:documentation', ''), ('AIP-69', 'Edge Executor'), ('provider:edge', 'Edge Executor / Worker (AIP-69)')]","[{'comment_id': 2571763444, 'issue_id': 2769045274, 'author': 'jscheffl', 'body': '> Looks good! Small suggestions for improvements :)\r\n\r\nThanks for the review! Applied the changes', 'created_at': datetime.datetime(2025, 1, 5, 21, 57, 32, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2025-01-05 21:57:32 UTC): Thanks for the review! Applied the changes

"
2769011200,pull_request,closed,,Allow empty value while variable creation,"As discussed in https://apache-airflow.slack.com/archives/C0809U4S1Q9/p1736000063416279 , Variables with empty value  is allowed.

<img width=""984"" alt=""image"" src=""https://github.com/user-attachments/assets/bbba686f-a916-4f77-86f5-1a3624be09e7"" />

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/583970ea-ea6c-4638-9793-61c8f1c2a2a9"" />


Incase of null :
<img width=""1406"" alt=""image"" src=""https://github.com/user-attachments/assets/ac93f58d-f370-428b-8434-ac4de178b3e8"" />



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-04 21:37:42+00:00,[],2025-01-04 23:09:32+00:00,2025-01-04 23:09:32+00:00,https://github.com/apache/airflow/pull/45402,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2768998792,pull_request,closed,,Trim the oversized text in the variables table and Implement variables view,"Legacy:

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/a3829e1b-9a2a-4eff-95d5-0af45dab87c1"" />

Before (New UI):

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/25e865ba-e8ce-4c11-93ad-bfc459cd3005"" />

After (New UI):

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/6fa7cef8-6aa9-4365-99f0-521a92c60efe"" />

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/81c0d701-81b4-4dde-aa12-4288158a3294"" />

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/5f804e01-75c8-451a-9940-3e689b19eff7"" />



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-04 20:54:40+00:00,[],2025-01-07 16:33:41+00:00,2025-01-05 10:14:00+00:00,https://github.com/apache/airflow/pull/45401,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2573312778, 'issue_id': 2768998792, 'author': 'pierrejeambrun', 'body': ""Not sure why we re-implement that manually why there is a `text-overflow: ellipsis` that does exactly that.\r\n\r\nIndeed in table cells it's a little more tricker to get right, but re-implementing everything by hands seems overkill..."", 'created_at': datetime.datetime(2025, 1, 6, 15, 11, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2573598333, 'issue_id': 2768998792, 'author': 'shubhamraj-git', 'body': 'Do you mean for the text wrap in the dialog? @pierrejeambrun', 'created_at': datetime.datetime(2025, 1, 6, 17, 41, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575742381, 'issue_id': 2768998792, 'author': 'pierrejeambrun', 'body': ""I mean implementing some code that will truncate the text, adding `...` at the end when it's too big to fit a container.\r\n\r\nThere is a css property to do exactly that."", 'created_at': datetime.datetime(2025, 1, 7, 16, 33, 23, tzinfo=datetime.timezone.utc)}]","pierrejeambrun on (2025-01-06 15:11:12 UTC): Not sure why we re-implement that manually why there is a `text-overflow: ellipsis` that does exactly that.

Indeed in table cells it's a little more tricker to get right, but re-implementing everything by hands seems overkill...

shubhamraj-git (Issue Creator) on (2025-01-06 17:41:50 UTC): Do you mean for the text wrap in the dialog? @pierrejeambrun

pierrejeambrun on (2025-01-07 16:33:23 UTC): I mean implementing some code that will truncate the text, adding `...` at the end when it's too big to fit a container.

There is a css property to do exactly that.

"
2768986675,pull_request,closed,,Remove some unnecessary FAB test setup code,Splitting out of #45371.,jedcunningham,2025-01-04 20:11:22+00:00,[],2025-01-04 21:03:23+00:00,2025-01-04 20:57:26+00:00,https://github.com/apache/airflow/pull/45400,"[('area:providers', ''), ('provider:fab', '')]",[],
2768939594,pull_request,closed,,Remove obsolete pandas specfication for pre-python 3.9,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-04 17:41:16+00:00,[],2025-01-04 18:58:35+00:00,2025-01-04 18:58:34+00:00,https://github.com/apache/airflow/pull/45399,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('provider:snowflake', 'Issues related to Snowflake provider'), ('provider:common-sql', ''), ('provider:databricks', ''), ('provider:trino', ''), ('provider:presto', ''), ('provider:exasol', ''), ('provider:papermill', ''), ('provider:apache-hive', ''), ('provider:apache-hdfs', ''), ('provider:salesforce', ''), ('provider:weaviate', '')]","[{'comment_id': 2571368652, 'issue_id': 2768939594, 'author': 'jscheffl', 'body': 'Oh, another leftover I seem to have missed when deprecating Python 3.8 :-D', 'created_at': datetime.datetime(2025, 1, 4, 17, 55, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571383420, 'issue_id': 2768939594, 'author': 'potiuk', 'body': '> Oh, another leftover I seem to have missed when deprecating Python 3.8 :-D\r\n\r\nWe all did :)', 'created_at': datetime.datetime(2025, 1, 4, 18, 58, 30, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-04 17:55:59 UTC): Oh, another leftover I seem to have missed when deprecating Python 3.8 :-D

potiuk (Issue Creator) on (2025-01-04 18:58:30 UTC): We all did :)

"
2768934358,pull_request,closed,,"Update uv, pip and pre-commit versions automatically in more places.","<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-04 17:25:34+00:00,[],2025-01-06 06:16:19+00:00,2025-01-04 21:36:45+00:00,https://github.com/apache/airflow/pull/45398,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2571365575, 'issue_id': 2768934358, 'author': 'potiuk', 'body': 'This should help: https://github.com/apache/airflow/pull/45399\r\n\r\nAlso follow-up #45398 - where pip, uv, pre-commit and pre-commit-uv should be updated everywhere automatically with pre-commit.', 'created_at': datetime.datetime(2025, 1, 4, 17, 42, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571389137, 'issue_id': 2768934358, 'author': 'gopidesupavan', 'body': 'BTW nice refactoring and updates :) thanks jarek.', 'created_at': datetime.datetime(2025, 1, 4, 19, 23, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571402779, 'issue_id': 2768934358, 'author': 'shahar1', 'body': '> This should help: #45399\r\n> \r\n> Also follow-up #45398 - where pip, uv, pre-commit and pre-commit-uv should be updated everywhere automatically with pre-commit.\r\n\r\nRecursive follow-up? :)', 'created_at': datetime.datetime(2025, 1, 4, 20, 23, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571409216, 'issue_id': 2768934358, 'author': 'potiuk', 'body': '> Recursive follow-up? :)\r\n\r\nFollow up on folllow up on follow up on the follow-up before... 🪄', 'created_at': datetime.datetime(2025, 1, 4, 20, 55, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2572365330, 'issue_id': 2768934358, 'author': 'amoghrajesh', 'body': 'Nice!', 'created_at': datetime.datetime(2025, 1, 6, 6, 16, 18, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-04 17:42:47 UTC): This should help: https://github.com/apache/airflow/pull/45399

Also follow-up #45398 - where pip, uv, pre-commit and pre-commit-uv should be updated everywhere automatically with pre-commit.

gopidesupavan on (2025-01-04 19:23:33 UTC): BTW nice refactoring and updates :) thanks jarek.

shahar1 on (2025-01-04 20:23:17 UTC): Recursive follow-up? :)

potiuk (Issue Creator) on (2025-01-04 20:55:07 UTC): Follow up on folllow up on follow up on the follow-up before... 🪄

amoghrajesh on (2025-01-06 06:16:18 UTC): Nice!

"
2768883889,pull_request,closed,,AIP-81 Add Overwrite for Bulk Insert Pool API,"
closes: #45303 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2025-01-04 15:04:45+00:00,[],2025-01-23 09:14:20+00:00,2025-01-05 08:16:50+00:00,https://github.com/apache/airflow/pull/45397,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-84', 'Modern Rest API')]","[{'comment_id': 2571357295, 'issue_id': 2768883889, 'author': 'jscheffl', 'body': 'Both of your PRs conflicts in the source tree, can you resolve this?', 'created_at': datetime.datetime(2025, 1, 4, 17, 6, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571480330, 'issue_id': 2768883889, 'author': 'jason810496', 'body': '> Both of your PRs conflicts in the source tree, can you resolve this?\r\n\r\nResolved! Thanks for the review!', 'created_at': datetime.datetime(2025, 1, 5, 2, 53, 46, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-04 17:06:10 UTC): Both of your PRs conflicts in the source tree, can you resolve this?

jason810496 (Issue Creator) on (2025-01-05 02:53:46 UTC): Resolved! Thanks for the review!

"
2768826653,pull_request,closed,,AIP-81 Add Overwrite for Bulk Insert Connection API,"
related: #45303



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2025-01-04 12:57:33+00:00,[],2025-01-04 17:05:34+00:00,2025-01-04 17:05:34+00:00,https://github.com/apache/airflow/pull/45396,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2768788088,pull_request,closed,,Bump uv to 0.5.14,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-04 11:01:26+00:00,[],2025-01-04 20:46:44+00:00,2025-01-04 20:46:44+00:00,https://github.com/apache/airflow/pull/45394,"[('area:dev-tools', ''), ('area:production-image', 'Production image improvements and fixes')]","[{'comment_id': 2571283644, 'issue_id': 2768788088, 'author': 'potiuk', 'body': 'One comment. I think we have one or two places where uv is not bumped automatically by precommit (I marked them with `TODO(potiuk)` - maybe worth finding it now and updating/reapplying the pre-commit?', 'created_at': datetime.datetime(2025, 1, 4, 13, 8, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571324010, 'issue_id': 2768788088, 'author': 'gopidesupavan', 'body': '> One comment. I think we have one or two places where uv is not bumped automatically by precommit (I marked them with `TODO(potiuk)` - maybe worth finding it now and updating/reapplying the pre-commit?\r\n\r\nyeah good call :) updated', 'created_at': datetime.datetime(2025, 1, 4, 14, 47, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571329867, 'issue_id': 2768788088, 'author': 'potiuk', 'body': ""Shall update automation for that one too  (i.e. update pre-commit for the next time )  ? I can do it, separately, no problem as well :). I think it's the right time."", 'created_at': datetime.datetime(2025, 1, 4, 15, 10, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571348439, 'issue_id': 2768788088, 'author': 'potiuk', 'body': ""Looks like we have the first serious case where new `uv` version behaves differently - looks like resolving the dependencies for lowest-direct is failing with some pandas problem. I will re-run to check, but It's likely we will have to adapt something."", 'created_at': datetime.datetime(2025, 1, 4, 16, 27, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571378205, 'issue_id': 2768788088, 'author': 'gopidesupavan', 'body': ""> Looks like we have the first serious case where new `uv` version behaves differently - looks like resolving the dependencies for lowest-direct is failing with some pandas problem. I will re-run to check, but It's likely we will have to adapt something.\r\n\r\nYeah interesting ..."", 'created_at': datetime.datetime(2025, 1, 4, 18, 34, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571378280, 'issue_id': 2768788088, 'author': 'gopidesupavan', 'body': ""> Looks like we have the first serious case where new `uv` version behaves differently - looks like resolving the dependencies for lowest-direct is failing with some pandas problem. I will re-run to check, but It's likely we will have to adapt something.\r\n\r\nThanks for updating :)"", 'created_at': datetime.datetime(2025, 1, 4, 18, 34, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571407553, 'issue_id': 2768788088, 'author': 'potiuk', 'body': 'accidental issue only :)', 'created_at': datetime.datetime(2025, 1, 4, 20, 46, 33, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-04 13:08:24 UTC): One comment. I think we have one or two places where uv is not bumped automatically by precommit (I marked them with `TODO(potiuk)` - maybe worth finding it now and updating/reapplying the pre-commit?

gopidesupavan (Issue Creator) on (2025-01-04 14:47:44 UTC): yeah good call :) updated

potiuk on (2025-01-04 15:10:25 UTC): Shall update automation for that one too  (i.e. update pre-commit for the next time )  ? I can do it, separately, no problem as well :). I think it's the right time.

potiuk on (2025-01-04 16:27:57 UTC): Looks like we have the first serious case where new `uv` version behaves differently - looks like resolving the dependencies for lowest-direct is failing with some pandas problem. I will re-run to check, but It's likely we will have to adapt something.

gopidesupavan (Issue Creator) on (2025-01-04 18:34:35 UTC): Yeah interesting ...

gopidesupavan (Issue Creator) on (2025-01-04 18:34:51 UTC): Thanks for updating :)

potiuk on (2025-01-04 20:46:33 UTC): accidental issue only :)

"
2768725773,pull_request,closed,,AIP-81 Add DAG Report API,"
closes: #45301



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",jason810496,2025-01-04 09:50:53+00:00,[],2025-01-27 13:11:31+00:00,2025-01-21 16:06:38+00:00,https://github.com/apache/airflow/pull/45393,"[('type:new-feature', 'Changelog: New Features'), ('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2582772022, 'issue_id': 2768725773, 'author': 'jason810496', 'body': 'All comments have been resolved. Thanks, @pierrejeambrun, for the code review!', 'created_at': datetime.datetime(2025, 1, 10, 13, 58, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594062457, 'issue_id': 2768725773, 'author': 'jason810496', 'body': 'Rebase to latest main.', 'created_at': datetime.datetime(2025, 1, 15, 22, 24, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2601423048, 'issue_id': 2768725773, 'author': 'jason810496', 'body': 'Hi @pierrejeambrun , I just fixed the broken test due to breaking change on `list_py_file__paths`.\r\nThe CI failure is caused by `CodeQL`.', 'created_at': datetime.datetime(2025, 1, 20, 5, 47, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605089886, 'issue_id': 2768725773, 'author': 'pierrejeambrun', 'body': 'Code QL seems happy 🎉', 'created_at': datetime.datetime(2025, 1, 21, 15, 45, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605132473, 'issue_id': 2768725773, 'author': 'jason810496', 'body': '> Code QL seems happy 🎉\r\n\r\nFinally passed all CI! Thanks, @pierrejeambrun, for the review!', 'created_at': datetime.datetime(2025, 1, 21, 16, 2, 7, tzinfo=datetime.timezone.utc)}]","jason810496 (Issue Creator) on (2025-01-10 13:58:50 UTC): All comments have been resolved. Thanks, @pierrejeambrun, for the code review!

jason810496 (Issue Creator) on (2025-01-15 22:24:56 UTC): Rebase to latest main.

jason810496 (Issue Creator) on (2025-01-20 05:47:38 UTC): Hi @pierrejeambrun , I just fixed the broken test due to breaking change on `list_py_file__paths`.
The CI failure is caused by `CodeQL`.

pierrejeambrun on (2025-01-21 15:45:43 UTC): Code QL seems happy 🎉

jason810496 (Issue Creator) on (2025-01-21 16:02:07 UTC): Finally passed all CI! Thanks, @pierrejeambrun, for the review!

"
2768669880,pull_request,closed,,Add action bar for the bulk operation on variable list,"This adds the action bar for the bulk operation on variables list page.
This will be followed up with delete and export selected functionality.

<img width=""1728"" alt=""image"" src=""https://github.com/user-attachments/assets/8c2f8b48-20ae-44f7-9fac-08c9fcb0d7ed"" />

Tooltip added to let user know about upcoming functionality
<img width=""745"" alt=""image"" src=""https://github.com/user-attachments/assets/a7854afa-42b9-441c-a272-c598c7c659ba"" />



<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",shubhamraj-git,2025-01-04 08:58:11+00:00,[],2025-01-04 14:31:15+00:00,2025-01-04 14:31:15+00:00,https://github.com/apache/airflow/pull/45392,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2571319229, 'issue_id': 2768669880, 'author': 'shubhamraj-git', 'body': 'Thanks @jscheffl , Nice catch!\r\nI will take care of this while implementing the bulk delete action.', 'created_at': datetime.datetime(2025, 1, 4, 14, 27, 38, tzinfo=datetime.timezone.utc)}]","shubhamraj-git (Issue Creator) on (2025-01-04 14:27:38 UTC): Thanks @jscheffl , Nice catch!
I will take care of this while implementing the bulk delete action.

"
2768657037,pull_request,closed,,Cease using ``InventoryFileReader``,"Hello,

In Sphinx we are looking to refactor handling of inventory reading, which might involve deprecating or removing `InventoryFileReader`. Airflow is one of four projects I have found in the wild that uses it, but your usage can be replaced with a single call to `.readline().decode()`, as you are only sanity-checking the first line of content.

A",AA-Turner,2025-01-04 08:46:12+00:00,[],2025-01-10 07:20:58+00:00,2025-01-10 07:20:09+00:00,https://github.com/apache/airflow/pull/45391,"[('kind:documentation', ''), ('backport-to-v2-10-test', 'Mark PR with this label to backport to v2-10-test branch')]","[{'comment_id': 2570799315, 'issue_id': 2768657037, 'author': 'boring-cyborg[bot]', 'body': ""Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)\nHere are some useful points:\n- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.\n- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.\n- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.\n- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.\n- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.\n- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).\n- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.\nApache Airflow is a community-driven project and together we are making it better 🚀.\nIn case of doubts contact the developers at:\nMailing List: dev@airflow.apache.org\nSlack: https://s.apache.org/airflow-slack"", 'created_at': datetime.datetime(2025, 1, 4, 8, 46, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2574089785, 'issue_id': 2768657037, 'author': 'AA-Turner', 'body': '> Was the deprecation discussed anywhere\r\n\r\nThe PR to move `InventoryFileReader` is here: https://github.com/sphinx-doc/sphinx/pull/13215\r\n\r\nThis is preparatory work for a future v3 of the objects.inv file format.\r\n\r\nA', 'created_at': datetime.datetime(2025, 1, 6, 23, 13, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2581947111, 'issue_id': 2768657037, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 1, 10, 7, 20, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2581948096, 'issue_id': 2768657037, 'author': 'github-actions[bot]', 'body': '### Backport successfully created: v2-10-test\n\n<table>\n                <tr>\n                    <th>Status</th>\n                    <th>Branch</th>\n                    <th>Result</th>\n                </tr>\n                <tr>\n                    <td>✅</td>\n                    <td>v2-10-test</td>\n                    <td><a href=""https://github.com/apache/airflow/pull/45538""><img src=""https://img.shields.io/badge/PR-45538-blue"" alt=""PR Link""></a></td>\n                </tr>\n            </table>', 'created_at': datetime.datetime(2025, 1, 10, 7, 20, 57, tzinfo=datetime.timezone.utc)}]","boring-cyborg[bot] on (2025-01-04 08:46:16 UTC): Congratulations on your first Pull Request and welcome to the Apache Airflow community! If you have any issues or are unsure about any anything please check our Contributors' Guide (https://github.com/apache/airflow/blob/main/contributing-docs/README.rst)
Here are some useful points:
- Pay attention to the quality of your code (ruff, mypy and type annotations). Our [pre-commits]( https://github.com/apache/airflow/blob/main/contributing-docs/08_static_code_checks.rst#prerequisites-for-pre-commit-hooks) will help you with that.
- In case of a new feature add useful documentation (in docstrings or in `docs/` directory). Adding a new operator? Check this short [guide](https://github.com/apache/airflow/blob/main/docs/apache-airflow/howto/custom-operator.rst) Consider adding an example DAG that shows how users should use it.
- Consider using [Breeze environment](https://github.com/apache/airflow/blob/main/dev/breeze/doc/README.rst) for testing locally, it's a heavy docker but it ships with a working Airflow and a lot of integrations.
- Be patient and persistent. It might take some time to get a review or get the final approval from Committers.
- Please follow [ASF Code of Conduct](https://www.apache.org/foundation/policies/conduct) for all communication including (but not limited to) comments on Pull Requests, Mailing list and Slack.
- Be sure to read the [Airflow Coding style]( https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#coding-style-and-best-practices).
- Always keep your Pull Requests rebased, otherwise your build might fail due to changes not related to your commits.
Apache Airflow is a community-driven project and together we are making it better 🚀.
In case of doubts contact the developers at:
Mailing List: dev@airflow.apache.org
Slack: https://s.apache.org/airflow-slack

AA-Turner (Issue Creator) on (2025-01-06 23:13:26 UTC): The PR to move `InventoryFileReader` is here: https://github.com/sphinx-doc/sphinx/pull/13215

This is preparatory work for a future v3 of the objects.inv file format.

A

boring-cyborg[bot] on (2025-01-10 07:20:12 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

github-actions[bot] on (2025-01-10 07:20:57 UTC): ### Backport successfully created: v2-10-test

<table>
                <tr>
                    <th>Status</th>
                    <th>Branch</th>
                    <th>Result</th>
                </tr>
                <tr>
                    <td>✅</td>
                    <td>v2-10-test</td>
                    <td><a href=""https://github.com/apache/airflow/pull/45538""><img src=""https://img.shields.io/badge/PR-45538-blue"" alt=""PR Link""></a></td>
                </tr>
            </table>

"
2768526620,pull_request,closed,,Set correct label for runs-on-as-json-public in selective check table,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-04 06:41:10+00:00,[],2025-01-04 09:10:32+00:00,2025-01-04 08:58:50+00:00,https://github.com/apache/airflow/pull/45390,"[('area:dev-tools', '')]",[],
2768400191,pull_request,open,,enable PT006  rule,related to #40567,rawwar,2025-01-04 03:47:18+00:00,[],2025-01-04 04:25:35+00:00,,https://github.com/apache/airflow/pull/45389,"[('area:webserver', 'Webserver related Issues')]","[{'comment_id': 2570037814, 'issue_id': 2768400191, 'author': 'rawwar', 'body': 'Used `ruff check --fix --select PT006 --unsafe-fixes` to fix all the PT006 failures. But, also looking into what are the ""unsafe"" cases and update the PR accordingly.', 'created_at': datetime.datetime(2025, 1, 4, 4, 0, 1, tzinfo=datetime.timezone.utc)}]","rawwar (Issue Creator) on (2025-01-04 04:00:01 UTC): Used `ruff check --fix --select PT006 --unsafe-fixes` to fix all the PT006 failures. But, also looking into what are the ""unsafe"" cases and update the PR accordingly.

"
2768278455,pull_request,closed,,Evaluate canary-run condition in run-tests SelectiveChecks,"This will help cases like when `run-tests` becomes false if it is canary-run . 
Some times tests are getting skipped in canary run.

We have condition in jobs to trigger for `run-tests`, even thought this works but often some times `run-tests` becomes false when the last merge commit main has only some UI changes. then this causing skipping of canary run tests jobs. see below it has skipped most of the jobs. because the selective check here https://github.com/apache/airflow/actions/runs/12602875121/job/35126775759#step:8:217 triggered only the ui file changes

https://github.com/apache/airflow/actions/runs/12602875121/job/35126775759
https://github.com/apache/airflow/actions/runs/12602875121/job/35126775759#step:8:310
<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-03 23:10:28+00:00,[],2025-01-04 15:16:11+00:00,2025-01-04 15:11:58+00:00,https://github.com/apache/airflow/pull/45387,"[('area:dev-tools', '')]","[{'comment_id': 2571285225, 'issue_id': 2768278455, 'author': 'potiuk', 'body': ""I think it would be better to reevaluate 'run-tests' condition in this case in `selective_checks` and make sure it's never false in canary runs. This would be more natural, actually testable with unit tests and we would avoid the strange ternary"", 'created_at': datetime.datetime(2025, 1, 4, 13, 14, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2571307689, 'issue_id': 2768278455, 'author': 'gopidesupavan', 'body': ""> I think it would be better to reevaluate 'run-tests' condition in this case in `selective_checks` and make sure it's never false in canary runs. This would be more natural, actually testable with unit tests and we would avoid the strange ternary\r\n\r\nYeah make sense , i think i got it where its failing check, let me get updated changes.."", 'created_at': datetime.datetime(2025, 1, 4, 13, 38, 48, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-04 13:14:17 UTC): I think it would be better to reevaluate 'run-tests' condition in this case in `selective_checks` and make sure it's never false in canary runs. This would be more natural, actually testable with unit tests and we would avoid the strange ternary

gopidesupavan (Issue Creator) on (2025-01-04 13:38:48 UTC): Yeah make sense , i think i got it where its failing check, let me get updated changes..

"
2768269402,pull_request,closed,,Mark image as refreshed after it's build,"Somewhere in the last refactorings and ci cache we lost marking the image as ""refreshed"" after it's build. Currently it does not matter if you press ""y"" or ""n"" when you are asked for image rebuilding next time you are asked again, but it should not happen if your image is rebuilt successfully.

This PR restores ""mark image as refreshed"" after it's rebuild and renames it to ""mark_image_as_rebuilt""

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-03 22:57:35+00:00,[],2025-01-04 07:32:37+00:00,2025-01-04 07:32:37+00:00,https://github.com/apache/airflow/pull/45386,"[('area:dev-tools', '')]",[],
2768174802,pull_request,closed,,Fix missing input and output variable references in github workflows,"Here are some of the missing references.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-03 21:06:48+00:00,[],2025-01-04 13:04:10+00:00,2025-01-03 22:09:40+00:00,https://github.com/apache/airflow/pull/45384,"[('area:dev-tools', '')]","[{'comment_id': 2571282437, 'issue_id': 2768174802, 'author': 'potiuk', 'body': 'BTW. We could maybe add some pre-commit verifications for those. Why it will not work in general case we could agree on certain concentions we. Use and add verification if those conventions are followed', 'created_at': datetime.datetime(2025, 1, 4, 13, 4, 9, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-04 13:04:09 UTC): BTW. We could maybe add some pre-commit verifications for those. Why it will not work in general case we could agree on certain concentions we. Use and add verification if those conventions are followed

"
2767939616,pull_request,closed,,Redo task instance details (#45382),"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

redo #45273 (as of #45382)

<img width=""511"" alt=""Screenshot 2025-01-03 at 11 09 54 AM"" src=""https://github.com/user-attachments/assets/2809d340-a052-4856-85d7-8eb85285ade6"" />

<img width=""511"" alt=""Screenshot 2025-01-03 at 11 09 58 AM"" src=""https://github.com/user-attachments/assets/01a13aa8-fa13-4f5d-83ed-22b70d1e96bb"" />

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",dauinh,2025-01-03 17:38:38+00:00,[],2025-01-03 18:16:06+00:00,2025-01-03 18:00:53+00:00,https://github.com/apache/airflow/pull/45383,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]",[],
2767846354,pull_request,closed,,"Revert ""Add task instance details for each run""","Reverts apache/airflow#45273

Some static checks fail - unfortunately the static checks were broken at the time this PR was merged, was only detected on main.
As it takes a little more time to rework all code, please re-revert and apply needed fixes @dauinh",jscheffl,2025-01-03 16:26:54+00:00,[],2025-01-11 19:42:53+00:00,2025-01-03 16:30:34+00:00,https://github.com/apache/airflow/pull/45382,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2569568722, 'issue_id': 2767846354, 'author': 'dauinh', 'body': 'got it!', 'created_at': datetime.datetime(2025, 1, 3, 17, 21, 4, tzinfo=datetime.timezone.utc)}]","dauinh on (2025-01-03 17:21:04 UTC): got it!

"
2767804187,pull_request,closed,,Use runs-on-as-json-public in install-pre-commit job,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",gopidesupavan,2025-01-03 15:56:32+00:00,[],2025-01-03 17:14:24+00:00,2025-01-03 16:16:55+00:00,https://github.com/apache/airflow/pull/45381,"[('area:dev-tools', '')]",[],
2767784408,pull_request,closed,,Adjust JSX element depth from 5 to 7,"After merge of PR #45273 the canary failed in UI static checks.

Error run is: https://github.com/apache/airflow/actions/runs/12598486200/job/35113887885

Reason is JSX validation which checks element depth <5 - which in my view does not make sense if we render tables with a few elements that unfortunately easily reach a level of 7 - cutting sub-components does not smell resonable.

Therefore with this PR I propose to change the accepted JSX element depth to 7.

Alternatively we would need to revert and rework the PR #45273 and cut more components to the UI.",jscheffl,2025-01-03 15:42:06+00:00,[],2025-01-03 22:04:24+00:00,2025-01-03 16:52:57+00:00,https://github.com/apache/airflow/pull/45380,"[('area:UI', 'Related to UI/UX. For Frontend Developers.')]","[{'comment_id': 2569496074, 'issue_id': 2767784408, 'author': 'jscheffl', 'body': 'Oh, there are more problems with curent code on main. Seems we need to revert the PR https://github.com/apache/airflow/pull/45273 and make it proper again...', 'created_at': datetime.datetime(2025, 1, 3, 16, 25, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569498109, 'issue_id': 2767784408, 'author': 'shubhamraj-git', 'body': ""Oh, thats strange, static check didn't failed for that PR."", 'created_at': datetime.datetime(2025, 1, 3, 16, 27, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569499193, 'issue_id': 2767784408, 'author': 'jscheffl', 'body': 'There was a bug in CI and checks were skipped :-(', 'created_at': datetime.datetime(2025, 1, 3, 16, 27, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569501141, 'issue_id': 2767784408, 'author': 'shubhamraj-git', 'body': 'Ohh, we need to have it fix, do we have any issue number to track that?', 'created_at': datetime.datetime(2025, 1, 3, 16, 29, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569533065, 'issue_id': 2767784408, 'author': 'jscheffl', 'body': 'Now green!', 'created_at': datetime.datetime(2025, 1, 3, 16, 52, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2569874556, 'issue_id': 2767784408, 'author': 'potiuk', 'body': 'Nice!', 'created_at': datetime.datetime(2025, 1, 3, 22, 4, 23, tzinfo=datetime.timezone.utc)}]","jscheffl (Issue Creator) on (2025-01-03 16:25:32 UTC): Oh, there are more problems with curent code on main. Seems we need to revert the PR https://github.com/apache/airflow/pull/45273 and make it proper again...

shubhamraj-git on (2025-01-03 16:27:04 UTC): Oh, thats strange, static check didn't failed for that PR.

jscheffl (Issue Creator) on (2025-01-03 16:27:56 UTC): There was a bug in CI and checks were skipped :-(

shubhamraj-git on (2025-01-03 16:29:25 UTC): Ohh, we need to have it fix, do we have any issue number to track that?

jscheffl (Issue Creator) on (2025-01-03 16:52:53 UTC): Now green!

potiuk on (2025-01-03 22:04:23 UTC): Nice!

"
2767754636,pull_request,closed,,Implement AlloyDB create/update/delete user and backups operators,"Implement new operators for AlloyDB service:
- create/update/delete backups
- create/update/delete users",moiseenkov,2025-01-03 15:25:49+00:00,[],2025-01-08 21:58:27+00:00,2025-01-08 21:58:27+00:00,https://github.com/apache/airflow/pull/45378,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', ''), ('kind:documentation', '')]","[{'comment_id': 2577343206, 'issue_id': 2767754636, 'author': 'VladaZakharova', 'body': 'hi @potiuk @eladkal ! Can you please check this PR?', 'created_at': datetime.datetime(2025, 1, 8, 10, 36, 6, tzinfo=datetime.timezone.utc)}]","VladaZakharova on (2025-01-08 10:36:06 UTC): hi @potiuk @eladkal ! Can you please check this PR?

"
2767683154,pull_request,closed,,forward port fab 1.5.2 to main branch,,eladkal,2025-01-03 14:38:28+00:00,[],2025-01-03 17:44:23+00:00,2025-01-03 17:44:20+00:00,https://github.com/apache/airflow/pull/45377,"[('area:providers', ''), ('kind:documentation', ''), ('provider:fab', '')]",[],
2767350961,pull_request,open,,Add a retry on first PowerBI refresh status check,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

Fix for the issue: https://github.com/apache/airflow/issues/44618

This MR aims to add a retry to the first request that checks the PowerBI refresh status, which sometimes fail due to lack of sync API side.

## Tests

- [x] This was tested locally:

![image](https://github.com/user-attachments/assets/5b018255-2616-40b6-acd4-d470c70ceca6)

- [ ] A unit test was added to check the retry behavior.

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",Ohashiro,2025-01-03 10:38:56+00:00,[],2025-01-03 13:42:20+00:00,,https://github.com/apache/airflow/pull/45375,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]",[],
2767261193,pull_request,closed,,AIP-72: Add missing client tests for connection operations,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->


In test_client.py, every ""component"" like xcoms, task instances, variables have tests but somehow it was missed for connection. Adding it to catch any issues


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-03 09:36:20+00:00,[],2025-01-03 11:02:53+00:00,2025-01-03 11:02:51+00:00,https://github.com/apache/airflow/pull/45374,"[('area:task-sdk', None)]",[],
2767014401,pull_request,closed,,AIP-66: Add support for parsing DAG bundles,"Let's start parsing DAG bundles! This moves us away from parsing a
single local directory to being able to parse many different bundles,
including optional support for versioning.

This is just the basics - it keeps the parsing loop largely untouched.
We still have a single list of ""dag files"" to parse, and queue of them.
However, instead of just a path, this list and queue now contain
`DagFilePath`s, which hold both a local path and the bundle its from.

There are a number of things that are not fully functional at this
stage, like versioned callbacks. These will be refactored later. There
is enough churn with the basics (particularly with the number of test
changes).",jedcunningham,2025-01-03 05:50:40+00:00,[],2025-01-09 16:55:05+00:00,2025-01-09 16:55:02+00:00,https://github.com/apache/airflow/pull/45371,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:CLI', ''), ('area:API', ""Airflow's REST/HTTP API""), ('full tests needed', 'We need to run full set of tests for this PR to merge')]",[],
2767001807,pull_request,closed,,Refactor DAG.create_dagrun() arguments,"This aims to make the interface more straightforward, removing auto inference logic from the function. Most importantly, it is now entirely the caller site's responsibility to provide valid run_id and run_type values, instead of the function automatically inferring one from the other under certain conditions.

The main goal is to make changes simpler when we make logical date an optional (nullable) value. run_id generation is currently very heavily based on the logical date, and will need to be changed a bit when logical date is None. Removing logic should help us change the run_id generation logic easier.

~~p.s. not yet ready, many tests should fail.~~ Finally ready; this took way much more than I thought.",uranusjr,2025-01-03 05:34:09+00:00,[],2025-01-15 12:08:45+00:00,2025-01-15 12:08:43+00:00,https://github.com/apache/airflow/pull/45370,"[('area:Scheduler', 'including HA (high availability) scheduler'), ('area:webserver', 'Webserver related Issues'), ('area:CLI', ''), ('area:dev-tools', ''), ('area:API', ""Airflow's REST/HTTP API""), ('kind:documentation', ''), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2591852358, 'issue_id': 2767001807, 'author': 'uranusjr', 'body': 're: Breaking change, I don’t think we need to since `create_dagrun` is considered private interface. If anyone is using it, the breakage is on them.', 'created_at': datetime.datetime(2025, 1, 15, 7, 46, 50, tzinfo=datetime.timezone.utc)}]","uranusjr (Issue Creator) on (2025-01-15 07:46:50 UTC): re: Breaking change, I don’t think we need to since `create_dagrun` is considered private interface. If anyone is using it, the breakage is on them.

"
2766777162,pull_request,closed,,Move update subscription from `AzureServiceBusTopicCreateOperator` to `AdminClientHook`,"The current update subscription operator calls the azure SDK directly. This refactor moves the calls into the hook.

In addition, it fixes some comments and naming in another test which was confusing (comments and variable names referred to a different feature than the one under test)",perry2of5,2025-01-02 23:18:16+00:00,[],2025-01-08 23:47:47+00:00,2025-01-07 09:40:00+00:00,https://github.com/apache/airflow/pull/45367,"[('provider:microsoft-azure', 'Azure-related issues'), ('area:providers', '')]",[],
2766476305,pull_request,closed,,AIP-81 Implement Create Default Connections Endpoint in REST API (FastAPI),"closes: #45302

This is used in CLI (`airflow connections create-default-connections`) which should be an endpoint for integration. 

<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",bugraoz93,2025-01-02 18:41:19+00:00,[],2025-01-08 10:48:28+00:00,2025-01-08 10:48:28+00:00,https://github.com/apache/airflow/pull/45363,"[('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('AIP-81', 'Enhanced Security in CLI via Integration of API')]","[{'comment_id': 2574166923, 'issue_id': 2766476305, 'author': 'bugraoz93', 'body': '> One small improvement for the test, but looking good.\r\n\r\nThanks for the review!', 'created_at': datetime.datetime(2025, 1, 7, 0, 30, 10, tzinfo=datetime.timezone.utc)}, {'comment_id': 2575788950, 'issue_id': 2766476305, 'author': 'pierrejeambrun', 'body': 'Re-running failed job that seem unrelated.', 'created_at': datetime.datetime(2025, 1, 7, 16, 54, 20, tzinfo=datetime.timezone.utc)}, {'comment_id': 2577309230, 'issue_id': 2766476305, 'author': 'pierrejeambrun', 'body': 'Weird, failure persists. Rebasing the branch. 🤞', 'created_at': datetime.datetime(2025, 1, 8, 10, 18, 54, tzinfo=datetime.timezone.utc)}]","bugraoz93 (Issue Creator) on (2025-01-07 00:30:10 UTC): Thanks for the review!

pierrejeambrun on (2025-01-07 16:54:20 UTC): Re-running failed job that seem unrelated.

pierrejeambrun on (2025-01-08 10:18:54 UTC): Weird, failure persists. Rebasing the branch. 🤞

"
2766434121,pull_request,closed,,Stop reserializing DAGs during db migration,"At first, this may seem strange, but we already have to deal with older versions of serialized DAGs - so the necessity of reserializing during migrations isn't there any longer. The DAG processor can simply do it once Airflow has started back up.p

I've opened #45361 as a check point, once the dust has settled, to see if we need to add it back.",jedcunningham,2025-01-02 18:06:57+00:00,[],2025-01-02 22:53:30+00:00,2025-01-02 22:53:28+00:00,https://github.com/apache/airflow/pull/45362,"[('area:CLI', ''), ('area:providers', ''), ('provider:fab', ''), ('AIP-66: DAG Bundle/Manifest', '')]","[{'comment_id': 2568483910, 'issue_id': 2766434121, 'author': 'jedcunningham', 'body': 'Failure is unrelated (see #45329).', 'created_at': datetime.datetime(2025, 1, 2, 22, 53, 17, tzinfo=datetime.timezone.utc)}]","jedcunningham (Issue Creator) on (2025-01-02 22:53:17 UTC): Failure is unrelated (see #45329).

"
2766338767,pull_request,closed,,Remove update-build-dependencies pre-commit,"After we contributed the fix to dependabot to also bump build-dependencies and having first PRs generated by the dependabot, we can now safely remove the pre-commit.

Here is the fix we contributed:

https://github.com/dependabot/dependabot-core/pull/10899

Related PRs: #45356, #45357, #45358

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-02 16:49:39+00:00,[],2025-01-02 17:12:44+00:00,2025-01-02 17:12:42+00:00,https://github.com/apache/airflow/pull/45359,"[('area:dev-tools', '')]","[{'comment_id': 2568072769, 'issue_id': 2766338767, 'author': 'potiuk', 'body': 'Hey @ashb -> you wanted this pre-commit removed, so we had first case where after @gopidesupavan contributed the dependabot fix, we finally CAN remove it.', 'created_at': datetime.datetime(2025, 1, 2, 16, 50, 56, tzinfo=datetime.timezone.utc)}]","potiuk (Issue Creator) on (2025-01-02 16:50:56 UTC): Hey @ashb -> you wanted this pre-commit removed, so we had first case where after @gopidesupavan contributed the dependabot fix, we finally CAN remove it.

"
2766304241,pull_request,closed,,Bump gitpython from 3.1.43 to 3.1.44,"Bumps [gitpython](https://github.com/gitpython-developers/GitPython) from 3.1.43 to 3.1.44.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/gitpython-developers/GitPython/releases"">gitpython's releases</a>.</em></p>
<blockquote>
<h2>3.1.44</h2>
<h2>What's Changed</h2>
<ul>
<li>Fix typo in _get_exe_extensions PATHEXT fallback by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1890"">gitpython-developers/GitPython#1890</a></li>
<li>Don't suppress pytest warning summaries by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1892"">gitpython-developers/GitPython#1892</a></li>
<li>Update the comment about <code>--mixed</code> and paths by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1894"">gitpython-developers/GitPython#1894</a></li>
<li>Fixed an error updating shallow submodules by <a href=""https://github.com/EduardTalanov""><code>@​EduardTalanov</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1899"">gitpython-developers/GitPython#1899</a></li>
<li>Initial Migration of Fuzz Tests &amp; Integration Scripts From the OSS-Fuzz Project Repo by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1901"">gitpython-developers/GitPython#1901</a></li>
<li>Fuzzer Migration Follow-ups by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1903"">gitpython-developers/GitPython#1903</a></li>
<li>Dockerize &quot;Direct Execution of Fuzz Targets&quot; by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1904"">gitpython-developers/GitPython#1904</a></li>
<li>Fix Fuzzer Crash in ClusterFuzz Due to Missing Git Executable by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1906"">gitpython-developers/GitPython#1906</a></li>
<li>Add GitPython's Standard License Header Comments to Shell Scripts by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1907"">gitpython-developers/GitPython#1907</a></li>
<li>Fix <code>IndexError</code> in <code>GitConfigParser</code> When a Quoted Config Value Contains a Trailing New Line by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1908"">gitpython-developers/GitPython#1908</a></li>
<li>Attempt 2 - Fix Missing Git Executable Causing ClusterFuzz Crash by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1909"">gitpython-developers/GitPython#1909</a></li>
<li>Replace the Suboptimal <code>fuzz_tree.py</code> Harness With a Better Alternative by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1910"">gitpython-developers/GitPython#1910</a></li>
<li>Add git.Blob Fuzz Target by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1911"">gitpython-developers/GitPython#1911</a></li>
<li>lint: switch order Ruff's hooks <code>fix</code> -&gt; <code>format</code> by <a href=""https://github.com/Borda""><code>@​Borda</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1912"">gitpython-developers/GitPython#1912</a></li>
<li>Update OSS-Fuzz Scripts to Use New QA-Assets Repo Structure by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1913"">gitpython-developers/GitPython#1913</a></li>
<li>Add <code>Diff</code> Fuzz Target by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1914"">gitpython-developers/GitPython#1914</a></li>
<li>Instrument test utility functions to increase fuzzer efficiency by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1915"">gitpython-developers/GitPython#1915</a></li>
<li>Add the <code>.git</code> subdir as another <code>safe.directory</code> on Cygwin CI by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1916"">gitpython-developers/GitPython#1916</a></li>
<li>Bump Vampire/setup-wsl from 3.0.0 to 3.1.0 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1917"">gitpython-developers/GitPython#1917</a></li>
<li>Add Submodules Fuzz Target by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1919"">gitpython-developers/GitPython#1919</a></li>
<li>Add graceful handling of expected exceptions in fuzz_submodule.py by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1922"">gitpython-developers/GitPython#1922</a></li>
<li>precommit: enable <code>validate-pyproject</code> by <a href=""https://github.com/Borda""><code>@​Borda</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1921"">gitpython-developers/GitPython#1921</a></li>
<li>typing fixes - DiffIndex generic type and IndexFile items by <a href=""https://github.com/Andrej730""><code>@​Andrej730</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1925"">gitpython-developers/GitPython#1925</a></li>
<li>Fix Improper Import Order Breaking <code>fuzz_submodule</code> Fuzzer by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1926"">gitpython-developers/GitPython#1926</a></li>
<li>Fix iter_change_type diff renamed property to prevent warning by <a href=""https://github.com/kamilkrzyskow""><code>@​kamilkrzyskow</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1918"">gitpython-developers/GitPython#1918</a></li>
<li>fixed doc to not faulty do <a href=""https://redirect.github.com/gitpython-developers/GitPython/issues/1924"">#1924</a> by <a href=""https://github.com/zerothi""><code>@​zerothi</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1932"">gitpython-developers/GitPython#1932</a></li>
<li>fix: fix incoherent beginning whitespace by <a href=""https://github.com/cardoeng""><code>@​cardoeng</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1933"">gitpython-developers/GitPython#1933</a></li>
<li>Change aliases to work around mypy issue. by <a href=""https://github.com/PatrickMassot""><code>@​PatrickMassot</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1935"">gitpython-developers/GitPython#1935</a></li>
<li>precommit: enable <code>end-of-file-fixer</code> by <a href=""https://github.com/Borda""><code>@​Borda</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1920"">gitpython-developers/GitPython#1920</a></li>
<li>lint: add typos check by <a href=""https://github.com/Borda""><code>@​Borda</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1888"">gitpython-developers/GitPython#1888</a></li>
<li>Add type of change to files_dict of a commit by <a href=""https://github.com/JonasScharpf""><code>@​JonasScharpf</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1943"">gitpython-developers/GitPython#1943</a></li>
<li>Enable Python 3.8 and 3.9 on M1 runners by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1944"">gitpython-developers/GitPython#1944</a></li>
<li>Use Alpine Linux in WSL on CI by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1945"">gitpython-developers/GitPython#1945</a></li>
<li>Remove the non-ARM macOS CI jobs by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1946"">gitpython-developers/GitPython#1946</a></li>
<li>Fix Several Bugs in the <code>fuzz_submodule</code> Causing a lot of False Alarms in the OSS-Fuzz Bug Tracker by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1950"">gitpython-developers/GitPython#1950</a></li>
<li>Gracefully handle <code>PermissionError</code> exceptions that crash fuzzer by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1951"">gitpython-developers/GitPython#1951</a></li>
<li>Fuzzing: Gracefully Handle Uninteresting Error to Fix OSS-Fuzz Issue by <a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1952"">gitpython-developers/GitPython#1952</a></li>
<li>Update and adjust pre-commit hooks by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1953"">gitpython-developers/GitPython#1953</a></li>
<li>Upgrade sphinx to ~7.1.2 by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1954"">gitpython-developers/GitPython#1954</a></li>
<li>Don't support building documentation on Python 3.7 by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1956"">gitpython-developers/GitPython#1956</a></li>
<li>_to_relative_path to support mixing slashes and backslashes by <a href=""https://github.com/Andrej730""><code>@​Andrej730</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1961"">gitpython-developers/GitPython#1961</a></li>
<li>Update base.py by <a href=""https://github.com/alex20230721""><code>@​alex20230721</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1965"">gitpython-developers/GitPython#1965</a></li>
<li>Fix Fetch progress bar by <a href=""https://github.com/fvalette-ledger""><code>@​fvalette-ledger</code></a> in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1971"">gitpython-developers/GitPython#1971</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/EduardTalanov""><code>@​EduardTalanov</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1899"">gitpython-developers/GitPython#1899</a></li>
<li><a href=""https://github.com/DaveLak""><code>@​DaveLak</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1901"">gitpython-developers/GitPython#1901</a></li>
<li><a href=""https://github.com/Andrej730""><code>@​Andrej730</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/GitPython/pull/1925"">gitpython-developers/GitPython#1925</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/fb1b05124f1070ed56231a782daee0ffce9e1372""><code>fb1b051</code></a> bump patch level to prepare new version</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/e51bf80ad576256f2fbeead41ea3f0b667c77055""><code>e51bf80</code></a> update GitDB submodule to latest pubslished version</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/a52722421e9afd333ed60be1ebf5a5aebb9a7e05""><code>a527224</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/GitPython/issues/1971"">#1971</a> from fvalette-ledger/fix-fetch-progress-bar</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/d6cdb67bcaa2cf606bfc0a9295aacb54677ea86d""><code>d6cdb67</code></a> See if python 3.7 still works when using an older Ubuntu version.</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/52cceaf2663422a79a0f1d21f905eb132e46b556""><code>52cceaf</code></a> git,cmd: add encoding arg to popen if universal newlines is True</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/1bb465122f9673c9834b094c49d815148e84b8eb""><code>1bb4651</code></a> git,remote: use universal new lines for fetch/pull stderr capture</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/49ca9099dc75d0d686ec6737da36637cbee1c000""><code>49ca909</code></a> Update base.py (<a href=""https://redirect.github.com/gitpython-developers/GitPython/issues/1965"">#1965</a>)</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/3470fb3e5ff7f77e5bd19bc264163cd31db4a5df""><code>3470fb3</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/GitPython/issues/1961"">#1961</a> from Andrej730/main</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/8327b82a1079f667006f649cb3f1bbdcc8792955""><code>8327b82</code></a> Fix test failing on unix</li>
<li><a href=""https://github.com/gitpython-developers/GitPython/commit/46740590f7918fd5b789c95db7e41fbda06fb46f""><code>4674059</code></a> Remove redundant path normalization for working_tree_dir</li>
<li>Additional commits viewable in <a href=""https://github.com/gitpython-developers/GitPython/compare/3.1.43...3.1.44"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=gitpython&package-manager=pip&previous-version=3.1.43&new-version=3.1.44)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2025-01-02 16:24:18+00:00,[],2025-01-02 16:48:59+00:00,2025-01-02 16:48:50+00:00,https://github.com/apache/airflow/pull/45358,"[('area:dependencies', 'Issues related to dependencies problems')]","[{'comment_id': 2568055826, 'issue_id': 2766304241, 'author': 'potiuk', 'body': '@dependabot rebase', 'created_at': datetime.datetime(2025, 1, 2, 16, 38, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568069797, 'issue_id': 2766304241, 'author': 'potiuk', 'body': 'Images were built, so we can safely merge it.', 'created_at': datetime.datetime(2025, 1, 2, 16, 48, 46, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 16:38:53 UTC): @dependabot rebase

potiuk on (2025-01-02 16:48:46 UTC): Images were built, so we can safely merge it.

"
2766303947,pull_request,closed,,Bump gitdb from 4.0.11 to 4.0.12,"Bumps [gitdb](https://github.com/gitpython-developers/gitdb) from 4.0.11 to 4.0.12.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/gitpython-developers/gitdb/releases"">gitdb's releases</a>.</em></p>
<blockquote>
<h2>4.0.12</h2>
<h2>What's Changed</h2>
<ul>
<li>Never add a vendored smmap directory to sys.path by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/102"">gitpython-developers/gitdb#102</a></li>
<li>Revise and update the readme by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/103"">gitpython-developers/gitdb#103</a></li>
<li>Set Dependabot submodule update cadence to weekly by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/104"">gitpython-developers/gitdb#104</a></li>
<li>Add missing asserts in test_base.py by <a href=""https://github.com/Clavss""><code>@​Clavss</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/109"">gitpython-developers/gitdb#109</a></li>
<li>Use contextlib.suppress instead of except: pass by <a href=""https://github.com/blablatdinov""><code>@​blablatdinov</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/113"">gitpython-developers/gitdb#113</a></li>
<li>Add support for Python 3.13 by <a href=""https://github.com/edgarrmondragon""><code>@​edgarrmondragon</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/114"">gitpython-developers/gitdb#114</a></li>
<li>Potential Race Condition Fix - OS Rename &amp; Chmod - PermissionError by <a href=""https://github.com/DEKHTIARJonathan""><code>@​DEKHTIARJonathan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/115"">gitpython-developers/gitdb#115</a></li>
<li>Bump gitdb/ext/smmap from <code>256c5a2</code> to <code>04dd210</code> by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/112"">gitpython-developers/gitdb#112</a></li>
<li>Bump actions/setup-python from 4 to 5 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/111"">gitpython-developers/gitdb#111</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/Clavss""><code>@​Clavss</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/109"">gitpython-developers/gitdb#109</a></li>
<li><a href=""https://github.com/blablatdinov""><code>@​blablatdinov</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/113"">gitpython-developers/gitdb#113</a></li>
<li><a href=""https://github.com/edgarrmondragon""><code>@​edgarrmondragon</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/114"">gitpython-developers/gitdb#114</a></li>
<li><a href=""https://github.com/DEKHTIARJonathan""><code>@​DEKHTIARJonathan</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/gitdb/pull/115"">gitpython-developers/gitdb#115</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/gitpython-developers/gitdb/compare/4.0.11...4.0.12"">https://github.com/gitpython-developers/gitdb/compare/4.0.11...4.0.12</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/104138c742a56d85bd2cb2cd8a9f90336daa5483""><code>104138c</code></a> bump patch level to prepare for next release</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/bcbe5dfbe36eb26b5f5134dba960021c6795f9c1""><code>bcbe5df</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/gitdb/issues/111"">#111</a> from gitpython-developers/dependabot/github_actions/a...</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/be483fc68010c3eaaa3ef2131b9f200338097a3d""><code>be483fc</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/gitdb/issues/112"">#112</a> from gitpython-developers/dependabot/submodules/gitdb...</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/38b5c385b4de522f37285128b7f405c04958f4a1""><code>38b5c38</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/gitdb/issues/115"">#115</a> from DEKHTIARJonathan/patch-1</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/b71e2730c3dcab148816f0193a45550ef0a38c79""><code>b71e273</code></a> Update gitdb/db/loose.py</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/74a0eabbc03209593ea1562498802359ae8a3db7""><code>74a0eab</code></a> Potential Race Condition Fix - OS Rename &amp; Chmod</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/a8c894f84a419b22583895789ef849090c2f7f49""><code>a8c894f</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/gitdb/issues/114"">#114</a> from edgarrmondragon/cp313</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/b38cbc43354523ffcd59a58c5a3aded054bd4442""><code>b38cbc4</code></a> Use older ubuntu to get Python 3.7</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/5bc95043792c2412b05263fb4bfca67d7923645c""><code>5bc9504</code></a> Add support for Python 3.13</li>
<li><a href=""https://github.com/gitpython-developers/gitdb/commit/88da5efb96f3578a315c3e819ccf0f3edb080eec""><code>88da5ef</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/gitdb/issues/113"">#113</a> from blablatdinov/use-contextlib-suppress</li>
<li>Additional commits viewable in <a href=""https://github.com/gitpython-developers/gitdb/compare/4.0.11...4.0.12"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=gitdb&package-manager=pip&previous-version=4.0.11&new-version=4.0.12)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2025-01-02 16:24:06+00:00,[],2025-01-02 16:38:25+00:00,2025-01-02 16:38:18+00:00,https://github.com/apache/airflow/pull/45357,"[('area:dependencies', 'Issues related to dependencies problems')]",[],
2766301419,pull_request,closed,,Bump smmap from 5.0.1 to 5.0.2,"Bumps [smmap](https://github.com/gitpython-developers/smmap) from 5.0.1 to 5.0.2.
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/gitpython-developers/smmap/releases"">smmap's releases</a>.</em></p>
<blockquote>
<h2>v5.0.2</h2>
<h2>What's Changed</h2>
<ul>
<li>Update CI, in line with gitdb by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/smmap/pull/53"">gitpython-developers/smmap#53</a></li>
<li>No longer treat 3.12 as experimental on smmap CI by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/smmap/pull/54"">gitpython-developers/smmap#54</a></li>
<li>Bump actions/setup-python from 4 to 5 by <a href=""https://github.com/dependabot""><code>@​dependabot</code></a> in <a href=""https://redirect.github.com/gitpython-developers/smmap/pull/55"">gitpython-developers/smmap#55</a></li>
<li>Replace use of mktemp by <a href=""https://github.com/EliahKagan""><code>@​EliahKagan</code></a> in <a href=""https://redirect.github.com/gitpython-developers/smmap/pull/56"">gitpython-developers/smmap#56</a></li>
<li>Use SPDX identifier by <a href=""https://github.com/Shortfinga""><code>@​Shortfinga</code></a> in <a href=""https://redirect.github.com/gitpython-developers/smmap/pull/57"">gitpython-developers/smmap#57</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/dependabot""><code>@​dependabot</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/smmap/pull/55"">gitpython-developers/smmap#55</a></li>
<li><a href=""https://github.com/Shortfinga""><code>@​Shortfinga</code></a> made their first contribution in <a href=""https://redirect.github.com/gitpython-developers/smmap/pull/57"">gitpython-developers/smmap#57</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/gitpython-developers/smmap/compare/v5.0.1...v5.0.2"">https://github.com/gitpython-developers/smmap/compare/v5.0.1...v5.0.2</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/f31bfa378c8840d38d31e7e11ef2b84f191a491e""><code>f31bfa3</code></a> bump patch level prior to new release</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/59c88c0a497192d3041c09272c60d78eeeea0062""><code>59c88c0</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/smmap/issues/57"">#57</a> from Shortfinga/master</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/f71bbd48fa80f5f4408f24be76e7739b2d860b91""><code>f71bbd4</code></a> Use SPDX identifier</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/04dd2103ee6e0b7483889e5feda25053c6df2b52""><code>04dd210</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/smmap/issues/56"">#56</a> from EliahKagan/no-mktemp</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/a315725c68295a02f3d007409ea3101430543289""><code>a315725</code></a> Replace use of mktemp</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/7d6f97c671608dfb72f7f8f318202fd1388515ad""><code>7d6f97c</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/smmap/issues/55"">#55</a> from gitpython-developers/dependabot/github_actions/ac...</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/36dd418b05f962569fd894d4edf533fc8d7c5bed""><code>36dd418</code></a> Bump actions/setup-python from 4 to 5</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/f1ace75be355fdec927793e462b9b12bf6ec9520""><code>f1ace75</code></a> Merge pull request <a href=""https://redirect.github.com/gitpython-developers/smmap/issues/54"">#54</a> from EliahKagan/312stable</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/44ac30a7481a619e32b13a4efc1de0479b1b4379""><code>44ac30a</code></a> No longer treat 3.12 as experimental on CI</li>
<li><a href=""https://github.com/gitpython-developers/smmap/commit/69cd90ff968bd466b26d52859e5a850b6ce300b1""><code>69cd90f</code></a> Run CI on all branches</li>
<li>Additional commits viewable in <a href=""https://github.com/gitpython-developers/smmap/compare/v5.0.1...v5.0.2"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=smmap&package-manager=pip&previous-version=5.0.1&new-version=5.0.2)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2025-01-02 16:22:17+00:00,[],2025-01-02 16:38:41+00:00,2025-01-02 16:37:43+00:00,https://github.com/apache/airflow/pull/45356,"[('area:dependencies', 'Issues related to dependencies problems')]","[{'comment_id': 2568043712, 'issue_id': 2766301419, 'author': 'potiuk', 'body': 'Look @gopidesupavan -> Your contribution to dependabot in action !', 'created_at': datetime.datetime(2025, 1, 2, 16, 30, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568055540, 'issue_id': 2766301419, 'author': 'gopidesupavan', 'body': '> Look @gopidesupavan -> Your contribution to dependabot in action !\r\n\r\nhaha Yeah :)', 'created_at': datetime.datetime(2025, 1, 2, 16, 38, 40, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 16:30:04 UTC): Look @gopidesupavan -> Your contribution to dependabot in action !

gopidesupavan on (2025-01-02 16:38:40 UTC): haha Yeah :)

"
2766167729,pull_request,open,,Introduce operation helper class and refactor Google provider hooks,"- Refactor google cloud hooks, that used generic 'wait_for_operation' methods.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",olegkachur-e,2025-01-02 14:54:51+00:00,[],2025-02-07 14:27:15+00:00,,https://github.com/apache/airflow/pull/45354,"[('provider:google', 'Google (including GCP) related issues'), ('area:providers', '')]","[{'comment_id': 2574932699, 'issue_id': 2766167729, 'author': 'MaksYermak', 'body': '@potiuk could you please check this PR?', 'created_at': datetime.datetime(2025, 1, 7, 10, 28, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2628930270, 'issue_id': 2766167729, 'author': 'potiuk', 'body': 'There are some conflicts to be resolved and we are about to migrate Google provider to the new provider structure, so you will have to rebase it and adapt to the moved files.', 'created_at': datetime.datetime(2025, 2, 1, 12, 17, 41, tzinfo=datetime.timezone.utc)}]","MaksYermak on (2025-01-07 10:28:54 UTC): @potiuk could you please check this PR?

potiuk on (2025-02-01 12:17:41 UTC): There are some conflicts to be resolved and we are about to migrate Google provider to the new provider structure, so you will have to rebase it and adapt to the moved files.

"
2766142193,pull_request,closed,,fix: spark operator label,"KubernetesPodOperator renamed create_labels_for_pod, _get_pod_identifying_label_string, but it seems that SparkKubernetesOperator hasn't changed them.",chenkovsky,2025-01-02 14:38:46+00:00,[],2025-02-05 22:24:24+00:00,2025-02-05 22:24:21+00:00,https://github.com/apache/airflow/pull/45353,"[('area:providers', ''), ('provider:cncf-kubernetes', 'Kubernetes provider related issues')]","[{'comment_id': 2585651182, 'issue_id': 2766142193, 'author': 'potiuk', 'body': 'Can you add a unit test there to avoid regressions?', 'created_at': datetime.datetime(2025, 1, 12, 9, 6, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2614108005, 'issue_id': 2766142193, 'author': 'potiuk', 'body': ""Can you please fix static checks @chenkovsky ? As an author, your task is to make things green, so that we can merge it -otherwise we will break other's work."", 'created_at': datetime.datetime(2025, 1, 25, 21, 39, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2638176232, 'issue_id': 2766142193, 'author': 'boring-cyborg[bot]', 'body': 'Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.', 'created_at': datetime.datetime(2025, 2, 5, 22, 24, 23, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-12 09:06:46 UTC): Can you add a unit test there to avoid regressions?

potiuk on (2025-01-25 21:39:12 UTC): Can you please fix static checks @chenkovsky ? As an author, your task is to make things green, so that we can merge it -otherwise we will break other's work.

boring-cyborg[bot] on (2025-02-05 22:24:23 UTC): Awesome work, congrats on your first merged pull request! You are invited to check our [Issue Tracker](https://github.com/apache/airflow/issues) for additional contributions.

"
2766108187,pull_request,closed,,Cleanup some (old) tasks UI tests,"(let's try #45335 again)

These tests don't need to use a dedicated DAG, plus this is the only use of DAGs from the tests dag dir, which means we can later switch to only parsing the example DAGs.

This also removes a couple leftover DAG code related tests that aren't needed anymore - all DAG code comes from the db, and we parse/store example DAGs all over the place, so no extra value with these tests.

Why am I touching old UI stuff? My parsing changes for DAG bundles breaks a bunch of these tests, and we aren't quite ready to remove the old UI...",jedcunningham,2025-01-02 14:17:09+00:00,[],2025-01-02 17:00:07+00:00,2025-01-02 17:00:06+00:00,https://github.com/apache/airflow/pull/45352,"[('area:webserver', 'Webserver related Issues')]",[],
2766040902,pull_request,open,,Add action for alerts on slack for new code scans,"<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->

closes: #44382

Added a new action that can send alerts on slack for any ""new"" code scans in the ""security"" tab. Ref: https://docs.github.com/en/code-security/code-scanning/managing-code-scanning-alerts/about-code-scanning-alerts

TODO:
- Test the working
- Change the channel name once we get a green run
- Refine 


<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",amoghrajesh,2025-01-02 13:31:37+00:00,[],2025-01-02 14:00:31+00:00,,https://github.com/apache/airflow/pull/45351,"[('area:dev-tools', '')]",[],
2766033119,pull_request,closed,,"Revert ""Cleanup some (old) tasks UI tests (#45335)""","This reverts commit 8fcde8cef91f9a7b37ef6a903ebf273aa4ecbf18.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-02 13:26:06+00:00,[],2025-01-02 13:27:26+00:00,2025-01-02 13:27:24+00:00,https://github.com/apache/airflow/pull/45350,"[('area:webserver', 'Webserver related Issues')]",[],
2765991846,pull_request,closed,,Update taskinstance clear endpoint to support mapped tasks,"closes: https://github.com/apache/airflow/issues/44867

**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",vatsrahul1001,2025-01-02 12:58:13+00:00,[],2025-01-27 11:35:07+00:00,2025-01-27 11:35:04+00:00,https://github.com/apache/airflow/pull/45349,"[('area:webserver', 'Webserver related Issues'), ('area:API', ""Airflow's REST/HTTP API""), ('area:UI', 'Related to UI/UX. For Frontend Developers.'), ('legacy ui', 'Whether legacy UI change should be allowed in PR'), ('legacy api', 'Whether legacy API changes should be allowed in PR')]","[{'comment_id': 2568117765, 'issue_id': 2765991846, 'author': 'jscheffl', 'body': 'I you plan to update the API, this one (connexion) is the legacy one which will be dropped in Airflow 3. Can you please also change the fast_api which will be the future/Airflow 3 API backend?\r\n\r\nAs this change is on connexion API, is this to be back-ported to Airflow 2.10 as well? Then it should be classified as a bug, as we actually do not plan to have new features on Airflow 2.10', 'created_at': datetime.datetime(2025, 1, 2, 17, 25, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2574393826, 'issue_id': 2765991846, 'author': 'vatsrahul1001', 'body': '+1 @pierrejeambrun @jscheffl . I agree as its a new feature/Improvement this should only go to FastAPI. I will update this for only FastAPI.\r\n>  I think this one is really an improvement/feature. I would be for simply not releasing this in 2.x at all. Features are for 3.0, and just do the change in the fastapi API.', 'created_at': datetime.datetime(2025, 1, 7, 4, 57, 18, tzinfo=datetime.timezone.utc)}]","jscheffl on (2025-01-02 17:25:18 UTC): I you plan to update the API, this one (connexion) is the legacy one which will be dropped in Airflow 3. Can you please also change the fast_api which will be the future/Airflow 3 API backend?

As this change is on connexion API, is this to be back-ported to Airflow 2.10 as well? Then it should be classified as a bug, as we actually do not plan to have new features on Airflow 2.10

vatsrahul1001 (Issue Creator) on (2025-01-07 04:57:18 UTC): +1 @pierrejeambrun @jscheffl . I agree as its a new feature/Improvement this should only go to FastAPI. I will update this for only FastAPI.

"
2765962030,pull_request,closed,,do not push stale update to related DagRun on TI update after task execution,"This is a re-targeted pr https://github.com/apache/airflow/pull/44547 for Airflow 2.X version only, as this fix loses relevancy for Airflow 3.

When TI is marked as failed via UI, and later fails itself, scheduler changes the state to failed twice.

(some extra logs for clarity)

```
[2024-11-28T14:48:11.276+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 75
[2024-11-28T14:48:11.284+0000] {scheduler_job_runner.py:1666} ERROR - Scheduling dag run <DagRun wait_to_fail @ 2024-11-28 14:48:04.731
025+00:00: manual__2024-11-28T14:48:04.731025+00:00, state:running, queued_at: 2024-11-28 14:48:04.739184+00:00. externally triggered:
True> state running
[2024-11-28T14:48:11.287+0000] {dagrun.py:906} ERROR - Marking run <DagRun wait_to_fail @ 2024-11-28 14:48:04.731025+00:00: manual__202
4-11-28T14:48:04.731025+00:00, state:running, queued_at: 2024-11-28 14:48:04.739184+00:00. externally triggered: True> failed - from st
ate running at 2024-11-28 14:48:11.286513+00:00
[2024-11-28T14:48:11.288+0000] {dagrun.py:1101} ERROR - NOTIFYING STATE CHANGED TO failed
[2024-11-28T14:48:11.289+0000] {dagrun.py:989} INFO - DagRun Finished: dag_id=wait_to_fail, logical_date=2024-11-28 14:48:04.731025+00:
00, run_id=manual__2024-11-28T14:48:04.731025+00:00, run_start_date=2024-11-28 14:48:05.186397+00:00, run_end_date=2024-11-28 14:48:11.
288084+00:00, run_duration=6.101687, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-11-28 14:48:04.7310
25+00:00, data_interval_end=2024-11-28 14:48:04.731025+00:00, dag_version_name=wait_to_fail-1
[2024-11-28T14:48:11.299+0000] {client.py:110} INFO - OpenLineageClient will use `http` transport
[2024-11-28T14:48:12.307+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 76
[2024-11-28T14:48:13.344+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 77
[2024-11-28T14:48:14.382+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 78
[2024-11-28T14:48:15.274+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 79
[2024-11-28T14:48:16.309+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 80
[2024-11-28T14:48:17.345+0000] {scheduler_job_runner.py:1092} INFO - another scheduler loop 81
[2024-11-28T14:48:17.361+0000] {scheduler_job_runner.py:1666} ERROR - Scheduling dag run <DagRun wait_to_fail @ 2024-11-28 14:48:04.731
025+00:00: manual__2024-11-28T14:48:04.731025+00:00, state:running, queued_at: 2024-11-28 14:48:04.739184+00:00. externally triggered:
True> state running
[2024-11-28T14:48:17.366+0000] {dagrun.py:906} ERROR - Marking run <DagRun wait_to_fail @ 2024-11-28 14:48:04.731025+00:00: manual__202
4-11-28T14:48:04.731025+00:00, state:running, queued_at: 2024-11-28 14:48:04.739184+00:00. externally triggered: True> failed - from st
ate running at 2024-11-28 14:48:17.364879+00:00
[2024-11-28T14:48:17.366+0000] {dagrun.py:1101} ERROR - NOTIFYING STATE CHANGED TO failed
[2024-11-28T14:48:17.367+0000] {dagrun.py:989} INFO - DagRun Finished: dag_id=wait_to_fail, logical_date=2024-11-28 14:48:04.731025+00:
00, run_id=manual__2024-11-28T14:48:04.731025+00:00, run_start_date=2024-11-28 14:48:05.186397+00:00, run_end_date=2024-11-28 14:48:17.
366330+00:00, run_duration=12.179933, state=failed, external_trigger=True, run_type=manual, data_interval_start=2024-11-28 14:48:04.731
025+00:00, data_interval_end=2024-11-28 14:48:04.731025+00:00, dag_version_name=wait_to_fail-1
[2024-11-28T14:48:17.370+0000] {client.py:110} INFO - OpenLineageClient will use `http` transport
```

This happens because on handle_failure, TaskInstance.save_to_db not only updates state of that task instance, it also pushes stale DagRun state - the one it got on TI start. So the actual DR state goes running -> failed -> running -> failed.

This causes other unintended behavior, such as calling on_dag_run_failed listeners twice.

The solution just loads DR state from db before pushing TI state. However, there probably is better solution, that someone with more knowledge of SQLAlchemy might help with.

Link to discussion on Airflow slack: https://apache-airflow.slack.com/archives/C06K9Q5G2UA/p1732805503889679",mobuchowski,2025-01-02 12:36:45+00:00,[],2025-01-28 12:06:40+00:00,2025-01-08 18:33:16+00:00,https://github.com/apache/airflow/pull/45348,"[('type:bug-fix', 'Changelog: Bug Fixes'), ('area:core-operators', 'Operators, Sensors and hooks within Core Airflow')]",[],
2765915731,pull_request,closed,,Fix wrongly skipping image artifacts upload,"The #45314 introduced the bug where image artifacts were not uploaded alongside cache mount artifacts. It caused all PRs to be tested with ""main"" version of code.

<!--
 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 ""License""); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

   http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing,
 software distributed under the License is distributed on an
 ""AS IS"" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY
 KIND, either express or implied.  See the License for the
 specific language governing permissions and limitations
 under the License.
 -->

<!--
Thank you for contributing! Please make sure that your code changes
are covered with tests. And in case of new features or big changes
remember to adjust the documentation.

Feel free to ping committers for the review!

In case of an existing issue, reference it using one of the following:

closes: #ISSUE
related: #ISSUE

How to write a good git commit message:
http://chris.beams.io/posts/git-commit/
-->



<!-- Please keep an empty line above the dashes. -->
---
**^ Add meaningful description above**
Read the **[Pull Request Guidelines](https://github.com/apache/airflow/blob/main/contributing-docs/05_pull_requests.rst#pull-request-guidelines)** for more information.
In case of fundamental code changes, an Airflow Improvement Proposal ([AIP](https://cwiki.apache.org/confluence/display/AIRFLOW/Airflow+Improvement+Proposals)) is needed.
In case of a new dependency, check compliance with the [ASF 3rd Party License Policy](https://www.apache.org/legal/resolved.html#category-x).
In case of backwards incompatible changes please leave a note in a newsfragment file, named `{pr_number}.significant.rst` or `{issue_number}.significant.rst`, in [newsfragments](https://github.com/apache/airflow/tree/main/newsfragments).
",potiuk,2025-01-02 12:03:12+00:00,[],2025-01-02 12:32:47+00:00,2025-01-02 12:14:03+00:00,https://github.com/apache/airflow/pull/45347,"[('area:dev-tools', '')]","[{'comment_id': 2567707025, 'issue_id': 2765915731, 'author': 'gopidesupavan', 'body': 'Nice, about to get to this one while looking at #44533  :)', 'created_at': datetime.datetime(2025, 1, 2, 12, 32, 30, tzinfo=datetime.timezone.utc)}]","gopidesupavan on (2025-01-02 12:32:30 UTC): Nice, about to get to this one while looking at #44533  :)

"
2765873745,pull_request,closed,,Workaround problems after release of pytest-asyncio 0.25.1 with Python 3.12,"Fixes broken canary after release of pytest-asyncio 0.25.1
see https://github.com/apache/airflow/actions/runs/12579028168
As well https://github.com/apache/airflow/actions/runs/12579028168",jscheffl,2025-01-02 11:32:51+00:00,[],2025-01-02 16:18:31+00:00,2025-01-02 16:18:31+00:00,https://github.com/apache/airflow/pull/45346,"[('disable image cache', 'Disables cache when buidling CI images'), ('area:task-sdk', None)]","[{'comment_id': 2567640157, 'issue_id': 2765873745, 'author': 'potiuk', 'body': ""Let's see if that one will work ,,, we can determine further actions based on that"", 'created_at': datetime.datetime(2025, 1, 2, 11, 35, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567670470, 'issue_id': 2765873745, 'author': 'jscheffl', 'body': ""Let's re-run w/o cache..."", 'created_at': datetime.datetime(2025, 1, 2, 12, 1, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567680140, 'issue_id': 2765873745, 'author': 'potiuk', 'body': '> Let\'s re-run w/o cache...\r\n\r\nI think this will not work - ""disable"" cache only disables cache when building the image - and the problem is that this image is anyhow not used in tests even if it is build without cache.', 'created_at': datetime.datetime(2025, 1, 2, 12, 9, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567680569, 'issue_id': 2765873745, 'author': 'potiuk', 'body': 'https://github.com/apache/airflow/pull/45347 is the solution', 'created_at': datetime.datetime(2025, 1, 2, 12, 9, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2567893034, 'issue_id': 2765873745, 'author': 'potiuk', 'body': ""(unless we can determine who's at fault ;)"", 'created_at': datetime.datetime(2025, 1, 2, 14, 51, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2568027027, 'issue_id': 2765873745, 'author': 'potiuk', 'body': 'Created https://github.com/apache/airflow/issues/45355 - there are other issues that are not relevant here.', 'created_at': datetime.datetime(2025, 1, 2, 16, 18, 12, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 11:35:33 UTC): Let's see if that one will work ,,, we can determine further actions based on that

jscheffl (Issue Creator) on (2025-01-02 12:01:23 UTC): Let's re-run w/o cache...

potiuk on (2025-01-02 12:09:22 UTC): I think this will not work - ""disable"" cache only disables cache when building the image - and the problem is that this image is anyhow not used in tests even if it is build without cache.

potiuk on (2025-01-02 12:09:43 UTC): https://github.com/apache/airflow/pull/45347 is the solution

potiuk on (2025-01-02 14:51:59 UTC): (unless we can determine who's at fault ;)

potiuk on (2025-01-02 16:18:12 UTC): Created https://github.com/apache/airflow/issues/45355 - there are other issues that are not relevant here.

"
2765745836,pull_request,closed,,Move Literal alias into TYPE_CHECKING block,"This allows us to always import Literal from typing, which has received quite some bug fixes between different versions. Doing this in the typing block avoids loading the runtime version at all, thus eliminating differences between runtime Python versions.
",uranusjr,2025-01-02 10:01:45+00:00,[],2025-01-09 05:34:07+00:00,2025-01-09 05:34:06+00:00,https://github.com/apache/airflow/pull/45345,"[('provider:amazon', 'AWS/Amazon - related issues'), ('area:CLI', ''), ('area:providers', ''), ('provider:docker', ''), ('provider:weaviate', ''), ('provider:standard', '')]","[{'comment_id': 2567697315, 'issue_id': 2765745836, 'author': 'potiuk', 'body': '@uranusjr   - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.', 'created_at': datetime.datetime(2025, 1, 2, 12, 24, tzinfo=datetime.timezone.utc)}]","potiuk on (2025-01-02 12:24:00 UTC): @uranusjr   - can you please rebase that one -> we found and issue with @jscheffl with the new caching scheme - fixed in https://github.com/apache/airflow/pull/45347 that would run ""main"" version of the tests. I am asking in all affected PRs to rebase.

"
