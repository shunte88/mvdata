id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2516204078,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:42:10+00:00,[],2024-09-11 12:20:16+00:00,2024-09-11 12:20:15+00:00,https://github.com/tensorflow/tensorflow/pull/75490,[],[],
2516178874,pull_request,closed,,PR #15317: Add rendezvous timeouts as new XLA flags.,"PR #15317: Add rendezvous timeouts as new XLA flags.

Imported from GitHub PR https://github.com/openxla/xla/pull/15317

We found the need to increase the warn-stuck timeout at @xai-org.
Copybara import of the project:

--
261f88f6a2e5cc5f8bb5cb13c15cbaee5b837883 by Heiner <heiner@x.ai>:

Add rendezvous timeouts as new XLA flags.

--
45579f82843beb1e041fd7afa049459a051926c1 by Heiner <heiner@x.ai>:

Add xla.proto entry, clang-format.

--
220e85c9107af7164c2d43ac01dce9535f37902d by Heiner <heiner@x.ai>:

bool -> int32.

--
83a1ddd997b9ab195c0c74ba804aeeb6dbff17d4 by Heiner <heiner@x.ai>:

Add missing arg.

Merging this change closes #15317

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15317 from heiner:heiner/rendezvous-timeout a5b464d7b77639313ba5e138e754ed370686f36a
",copybara-service[bot],2024-09-10 11:29:44+00:00,[],2024-09-10 12:40:05+00:00,2024-09-10 12:40:04+00:00,https://github.com/tensorflow/tensorflow/pull/75489,[],[],
2516133587,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:07:51+00:00,[],2024-09-11 05:44:16+00:00,,https://github.com/tensorflow/tensorflow/pull/75488,[],[],
2516127185,pull_request,closed,,PR #16954: Avoid dynamic-slice-fusion when reduce-scatter has tuple output,"PR #16954: Avoid dynamic-slice-fusion when reduce-scatter has tuple output

Imported from GitHub PR https://github.com/openxla/xla/pull/16954

Tuple outputs are not handled while emitting thunks for dynamic-slice fusion. This patch avoids fusing them altogether while the support for multiple outputs is implemented.
Copybara import of the project:

--
3920334579c5a64f7de2adc97fb1ff3107ce9a04 by Shraiysh Vaishay <svaishay@nvidia.com>:

Avoid dynamic-slice-fusion when reduce-scatter has tuple output

Tuple outputs are not handled while emitting thunks for dynamic-slice
fusion. This patch avoids fusing them altogether while the support for
multiple outputs is implemented.

Merging this change closes #16954

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16954 from shraiysh:fix_reduce_scatter_ds_fusion 3920334579c5a64f7de2adc97fb1ff3107ce9a04
",copybara-service[bot],2024-09-10 11:04:47+00:00,[],2024-09-10 20:01:28+00:00,2024-09-10 20:01:27+00:00,https://github.com/tensorflow/tensorflow/pull/75487,[],[],
2516124793,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:03:37+00:00,[],2024-09-11 05:30:18+00:00,,https://github.com/tensorflow/tensorflow/pull/75486,[],[],
2516123828,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17021 from openxla:skozub/f8-cvt-intrinsics-v2 c7d86e0e1ee5a7e1db6c0828009c992639b48af0
",copybara-service[bot],2024-09-10 11:03:09+00:00,[],2024-09-11 07:05:53+00:00,,https://github.com/tensorflow/tensorflow/pull/75485,[],[],
2516122739,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:02:40+00:00,[],2024-09-11 05:21:10+00:00,2024-09-11 05:21:09+00:00,https://github.com/tensorflow/tensorflow/pull/75484,[],[],
2516120433,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:01:33+00:00,[],2024-09-11 08:10:05+00:00,,https://github.com/tensorflow/tensorflow/pull/75483,[],[],
2516120122,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:01:24+00:00,[],2024-09-11 06:07:04+00:00,,https://github.com/tensorflow/tensorflow/pull/75482,[],[],
2516120087,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:01:23+00:00,[],2024-09-14 04:48:15+00:00,2024-09-14 04:48:15+00:00,https://github.com/tensorflow/tensorflow/pull/75481,[],[],
2516119979,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16950 from dimvar:clarify-sm90a 0a90a5e15e132773288c6f6c48339fee85ec4cbf
",copybara-service[bot],2024-09-10 11:01:20+00:00,[],2024-09-10 11:01:20+00:00,,https://github.com/tensorflow/tensorflow/pull/75480,[],[],
2516119744,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:01:13+00:00,[],2024-09-11 07:26:57+00:00,,https://github.com/tensorflow/tensorflow/pull/75479,[],[],
2516119243,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:00:58+00:00,[],2024-09-11 08:20:08+00:00,,https://github.com/tensorflow/tensorflow/pull/75478,[],[],
2516118787,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:00:45+00:00,[],2024-09-11 07:13:06+00:00,,https://github.com/tensorflow/tensorflow/pull/75477,[],[],
2516118699,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:00:43+00:00,[],2024-09-11 09:51:57+00:00,,https://github.com/tensorflow/tensorflow/pull/75476,[],[],
2516118339,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:00:33+00:00,[],2024-09-11 08:23:41+00:00,,https://github.com/tensorflow/tensorflow/pull/75475,[],[],
2516118310,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 11:00:32+00:00,[],2024-09-11 04:12:19+00:00,,https://github.com/tensorflow/tensorflow/pull/75474,[],[],
2516116660,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 10:59:43+00:00,[],2024-09-11 04:36:28+00:00,,https://github.com/tensorflow/tensorflow/pull/75473,[],[],
2516116603,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 10:59:42+00:00,[],2024-09-11 07:45:16+00:00,,https://github.com/tensorflow/tensorflow/pull/75472,[],[],
2516114926,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 10:58:53+00:00,[],2024-09-11 06:00:11+00:00,,https://github.com/tensorflow/tensorflow/pull/75471,[],[],
2516114394,pull_request,open,,[XLA:GPU] Add a comment to 'is_simplified' field.,"[XLA:GPU] Add a comment to 'is_simplified' field.
",copybara-service[bot],2024-09-10 10:58:37+00:00,['pifon2a'],2024-09-10 10:58:38+00:00,,https://github.com/tensorflow/tensorflow/pull/75470,[],[],
2516112704,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 10:57:50+00:00,[],2024-09-11 06:09:38+00:00,,https://github.com/tensorflow/tensorflow/pull/75469,[],[],
2516091157,pull_request,closed,,[XLA:GPU][NFC] Make HloFusionAdaptor non-copyable and non-movable and make the ctor private.,"[XLA:GPU][NFC] Make HloFusionAdaptor non-copyable and non-movable and make the ctor private.
",copybara-service[bot],2024-09-10 10:47:55+00:00,['chsigg'],2024-09-10 14:21:00+00:00,2024-09-10 14:20:59+00:00,https://github.com/tensorflow/tensorflow/pull/75468,[],[],
2516065360,pull_request,open,,PR #16236: Align the scheduling name with the instruction name after HLO rematerialization,"PR #16236: Align the scheduling name with the instruction name after HLO rematerialization

Imported from GitHub PR https://github.com/openxla/xla/pull/16236

This CL is to fix the assertion failures in HLO verifier when checking scheduling names after HLO rematerialization.
Copybara import of the project:

--
274920bc7e7de159224bc8fa2cd7781eecbf1bb6 by Jane Liu <janeliu@nvidia.com>:

Align the scheduling name with the instruction name after HLO rematerialization.

--
d40260eb1846df37ce21faacc4c6dcb66c840b78 by Jane Liu <janeliu@nvidia.com>:

Simplify the code by changing hlo_rematerialization only.

--
1c1c76d42b05839563e4a44cb367ce091f44d00d by Jane Liu <janeliu@nvidia.com>:

Only update scheduling_name for mismatched instructions

Merging this change closes #16236

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16236 from zhenying-liu:remat-scheduling-name 1c1c76d42b05839563e4a44cb367ce091f44d00d
",copybara-service[bot],2024-09-10 10:36:34+00:00,[],2024-09-10 10:36:34+00:00,,https://github.com/tensorflow/tensorflow/pull/75467,[],[],
2516058586,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 10:33:14+00:00,[],2024-09-10 10:33:14+00:00,,https://github.com/tensorflow/tensorflow/pull/75466,[],[],
2515955181,pull_request,closed,,PR #16950: Clarify that sm_90a should only be used on Hopper,"PR #16950: Clarify that sm_90a should only be used on Hopper

Imported from GitHub PR https://github.com/openxla/xla/pull/16950

Same as the comment in xla/service/gpu/llvm_gpu_backend/gpu_backend_lib.cc, from the original change:
https://github.com/openxla/xla/commit/754b68363d48215baf90f32288d411406761af9f
Copybara import of the project:

--
0a90a5e15e132773288c6f6c48339fee85ec4cbf by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Clarify that sm_90a should only be used on Hopper

Merging this change closes #16950

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16950 from dimvar:clarify-sm90a 0a90a5e15e132773288c6f6c48339fee85ec4cbf
",copybara-service[bot],2024-09-10 09:47:57+00:00,[],2024-09-10 10:57:46+00:00,2024-09-10 10:57:44+00:00,https://github.com/tensorflow/tensorflow/pull/75464,[],[],
2515935355,pull_request,open,,PR #15317: Add rendezvous timeouts as new XLA flags.,"PR #15317: Add rendezvous timeouts as new XLA flags.

Imported from GitHub PR https://github.com/openxla/xla/pull/15317

We found the need to increase the warn-stuck timeout at @xai-org.
Copybara import of the project:

--
261f88f6a2e5cc5f8bb5cb13c15cbaee5b837883 by Heiner <heiner@x.ai>:

Add rendezvous timeouts as new XLA flags.

--
45579f82843beb1e041fd7afa049459a051926c1 by Heiner <heiner@x.ai>:

Add xla.proto entry, clang-format.

--
220e85c9107af7164c2d43ac01dce9535f37902d by Heiner <heiner@x.ai>:

bool -> int32.

--
83a1ddd997b9ab195c0c74ba804aeeb6dbff17d4 by Heiner <heiner@x.ai>:

Add missing arg.

Merging this change closes #15317

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15317 from heiner:heiner/rendezvous-timeout a5b464d7b77639313ba5e138e754ed370686f36a
",copybara-service[bot],2024-09-10 09:39:54+00:00,[],2024-09-10 09:39:54+00:00,,https://github.com/tensorflow/tensorflow/pull/75463,[],[],
2515860815,pull_request,closed,,PR #16804: Add flag `xla_gpu_enable_pgle_accuracy_checker` to enable accuracy checker,"PR #16804: Add flag `xla_gpu_enable_pgle_accuracy_checker` to enable accuracy checker

Imported from GitHub PR https://github.com/openxla/xla/pull/16804

To enable the strict pgle accuracy checker, set `--xla_gpu_enable_pgle_accuracy_checker` in XLA_FLAGS

Copybara import of the project:

--
932ac20717518a09042d4cea1d4699dc86d8287a by Shraiysh Vaishay <svaishay@nvidia.com>:

Add flag for pgle_accuracy_checker

Adding the flag `--xla_gpu_enable_pgle_accuracy_checker` for enabling PGLE accurcay checker.

Merging this change closes #16804

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16804 from shraiysh:pgle_fix 932ac20717518a09042d4cea1d4699dc86d8287a
",copybara-service[bot],2024-09-10 09:07:55+00:00,[],2024-09-10 10:41:29+00:00,2024-09-10 10:41:28+00:00,https://github.com/tensorflow/tensorflow/pull/75462,[],[],
2515825396,pull_request,open,,"Add `aarch64` `sve`, `sve2`, and `sme` to `xnn_hardware_config`.","Add `aarch64` `sve`, `sve2`, and `sme` to `xnn_hardware_config`.

Also makes `hardware_config.use_arm_neon_i8mm` an `aarch64`-only flag since it is not supported in `aarch32` ([`cpuinfo_has_arm_i8mm()`](https://github.com/pytorch/cpuinfo/blob/main/include/cpuinfo.h#L1975-L1981) returns `false` for anything not `aarch64`).
",copybara-service[bot],2024-09-10 08:53:45+00:00,[],2024-09-10 10:39:41+00:00,,https://github.com/tensorflow/tensorflow/pull/75461,[],[],
2515772932,pull_request,closed,,Update `cpuinfo` version.,"Update `cpuinfo` version.
",copybara-service[bot],2024-09-10 08:31:24+00:00,[],2024-09-10 12:06:45+00:00,2024-09-10 12:06:45+00:00,https://github.com/tensorflow/tensorflow/pull/75460,[],[],
2515763910,pull_request,open,,Integrate LLVM at llvm/llvm-project@7ba6768df818,"Integrate LLVM at llvm/llvm-project@7ba6768df818

Updates LLVM usage to match
[7ba6768df818](https://github.com/llvm/llvm-project/commit/7ba6768df818)
",copybara-service[bot],2024-09-10 08:27:19+00:00,[],2024-09-10 16:24:39+00:00,,https://github.com/tensorflow/tensorflow/pull/75459,[],[],
2515675628,pull_request,closed,,[XLA:GPU][Emitters][NFC] Small formatting changes.,"[XLA:GPU][Emitters][NFC] Small formatting changes.
",copybara-service[bot],2024-09-10 07:49:04+00:00,['pifon2a'],2024-09-10 08:40:58+00:00,2024-09-10 08:40:57+00:00,https://github.com/tensorflow/tensorflow/pull/75458,[],[],
2515634173,pull_request,open,,Removed unused PostCompileCheck.,"Removed unused PostCompileCheck.
",copybara-service[bot],2024-09-10 07:28:36+00:00,[],2024-09-10 07:28:36+00:00,,https://github.com/tensorflow/tensorflow/pull/75457,[],[],
2515605447,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 07:14:18+00:00,[],2024-09-10 07:14:18+00:00,,https://github.com/tensorflow/tensorflow/pull/75456,[],[],
2515590770,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-10 07:07:10+00:00,[],2024-09-10 07:07:10+00:00,,https://github.com/tensorflow/tensorflow/pull/75455,[],[],
2515494718,pull_request,open,,"PR #16734: [NV] Use FP8 conversion intrinsics, when available","PR #16734: [NV] Use FP8 conversion intrinsics, when available

Imported from GitHub PR https://github.com/openxla/xla/pull/16734

PTX ""cvt"" instruction supports converting to/from FP8 types. The NV hardware supports E4M3FN and E5M2 types.
This PR updates the MLIR emitter to use this instruction instead of emitting a long sequence of operations (this matters in compute-bound FP8 kernels).

The NVVM intrinsic allows converting two FP8 values with a single instruction, but as the emitter is elementwise, only one of the inputs is used. This is wasteful, but still much faster than emitting the sequence of instructions.

Before ptx 7.8 (cuda 11.8), the instruction is not supported. Starting with ptx 8.1 (cuda 12.1), the instruction is supported for sm89+. Between those versions, the instruction is supported for sm90+, thas is, if trying to compile on Ada (sm89) with cuda version < 12.1, the ptxas will complain..

Reference:
https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt (see ""PTX ISA Notes"" and ""Target ISA Notes"").

Reverts 4356505d79f726c2671767ade9b926d9fdce50ea
",copybara-service[bot],2024-09-10 06:09:29+00:00,[],2024-09-10 10:17:08+00:00,,https://github.com/tensorflow/tensorflow/pull/75454,[],[],
2515367386,pull_request,closed,,Add debug metadata support to TFLite flatbuffer schema.,"Add debug metadata support to TFLite flatbuffer schema.
",copybara-service[bot],2024-09-10 04:25:46+00:00,[],2024-09-14 00:50:07+00:00,2024-09-14 00:50:07+00:00,https://github.com/tensorflow/tensorflow/pull/75453,[],[],
2515240608,pull_request,closed,,Move `tsl/profiler/rpc` to `xla/tsl/profiler/rpc`,"Move `tsl/profiler/rpc` to `xla/tsl/profiler/rpc`
",copybara-service[bot],2024-09-10 02:03:11+00:00,['ddunl'],2024-09-12 17:12:29+00:00,2024-09-12 17:12:28+00:00,https://github.com/tensorflow/tensorflow/pull/75452,[],[],
2515204706,pull_request,closed,,Fixed the bug that remote predict ops are not parallelized correctly when being called in control op in nested private functions.,"Fixed the bug that remote predict ops are not parallelized correctly when being called in control op in nested private functions.
",copybara-service[bot],2024-09-10 01:22:23+00:00,[],2024-09-11 07:09:50+00:00,2024-09-11 07:09:49+00:00,https://github.com/tensorflow/tensorflow/pull/75451,[],[],
2515201548,pull_request,closed,,[tflite-gpu] Add reverse to gpu_compatibility,"[tflite-gpu] Add reverse to gpu_compatibility
",copybara-service[bot],2024-09-10 01:18:39+00:00,['grantjensen'],2024-09-10 20:57:43+00:00,2024-09-10 20:57:42+00:00,https://github.com/tensorflow/tensorflow/pull/75450,[],[],
2515149484,pull_request,closed,,Reverts 919663b95c37d8f27e53e787430f4eeeab032d87,"Reverts 919663b95c37d8f27e53e787430f4eeeab032d87
",copybara-service[bot],2024-09-10 00:17:27+00:00,[],2024-09-10 07:37:07+00:00,2024-09-10 07:37:06+00:00,https://github.com/tensorflow/tensorflow/pull/75449,[],[],
2515140887,pull_request,closed,,"Amend HostOffloader to support dynamic-update-slicing into a tensor which was allocated by an ""AllocateBuffer"".","Amend HostOffloader to support dynamic-update-slicing into a tensor which was allocated by an ""AllocateBuffer"".
",copybara-service[bot],2024-09-10 00:09:26+00:00,['SandSnip3r'],2024-09-11 22:40:01+00:00,2024-09-11 22:40:01+00:00,https://github.com/tensorflow/tensorflow/pull/75448,[],[],
2515109822,pull_request,closed,,Remove certain checks that failed for >2/3D mesh shapes. This case is now supported. Also enable some (related and unrelated) disabled tests.,"Remove certain checks that failed for >2/3D mesh shapes. This case is now supported. Also enable some (related and unrelated) disabled tests.
",copybara-service[bot],2024-09-09 23:38:03+00:00,[],2024-09-10 00:25:37+00:00,2024-09-10 00:25:37+00:00,https://github.com/tensorflow/tensorflow/pull/75447,[],[],
2515082025,pull_request,open,,Switch tensorflow/core/kernels from wrapper ScopedActivateExecutorContext class to ScopedActivateContext class.,"Switch tensorflow/core/kernels from wrapper ScopedActivateExecutorContext class to ScopedActivateContext class.
",copybara-service[bot],2024-09-09 23:09:17+00:00,[],2024-09-09 23:09:17+00:00,,https://github.com/tensorflow/tensorflow/pull/75446,[],[],
2515061240,pull_request,closed,,Integrate LLVM at llvm/llvm-project@5f74671c8587,"Integrate LLVM at llvm/llvm-project@5f74671c8587

Updates LLVM usage to match
[5f74671c8587](https://github.com/llvm/llvm-project/commit/5f74671c8587)
",copybara-service[bot],2024-09-09 22:50:22+00:00,[],2024-09-10 02:59:00+00:00,2024-09-10 02:59:00+00:00,https://github.com/tensorflow/tensorflow/pull/75445,[],[],
2515055017,pull_request,closed,,[tflite-gpu] Add left & right shift to gpu_compabibility,"[tflite-gpu] Add left & right shift to gpu_compabibility
",copybara-service[bot],2024-09-09 22:44:47+00:00,['grantjensen'],2024-10-16 00:09:24+00:00,2024-10-16 00:09:23+00:00,https://github.com/tensorflow/tensorflow/pull/75444,[],[],
2515037905,pull_request,closed,,Fix issues with XLA API where device_assignment is not passed in.,"Fix issues with XLA API where device_assignment is not passed in.
",copybara-service[bot],2024-09-09 22:30:16+00:00,['Tongfei-Guo'],2024-09-18 16:56:40+00:00,2024-09-18 16:56:38+00:00,https://github.com/tensorflow/tensorflow/pull/75442,[],[],
2515035552,pull_request,closed,,Use ScopedActivateContext instead of the ScopedActivateExecutorContext wrapper in common_runtime code.,"Use ScopedActivateContext instead of the ScopedActivateExecutorContext wrapper in common_runtime code.
",copybara-service[bot],2024-09-09 22:28:16+00:00,[],2024-09-11 21:13:07+00:00,2024-09-11 21:13:07+00:00,https://github.com/tensorflow/tensorflow/pull/75441,[],[],
2515033325,pull_request,closed,,Refactor `ExhaustiveOpTestBase`,"Refactor `ExhaustiveOpTestBase`

Move as many methods as possible to free functions in the implementation file and move all method implementations to the implementation file.
",copybara-service[bot],2024-09-09 22:26:16+00:00,[],2024-09-10 18:04:41+00:00,2024-09-10 18:04:40+00:00,https://github.com/tensorflow/tensorflow/pull/75440,[],[],
2515022858,pull_request,closed,,Refactor exhaustive_op_test_utils into multiple headers,"Refactor exhaustive_op_test_utils into multiple headers

Splits the single `exhaustive_test_op_utils.h` into multiple headers.
",copybara-service[bot],2024-09-09 22:17:28+00:00,[],2024-09-10 06:42:26+00:00,2024-09-10 06:42:25+00:00,https://github.com/tensorflow/tensorflow/pull/75439,[],[],
2514994589,pull_request,closed,,Use ScopedActivateContext in service/gpu instead of the ScopedActivateExecutorContext wrapper class.,"Use ScopedActivateContext in service/gpu instead of the ScopedActivateExecutorContext wrapper class.
",copybara-service[bot],2024-09-09 21:55:03+00:00,[],2024-09-11 20:10:02+00:00,2024-09-11 20:10:01+00:00,https://github.com/tensorflow/tensorflow/pull/75438,[],[],
2514955207,pull_request,closed,,Reverts 49f1a067a8a39aba7f2f03ea3aeb0729f8ff9a03,"Reverts 49f1a067a8a39aba7f2f03ea3aeb0729f8ff9a03
",copybara-service[bot],2024-09-09 21:26:44+00:00,[],2024-09-09 22:10:09+00:00,2024-09-09 22:10:09+00:00,https://github.com/tensorflow/tensorflow/pull/75437,[],[],
2514827181,pull_request,closed,,Use ScopedActivateContext in GpuCudaMallocAsyncAllocator instead of the ScopedActivateExecutorContext wrapper class.,"Use ScopedActivateContext in GpuCudaMallocAsyncAllocator instead of the ScopedActivateExecutorContext wrapper class.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16632 from shraiysh:degenerate_rs_dynamic_slice_fusion 0385dd42a9c325750b34a240a883a3b22718962f
",copybara-service[bot],2024-09-09 20:12:25+00:00,[],2024-09-11 18:48:41+00:00,2024-09-11 18:48:41+00:00,https://github.com/tensorflow/tensorflow/pull/75436,[],[],
2514819078,pull_request,closed,,Add more corner cases in tests for Div() and tighten the error tolerances for AbsComplex on TPU.,"Add more corner cases in tests for Div() and tighten the error tolerances for AbsComplex on TPU.
",copybara-service[bot],2024-09-09 20:08:01+00:00,[],2024-09-11 19:33:55+00:00,2024-09-11 19:33:54+00:00,https://github.com/tensorflow/tensorflow/pull/75435,[],[],
2514814436,pull_request,closed,,Use ScopedActivateContext instead of wrapper ScopedActivateExecutorContext class in rocm classes.,"Use ScopedActivateContext instead of wrapper ScopedActivateExecutorContext class in rocm classes.
",copybara-service[bot],2024-09-09 20:05:29+00:00,[],2024-09-11 17:48:42+00:00,2024-09-11 17:48:41+00:00,https://github.com/tensorflow/tensorflow/pull/75434,[],[],
2514804672,pull_request,closed,,Use ScopedActivateContext instead of the ScopedActivateExecutorContext wrapper class.,"Use ScopedActivateContext instead of the ScopedActivateExecutorContext wrapper class.
",copybara-service[bot],2024-09-09 20:01:18+00:00,[],2024-09-11 15:43:04+00:00,2024-09-11 15:43:03+00:00,https://github.com/tensorflow/tensorflow/pull/75433,[],[],
2514763818,pull_request,closed,,"Allow fusion to accept more operands than parameters. This relaxation is mainly for window prefetch. With this change, now, the MSA can just append operands, without inserting a custom op inside the fusion to consume the appended operands.","Allow fusion to accept more operands than parameters. This relaxation is mainly for window prefetch. With this change, now, the MSA can just append operands, without inserting a custom op inside the fusion to consume the appended operands.
",copybara-service[bot],2024-09-09 19:38:45+00:00,[],2024-09-10 22:13:35+00:00,2024-09-10 22:13:35+00:00,https://github.com/tensorflow/tensorflow/pull/75432,[],[],
2514697919,pull_request,closed,,[IFRT] Verify that devices is not nullptr when used in Sharding,"[IFRT] Verify that devices is not nullptr when used in Sharding

`Sharding` currently expects one or more devices, and this expects any
`tsl::RCReference<DeviceList>` to be not `nullptr`. While this invariant may
change in the future depending on how we express an empty device list, we add a
check (in addition to `devices` access) that clarifies `devices != nullptr`
when used in `Sharding`.
",copybara-service[bot],2024-09-09 19:00:48+00:00,[],2024-09-10 04:19:01+00:00,2024-09-10 04:19:00+00:00,https://github.com/tensorflow/tensorflow/pull/75431,[],[],
2514696780,pull_request,closed,,PR #16921: [PJRT:GPU] Treat GPU collective memory space as device memory space,"PR #16921: [PJRT:GPU] Treat GPU collective memory space as device memory space

Imported from GitHub PR https://github.com/openxla/xla/pull/16921

This is a regression fix when using --xla_gpu_enable_nccl_user_buffers=true.
Return device memory space when collective memory space is used as an output on GPU.
Copybara import of the project:

--
8113e6fbe23d5902ecdd406793555c602c1b7f81 by Jane Liu <janeliu@nvidia.com>:

Treat collective memory space as device memory space when using as an output

--
b5e43d6455adc49f5ac99a9a9e95cf495eb46170 by Jane Liu <janeliu@nvidia.com>:

fix the test

Merging this change closes #16921

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16921 from zhenying-liu:nccl-buffer-output b5e43d6455adc49f5ac99a9a9e95cf495eb46170
",copybara-service[bot],2024-09-09 19:00:23+00:00,[],2024-09-13 00:44:14+00:00,2024-09-13 00:44:14+00:00,https://github.com/tensorflow/tensorflow/pull/75430,[],[],
2514686785,pull_request,closed,,"PR #16953: Revert ""[XLA:GPU] Enable --xla_gpu_enable_pipelined_{all_gather,all_r…","PR #16953: Revert ""[XLA:GPU] Enable --xla_gpu_enable_pipelined_{all_gather,all_r…

Imported from GitHub PR https://github.com/openxla/xla/pull/16953

A recent commit enabled the pipelined collectives. However, we saw some divergence issue after the change (Will share more info on this). This PR reverts those changes.


Copybara import of the project:

--
2dd0b451f9a5bcaeffe1d5c9c5f1eab90eac2603 by kaixih <kaixih@nvidia.com>:

Revert ""[XLA:GPU] Enable --xla_gpu_enable_pipelined_{all_gather,all_reduce,reduce_scatter} by default.""

This reverts commit 489f86bd33277f6dbec7e085131fb934d79967b2.

Merging this change closes #16953

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16953 from kaixih:disable_pipelined_collectives 2dd0b451f9a5bcaeffe1d5c9c5f1eab90eac2603
",copybara-service[bot],2024-09-09 18:56:25+00:00,[],2024-09-09 20:43:29+00:00,2024-09-09 20:43:27+00:00,https://github.com/tensorflow/tensorflow/pull/75429,[],[],
2514649506,pull_request,closed,,Make it possible to avoid logging of the errors if needed,"Make it possible to avoid logging of the errors if needed

Reverts 49f1a067a8a39aba7f2f03ea3aeb0729f8ff9a03
",copybara-service[bot],2024-09-09 18:34:40+00:00,['denisvnukov'],2024-09-09 22:41:31+00:00,2024-09-09 22:41:30+00:00,https://github.com/tensorflow/tensorflow/pull/75428,[],[],
2514642243,pull_request,closed,,Reduces logging verbosity when skipping setting shardings.,"Reduces logging verbosity when skipping setting shardings.
",copybara-service[bot],2024-09-09 18:30:33+00:00,[],2024-09-10 00:38:59+00:00,2024-09-10 00:38:58+00:00,https://github.com/tensorflow/tensorflow/pull/75427,[],[],
2514576443,pull_request,closed,,De-duplicate code to read a NUMA node into a common library to be used by both ROCm and CUDA executors.,"De-duplicate code to read a NUMA node into a common library to be used by both ROCm and CUDA executors.
",copybara-service[bot],2024-09-09 17:58:51+00:00,[],2024-09-10 16:17:09+00:00,2024-09-10 16:17:09+00:00,https://github.com/tensorflow/tensorflow/pull/75426,[],[],
2514566616,pull_request,closed,,[tflite] Allow any padding on MaxPool2d,"[tflite] Allow any padding on MaxPool2d

Currently a tfl.max_pool_2d is emitted for an appropriate stablehlo.reduce_window only when the requested padding can be accommodated using SAME or VALID padding modes that tfl.max_pool_2d supports.

This CL allows any padding on a stablehlo.reduce_window. When the padding is not SAME or VALID, we insert an explicit tfl.pad_v2 before the created tfl.max_pool_2d.
",copybara-service[bot],2024-09-09 17:54:05+00:00,['majiddadashi'],2024-09-11 18:26:53+00:00,2024-09-11 18:26:52+00:00,https://github.com/tensorflow/tensorflow/pull/75425,[],[],
2514561887,pull_request,closed,,Automated rollback of 38 IncludeCleaner findings,"Automated rollback of 38 IncludeCleaner findings

Reverts d39c8774883d994ee1350656085c5184fd625e7e
",copybara-service[bot],2024-09-09 17:51:32+00:00,['SeeForTwo'],2024-09-10 00:49:17+00:00,2024-09-10 00:49:16+00:00,https://github.com/tensorflow/tensorflow/pull/75424,[],[],
2514511254,pull_request,open,,Prevent deps from tfl converter to tfl runtime.,"Prevent deps from tfl converter to tfl runtime.
",copybara-service[bot],2024-09-09 17:29:00+00:00,[],2024-09-09 22:44:26+00:00,,https://github.com/tensorflow/tensorflow/pull/75422,[],[],
2514497808,pull_request,closed,,Remove UnfreezeMutableGlobalTensorsPass definition from passes.td and migrate it to use the new TFLite Converter Pass base-class and registry utils.,"Remove UnfreezeMutableGlobalTensorsPass definition from passes.td and migrate it to use the new TFLite Converter Pass base-class and registry utils.
",copybara-service[bot],2024-09-09 17:21:23+00:00,['vamsimanchala'],2024-09-18 18:57:13+00:00,2024-09-18 18:57:12+00:00,https://github.com/tensorflow/tensorflow/pull/75421,[],[],
2514492563,pull_request,closed,,Create the concept of pass_regisrty_utils that will offer boilerplate code to `Create` and `Register` passes.,"Create the concept of pass_regisrty_utils that will offer boilerplate code to `Create` and `Register` passes.
",copybara-service[bot],2024-09-09 17:18:18+00:00,['vamsimanchala'],2024-09-12 01:33:45+00:00,2024-09-12 01:33:44+00:00,https://github.com/tensorflow/tensorflow/pull/75420,[],[],
2514476757,pull_request,closed,,Revert header cleanup,"Revert header cleanup

Reverts d39c8774883d994ee1350656085c5184fd625e7e
",copybara-service[bot],2024-09-09 17:09:17+00:00,['akuegel'],2024-09-10 12:27:12+00:00,2024-09-10 12:27:12+00:00,https://github.com/tensorflow/tensorflow/pull/75419,[],[],
2514441480,pull_request,closed,,Remove dependency on lite/schema.,"Remove dependency on lite/schema.
",copybara-service[bot],2024-09-09 16:50:02+00:00,[],2024-09-10 20:29:25+00:00,2024-09-10 20:29:24+00:00,https://github.com/tensorflow/tensorflow/pull/75418,[],[],
2514416939,pull_request,closed,,Remove unused code in driver & executor files.,"Remove unused code in driver & executor files.
",copybara-service[bot],2024-09-09 16:37:11+00:00,[],2024-09-10 02:19:24+00:00,2024-09-10 02:19:24+00:00,https://github.com/tensorflow/tensorflow/pull/75417,[],[],
2514416613,pull_request,closed,,Update schema dep for flatbuffer_export,"Update schema dep for flatbuffer_export
",copybara-service[bot],2024-09-09 16:37:01+00:00,[],2024-09-10 17:41:19+00:00,2024-09-10 17:41:18+00:00,https://github.com/tensorflow/tensorflow/pull/75416,[],[],
2514378246,pull_request,closed,,Integrate LLVM at llvm/llvm-project@2d338bed00b2,"Integrate LLVM at llvm/llvm-project@2d338bed00b2

Updates LLVM usage to match
[2d338bed00b2](https://github.com/llvm/llvm-project/commit/2d338bed00b2)
",copybara-service[bot],2024-09-09 16:17:45+00:00,[],2024-09-09 18:50:29+00:00,2024-09-09 18:50:28+00:00,https://github.com/tensorflow/tensorflow/pull/75414,[],[],
2514356788,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 16:06:24+00:00,[],2024-09-16 20:42:08+00:00,2024-09-16 20:42:07+00:00,https://github.com/tensorflow/tensorflow/pull/75413,[],[],
2514355863,pull_request,open,,Integrate LLVM at llvm/llvm-project@3940a1ba1454,"Integrate LLVM at llvm/llvm-project@3940a1ba1454

Updates LLVM usage to match
[3940a1ba1454](https://github.com/llvm/llvm-project/commit/3940a1ba1454)
",copybara-service[bot],2024-09-09 16:05:56+00:00,[],2024-09-09 16:05:56+00:00,,https://github.com/tensorflow/tensorflow/pull/75412,[],[],
2514275315,pull_request,open,,Handle when JAX saves the manual axes on the `CallOp` of the `shmap_body`.,"Handle when JAX saves the manual axes on the `CallOp` of the `shmap_body`.

JAX will save the list of manual axes as an `ArrayAttr` of strings. In a followup clean this up to use `ManualAxesAttr` instead. This requires exposing the C/Python bindings for it.
",copybara-service[bot],2024-09-09 15:27:47+00:00,[],2024-09-09 15:27:47+00:00,,https://github.com/tensorflow/tensorflow/pull/75411,[],[],
2514254313,pull_request,open,,#sdy Handle redundant shard maps during import.,"#sdy Handle redundant shard maps during import.

Even with a mesh with multiple axes size > 1, if the shmap is operating on no axes > 1, then JAX will create the call but not have the pattern of the custom calls. So just inline.
",copybara-service[bot],2024-09-09 15:18:13+00:00,[],2024-09-09 15:18:13+00:00,,https://github.com/tensorflow/tensorflow/pull/75410,[],[],
2514188820,pull_request,closed,,Use `DeviceDescription::runtime_version` in `CommandBufferScheduling` pass,"Use `DeviceDescription::runtime_version` in `CommandBufferScheduling` pass

This change:

- Replaces the usage of integers for version number by `SemanticVersion`.
- Obtains the runtime and driver versions from the `DeviceDescription` type.
- Removes the now obsolete `GpuCompiler::GetToolkitVersion` function.
- Applies the usual cleanups (includes and dependencies) to the touched files/targets.
",copybara-service[bot],2024-09-09 14:50:51+00:00,[],2024-09-09 16:32:20+00:00,2024-09-09 16:32:20+00:00,https://github.com/tensorflow/tensorflow/pull/75409,[],[],
2514157261,pull_request,closed,,Remove `CUDA_VERSION` usage from GpuCommandBufferTest,"Remove `CUDA_VERSION` usage from GpuCommandBufferTest

The replaces all preprocessor conditions by runtime conditions.
",copybara-service[bot],2024-09-09 14:37:45+00:00,[],2024-09-09 16:42:32+00:00,2024-09-09 16:42:31+00:00,https://github.com/tensorflow/tensorflow/pull/75408,[],[],
2514139315,pull_request,closed,,Log ptx compilation warnings.,"Log ptx compilation warnings.

We already log those warning when compiling with `ptxas`, but not with `nvptx` and `nvjitlink`.
",copybara-service[bot],2024-09-09 14:31:01+00:00,[],2024-09-09 16:20:53+00:00,2024-09-09 16:20:52+00:00,https://github.com/tensorflow/tensorflow/pull/75407,[],[],
2514107474,pull_request,open,,Rename GemmFusion to TritonFusionRewriter.,"Rename GemmFusion to TritonFusionRewriter.
",copybara-service[bot],2024-09-09 14:18:24+00:00,[],2024-09-12 12:38:50+00:00,,https://github.com/tensorflow/tensorflow/pull/75405,[],[],
2514100915,pull_request,closed,,[XLA:GPU][IndexAnalysis] Unify printing of indexing map class and attribute.,"[XLA:GPU][IndexAnalysis] Unify printing of indexing map class and attribute.
",copybara-service[bot],2024-09-09 14:15:41+00:00,['pifon2a'],2024-09-10 10:02:11+00:00,2024-09-10 10:02:09+00:00,https://github.com/tensorflow/tensorflow/pull/75404,[],[],
2514029202,pull_request,closed,,Update DPB metric names to better reflect their actual meaning.,"Update DPB metric names to better reflect their actual meaning.

In particular:
  - s/in_use/in_use_heap/
  - s/total_allocated/total_non_mmapped_heap/

""in_use"" memory was actually referring only to in-use *heap* space.
Likewise ""total_allocated"" memory was actually referring only to *heap* space,
not all memory space, and also was excluding mmap'ed heap sections.
",copybara-service[bot],2024-09-09 13:48:34+00:00,[],2024-09-16 13:31:59+00:00,2024-09-16 13:31:58+00:00,https://github.com/tensorflow/tensorflow/pull/75403,[],[],
2513807450,pull_request,closed,,Use `SemanticVersion` and `DeviceDescription::runtime_version` in `CudnnFusedConvRewriter`,"Use `SemanticVersion` and `DeviceDescription::runtime_version` in `CudnnFusedConvRewriter`

This simplifies toolkit version dependencies in the `CudnnFusedConvRewriter` pass and related tests. All version checks are now done with `SemanticVersion` and the toolkit version is retrieved from the `DeviceDescription` type. It also replaces a bunch of `CUDA_VERSION` and `TF_ROCM_VERSION` usages.
",copybara-service[bot],2024-09-09 12:18:04+00:00,[],2024-09-09 14:33:09+00:00,2024-09-09 14:33:08+00:00,https://github.com/tensorflow/tensorflow/pull/75402,[],[],
2513681742,pull_request,closed,,Use SemanticVersion in DotAlgorithmSupportTest,"Use SemanticVersion in DotAlgorithmSupportTest

This replaces plain integers by the new type `SemanticVersion`
and makes use of the new field `DeviceDescription::runtime_version` to check
for a sufficient ROCm toolkit version.
",copybara-service[bot],2024-09-09 11:23:06+00:00,[],2024-09-09 12:23:29+00:00,2024-09-09 12:23:29+00:00,https://github.com/tensorflow/tensorflow/pull/75401,[],[],
2513661286,pull_request,closed,,"PR #16734: [NV] Use FP8 conversion intrinsics, when available","PR #16734: [NV] Use FP8 conversion intrinsics, when available

Imported from GitHub PR https://github.com/openxla/xla/pull/16734

PTX ""cvt"" instruction supports converting to/from FP8 types. The NV hardware supports E4M3FN and E5M2 types.
This PR updates the MLIR emitter to use this instruction instead of emitting a long sequence of operations (this matters in compute-bound FP8 kernels).

The NVVM intrinsic allows converting two FP8 values with a single instruction, but as the emitter is elementwise, only one of the inputs is used. This is wasteful, but still much faster than emitting the sequence of instructions.

Before ptx 7.8 (cuda 11.8), the instruction is not supported. Starting with ptx 8.1 (cuda 12.1), the instruction is supported for sm89+. Between those versions, the instruction is supported for sm90+, thas is, if trying to compile on Ada (sm89) with cuda version < 12.1, the ptxas will complain..

Reference:
https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt (see ""PTX ISA Notes"" and ""Target ISA Notes"").
Copybara import of the project:

--
67445bbafb5a380fa580bb3b2052f6775dd11516 by Sergey Kozub <skozub@nvidia.com>:

[NV] Use FP8 conversion intrinsics, when available

PTX ""cvt"" instruction supports converting to/from FP8 types.
The NV hardware supports E4M3FN and E5M2 types.
This PR updates the MLIR emitter to use this instruction instead of emitting
a long sequence of operations (this matters in compute-bound FP8 kernels).

The NVVM intrinsic allows converting two FP8 values with a single instruction, but
as the emitter is elementwise, only one of the inputs is used. This is wasteful,
but still much faster than emitting the sequence of instructions.

Before ptx 7.8 (cuda 11.8), the instruction is not supported.
Starting with ptx 8.1 (cuda 12.1), the instruction is supported for sm89+.
Between those versions, the instruction is supported for sm90+, thas is, if trying to compile
on Ada (sm89) with cuda version < 12.1, the ptxas will complain..

Reference:
https://docs.nvidia.com/cuda/parallel-thread-execution/index.html#data-movement-and-conversion-instructions-cvt
(see ""PTX ISA Notes"" and ""Target ISA Notes"").

Merging this change closes #16734

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16734 from openxla:skozub/f8-cvt-intrinsics 67445bbafb5a380fa580bb3b2052f6775dd11516
",copybara-service[bot],2024-09-09 11:13:05+00:00,[],2024-09-09 18:11:13+00:00,2024-09-09 18:11:12+00:00,https://github.com/tensorflow/tensorflow/pull/75399,[],[],
2513635320,pull_request,closed,,[XLA:GPU] Fix power of 2 padding for tiled transpose.,"[XLA:GPU] Fix power of 2 padding for tiled transpose.

Also add a helper `GetPaddedTileSizes` to pad tile size to powers of 2 and use it in Broadcast and Reshape as well. Before we had the same logic for padding copied in different places.

The real change should be only in `EmitTiledTranspose`. Everything else is NFC.
",copybara-service[bot],2024-09-09 11:00:51+00:00,[],2024-09-10 17:04:16+00:00,2024-09-10 17:04:15+00:00,https://github.com/tensorflow/tensorflow/pull/75398,[],[],
2513620003,pull_request,closed,,[lrt-model] utils for working with IR,"[lrt-model] utils for working with IR
",copybara-service[bot],2024-09-09 10:53:45+00:00,['LukeBoyer'],2024-09-11 00:07:26+00:00,2024-09-11 00:07:25+00:00,https://github.com/tensorflow/tensorflow/pull/75397,[],[],
2513616460,pull_request,closed,,[lrt-common] lrt op codes,"[lrt-common] lrt op codes
",copybara-service[bot],2024-09-09 10:52:15+00:00,['LukeBoyer'],2024-09-10 20:49:31+00:00,2024-09-10 20:49:30+00:00,https://github.com/tensorflow/tensorflow/pull/75396,[],[],
2513614431,pull_request,closed,,[lrt-model] abi safe model header,"[lrt-model] abi safe model header
",copybara-service[bot],2024-09-09 10:51:12+00:00,['LukeBoyer'],2024-09-10 23:11:19+00:00,2024-09-10 23:11:18+00:00,https://github.com/tensorflow/tensorflow/pull/75395,[],[],
2513613885,pull_request,closed,,[lrt-common] support header/macros/utils,"[lrt-common] support header/macros/utils
",copybara-service[bot],2024-09-09 10:50:56+00:00,['LukeBoyer'],2024-09-10 20:40:52+00:00,2024-09-10 20:40:52+00:00,https://github.com/tensorflow/tensorflow/pull/75394,[],[],
2513610416,pull_request,closed,,[lrt-common] common header (status),"[lrt-common] common header (status)
",copybara-service[bot],2024-09-09 10:49:17+00:00,['LukeBoyer'],2024-09-10 20:16:36+00:00,2024-09-10 20:16:36+00:00,https://github.com/tensorflow/tensorflow/pull/75393,[],[],
2513600903,pull_request,closed,,[lrt-common] mlir -> tflite test data,"[lrt-common] mlir -> tflite test data
",copybara-service[bot],2024-09-09 10:45:05+00:00,['LukeBoyer'],2024-09-10 18:13:29+00:00,2024-09-10 18:13:28+00:00,https://github.com/tensorflow/tensorflow/pull/75392,[],[],
2513599598,pull_request,closed,,Make GemmRewriter use semantic runtime version,"Make GemmRewriter use semantic runtime version

This replaces usages of `CUDA_VERSION` and `TF_ROCM_VERSION` by a runtime version provided through the `DeviceDescription` type.
",copybara-service[bot],2024-09-09 10:44:36+00:00,[],2024-09-09 12:55:46+00:00,2024-09-09 12:55:45+00:00,https://github.com/tensorflow/tensorflow/pull/75391,[],[],
2513518152,pull_request,closed,,[XLA:GPU] Change format of InsertOp,"[XLA:GPU] Change format of InsertOp

This more accurately reflects how the indexing maps are being applied since the indices are first applied to the indexing map in indexed_vector (the operand given, $source) & then those results are applied to the indexing map attribute of InsertOp. The previous representation was confusing as it could show a mismatch of dimensions between the indexing maps and the indices given.
",copybara-service[bot],2024-09-09 10:07:15+00:00,[],2024-09-09 11:39:26+00:00,2024-09-09 11:39:25+00:00,https://github.com/tensorflow/tensorflow/pull/75390,[],[],
2513452821,pull_request,closed,,[XLA:GPU] Improve error message for Triton fusion emitter.,"[XLA:GPU] Improve error message for Triton fusion emitter.

Extract the problematic fusion into an HLO module to reproduce the error.
",copybara-service[bot],2024-09-09 09:38:49+00:00,[],2024-09-09 10:17:46+00:00,2024-09-09 10:17:46+00:00,https://github.com/tensorflow/tensorflow/pull/75389,[],[],
2513435205,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 09:30:58+00:00,[],2024-09-09 09:30:58+00:00,,https://github.com/tensorflow/tensorflow/pull/75388,[],[],
2513434945,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 09:30:52+00:00,[],2024-09-09 09:30:52+00:00,,https://github.com/tensorflow/tensorflow/pull/75387,[],[],
2513431038,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 09:29:05+00:00,[],2024-09-09 09:29:05+00:00,,https://github.com/tensorflow/tensorflow/pull/75386,[],[],
2513428496,pull_request,closed,,Integrate LLVM at llvm/llvm-project@6b67f79f5f85,"Integrate LLVM at llvm/llvm-project@6b67f79f5f85

Updates LLVM usage to match
[6b67f79f5f85](https://github.com/llvm/llvm-project/commit/6b67f79f5f85)
",copybara-service[bot],2024-09-09 09:28:01+00:00,[],2024-09-09 14:22:29+00:00,2024-09-09 14:22:28+00:00,https://github.com/tensorflow/tensorflow/pull/75385,[],[],
2513420834,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 09:24:33+00:00,[],2024-09-09 11:50:32+00:00,2024-09-09 11:50:32+00:00,https://github.com/tensorflow/tensorflow/pull/75384,[],[],
2513418934,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 09:23:38+00:00,[],2024-09-09 09:23:38+00:00,,https://github.com/tensorflow/tensorflow/pull/75383,[],[],
2513407873,pull_request,open,,Update GraphDef version to 1980.,"Update GraphDef version to 1980.
",copybara-service[bot],2024-09-09 09:18:36+00:00,[],2024-09-09 09:18:36+00:00,,https://github.com/tensorflow/tensorflow/pull/75382,[],[],
2513405959,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 09:17:46+00:00,[],2024-09-09 09:17:46+00:00,,https://github.com/tensorflow/tensorflow/pull/75381,[],[],
2513405803,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 09:17:42+00:00,[],2024-09-09 09:17:42+00:00,,https://github.com/tensorflow/tensorflow/pull/75380,[],[],
2513326059,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 08:47:13+00:00,[],2024-09-09 12:14:24+00:00,2024-09-09 12:14:23+00:00,https://github.com/tensorflow/tensorflow/pull/75379,[],[],
2513325059,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 08:46:45+00:00,[],2024-09-10 05:11:37+00:00,,https://github.com/tensorflow/tensorflow/pull/75378,[],[],
2513317652,pull_request,closed,,PR #16632: Convert degenerate reduce-scatter to D2D thunk,"PR #16632: Convert degenerate reduce-scatter to D2D thunk

Imported from GitHub PR https://github.com/openxla/xla/pull/16632

This patch converts a degenerate collective (currently only reduce- scatter) into a D2D copy thunk. It also exposes the thunks from a GpuExecutable, because that is required for testing this.

This behavior with degenerate collectives is in line with their behavior outside a fusion.
Copybara import of the project:

--
0385dd42a9c325750b34a240a883a3b22718962f by Shraiysh Vaishay <svaishay@nvidia.com>:

Convert degenerate reduce-scatter to D2D thunk

This patch converts a degenerate collective (currently only reduce-
scatter) into a D2D copy thunk. It also exposes the thunks from
a GpuExecutable, because that is required for testing this.

This behavior with degenerate collectives is in line with their
behavior outside a fusion.

Merging this change closes #16632

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16632 from shraiysh:degenerate_rs_dynamic_slice_fusion 0385dd42a9c325750b34a240a883a3b22718962f
",copybara-service[bot],2024-09-09 08:43:48+00:00,[],2024-09-11 17:58:28+00:00,2024-09-11 17:58:28+00:00,https://github.com/tensorflow/tensorflow/pull/75377,[],[],
2513278446,pull_request,closed,,XLA_FLAGS: Make it possible to override `xla_step_marker_location`.,"XLA_FLAGS: Make it possible to override `xla_step_marker_location`.
",copybara-service[bot],2024-09-09 08:28:51+00:00,[],2024-09-09 10:06:42+00:00,2024-09-09 10:06:41+00:00,https://github.com/tensorflow/tensorflow/pull/75376,[],[],
2513276081,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/74948 from tensorflow:dependabot/docker/tensorflow/tools/tf_sig_build_dockerfiles/ubuntu-adbb901 a8de7706e07aa59b576f58bf6ad8b3b0dc5d6162
",copybara-service[bot],2024-09-09 08:27:58+00:00,[],2024-09-09 08:27:58+00:00,,https://github.com/tensorflow/tensorflow/pull/75375,[],[],
2513263475,pull_request,closed,,Use runtime toolkit version in GpuFusedMhaTest,"Use runtime toolkit version in GpuFusedMhaTest

This avoid the need for macros and for including CUDA headers directly in the test.
",copybara-service[bot],2024-09-09 08:22:43+00:00,[],2024-09-09 10:38:16+00:00,2024-09-09 10:38:15+00:00,https://github.com/tensorflow/tensorflow/pull/75374,[],[],
2513251986,pull_request,closed,,Removed unused PostCompileCheck.,"Removed unused PostCompileCheck.
",copybara-service[bot],2024-09-09 08:17:48+00:00,[],2024-09-10 07:24:22+00:00,2024-09-10 07:24:21+00:00,https://github.com/tensorflow/tensorflow/pull/75373,[],[],
2513078383,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:57:23+00:00,[],2024-09-09 06:57:23+00:00,,https://github.com/tensorflow/tensorflow/pull/75372,[],[],
2513073899,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:54:46+00:00,[],2024-09-09 06:54:46+00:00,,https://github.com/tensorflow/tensorflow/pull/75371,[],[],
2513073755,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:54:40+00:00,[],2024-09-09 06:54:40+00:00,,https://github.com/tensorflow/tensorflow/pull/75370,[],[],
2513072477,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:53:56+00:00,[],2024-09-09 06:53:56+00:00,,https://github.com/tensorflow/tensorflow/pull/75369,[],[],
2513072345,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/60056 from kristofmaar:go-add-support-for-empty-tags 3bff18b434000256c97c338d639022aa1dda64d9
",copybara-service[bot],2024-09-09 06:53:52+00:00,[],2024-09-09 07:48:04+00:00,,https://github.com/tensorflow/tensorflow/pull/75368,[],[],
2513070677,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:52:55+00:00,[],2024-09-12 04:52:24+00:00,2024-09-12 04:52:23+00:00,https://github.com/tensorflow/tensorflow/pull/75367,[],[],
2513068152,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:51:28+00:00,[],2024-09-09 06:53:14+00:00,,https://github.com/tensorflow/tensorflow/pull/75366,[],[],
2513065531,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:49:55+00:00,[],2024-09-09 06:49:55+00:00,,https://github.com/tensorflow/tensorflow/pull/75365,[],[],
2513063421,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:48:44+00:00,[],2024-09-09 06:48:44+00:00,,https://github.com/tensorflow/tensorflow/pull/75364,[],[],
2513060561,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:47:06+00:00,[],2024-09-09 06:47:06+00:00,,https://github.com/tensorflow/tensorflow/pull/75363,[],[],
2513058842,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:46:08+00:00,[],2024-09-09 06:46:08+00:00,,https://github.com/tensorflow/tensorflow/pull/75362,[],[],
2513055950,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:44:31+00:00,[],2024-09-09 06:44:31+00:00,,https://github.com/tensorflow/tensorflow/pull/75361,[],[],
2513048720,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:40:16+00:00,[],2024-09-10 06:52:52+00:00,2024-09-10 06:52:51+00:00,https://github.com/tensorflow/tensorflow/pull/75360,[],[],
2513048313,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:40:01+00:00,[],2024-09-09 06:40:01+00:00,,https://github.com/tensorflow/tensorflow/pull/75359,[],[],
2513044665,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/74948 from tensorflow:dependabot/docker/tensorflow/tools/tf_sig_build_dockerfiles/ubuntu-adbb901 a8de7706e07aa59b576f58bf6ad8b3b0dc5d6162
",copybara-service[bot],2024-09-09 06:37:49+00:00,[],2024-09-09 08:53:30+00:00,2024-09-09 08:53:29+00:00,https://github.com/tensorflow/tensorflow/pull/75358,[],[],
2513044007,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-09 06:37:25+00:00,[],2024-09-12 05:42:50+00:00,2024-09-12 05:42:49+00:00,https://github.com/tensorflow/tensorflow/pull/75357,[],[],
2513009170,pull_request,closed,,PR #16864: [GPU][NFC] Remove a warning about use of XLA_PYTHON_CLIENT_MEM_FRACTION.,"PR #16864: [GPU][NFC] Remove a warning about use of XLA_PYTHON_CLIENT_MEM_FRACTION.

Imported from GitHub PR https://github.com/openxla/xla/pull/16864


Copybara import of the project:

--
88fb31030fb0e099f1cea7320178298718143b39 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU][NFC] Remove a warning about use of XLA_PYTHON_CLIENT_MEM_FRACTION.

XLA_PYTHON_CLIENT_MEM_FRACTION will remain acceptable.

Merging this change closes #16864

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16864 from openxla:remove_warning 88fb31030fb0e099f1cea7320178298718143b39
",copybara-service[bot],2024-09-09 06:16:04+00:00,[],2024-09-09 07:19:22+00:00,2024-09-09 07:19:22+00:00,https://github.com/tensorflow/tensorflow/pull/75356,[],[],
2512818363,pull_request,open,,Remove the wait for definition events in PjrtStreamExecutorBuffer::Release.,"Remove the wait for definition events in PjrtStreamExecutorBuffer::Release.
",copybara-service[bot],2024-09-09 03:31:27+00:00,[],2024-09-09 06:04:24+00:00,,https://github.com/tensorflow/tensorflow/pull/75355,[],[],
2512533636,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 19:17:40+00:00,[],2024-09-08 19:17:40+00:00,,https://github.com/tensorflow/tensorflow/pull/75354,[],[],
2512408473,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 14:12:05+00:00,[],2024-09-08 14:12:05+00:00,,https://github.com/tensorflow/tensorflow/pull/75352,[],[],
2512285248,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 09:21:35+00:00,[],2024-09-08 09:21:35+00:00,,https://github.com/tensorflow/tensorflow/pull/75350,[],[],
2512256066,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 08:06:50+00:00,[],2024-09-10 02:27:27+00:00,2024-09-10 02:27:26+00:00,https://github.com/tensorflow/tensorflow/pull/75349,[],[],
2512216447,pull_request,closed,,TensorFlow #75329 subclass of tf.TypeSpec but found <class 'list'> which is not,"TypeError: output_signature must contain objects that are a subclass of tf.TypeSpec but found <class 'list'> which is not.

Issue Description
The error message encountered is related to TensorFlow's tf.function and its usage of output_signature. When using tf.function, you can specify the output signature of the function using the output_signature argument. This argument should be a tf.TypeSpec object or a nested structure of tf.TypeSpec objects.

Causes
In this case, it seems like you're passing a list (<class 'list'>) as the output_signature, which is not a subclass of tf.TypeSpec.

Step-by-Step Solution

Step 1: Identify the Issue
Check the error message and identify the line of code that's causing the issue.
Verify that you're using the correct version of TensorFlow.

Step 2: Understand the output_signature Argument
The output_signature argument should be a tf.TypeSpec object or a nested structure of tf.TypeSpec objects.
tf.TypeSpec is a type specification for TensorFlow values.

Step 3: Fix the output_signature Argument
Replace the list with a valid tf.TypeSpec object or a nested structure of tf.TypeSpec objects.
Use tf.TensorSpec to define the output signature of the function.

Step 5: Verify the Fix
Run the code again to verify that the issue is resolved.

API Documentation
tf.function
output_signature: A possible return type of the function.

tf.TypeSpec
A type specification for TensorFlow values.

tf.TensorSpec
A type specification for TensorFlow tensors.

By following these steps and using the provided example code, you should be able to resolve the TypeError: output_signature must contain objects that are a subclass of tf.TypeSpec but found <class 'list'> which is not. issue.

code 

import tensorflow as tf

# Define a simple function
@tf.function(output_signature=tf.TensorSpec(shape=[None, 10], dtype=tf.float32))
def my_function(x):
    return x

# Or if you have multiple outputs
@tf.function(output_signature=(tf.TensorSpec(shape=[None, 10], dtype=tf.float32), 
                             tf.TensorSpec(shape=[None, 20], dtype=tf.float32)))
def my_function(x):
    return x, x * 2

# If you're using the experimental Callable type
from tensorflow.types.experimental import Callable

my_callable = Callable(
    input_signature=[tf.TensorSpec(shape=[None, 10], dtype=tf.float32)],
    output_signature=tf.TensorSpec(shape=[None, 10], dtype=tf.float32),
    function=my_function
)

![Screenshot 2024-09-08 112208](https://github.com/user-attachments/assets/efd9c155-0c7e-4c02-9489-b066246ccd4e)
",BadakalaYashwanth,2024-09-08 06:05:20+00:00,['gbaned'],2025-01-16 19:33:53+00:00,2025-01-16 19:33:50+00:00,https://github.com/tensorflow/tensorflow/pull/75348,"[('size:S', 'CL Change Size: Small')]","[{'comment_id': 2336560430, 'issue_id': 2512216447, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/75348/checks?check_run_id=29831730738) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 9, 8, 6, 5, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2337260437, 'issue_id': 2512216447, 'author': 'gbaned', 'body': 'Hi @BadakalaYashwanth Can you please sign the CLA? Thank you!', 'created_at': datetime.datetime(2024, 9, 9, 6, 45, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2338790862, 'issue_id': 2512216447, 'author': 'faizan-m', 'body': 'This PR is modifying an API goldens file (which are used for testing only and is a proto instead of python code) and the description is what I would guess to be an LLM-generated text for how to approach issue #75329?', 'created_at': datetime.datetime(2024, 9, 9, 18, 18, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2339486106, 'issue_id': 2512216447, 'author': 'BadakalaYashwanth', 'body': '@google-cla and @gbaned \r\n\r\nThank you for reviewing my pull request. Yes, this is my first contribution to a Google open-source project, and I would appreciate some guidance on how to resolve the CLA issue and move forward with the contribution.\r\n\r\nCould you please provide step-by-step instructions or point me in the right direction to ensure everything is in order?\r\n\r\nThank you for your help!', 'created_at': datetime.datetime(2024, 9, 10, 2, 28, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594630051, 'issue_id': 2512216447, 'author': 'keerthanakadiri', 'body': '> @google-cla and @gbaned\r\n> \r\n> Thank you for reviewing my pull request. Yes, this is my first contribution to a Google open-source project, and I would appreciate some guidance on how to resolve the CLA issue and move forward with the contribution.\r\n> \r\n> Could you please provide step-by-step instructions or point me in the right direction to ensure everything is in order?\r\n> \r\n> Thank you for your help!\r\n\r\nHi @BadakalaYashwanth, kindly check the [comment ](https://github.com/tensorflow/tensorflow/pull/75348#issuecomment-2336560430)for your further refference.', 'created_at': datetime.datetime(2025, 1, 16, 6, 24, 17, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-09-08 06:05:25 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/75348/checks?check_run_id=29831730738) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

gbaned (Assginee) on (2024-09-09 06:45:06 UTC): Hi @BadakalaYashwanth Can you please sign the CLA? Thank you!

faizan-m on (2024-09-09 18:18:07 UTC): This PR is modifying an API goldens file (which are used for testing only and is a proto instead of python code) and the description is what I would guess to be an LLM-generated text for how to approach issue #75329?

BadakalaYashwanth (Issue Creator) on (2024-09-10 02:28:29 UTC): @google-cla and @gbaned 

Thank you for reviewing my pull request. Yes, this is my first contribution to a Google open-source project, and I would appreciate some guidance on how to resolve the CLA issue and move forward with the contribution.

Could you please provide step-by-step instructions or point me in the right direction to ensure everything is in order?

Thank you for your help!

keerthanakadiri on (2025-01-16 06:24:17 UTC): Hi @BadakalaYashwanth, kindly check the [comment ](https://github.com/tensorflow/tensorflow/pull/75348#issuecomment-2336560430)for your further refference.

"
2512180616,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 03:47:23+00:00,[],2024-09-08 03:47:23+00:00,,https://github.com/tensorflow/tensorflow/pull/75347,[],[],
2512172087,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 03:09:14+00:00,[],2024-09-08 03:09:14+00:00,,https://github.com/tensorflow/tensorflow/pull/75346,[],[],
2512171643,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 03:07:33+00:00,[],2024-09-08 03:07:33+00:00,,https://github.com/tensorflow/tensorflow/pull/75345,[],[],
2512171177,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 03:05:50+00:00,[],2024-09-08 03:05:50+00:00,,https://github.com/tensorflow/tensorflow/pull/75344,[],[],
2512170966,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 03:05:02+00:00,[],2024-09-08 03:05:02+00:00,,https://github.com/tensorflow/tensorflow/pull/75343,[],[],
2512170764,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/74948 from tensorflow:dependabot/docker/tensorflow/tools/tf_sig_build_dockerfiles/ubuntu-adbb901 a8de7706e07aa59b576f58bf6ad8b3b0dc5d6162
",copybara-service[bot],2024-09-08 03:04:19+00:00,[],2024-09-09 09:10:17+00:00,2024-09-09 09:10:15+00:00,https://github.com/tensorflow/tensorflow/pull/75342,[],[],
2512170578,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 03:03:39+00:00,[],2024-09-08 03:03:39+00:00,,https://github.com/tensorflow/tensorflow/pull/75341,[],[],
2512169344,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 02:59:08+00:00,[],2024-09-08 02:59:08+00:00,,https://github.com/tensorflow/tensorflow/pull/75340,[],[],
2512169118,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 02:58:08+00:00,[],2024-09-08 02:58:08+00:00,,https://github.com/tensorflow/tensorflow/pull/75339,[],[],
2512168830,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 02:56:54+00:00,[],2024-09-08 02:56:54+00:00,,https://github.com/tensorflow/tensorflow/pull/75338,[],[],
2512168467,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 02:55:17+00:00,[],2024-09-08 02:55:17+00:00,,https://github.com/tensorflow/tensorflow/pull/75337,[],[],
2512167393,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 02:51:04+00:00,[],2024-09-08 02:51:04+00:00,,https://github.com/tensorflow/tensorflow/pull/75336,[],[],
2512162892,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 02:31:43+00:00,[],2024-09-08 02:31:43+00:00,,https://github.com/tensorflow/tensorflow/pull/75335,[],[],
2512156488,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 02:05:33+00:00,[],2024-09-10 06:17:40+00:00,2024-09-10 06:17:40+00:00,https://github.com/tensorflow/tensorflow/pull/75334,[],[],
2512155329,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-08 02:01:10+00:00,[],2024-09-10 05:09:31+00:00,,https://github.com/tensorflow/tensorflow/pull/75333,[],[],
2512114389,pull_request,closed,,Adds a solver option to minimize the # of departures.,"Adds a solver option to minimize the # of departures.
",copybara-service[bot],2024-09-07 23:26:10+00:00,[],2024-09-09 14:47:29+00:00,2024-09-09 14:47:28+00:00,https://github.com/tensorflow/tensorflow/pull/75332,[],[],
2512103159,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 22:41:40+00:00,[],2024-09-07 22:41:40+00:00,,https://github.com/tensorflow/tensorflow/pull/75331,[],[],
2511955523,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 17:38:07+00:00,[],2024-09-20 17:52:28+00:00,,https://github.com/tensorflow/tensorflow/pull/75330,"[('kokoro:force-run', 'Tests on submitted change'), ('ready to pull', 'PR ready for merge process')]",[],
2511720248,pull_request,closed,,Rollback due to internal breaking change,"Rollback due to internal breaking change

Reverts a1f1dc4c701c799b13bd6672cba593f93b9f609e
",copybara-service[bot],2024-09-07 14:53:48+00:00,[],2024-09-07 18:07:39+00:00,2024-09-07 18:07:39+00:00,https://github.com/tensorflow/tensorflow/pull/75328,[],[],
2511630497,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 12:42:06+00:00,[],2024-09-07 12:42:06+00:00,,https://github.com/tensorflow/tensorflow/pull/75327,[],[],
2511601390,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 11:17:27+00:00,[],2024-09-07 11:17:27+00:00,,https://github.com/tensorflow/tensorflow/pull/75326,[],[],
2511590022,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 10:43:35+00:00,[],2024-09-07 10:43:35+00:00,,https://github.com/tensorflow/tensorflow/pull/75325,[],[],
2511577212,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 10:07:11+00:00,[],2024-09-09 11:22:31+00:00,,https://github.com/tensorflow/tensorflow/pull/75324,[],[],
2511570674,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 09:51:45+00:00,[],2024-09-10 08:00:05+00:00,2024-09-10 08:00:04+00:00,https://github.com/tensorflow/tensorflow/pull/75323,[],[],
2511554941,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 09:08:13+00:00,[],2024-09-07 09:08:13+00:00,,https://github.com/tensorflow/tensorflow/pull/75322,[],[],
2511553002,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 09:02:47+00:00,[],2024-09-10 04:50:45+00:00,2024-09-10 04:50:45+00:00,https://github.com/tensorflow/tensorflow/pull/75321,[],[],
2511548697,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 08:50:48+00:00,[],2024-09-07 08:50:48+00:00,,https://github.com/tensorflow/tensorflow/pull/75320,[],[],
2511539648,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 08:25:44+00:00,[],2024-09-10 04:39:25+00:00,2024-09-10 04:39:24+00:00,https://github.com/tensorflow/tensorflow/pull/75319,[],[],
2511529240,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 07:56:48+00:00,[],2024-09-07 07:56:48+00:00,,https://github.com/tensorflow/tensorflow/pull/75318,[],[],
2511514939,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 07:16:05+00:00,[],2024-09-07 07:16:05+00:00,,https://github.com/tensorflow/tensorflow/pull/75317,[],[],
2511507261,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 06:53:19+00:00,[],2024-09-07 06:53:19+00:00,,https://github.com/tensorflow/tensorflow/pull/75316,[],[],
2511505976,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 06:49:17+00:00,[],2024-09-09 01:26:20+00:00,2024-09-09 01:26:20+00:00,https://github.com/tensorflow/tensorflow/pull/75315,[],[],
2511489759,pull_request,open,,Add test case for floor div jnp.,"Add test case for floor div jnp.
",copybara-service[bot],2024-09-07 06:00:46+00:00,['LukeBoyer'],2024-09-07 06:00:48+00:00,,https://github.com/tensorflow/tensorflow/pull/75314,[],[],
2511479452,pull_request,closed,,Update rounding patterns to support floordiv from `jnp`.,"Update rounding patterns to support floordiv from `jnp`.

Run all the large rounding patterns in ""phase 1"". Remove obsolete legatlity functions related to rounding.
",copybara-service[bot],2024-09-07 05:26:48+00:00,['LukeBoyer'],2024-09-07 06:28:41+00:00,2024-09-07 06:28:40+00:00,https://github.com/tensorflow/tensorflow/pull/75313,[],[],
2511478161,pull_request,open,,Update meaningless lit tests for dynamic iota.,"Update meaningless lit tests for dynamic iota.
",copybara-service[bot],2024-09-07 05:22:40+00:00,['LukeBoyer'],2024-09-07 05:22:41+00:00,,https://github.com/tensorflow/tensorflow/pull/75312,[],[],
2511476434,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 05:17:10+00:00,[],2024-09-07 05:17:10+00:00,,https://github.com/tensorflow/tensorflow/pull/75311,[],[],
2511474845,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 05:12:14+00:00,[],2024-09-07 05:12:14+00:00,,https://github.com/tensorflow/tensorflow/pull/75310,[],[],
2511450198,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:56:12+00:00,[],2024-09-07 06:20:44+00:00,2024-09-07 06:20:43+00:00,https://github.com/tensorflow/tensorflow/pull/75309,[],[],
2511444297,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:35:23+00:00,[],2024-09-07 03:35:23+00:00,,https://github.com/tensorflow/tensorflow/pull/75308,[],[],
2511444015,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:34:26+00:00,[],2024-09-13 07:20:33+00:00,,https://github.com/tensorflow/tensorflow/pull/75307,[],[],
2511442983,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:30:56+00:00,[],2024-09-07 03:30:56+00:00,,https://github.com/tensorflow/tensorflow/pull/75306,[],[],
2511442261,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:28:37+00:00,[],2024-09-07 07:52:30+00:00,2024-09-07 07:52:29+00:00,https://github.com/tensorflow/tensorflow/pull/75305,[],[],
2511442102,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:28:00+00:00,[],2024-09-07 08:46:51+00:00,,https://github.com/tensorflow/tensorflow/pull/75304,[],[],
2511439622,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:19:20+00:00,[],2024-09-07 03:19:20+00:00,,https://github.com/tensorflow/tensorflow/pull/75303,[],[],
2511439534,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:19:01+00:00,[],2024-09-07 03:19:01+00:00,,https://github.com/tensorflow/tensorflow/pull/75302,[],[],
2511438903,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:16:59+00:00,[],2024-09-07 03:16:59+00:00,,https://github.com/tensorflow/tensorflow/pull/75301,[],[],
2511438308,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-07 03:15:42+00:00,[],2024-09-07 03:15:42+00:00,,https://github.com/tensorflow/tensorflow/pull/75300,[],[],
2511379018,pull_request,closed,,Fix a bug in op_stats_combiner.cc,"Fix a bug in op_stats_combiner.cc
",copybara-service[bot],2024-09-07 01:53:35+00:00,['lionelfeng'],2024-09-09 23:50:55+00:00,2024-09-09 23:50:54+00:00,https://github.com/tensorflow/tensorflow/pull/75299,[],[],
2511334457,pull_request,closed,,Add int support for GATHER,"Add int support for GATHER
",copybara-service[bot],2024-09-07 00:10:08+00:00,['grantjensen'],2024-09-10 01:58:51+00:00,2024-09-10 01:58:51+00:00,https://github.com/tensorflow/tensorflow/pull/75298,[],[],
2511331641,pull_request,closed,,Fix signed integer overflow issue in xla::CalculateDistanceInFloats,"Fix signed integer overflow issue in xla::CalculateDistanceInFloats

Reads the magnitude of the two inputs as `uint64_t`. Negation is defined on unsigned types to follow twos complement. We then do the subtraction in unsigned types to allow overflow before casting back to signed and taking the absolute value.

Adds a set of F64 tests as well.
",copybara-service[bot],2024-09-07 00:04:28+00:00,[],2024-09-08 18:48:44+00:00,2024-09-08 18:48:43+00:00,https://github.com/tensorflow/tensorflow/pull/75297,[],[],
2511324462,pull_request,closed,,Check for trivial unit dims in fully connected folding,"Check for trivial unit dims in fully connected folding
",copybara-service[bot],2024-09-06 23:49:30+00:00,['LukeBoyer'],2024-09-10 02:08:04+00:00,2024-09-10 02:08:03+00:00,https://github.com/tensorflow/tensorflow/pull/75296,[],[],
2511321010,pull_request,closed,,[XLA:GPU] Use cuda_library for command_buffer_kernels,"[XLA:GPU] Use cuda_library for command_buffer_kernels
",copybara-service[bot],2024-09-06 23:42:08+00:00,[],2024-09-07 00:03:04+00:00,2024-09-07 00:03:03+00:00,https://github.com/tensorflow/tensorflow/pull/75295,[],[],
2511320716,pull_request,closed,,Remove a bunch of unused GpuDriver APIs and associated implementations.,"Remove a bunch of unused GpuDriver APIs and associated implementations.
",copybara-service[bot],2024-09-06 23:41:37+00:00,[],2024-09-09 18:31:48+00:00,2024-09-09 18:31:47+00:00,https://github.com/tensorflow/tensorflow/pull/75294,[],[],
2511289619,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@e51fd95e,"Integrate StableHLO at openxla/stablehlo@e51fd95e
",copybara-service[bot],2024-09-06 22:51:07+00:00,[],2024-09-07 01:49:22+00:00,2024-09-07 01:49:22+00:00,https://github.com/tensorflow/tensorflow/pull/75293,[],[],
2511279173,pull_request,closed,,Remove no longer used GpuDriver::GetMFMASupport function.,"Remove no longer used GpuDriver::GetMFMASupport function.
",copybara-service[bot],2024-09-06 22:35:37+00:00,[],2024-09-07 01:15:58+00:00,2024-09-07 01:15:57+00:00,https://github.com/tensorflow/tensorflow/pull/75292,[],[],
2511274126,pull_request,closed,,Generalize slice folding,"Generalize slice folding
",copybara-service[bot],2024-09-06 22:28:28+00:00,['LukeBoyer'],2024-09-10 01:27:30+00:00,2024-09-10 01:27:30+00:00,https://github.com/tensorflow/tensorflow/pull/75291,[],[],
2511270154,pull_request,closed,,Make GpuDriver::GetEventElapsedTime return an absl::StatusOr<float> instead of a bool.,"Make GpuDriver::GetEventElapsedTime return an absl::StatusOr<float> instead of a bool.
",copybara-service[bot],2024-09-06 22:24:28+00:00,[],2024-09-07 00:52:55+00:00,2024-09-07 00:52:55+00:00,https://github.com/tensorflow/tensorflow/pull/75290,[],[],
2511255601,pull_request,closed,,Tighten error tolerances for exhaustive test of AbsComplex.,"Tighten error tolerances for exhaustive test of AbsComplex.
",copybara-service[bot],2024-09-06 22:11:17+00:00,[],2024-09-07 00:42:28+00:00,2024-09-07 00:42:27+00:00,https://github.com/tensorflow/tensorflow/pull/75289,[],[],
2511250066,pull_request,closed,,CL_DIFF,,vam-google,2024-09-06 22:04:43+00:00,[],2024-10-10 07:12:13+00:00,2024-10-10 07:12:13+00:00,https://github.com/tensorflow/tensorflow/pull/75287,[],[],
2511208314,pull_request,closed,,CL diff (linking-hell),,vam-google,2024-09-06 21:19:23+00:00,[],2024-09-06 22:03:37+00:00,2024-09-06 22:03:37+00:00,https://github.com/tensorflow/tensorflow/pull/75285,[],[],
2511188991,pull_request,closed,,Make GpuDriver::SynchronizeContext return an absl::Status.,"Make GpuDriver::SynchronizeContext return an absl::Status.
",copybara-service[bot],2024-09-06 21:01:43+00:00,[],2024-09-06 23:13:26+00:00,2024-09-06 23:13:26+00:00,https://github.com/tensorflow/tensorflow/pull/75284,[],[],
2511188972,pull_request,closed,,Fold GpuDriver::IsStreamIdle into GpuDriver::DestroyStream.,"Fold GpuDriver::IsStreamIdle into GpuDriver::DestroyStream.
",copybara-service[bot],2024-09-06 21:01:41+00:00,[],2024-09-07 00:13:45+00:00,2024-09-07 00:13:44+00:00,https://github.com/tensorflow/tensorflow/pull/75283,[],[],
2511149912,pull_request,open,,Integrate LLVM at llvm/llvm-project@2f6e4ed389a6,"Integrate LLVM at llvm/llvm-project@2f6e4ed389a6

Updates LLVM usage to match
[2f6e4ed389a6](https://github.com/llvm/llvm-project/commit/2f6e4ed389a6)

Reverts 5c848cb14ba1785dbbb98759bdb3fe6fd9469083
",copybara-service[bot],2024-09-06 20:28:35+00:00,[],2024-09-06 20:28:35+00:00,,https://github.com/tensorflow/tensorflow/pull/75282,[],[],
2511124213,pull_request,open,,Integrate LLVM at llvm/llvm-project@c08f80e348ed,"Integrate LLVM at llvm/llvm-project@c08f80e348ed

Updates LLVM usage to match
[c08f80e348ed](https://github.com/llvm/llvm-project/commit/c08f80e348ed)
",copybara-service[bot],2024-09-06 20:09:18+00:00,[],2024-09-06 20:09:18+00:00,,https://github.com/tensorflow/tensorflow/pull/75281,[],[],
2511095529,pull_request,closed,,Reduce the complexity of function `Lower`.,"Reduce the complexity of function `Lower`.

According to Clang-Tidy's [readability-function-cognitive-complexity](https://clang.llvm.org/extra/clang-tidy/checks/readability/function-cognitive-complexity.html), the recommended threshold is 15. However, the function `Lower` had a cognitive complexity of 134. This number is now reduced to 18. Although it's still higher than the threshold, it's in a much better state than before.
",copybara-service[bot],2024-09-06 19:47:38+00:00,['ghpvnist'],2024-09-18 19:37:41+00:00,2024-09-18 19:37:40+00:00,https://github.com/tensorflow/tensorflow/pull/75278,[],[],
2511091887,pull_request,open,,Enhanced TensorFlow-Keras Integration: Some of the techniques that are used in Lazy Loading and Error Handling   ,"#### 1. **Summary**: 
 In this pull request, The TensorFlow-Keras integration script has been updated with important changes that include; enhancements on lazy loading, exception handling and module compatibility. The changes are aimed at the treatment of module imports in a more flexible manner, case-sensitivity problem, and compatibility with TensorFlow and Keras of any version. These changes help in enhancing the stability of the script thus making it easier to detect and manage errors that may arise during the import process. The dynamic management of module paths also adds more flexibility into the usage of several TensorFlow configurations. 
 
 #### 2. **Related Issues**: 
 - There has been complications associated with case sensitivity while importing modules especially with different TensorFlow configurations. This issue can be solved by the new case insensitive check of variable values for true, True or 1. 
 - Inaccurate or absence of modules that are required during the import process caused run time errors that have been solved with better error handling. 
 - It was also an issue that the compatibility with different versions of TensorFlow and Keras was not always consistent and this has been fixed through the use of dynamic path management. 
 
 #### 3. **Discussions**: 
 The primary concern was how to enhance the integration of TensorFlow and Keras and particularly in environments that have different settings. The issues of dealing with lazy loading and how to address the problem of managing module paths were deemed important. This also involved how to incorporate error handling in a better way so as to avoid problems that may arise due to imports and conflicting configurations. 
 
 #### 4. **QA Instructions**: 
 - **Lazy Loading**: Check the effectiveness of the lazy loading mechanism by executing scripts with various TensorFlow and Keras editions and ensure that the modules will be loaded correctly depending on the settings. 
 - **Case-Sensitive Check**: Confirm the case insensitive check by defining environment variables using different case sensitivity (true, True, 1). 
 - **Error Handling**: It is also necessary to mimic missing or wrong modules while importing so as to provide meaningful error messages. 
 - **Dynamic Path Management**: Continue to execute tests in different TensorFlow configurations and verify that the script appropriately changes the path of modules and loads relevant modules. 
 
 #### 5. **Merge Plan**: 
 Then the changes will be pushed into the main branch after passing through QA testing. It is suggested that performance checks should be carried out in different configurations of TensorFlow and Keras and ensure that there are no conflicts and that the code is stable before making the merge. 
 
 #### 6. **Motivation and Context**: 
 These changes were made to cope with case sensitivity concerns in variables, module import problems and compatibility issues with TensorFlow-Keras integration. They include the enhanced lazy loading and dynamic path management as means to increase the script’s adaptability to different environments. These changes are intended to improve the stability of TensorFlow and Keras integration and make it work correctly in various environments as well as to facilitate problem solving. 
 
 #### 7. **Types of Changes**: 
 - **Bug Fixes**: Added checks that are insensitive to the case of the symbols used and better error handling during module imports. 
 - **New Features**: Improved Dynamic module path management and the enhancement in lazy loading. 
 - **Performance Improvements**: Fewer run time issues and more compatibility with various TensorFlow environments.",AnandPolamarasetti,2024-09-06 19:44:38+00:00,['gbaned'],2024-11-27 10:45:26+00:00,,https://github.com/tensorflow/tensorflow/pull/75277,"[('awaiting review', 'Pull request awaiting review'), ('size:M', 'CL Change Size: Medium')]","[{'comment_id': 2354442329, 'issue_id': 2511091887, 'author': 'keerthanakadiri', 'body': 'Hi @sachinprasadhs  , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 9, 17, 3, 40, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2367657896, 'issue_id': 2511091887, 'author': 'keerthanakadiri', 'body': 'Hi @sachinprasadhs , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 9, 23, 9, 21, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384868030, 'issue_id': 2511091887, 'author': 'keerthanakadiri', 'body': 'Hi @sachinprasadhs , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 1, 5, 59, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413423568, 'issue_id': 2511091887, 'author': 'keerthanakadiri', 'body': 'Hi @sachinprasadhs , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 15, 9, 51, 17, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-09-17 03:40:17 UTC): Hi @sachinprasadhs  , Can you please review this PR? Thank you !

keerthanakadiri on (2024-09-23 09:21:03 UTC): Hi @sachinprasadhs , Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-01 05:59:42 UTC): Hi @sachinprasadhs , Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-15 09:51:17 UTC): Hi @sachinprasadhs , Can you please review this PR? Thank you !

"
2511081165,pull_request,closed,,Reverts 5c848cb14ba1785dbbb98759bdb3fe6fd9469083,"Reverts 5c848cb14ba1785dbbb98759bdb3fe6fd9469083
",copybara-service[bot],2024-09-06 19:36:10+00:00,['kanglant'],2024-09-06 20:32:41+00:00,2024-09-06 20:32:39+00:00,https://github.com/tensorflow/tensorflow/pull/75276,[],[],
2511042761,pull_request,open,,[StableHLO] Fix jax windows ci build,"[StableHLO] Fix jax windows ci build
",copybara-service[bot],2024-09-06 19:06:07+00:00,[],2024-09-06 19:06:07+00:00,,https://github.com/tensorflow/tensorflow/pull/75275,[],[],
2511000044,pull_request,closed,,Internal only changes,"Internal only changes
",copybara-service[bot],2024-09-06 18:39:25+00:00,['zzzaries'],2024-09-06 19:11:04+00:00,2024-09-06 19:11:03+00:00,https://github.com/tensorflow/tensorflow/pull/75274,[],[],
2510991047,pull_request,closed,,Restore VLOG in GpuDriver::AsynchronousMemcpyD2D good path.,"Restore VLOG in GpuDriver::AsynchronousMemcpyD2D good path.
",copybara-service[bot],2024-09-06 18:32:43+00:00,[],2024-09-06 20:54:50+00:00,2024-09-06 20:54:50+00:00,https://github.com/tensorflow/tensorflow/pull/75273,[],[],
2510984136,pull_request,closed,,Make GpuDriver::WaitStreamOnEvent return an absl::Status.,"Make GpuDriver::WaitStreamOnEvent return an absl::Status.
",copybara-service[bot],2024-09-06 18:27:38+00:00,[],2024-09-06 22:52:48+00:00,2024-09-06 22:52:46+00:00,https://github.com/tensorflow/tensorflow/pull/75272,[],[],
2510961008,pull_request,closed,,Internal only changes,"Internal only changes
",copybara-service[bot],2024-09-06 18:10:17+00:00,['zzzaries'],2024-09-06 20:41:58+00:00,2024-09-06 20:41:58+00:00,https://github.com/tensorflow/tensorflow/pull/75271,[],[],
2510957028,pull_request,closed,,Make GpuDriver::AddStreamCallback return absl::Status instead of bool.,"Make GpuDriver::AddStreamCallback return absl::Status instead of bool.
",copybara-service[bot],2024-09-06 18:07:31+00:00,[],2024-09-06 20:11:58+00:00,2024-09-06 20:11:57+00:00,https://github.com/tensorflow/tensorflow/pull/75270,[],[],
2510906378,pull_request,closed,,Internal build change.,"Internal build change.
",copybara-service[bot],2024-09-06 17:35:56+00:00,['junjiang-lab'],2024-09-06 19:30:54+00:00,2024-09-06 19:30:54+00:00,https://github.com/tensorflow/tensorflow/pull/75268,[],[],
2510906285,pull_request,open,,Launch noop kernel instead of directly using GpuDriver for conditional empty graph workaround.,"Launch noop kernel instead of directly using GpuDriver for conditional empty graph workaround.
",copybara-service[bot],2024-09-06 17:35:52+00:00,[],2024-09-06 17:35:52+00:00,,https://github.com/tensorflow/tensorflow/pull/75267,[],[],
2510897606,pull_request,open,,Support JAX shard map lowering with Shardy enabled.,"Support JAX shard map lowering with Shardy enabled.

This doesn't lower it to a `ManualComputationOp`, but just adds some extra attributes on the existing Sharding/FullToShard/ShardToFull custom calls and call ops. Natively lowering to `ManualComputationOp` is a bit more invasive, and we can do this as a future cleanup in JAX.
",copybara-service[bot],2024-09-06 17:30:21+00:00,[],2024-09-06 17:30:21+00:00,,https://github.com/tensorflow/tensorflow/pull/75266,[],[],
2510891817,pull_request,closed,,[XLA:GPU] Add spilling heuristic to Tiled Cost Model.,"[XLA:GPU] Add spilling heuristic to Tiled Cost Model.

We assume that a tile that doesn't fit into registers will result in register spilling and cause performance degradation. We will filter out those cases for now, until we have a better heuristic.
",copybara-service[bot],2024-09-06 17:26:08+00:00,[],2024-09-10 11:49:57+00:00,2024-09-10 11:49:56+00:00,https://github.com/tensorflow/tensorflow/pull/75265,[],[],
2510890207,pull_request,closed,,Fix GpuCompiler test for ROCm,"Fix GpuCompiler test for ROCm
",copybara-service[bot],2024-09-06 17:24:59+00:00,[],2024-09-06 18:35:02+00:00,2024-09-06 18:35:01+00:00,https://github.com/tensorflow/tensorflow/pull/75264,[],[],
2510875333,pull_request,closed,,Use absolute path to invoke `generate_index_html.sh`,"Use absolute path to invoke `generate_index_html.sh`
",copybara-service[bot],2024-09-06 17:14:52+00:00,['ddunl'],2024-09-06 18:27:38+00:00,2024-09-06 18:27:37+00:00,https://github.com/tensorflow/tensorflow/pull/75263,[],[],
2510867288,pull_request,closed,,Improve sharding strategy generation for gather ops.,"Improve sharding strategy generation for gather ops.
",copybara-service[bot],2024-09-06 17:08:56+00:00,[],2024-09-06 20:17:44+00:00,2024-09-06 20:17:43+00:00,https://github.com/tensorflow/tensorflow/pull/75262,[],[],
2510847805,pull_request,closed,,"Combine IsPredeterminedError and DefinedOn. This is in case another thread sets the buffer as an error buffer in between those 2 calls, which would make the DefinedOn call indefinitely wait.","Combine IsPredeterminedError and DefinedOn. This is in case another thread sets the buffer as an error buffer in between those 2 calls, which would make the DefinedOn call indefinitely wait.
",copybara-service[bot],2024-09-06 16:56:40+00:00,[],2024-09-10 23:47:02+00:00,2024-09-10 23:47:01+00:00,https://github.com/tensorflow/tensorflow/pull/75261,[],[],
2510834933,pull_request,closed,,"Compute memory usage values that are shown as ""MB"" as megabytes (1000 * 1000)","Compute memory usage values that are shown as ""MB"" as megabytes (1000 * 1000)
rather than mebibytes (1024 * 1024), which should be shown as ""MiB"" not ""MB"".

Add unit test of `operator<<` for `MemoryUsage`.

Improve the unit test of `GetMemoryUsage` to allocate a non-trivial amount
of memory and verify that the memory reported is at least as high as that.
",copybara-service[bot],2024-09-06 16:47:26+00:00,[],2024-09-13 20:04:16+00:00,2024-09-13 20:04:16+00:00,https://github.com/tensorflow/tensorflow/pull/75260,[],[],
2510798469,pull_request,closed,,Support mlir::ShapedType during import,"Support mlir::ShapedType during import
",copybara-service[bot],2024-09-06 16:26:57+00:00,[],2024-09-09 11:27:12+00:00,2024-09-09 11:27:12+00:00,https://github.com/tensorflow/tensorflow/pull/75259,[],[],
2510761495,pull_request,closed,,Reverts 31001e011efa7c1acca4f0fc82e39b7d85d5ac30,"Reverts 31001e011efa7c1acca4f0fc82e39b7d85d5ac30
",copybara-service[bot],2024-09-06 16:05:48+00:00,[],2024-09-12 15:45:20+00:00,2024-09-12 15:45:18+00:00,https://github.com/tensorflow/tensorflow/pull/75258,[],[],
2510689477,pull_request,closed,,Reverts 39d4959f3d944adc1f85cb3f167a5c7bdd13d2ee,"Reverts 39d4959f3d944adc1f85cb3f167a5c7bdd13d2ee
",copybara-service[bot],2024-09-06 15:29:35+00:00,[],2024-09-11 23:17:16+00:00,2024-09-11 23:17:16+00:00,https://github.com/tensorflow/tensorflow/pull/75257,[],[],
2510609437,pull_request,closed,,Refactor `ExhaustiveOpTestBase` associated constants and types to `ExhaustiveOpTestTraits`,"Refactor `ExhaustiveOpTestBase` associated constants and types to `ExhaustiveOpTestTraits`

Factors out all of the associated constants and types from `ExhaustiveOpTestBase` into a ""traits"" object to ease with sharing the constants between multiple types in future refactorings.
",copybara-service[bot],2024-09-06 14:47:26+00:00,[],2024-09-07 21:02:24+00:00,2024-09-07 21:02:23+00:00,https://github.com/tensorflow/tensorflow/pull/75255,[],[],
2510587317,pull_request,open,,[PjRT] Remove unused allocation mode,"[PjRT] Remove unused allocation mode
",copybara-service[bot],2024-09-06 14:35:51+00:00,['cheshire'],2024-09-06 14:35:52+00:00,,https://github.com/tensorflow/tensorflow/pull/75254,[],[],
2510567422,pull_request,open,,[XLA:GPU] Slightly improve the readability and discoverability of the fusion decline reasons.,"[XLA:GPU] Slightly improve the readability and discoverability of the fusion decline reasons.

With the cl we could log the decline fusion reasons by enabling logging for instruction_fusion.
--vmodule=instruction_fusion=1 enables the logging for the reasons.
--vmodule=instruction_fusion=3 also logs the instruction.
",copybara-service[bot],2024-09-06 14:26:09+00:00,[],2024-09-06 18:28:13+00:00,,https://github.com/tensorflow/tensorflow/pull/75253,[],[],
2510557950,pull_request,closed,,[XLA:GPU] Flatten vectors,"[XLA:GPU] Flatten vectors

Flatten vectors alongside tensors.
",copybara-service[bot],2024-09-06 14:21:22+00:00,[],2024-09-09 12:02:46+00:00,2024-09-09 12:02:46+00:00,https://github.com/tensorflow/tensorflow/pull/75252,[],[],
2510555612,pull_request,closed,,PR #15615: [PJRT:GPU] Respect auto layout modes in MLIR compilation,"PR #15615: [PJRT:GPU] Respect auto layout modes in MLIR compilation

Imported from GitHub PR https://github.com/openxla/xla/pull/15615

Without this patch, auto layouts for arguments and results turn into default layouts (in the
DetermineArgumentLayoutsFromCompileOptions function). This patch avoids calling
DetermineArgumentLayoutsFromCompileOptions from the MLIR compilation method
so that empty layouts on shapes are preserved.

With this patch we should be able to enable four more layout tests in JAX on GPUs.
Copybara import of the project:

--
84728bb316feab79a62f2585f63c70d1bb3f693b by Jaroslav Sevcik <jsevcik@nvidia.com>:

Respect auto layouts

--
cb0da2ed54f490c7f1bee8e91eb1038e2ac4e855 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Reset layout canonicalization callback for executable's options

--
cf857ede0e9e8dd504566e79e5a715f367848e63 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Add an explicit layout callback parameter

Merging this change closes #15615

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15615 from jaro-sevcik:respect-auto-layouts-from-mlir cf857ede0e9e8dd504566e79e5a715f367848e63
",copybara-service[bot],2024-09-06 14:20:10+00:00,[],2024-09-06 15:09:07+00:00,2024-09-06 15:09:07+00:00,https://github.com/tensorflow/tensorflow/pull/75251,[],[],
2510553542,pull_request,open,,[PjRt] Remove unused/redundant argument,"[PjRt] Remove unused/redundant argument
",copybara-service[bot],2024-09-06 14:19:06+00:00,['cheshire'],2024-09-06 14:19:08+00:00,,https://github.com/tensorflow/tensorflow/pull/75250,[],[],
2510479409,pull_request,open,,[PjRT] Remove unused argument,"[PjRT] Remove unused argument
",copybara-service[bot],2024-09-06 13:46:01+00:00,['cheshire'],2024-09-06 13:46:03+00:00,,https://github.com/tensorflow/tensorflow/pull/75249,[],[],
2510425933,pull_request,closed,,Relax verifier to allow for partially pipelined async collectives,"Relax verifier to allow for partially pipelined async collectives
",copybara-service[bot],2024-09-06 13:21:28+00:00,['frgossen'],2024-09-24 22:24:55+00:00,2024-09-24 22:24:54+00:00,https://github.com/tensorflow/tensorflow/pull/75248,[],[],
2510194283,pull_request,open,,Integrate LLVM at llvm/llvm-project@b525ead65c22,"Integrate LLVM at llvm/llvm-project@b525ead65c22

Updates LLVM usage to match
[b525ead65c22](https://github.com/llvm/llvm-project/commit/b525ead65c22)
",copybara-service[bot],2024-09-06 11:13:31+00:00,[],2024-09-06 15:02:58+00:00,,https://github.com/tensorflow/tensorflow/pull/75247,[],[],
2510142395,pull_request,open,,Enhanced version of Benchmarking Script incorporating Artificial Intelligence and Optimization.,"#### 1. **Summary**: 
 This pull request brings in major changes to the benchmarking script and incorporates the use of AI elements and also makes the code more readable and easy to maintain. The major changes that have been integrated are the utilization of the `AIDrivenMetricSelection` component that automates the identification of performance metrics thus providing more specific and relevant summary of benchmarking. The code in the script has been revamped in order to decrease the cognitive load, especially in the `summarize` function so that it is easier to modify. Moreover, the enhancement has been made in reporting with the help of the new function of `combine_summaries` which integrates the details of benchmarking results in a better manner for the purpose of comparison. The benchmarking process has also been improved by the use of context managers and temporary folders as a means of ensuring that the process is accurate. Last but not the least, the script has been updated in such a way that it can upload the benchmark summaries to the Hugging Face Hub for easy sharing and collaboration. 
 
 #### 2. **Related Issues**: 
 - To this, the problem of intricate benchmarking processes was solved by the AI-based metric selection that reduces analysis and reporting complexity. 
 - Solved issues with the codebase update by refactoring the `summarize` function which brought the cognitive complexity down to 15. 
 - Increased the robustness of benchmarking by wrapping benchmark runs with context managers and employing proper file management. 
 - Implemented the ability to submit benchmark results to the Hugging Face Hub in order to address the problems with the results sharing and availability. 
 
 #### 3. **Discussions**: 
 The major topic of discussions was the importance of using AI in automation of benchmarking activities especially in choosing the right metrics to use when evaluating performance. The team also discussed whether it was necessary to refactor the code to enhance code maintainability for instance by decomposing the complicated functions such as `summarize`. There was agreement on the importance of improving the report aggregation and the report reliability and on the advantage of using the Hugging Face Hub for result sharing. 
 
 #### 4. **QA Instructions**: 
 - **AI-Driven Metric Selection**: Validate the `AIDrivenMetricSelection` component by performing benchmarks and confirming that the chosen metrics represent the most significant performance characteristics. 
 - **Refactored Summarize Function**: Ensure that the refactored summarize function outputs meaningful and correct summaries and has a low cognitive complexity. 
 - **Report Aggregation**: To properly combine multiple benchmark summaries into a single report for comparison, use the combine_summaries function. 
 - **Commit Containment**: Ensure that the context manager is correctly managing the isolation of benchmarking runs and that all the directories operations are done in the temporary folders. 
 - **Hugging Face Hub Integration**: Check if the uploaded model and data will appear correctly on the Hugging Face Hub after uploading a benchmark summary. 
 
 #### 5. **Merge Plan**: 
 After that the QA tests will be conducted to ensure all the AI features and the refactored functions are working as expected and then the branch will be merged to the main branch. Particular focus will be placed on how the AI-based metrics selection and Hugging Face Hub do not affect the current benchmarking process. 
 
 #### 6. **Motivation and Context**: 
 This has been brought about by the necessity to enhance the effectiveness of the benchmarking process, its ease of use and dependability. The use of AI driven features enable automated selection of metrics to be used thereby minimizing the time taken in analyzing metrics manually and enhancing the significance of summaries. This is because by refactoring the code to remove high cognitive complexity then the script is more manageable and more easily modifiable. The improvements in the aggregation of the results reports and the connection to the Hugging Face Hub also increase the usefulness of the benchmarking. 
 
 #### 7. **Types of Changes**: 
 - **New Feature**: Choosing metrics with the help of artificial intelligence and integration with the Hugging Face Hub. 
 - **Enhancement**: Revised the ‘summarize’ function and enhanced the reporting through the function that combines the summaries. 
 - **Reliability**: To avoid any interferences and to get consistent results, context managers and temporary folders have been used. 
 - **Performance**: Improved benchmarking methods and more effective as well as meaningful data analysis methods.",RahulVadisetty91,2024-09-06 10:42:52+00:00,[],2024-09-10 08:27:21+00:00,,https://github.com/tensorflow/tensorflow/pull/75246,[],"[{'comment_id': 2340003990, 'issue_id': 2510142395, 'author': 'RahulVadisetty91', 'body': ""Could someone provide advice on how I can pass the build check for this pull request? I've updated the build as requested, but it never seems to pass the checks. Is this build check critical to the merge, or is there an alternative approach to handle this issue? Any guidance on resolving this would be greatly appreciated"", 'created_at': datetime.datetime(2024, 9, 10, 8, 27, 20, tzinfo=datetime.timezone.utc)}]","RahulVadisetty91 (Issue Creator) on (2024-09-10 08:27:20 UTC): Could someone provide advice on how I can pass the build check for this pull request? I've updated the build as requested, but it never seems to pass the checks. Is this build check critical to the merge, or is there an alternative approach to handle this issue? Any guidance on resolving this would be greatly appreciated

"
2510073390,pull_request,closed,,[XLA:GPU][IndexAnalysis] Add `is_simplified` to IndexingMap.,"[XLA:GPU][IndexAnalysis] Add `is_simplified` to IndexingMap.
",copybara-service[bot],2024-09-06 10:09:11+00:00,['pifon2a'],2024-09-06 19:38:59+00:00,2024-09-06 19:38:59+00:00,https://github.com/tensorflow/tensorflow/pull/75245,[],[],
2510037241,pull_request,closed,,"Clarify that `allocated_bytes` refers to heap only, not total memory usage.","Clarify that `allocated_bytes` refers to heap only, not total memory usage.

Also clarify that GetMemoryUsage() works on Apple devices too now,
not just on Linux.

Also some include-what-you-use fixes.
",copybara-service[bot],2024-09-06 09:52:00+00:00,[],2024-09-13 19:34:55+00:00,2024-09-13 19:34:54+00:00,https://github.com/tensorflow/tensorflow/pull/75244,[],[],
2510023854,pull_request,open,,Change lite/builtin_op_data.h to include lite/core/c/builtin_op_data.h,"Change lite/builtin_op_data.h to include lite/core/c/builtin_op_data.h
via lite/c/builtin_op_data.h, rather than directly, and use
`cc_library_with_tflite` rather than `cc_library` for the BUILD target.

This is for better compatibility with TFLite in Play services.
",copybara-service[bot],2024-09-06 09:45:42+00:00,[],2024-09-25 13:41:13+00:00,,https://github.com/tensorflow/tensorflow/pull/75243,[],[],
2510005777,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-06 09:37:30+00:00,[],2024-09-06 09:37:30+00:00,,https://github.com/tensorflow/tensorflow/pull/75242,[],[],
2509883518,pull_request,closed,,[XLA:GPU] Implement CallOpInterface to XLAGPU_MaterializeOp,"[XLA:GPU] Implement CallOpInterface to XLAGPU_MaterializeOp

This is needed to prevent EraseDeadFunctionsPass from removing materialize's function.
",copybara-service[bot],2024-09-06 08:51:58+00:00,[],2024-09-06 10:06:29+00:00,2024-09-06 10:06:28+00:00,https://github.com/tensorflow/tensorflow/pull/75240,[],[],
2509880222,pull_request,closed,,Fix unit test with incorrect input dimensions.,"Fix unit test with incorrect input dimensions.
",copybara-service[bot],2024-09-06 08:50:12+00:00,[],2024-09-10 11:09:27+00:00,2024-09-10 11:09:26+00:00,https://github.com/tensorflow/tensorflow/pull/75239,[],[],
2509689642,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-06 07:08:30+00:00,[],2024-09-06 07:54:32+00:00,,https://github.com/tensorflow/tensorflow/pull/75238,[],[],
2509622705,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-06 06:26:11+00:00,[],2024-09-10 07:11:43+00:00,2024-09-10 07:11:42+00:00,https://github.com/tensorflow/tensorflow/pull/75237,[],[],
2509533258,pull_request,closed,,Integrate LLVM at llvm/llvm-project@ede40da1f8c1,"Integrate LLVM at llvm/llvm-project@ede40da1f8c1

Updates LLVM usage to match
[ede40da1f8c1](https://github.com/llvm/llvm-project/commit/ede40da1f8c1)
",copybara-service[bot],2024-09-06 05:13:20+00:00,[],2024-09-07 01:04:04+00:00,2024-09-07 01:04:03+00:00,https://github.com/tensorflow/tensorflow/pull/75236,[],[],
2509478991,pull_request,closed,,Move TF Lite API docs to TF repo.,"Move TF Lite API docs to TF repo.

https://github.com/tensorflow/docs/tree/master/site/en/lite/api_docs -> https://github.com/tensorflow/tensorflow/tree/master/tensorflow/lite/g3doc/api_docs

This keeps the API docs with the other TF Lite documentation.
",copybara-service[bot],2024-09-06 04:18:29+00:00,['markmcd'],2024-09-06 08:26:11+00:00,2024-09-06 08:26:10+00:00,https://github.com/tensorflow/tensorflow/pull/75235,[],[],
2509420420,pull_request,closed,,Add general case folding for reverse,"Add general case folding for reverse
",copybara-service[bot],2024-09-06 03:16:10+00:00,['LukeBoyer'],2024-09-06 21:50:34+00:00,2024-09-06 21:50:33+00:00,https://github.com/tensorflow/tensorflow/pull/75234,[],[],
2509290917,pull_request,open,,Always generate mhlo.sharding when exporting sdy.manual_computation to support nested manual computations.,"Always generate mhlo.sharding when exporting sdy.manual_computation to support nested manual computations.

In the nested sdy.manual_computation, we need to generate the sharding based on the old and new manual axes. In the following example, we need ensure that ""a"" is marked as manual in all the instructions that are related to the inner sdy.manual_computation.

```
outer sdy.manual_computation with manual_axes = {""a""}
  inner sdy.manual_computation with manual_axes = {""b""}
```

Since sdy.sharding has no information on the manual axes, we have to export to mhlo.sharding directly.
",copybara-service[bot],2024-09-06 02:11:16+00:00,[],2024-09-06 02:11:16+00:00,,https://github.com/tensorflow/tensorflow/pull/75233,[],[],
2509230334,pull_request,closed,,Prefer 32bit padding amount operands (better for XNN),"Prefer 32bit padding amount operands (better for XNN)
",copybara-service[bot],2024-09-06 01:35:10+00:00,['LukeBoyer'],2024-09-06 21:37:14+00:00,2024-09-06 21:37:13+00:00,https://github.com/tensorflow/tensorflow/pull/75232,[],[],
2509221641,pull_request,closed,,Add `GPU_HOST_MEMORY_PREALLOCATE` flag to enable users to preallocate pinned memory.,"Add `GPU_HOST_MEMORY_PREALLOCATE` flag to enable users to preallocate pinned memory.

Change `GPU_HOST_MEMORY_LIMIT_GB` default value to 16GB when `GPU_HOST_MEMORY_PREALLOCATE` is enabled.
",copybara-service[bot],2024-09-06 01:30:18+00:00,[],2024-09-09 18:00:27+00:00,2024-09-09 18:00:26+00:00,https://github.com/tensorflow/tensorflow/pull/75231,[],[],
2509201346,pull_request,closed,,Integrate LLVM at llvm/llvm-project@eaa95a1c2bd3,"Integrate LLVM at llvm/llvm-project@eaa95a1c2bd3

Updates LLVM usage to match
[eaa95a1c2bd3](https://github.com/llvm/llvm-project/commit/eaa95a1c2bd3)
",copybara-service[bot],2024-09-06 01:16:55+00:00,[],2024-09-06 03:25:07+00:00,2024-09-06 03:25:07+00:00,https://github.com/tensorflow/tensorflow/pull/75230,[],[],
2509155042,pull_request,open,,Update ML Drift Delegate for external tensors,"Update ML Drift Delegate for external tensors

external tensors are used via create_info.external_mutable_tensors
",copybara-service[bot],2024-09-06 00:46:27+00:00,['terryheo'],2024-09-06 00:46:28+00:00,,https://github.com/tensorflow/tensorflow/pull/75229,[],[],
2509148777,pull_request,closed,,Allow python interpreter to access tensor details for all the subgraphs.,"Allow python interpreter to access tensor details for all the subgraphs.
",copybara-service[bot],2024-09-06 00:42:04+00:00,['rewu93'],2024-09-12 17:31:21+00:00,2024-09-12 17:31:20+00:00,https://github.com/tensorflow/tensorflow/pull/75228,[],[],
2509138698,pull_request,open,,Fix KV Cache for GPU,"Fix KV Cache for GPU

- Set KV Cache `buffer_handle` before applying delegate
- Fix typo on setting output `buffer_handle`
",copybara-service[bot],2024-09-06 00:34:54+00:00,['terryheo'],2024-09-06 00:34:55+00:00,,https://github.com/tensorflow/tensorflow/pull/75227,[],[],
2509089286,pull_request,closed,,Update SignatureRunner API,"Update SignatureRunner API

- GetSignatureRunner() has an option to not to apply default delegate.
- SetInputBufferHandle() will fail when the given name is not found.
",copybara-service[bot],2024-09-06 00:07:11+00:00,['terryheo'],2024-09-06 18:50:29+00:00,2024-09-06 18:50:27+00:00,https://github.com/tensorflow/tensorflow/pull/75226,[],[],
2509032925,pull_request,closed,,internal code change,"internal code change
",copybara-service[bot],2024-09-05 23:30:56+00:00,[],2024-09-10 19:38:37+00:00,2024-09-10 19:38:36+00:00,https://github.com/tensorflow/tensorflow/pull/75225,[],[],
2508970211,pull_request,closed,,Run `build.py` in correct directory for XLA's MacOS build,"Run `build.py` in correct directory for XLA's MacOS build
",copybara-service[bot],2024-09-05 22:58:40+00:00,['ddunl'],2024-09-05 23:35:04+00:00,2024-09-05 23:35:03+00:00,https://github.com/tensorflow/tensorflow/pull/75224,[],[],
2508965277,pull_request,closed,,Reorder optimization passes in tflite to tackle BatchMatMul optimizations prior to converting them to FC.,"Reorder optimization passes in tflite to tackle BatchMatMul optimizations prior to converting them to FC.
",copybara-service[bot],2024-09-05 22:55:30+00:00,['vamsimanchala'],2024-09-12 20:53:46+00:00,2024-09-12 20:53:45+00:00,https://github.com/tensorflow/tensorflow/pull/75223,[],[],
2508950699,pull_request,closed,,[xla:ffi] Add support for token inputs and outputs to FFI calls in the GPU runtime.,"[xla:ffi] Add support for token inputs and outputs to FFI calls in the GPU runtime.

This adds new `AddTokenArg` and `AddTokenRet` methods to `CallFrameBuilder` which generate ""buffers"" with `nullptr` and the appropriate data type. I think this is a sensible approach, and these methods can be reused for the CPU backend.
",copybara-service[bot],2024-09-05 22:46:43+00:00,[],2024-09-06 18:05:47+00:00,2024-09-06 18:05:46+00:00,https://github.com/tensorflow/tensorflow/pull/75222,[],[],
2508892725,pull_request,closed,,Add support for `-hlo-flatten-computation-args-result` for importing `entry_computation_layout`.,"Add support for `-hlo-flatten-computation-args-result` for importing `entry_computation_layout`.
",copybara-service[bot],2024-09-05 22:26:48+00:00,['ghpvnist'],2024-10-08 20:07:52+00:00,2024-10-08 20:07:52+00:00,https://github.com/tensorflow/tensorflow/pull/75221,[],[],
2508839211,pull_request,closed,,Cost model now considers the compute latency in addition to its throughput.,"Cost model now considers the compute latency in addition to its throughput.
",copybara-service[bot],2024-09-05 21:59:12+00:00,[],2024-09-17 22:13:32+00:00,2024-09-17 22:13:31+00:00,https://github.com/tensorflow/tensorflow/pull/75220,[],[],
2508822212,pull_request,closed,,Make GpuDriver::AsynchronousMemcpyD2H return absl::Status instead of bool.,"Make GpuDriver::AsynchronousMemcpyD2H return absl::Status instead of bool.
",copybara-service[bot],2024-09-05 21:49:17+00:00,[],2024-09-06 19:02:26+00:00,2024-09-06 19:02:25+00:00,https://github.com/tensorflow/tensorflow/pull/75219,[],[],
2508821550,pull_request,closed,,"Stop creating absl::InternalError, absl::NotFoundError, etc. by hand in rocm_driver.cc.","Stop creating absl::InternalError, absl::NotFoundError, etc. by hand in rocm_driver.cc.
",copybara-service[bot],2024-09-05 21:48:53+00:00,[],2024-09-06 17:56:33+00:00,2024-09-06 17:56:32+00:00,https://github.com/tensorflow/tensorflow/pull/75218,[],[],
2508813201,pull_request,closed,,Internal build change.,"Internal build change.
",copybara-service[bot],2024-09-05 21:44:07+00:00,['junjiang-lab'],2024-09-05 22:20:01+00:00,2024-09-05 22:20:01+00:00,https://github.com/tensorflow/tensorflow/pull/75217,[],[],
2508811754,pull_request,closed,,Reverts df64d69d557879315faa9e451dcd48865ccbb60e,"Reverts df64d69d557879315faa9e451dcd48865ccbb60e
",copybara-service[bot],2024-09-05 21:43:18+00:00,[],2024-09-05 23:18:25+00:00,2024-09-05 23:18:23+00:00,https://github.com/tensorflow/tensorflow/pull/75216,[],[],
2508667208,pull_request,closed,,This CL ensures that the entry_computation_layout has the correct layouts set.,"This CL ensures that the entry_computation_layout has the correct layouts set.
",copybara-service[bot],2024-09-05 20:37:02+00:00,[],2024-09-05 21:27:30+00:00,2024-09-05 21:27:29+00:00,https://github.com/tensorflow/tensorflow/pull/75215,[],[],
2508660941,pull_request,closed,,Reserve space in a vector rathen than re-allocating when populating the vector in a loop.,"Reserve space in a vector rathen than re-allocating when populating the vector in a loop.
",copybara-service[bot],2024-09-05 20:32:50+00:00,[],2024-09-07 03:41:19+00:00,2024-09-07 03:41:18+00:00,https://github.com/tensorflow/tensorflow/pull/75214,[],[],
2508659586,pull_request,closed,,More folding for tfl.minimum,"More folding for tfl.minimum
",copybara-service[bot],2024-09-05 20:31:55+00:00,['LukeBoyer'],2024-09-06 00:48:00+00:00,2024-09-06 00:47:59+00:00,https://github.com/tensorflow/tensorflow/pull/75213,[],[],
2508658419,pull_request,closed,,Fuse commutative relu6,"Fuse commutative relu6
",copybara-service[bot],2024-09-05 20:31:04+00:00,['LukeBoyer'],2024-09-06 19:56:44+00:00,2024-09-06 19:56:43+00:00,https://github.com/tensorflow/tensorflow/pull/75212,[],[],
2508657597,pull_request,closed,,Add more fine-grained checks for supported rank in broadcast folding.,"Add more fine-grained checks for supported rank in broadcast folding.
",copybara-service[bot],2024-09-05 20:30:29+00:00,['LukeBoyer'],2024-09-06 20:02:58+00:00,2024-09-06 20:02:56+00:00,https://github.com/tensorflow/tensorflow/pull/75211,[],[],
2508657285,pull_request,closed,,Add i64 support for tfl.less_equal folding,"Add i64 support for tfl.less_equal folding
",copybara-service[bot],2024-09-05 20:30:17+00:00,['LukeBoyer'],2024-09-06 02:24:43+00:00,2024-09-06 02:24:42+00:00,https://github.com/tensorflow/tensorflow/pull/75210,[],[],
2508656620,pull_request,closed,,Add i64 support for tfl.equal folding,"Add i64 support for tfl.equal folding
",copybara-service[bot],2024-09-05 20:29:50+00:00,['LukeBoyer'],2024-09-06 02:59:20+00:00,2024-09-06 02:59:19+00:00,https://github.com/tensorflow/tensorflow/pull/75209,[],[],
2508656599,pull_request,closed,,Add i64 support for tfl.not_equal folding,"Add i64 support for tfl.not_equal folding
",copybara-service[bot],2024-09-05 20:29:48+00:00,['LukeBoyer'],2024-09-06 03:10:56+00:00,2024-09-06 03:10:55+00:00,https://github.com/tensorflow/tensorflow/pull/75208,[],[],
2508654865,pull_request,closed,,Add i64 support for tfl.greater_equal folding,"Add i64 support for tfl.greater_equal folding
",copybara-service[bot],2024-09-05 20:28:38+00:00,['LukeBoyer'],2024-09-06 02:49:40+00:00,2024-09-06 02:49:38+00:00,https://github.com/tensorflow/tensorflow/pull/75207,[],[],
2508654414,pull_request,closed,,Add i64 support for tfl.greater folding,"Add i64 support for tfl.greater folding
",copybara-service[bot],2024-09-05 20:28:18+00:00,['LukeBoyer'],2024-09-06 02:38:29+00:00,2024-09-06 02:38:29+00:00,https://github.com/tensorflow/tensorflow/pull/75206,[],[],
2508652682,pull_request,closed,,Add i64 support for tfl.less folding,"Add i64 support for tfl.less folding
",copybara-service[bot],2024-09-05 20:27:06+00:00,['LukeBoyer'],2024-09-06 02:17:00+00:00,2024-09-06 02:16:59+00:00,https://github.com/tensorflow/tensorflow/pull/75205,[],[],
2508652296,pull_request,closed,,"Move `tsl/profiler/{backends,convert}` to `xla/tsl`","Move `tsl/profiler/{backends,convert}` to `xla/tsl`
",copybara-service[bot],2024-09-05 20:26:51+00:00,['ddunl'],2024-09-10 01:39:11+00:00,2024-09-10 01:39:10+00:00,https://github.com/tensorflow/tensorflow/pull/75204,[],[],
2508651459,pull_request,closed,,More folding for tfl.maximum.,"More folding for tfl.maximum.
",copybara-service[bot],2024-09-05 20:26:15+00:00,['LukeBoyer'],2024-09-06 00:27:27+00:00,2024-09-06 00:27:25+00:00,https://github.com/tensorflow/tensorflow/pull/75203,[],[],
2508640200,pull_request,closed,,Make GpuDriver::AsynchronousMemcpyH2D return an absl::Status instead of a bool.,"Make GpuDriver::AsynchronousMemcpyH2D return an absl::Status instead of a bool.
",copybara-service[bot],2024-09-05 20:18:57+00:00,[],2024-09-06 16:49:22+00:00,2024-09-06 16:49:22+00:00,https://github.com/tensorflow/tensorflow/pull/75202,[],[],
2508611288,pull_request,closed,,Rename unreachable macro.,"Rename unreachable macro.
",copybara-service[bot],2024-09-05 20:00:27+00:00,['LukeBoyer'],2024-09-05 22:36:48+00:00,2024-09-05 22:36:47+00:00,https://github.com/tensorflow/tensorflow/pull/75201,[],[],
2508577613,pull_request,closed,,"[StableHLO] stablehlo_capi_objects to depend on :CAPIIRObjects, not :CAPIIR","[StableHLO] stablehlo_capi_objects to depend on :CAPIIRObjects, not :CAPIIR
",copybara-service[bot],2024-09-05 19:38:17+00:00,[],2024-09-05 23:00:21+00:00,2024-09-05 23:00:20+00:00,https://github.com/tensorflow/tensorflow/pull/75200,[],[],
2508558271,pull_request,open,,Integrate LLVM at llvm/llvm-project@5edede2db09d,"Integrate LLVM at llvm/llvm-project@5edede2db09d

Updates LLVM usage to match
[5edede2db09d](https://github.com/llvm/llvm-project/commit/5edede2db09d)
",copybara-service[bot],2024-09-05 19:25:45+00:00,[],2024-09-05 19:25:45+00:00,,https://github.com/tensorflow/tensorflow/pull/75199,[],[],
2508499881,pull_request,closed,,Make GpuDriver::AsynchronousMemcpyD2D return absl::Status instead of bool.,"Make GpuDriver::AsynchronousMemcpyD2D return absl::Status instead of bool.
",copybara-service[bot],2024-09-05 18:49:39+00:00,[],2024-09-05 22:46:19+00:00,2024-09-05 22:46:18+00:00,https://github.com/tensorflow/tensorflow/pull/75198,[],[],
2508490188,pull_request,closed,,Pull cuda command buffer kernel definitions behind methods that return MultiKernelLoaderSpec.,"Pull cuda command buffer kernel definitions behind methods that return MultiKernelLoaderSpec.
",copybara-service[bot],2024-09-05 18:44:28+00:00,[],2024-09-05 20:47:00+00:00,2024-09-05 20:46:59+00:00,https://github.com/tensorflow/tensorflow/pull/75197,[],[],
2508468285,pull_request,closed,,Add cuda c++ for command buffer kernels,"Add cuda c++ for command buffer kernels
",copybara-service[bot],2024-09-05 18:31:30+00:00,[],2024-09-06 22:42:23+00:00,2024-09-06 22:42:23+00:00,https://github.com/tensorflow/tensorflow/pull/75195,[],[],
2508424485,pull_request,closed,,Omits max costs & hints for highly over-subscribed problems (to avoid Invalid MIPs).,"Omits max costs & hints for highly over-subscribed problems (to avoid Invalid MIPs).
",copybara-service[bot],2024-09-05 18:05:38+00:00,[],2024-09-05 19:58:52+00:00,2024-09-05 19:58:50+00:00,https://github.com/tensorflow/tensorflow/pull/75193,[],[],
2508419059,pull_request,closed,,Integrate LLVM at llvm/llvm-project@1061c6da53a7,"Integrate LLVM at llvm/llvm-project@1061c6da53a7

Updates LLVM usage to match
[1061c6da53a7](https://github.com/llvm/llvm-project/commit/1061c6da53a7)
",copybara-service[bot],2024-09-05 18:02:29+00:00,[],2024-09-05 23:53:19+00:00,2024-09-05 23:53:19+00:00,https://github.com/tensorflow/tensorflow/pull/75192,[],[],
2508404319,pull_request,closed,,Add folding f32->i64,"Add folding f32->i64
",copybara-service[bot],2024-09-05 17:54:20+00:00,['LukeBoyer'],2024-09-06 00:10:36+00:00,2024-09-06 00:10:36+00:00,https://github.com/tensorflow/tensorflow/pull/75191,[],[],
2508388886,pull_request,open,,Update migration script,"Update migration script
",copybara-service[bot],2024-09-05 17:45:17+00:00,[],2024-09-05 17:45:17+00:00,,https://github.com/tensorflow/tensorflow/pull/75190,[],[],
2508347931,pull_request,closed,,[XLA:GPU] Remove dead configuration parameter from pass,"[XLA:GPU] Remove dead configuration parameter from pass

This was previously used but is not needed anymore.
",copybara-service[bot],2024-09-05 17:22:01+00:00,['majnemer'],2024-09-06 21:14:22+00:00,2024-09-06 21:14:22+00:00,https://github.com/tensorflow/tensorflow/pull/75189,[],[],
2508332927,pull_request,closed,,Add extra env flags to lit test config.,"Add extra env flags to lit test config.
",copybara-service[bot],2024-09-05 17:13:15+00:00,[],2024-09-05 19:49:06+00:00,2024-09-05 19:49:05+00:00,https://github.com/tensorflow/tensorflow/pull/75188,[],[],
2508320273,pull_request,open,,Remove the usage of internal bridge passes.,"Remove the usage of internal bridge passes.
",copybara-service[bot],2024-09-05 17:05:34+00:00,[],2024-09-13 19:16:19+00:00,,https://github.com/tensorflow/tensorflow/pull/75187,[],[],
2508243163,pull_request,open,,"Disable QU8 convolution, transpose convolution, depthwise convolution and fully connected ops.","Disable QU8 convolution, transpose convolution, depthwise convolution and fully connected ops.

UDOT is buggy on many arm devices so XNNPack's performance is worse than TFLite's

This should improve performance for most users, however, if there is a regression, we recommend re-exporting your model either as QS8 or using dynamic range quantization.
",copybara-service[bot],2024-09-05 16:25:35+00:00,['alankelly'],2024-09-05 16:25:36+00:00,,https://github.com/tensorflow/tensorflow/pull/75186,[],[],
2508237362,pull_request,open,,Integrate LLVM at llvm/llvm-project@1061c6da53a7,"Integrate LLVM at llvm/llvm-project@1061c6da53a7

Updates LLVM usage to match
[1061c6da53a7](https://github.com/llvm/llvm-project/commit/1061c6da53a7)
",copybara-service[bot],2024-09-05 16:22:46+00:00,[],2024-09-05 16:22:46+00:00,,https://github.com/tensorflow/tensorflow/pull/75185,[],[],
2508215435,pull_request,open,,Add experimental GCC support in hermetic CUDA rules.,"Add experimental GCC support in hermetic CUDA rules.
",copybara-service[bot],2024-09-05 16:12:26+00:00,[],2024-09-05 16:12:26+00:00,,https://github.com/tensorflow/tensorflow/pull/75184,[],[],
2508049325,pull_request,closed,,Remove cc_api_version stage 4: deletion where cc_api_version = 2,"Remove cc_api_version stage 4: deletion where cc_api_version = 2
",copybara-service[bot],2024-09-05 15:00:14+00:00,[],2024-09-06 17:47:08+00:00,2024-09-06 17:47:07+00:00,https://github.com/tensorflow/tensorflow/pull/75183,[],[],
2508004317,pull_request,closed,,Refactor `MMapHandle` code to use `FileDescriptor` and other fixes.,"Refactor `MMapHandle` code to use `FileDescriptor` and other fixes.

- Use `FileDescriptor` to handle file descriptor lifetimes.
- Add and use `XNNPACK_CHECK_RETURN` macro to simplify `check/log/return false` blocks.
- Unconditionally reset `data_` and `size_` when calling `UnMap`. This closes a
  loophole in internal functions where `UnMap` is called in case of a memory
  management failure but the size_ wouldn't be reset.
",copybara-service[bot],2024-09-05 14:41:47+00:00,['qukhan'],2024-09-06 12:48:25+00:00,2024-09-06 12:48:24+00:00,https://github.com/tensorflow/tensorflow/pull/75182,[],[],
2507915124,pull_request,closed,,"Export ""builtin_op_data.h"" header.","Export ""builtin_op_data.h"" header.
",copybara-service[bot],2024-09-05 14:08:32+00:00,[],2024-09-06 19:47:49+00:00,2024-09-06 19:47:48+00:00,https://github.com/tensorflow/tensorflow/pull/75181,[],[],
2507759290,pull_request,closed,,Add convenience functions and tests to file_util.,"Add convenience functions and tests to file_util.

- Fixes to `FileDescriptor`
- Add `Open`, `Read` and `Write` convenience functions.
",copybara-service[bot],2024-09-05 13:05:54+00:00,['qukhan'],2024-09-05 13:35:43+00:00,2024-09-05 13:35:42+00:00,https://github.com/tensorflow/tensorflow/pull/75180,[],[],
2507668594,pull_request,closed,,PR #16804: Add flag `xla_gpu_enable_pgle_accuracy_checker` to enable accuracy checker,"PR #16804: Add flag `xla_gpu_enable_pgle_accuracy_checker` to enable accuracy checker

Imported from GitHub PR https://github.com/openxla/xla/pull/16804

To enable the strict pgle accuracy checker, set `--xla_gpu_enable_pgle_accuracy_checker` in XLA_FLAGS

Copybara import of the project:

--
932ac20717518a09042d4cea1d4699dc86d8287a by Shraiysh Vaishay <svaishay@nvidia.com>:

Add flag for pgle_accuracy_checker

Adding the flag `--xla_gpu_enable_pgle_accuracy_checker` for enabling PGLE accurcay checker.

Merging this change closes #16804

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16804 from shraiysh:pgle_fix 932ac20717518a09042d4cea1d4699dc86d8287a
",copybara-service[bot],2024-09-05 12:35:21+00:00,[],2024-09-10 09:39:36+00:00,2024-09-10 09:39:35+00:00,https://github.com/tensorflow/tensorflow/pull/75179,[],[],
2507651082,pull_request,closed,,Fixed the type of `FftType` entries in `xla_extension`,"Fixed the type of `FftType` entries in `xla_extension`
",copybara-service[bot],2024-09-05 12:29:30+00:00,['superbobry'],2024-09-05 13:02:19+00:00,2024-09-05 13:02:18+00:00,https://github.com/tensorflow/tensorflow/pull/75178,[],[],
2507376017,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-05 10:17:49+00:00,[],2024-09-05 10:17:49+00:00,,https://github.com/tensorflow/tensorflow/pull/75174,[],[],
2507143666,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-05 08:35:17+00:00,[],2024-09-05 08:35:17+00:00,,https://github.com/tensorflow/tensorflow/pull/75173,[],[],
2507133678,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-05 08:30:32+00:00,[],2024-09-05 08:30:32+00:00,,https://github.com/tensorflow/tensorflow/pull/75172,[],[],
2507030855,pull_request,closed,,Replace C-style casts by C++ static casts in ROCm executor,"Replace C-style casts by C++ static casts in ROCm executor

Just some random clang-tidy suggested fix.
",copybara-service[bot],2024-09-05 07:42:30+00:00,[],2024-09-05 09:34:54+00:00,2024-09-05 09:34:53+00:00,https://github.com/tensorflow/tensorflow/pull/75171,[],[],
2506908849,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-05 06:42:50+00:00,[],2024-09-05 06:42:50+00:00,,https://github.com/tensorflow/tensorflow/pull/75170,[],[],
