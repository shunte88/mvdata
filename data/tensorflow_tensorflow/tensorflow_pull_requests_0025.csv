id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2592957881,pull_request,closed,,Migrate graph_executor to use ConvertGraphToTfExecutor.,"Migrate graph_executor to use ConvertGraphToTfExecutor.

Reverts 7a976f8c802ede5aaaeba6db33a99c1ef352d30f
",copybara-service[bot],2024-10-16 20:14:04+00:00,['rocketas'],2024-10-16 21:09:46+00:00,2024-10-16 21:09:45+00:00,https://github.com/tensorflow/tensorflow/pull/78055,[],[],
2592951149,pull_request,closed,,PR #18139: Enable gpu latency hiding for copy-start/copy-done,"PR #18139: Enable gpu latency hiding for copy-start/copy-done

Imported from GitHub PR https://github.com/openxla/xla/pull/18139

This CL adds copy-start and copy-done instructions to the missing pairs in GPUProfileStatisticsAggregator, enabling correct handling of host memory offloading segments in profiling data. The scheduler optimizes instruction placement by moving copy-start instructions earlier and adjusting copy-done instructions to maximize overlap with computation while ensuring program correctness.
This helps MaxText latency hiding when enabling offloading and scan_layers=false.
Copybara import of the project:

--
e4f72dd5afe25fb1d537b22b3a35099118ebae1e by Jane Liu <janeliu@nvidia.com>:

Enable gpu latency hiding for copy-start/copy-done

--
f5bc4e4de00419dd5d285a6a0f3254e3269dc432 by Jane Liu <janeliu@nvidia.com>:

simplify the tests

--
9b38e137738539dcf9255e32b48a800120a2f892 by Jane Liu <janeliu@nvidia.com>:

add comments

Merging this change closes #18139

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18139 from zhenying-liu:latency_hiding 9b38e137738539dcf9255e32b48a800120a2f892
",copybara-service[bot],2024-10-16 20:10:01+00:00,[],2024-10-17 11:46:20+00:00,2024-10-17 11:46:18+00:00,https://github.com/tensorflow/tensorflow/pull/78054,[],[],
2592865142,pull_request,closed,,Logs max departures (if specified) along with all the other solver parameters & problem stats.,"Logs max departures (if specified) along with all the other solver parameters & problem stats.
",copybara-service[bot],2024-10-16 19:32:59+00:00,[],2024-10-16 21:28:50+00:00,2024-10-16 21:28:48+00:00,https://github.com/tensorflow/tensorflow/pull/78053,[],[],
2592758586,pull_request,open,,Integrate LLVM at llvm/llvm-project@9b7491e86691,"Integrate LLVM at llvm/llvm-project@9b7491e86691

Updates LLVM usage to match
[9b7491e86691](https://github.com/llvm/llvm-project/commit/9b7491e86691)
",copybara-service[bot],2024-10-16 18:47:50+00:00,[],2024-10-16 18:47:50+00:00,,https://github.com/tensorflow/tensorflow/pull/78052,[],[],
2592741843,pull_request,open,,Internal change only,"Internal change only
",copybara-service[bot],2024-10-16 18:42:44+00:00,[],2024-10-17 18:04:14+00:00,,https://github.com/tensorflow/tensorflow/pull/78051,[],[],
2592737795,pull_request,closed,,PR #18271: [NVIDIA GPU] Add a new option to enable windowed einsum based on total flops of the gemm,"PR #18271: [NVIDIA GPU] Add a new option to enable windowed einsum based on total flops of the gemm

Imported from GitHub PR https://github.com/openxla/xla/pull/18271

The current thresholding mechanism to enable windowed einsum(collective matmul) relies on the total size of the sharded operand, this is not sufficient in some cases as we will need to know the total size of the gemm to see if it's beneficial to split it or not. This pr adds a new option to consider the total sizes of both operands. It will override the current xla_gpu_threshold_for_windowed_einsum_mib.

Copybara import of the project:

--
42f679c13e1f8a4529d7665fd3dd2e15f26eb821 by TJ Xu <tjx@nvidia.com>:

Add a new option to enable windowed einsum based on total flops of the
gemm

--
9b4ff4a7d445488412992abd60ccdc74689c84bb by TJ Xu <tjx@nvidia.com>:

add test

--
3f68bcbf206e8809edbea7772f0fb19e817b2a75 by TJ Xu <tjx@nvidia.com>:

Address comments

--
b160e218a8168d5e6d24b1ee794ab171e251e769 by TJ Xu <tjx@nvidia.com>:

Addressed pr comments

--
ff5962b2b20a2fe49c1cf085836f63b09da0ac9f by TJ Xu <tjx@nvidia.com>:

added check for null for lhs and rhs

Merging this change closes #18271

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18271 from Tixxx:tixxx/cm_threshold ff5962b2b20a2fe49c1cf085836f63b09da0ac9f
",copybara-service[bot],2024-10-16 18:41:52+00:00,[],2024-10-24 10:32:09+00:00,2024-10-24 10:32:08+00:00,https://github.com/tensorflow/tensorflow/pull/78050,[],[],
2592726037,pull_request,closed,,Move GetKernelMetadata from Executor classes to Kernel classes.,"Move GetKernelMetadata from Executor classes to Kernel classes.
",copybara-service[bot],2024-10-16 18:36:32+00:00,[],2024-10-16 21:17:25+00:00,2024-10-16 21:17:24+00:00,https://github.com/tensorflow/tensorflow/pull/78049,[],[],
2592713986,pull_request,open,,Fix test failure on cuda build,"Fix test failure on cuda build
",copybara-service[bot],2024-10-16 18:30:22+00:00,[],2024-10-21 19:05:57+00:00,,https://github.com/tensorflow/tensorflow/pull/78048,[],[],
2592699988,pull_request,closed,,[XLA:AlgSimp] Fix gather+pad bug in padding size.,"[XLA:AlgSimp] Fix gather+pad bug in padding size.
",copybara-service[bot],2024-10-16 18:22:55+00:00,['Tongfei-Guo'],2024-10-21 18:38:21+00:00,2024-10-21 18:38:20+00:00,https://github.com/tensorflow/tensorflow/pull/78047,[],[],
2592658864,pull_request,open,,Automated Code Change.,"Automated Code Change.
",copybara-service[bot],2024-10-16 18:04:22+00:00,['changm'],2024-10-21 16:40:10+00:00,,https://github.com/tensorflow/tensorflow/pull/78046,[],[],
2592651211,pull_request,closed,,"Cache the actual concrete Context pointer in each GpuExecutor class, and stop calling gpu_context() where possible.","Cache the actual concrete Context pointer in each GpuExecutor class, and stop calling gpu_context() where possible.
",copybara-service[bot],2024-10-16 18:00:31+00:00,[],2024-10-16 20:06:50+00:00,2024-10-16 20:06:50+00:00,https://github.com/tensorflow/tensorflow/pull/78045,[],[],
2592591523,pull_request,closed,,[hlo] Do not overwrite derived instruction backend config,"[hlo] Do not overwrite derived instruction backend config

Derived instruction might set its own backend config, and it's not safe to overwrite it with an original one.

Fix for: https://github.com/openxla/xla/issues/18214
",copybara-service[bot],2024-10-16 17:36:45+00:00,['ezhulenev'],2024-10-16 19:58:50+00:00,2024-10-16 19:58:49+00:00,https://github.com/tensorflow/tensorflow/pull/78044,[],[],
2592492538,pull_request,closed,,Ensures that Auto Sharding continues even if DCN axis inference fails.,"Ensures that Auto Sharding continues even if DCN axis inference fails.
",copybara-service[bot],2024-10-16 16:55:50+00:00,[],2024-10-16 18:16:33+00:00,2024-10-16 18:16:32+00:00,https://github.com/tensorflow/tensorflow/pull/78043,[],[],
2592491940,pull_request,closed,,Error handling for missing variable nodes,"Error Logging: Added better error logging for missing nodes or variable issues (LOG(ERROR)).
Memory Handling: Removed the need for a static variable (kVariableTypes) and replaced it with a local unordered_set.
API Adaptation: Fixed some outdated TensorFlow API calls and ensured compatibility with modern versions.",SaurabhDesai20,2024-10-16 16:55:36+00:00,['gbaned'],2024-12-10 08:14:34+00:00,2024-12-10 08:14:32+00:00,https://github.com/tensorflow/tensorflow/pull/78042,"[('size:M', 'CL Change Size: Medium')]","[{'comment_id': 2417400328, 'issue_id': 2592491940, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78042/checks?check_run_id=31629708229) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 16, 16, 55, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2418650975, 'issue_id': 2592491940, 'author': 'keerthanakadiri', 'body': 'Hi @SaurabhDesai20 , Can you please sign CLA , thank you !', 'created_at': datetime.datetime(2024, 10, 17, 6, 39, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2419286829, 'issue_id': 2592491940, 'author': 'mihaimaruseac', 'body': 'This should be reviewed by someone from SavedModel team', 'created_at': datetime.datetime(2024, 10, 17, 11, 37, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431050372, 'issue_id': 2592491940, 'author': 'keerthanakadiri', 'body': 'Hi @SaurabhDesai20 , Can you please sign CLA , thank you !', 'created_at': datetime.datetime(2024, 10, 23, 6, 40, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530500304, 'issue_id': 2592491940, 'author': 'keerthanakadiri', 'body': 'Hi @SaurabhDesai20 , Can you kindly sign CLA ? thank you !', 'created_at': datetime.datetime(2024, 12, 10, 5, 53, 46, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-16 16:55:41 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78042/checks?check_run_id=31629708229) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

keerthanakadiri on (2024-10-17 06:39:33 UTC): Hi @SaurabhDesai20 , Can you please sign CLA , thank you !

mihaimaruseac on (2024-10-17 11:37:14 UTC): This should be reviewed by someone from SavedModel team

keerthanakadiri on (2024-10-23 06:40:37 UTC): Hi @SaurabhDesai20 , Can you please sign CLA , thank you !

keerthanakadiri on (2024-12-10 05:53:46 UTC): Hi @SaurabhDesai20 , Can you kindly sign CLA ? thank you !

"
2592491593,pull_request,closed,,Fix BMM per channel reference kernel,"Fix BMM per channel reference kernel
",copybara-service[bot],2024-10-16 16:55:28+00:00,['alankelly'],2024-10-18 08:15:38+00:00,2024-10-18 08:15:36+00:00,https://github.com/tensorflow/tensorflow/pull/78041,[],[],
2592456249,pull_request,closed,,Add default unimplement methods for PJRT so there's less boilerplate,"Add default unimplement methods for PJRT so there's less boilerplate
",copybara-service[bot],2024-10-16 16:42:12+00:00,['changm'],2024-10-16 17:58:12+00:00,2024-10-16 17:58:10+00:00,https://github.com/tensorflow/tensorflow/pull/78040,[],[],
2592410425,pull_request,closed,,[XLA:GPU] Remove unused argument from TranslateLLVMToLLVMIR,"[XLA:GPU] Remove unused argument from TranslateLLVMToLLVMIR
",copybara-service[bot],2024-10-16 16:28:05+00:00,[],2024-10-16 18:39:17+00:00,2024-10-16 18:39:14+00:00,https://github.com/tensorflow/tensorflow/pull/78039,[],[],
2592385667,pull_request,closed,,[XLA:GPU] Fix bug in slice matching logic for dynamic-slice-fusions.,"[XLA:GPU] Fix bug in slice matching logic for dynamic-slice-fusions.

This should resolve the issue at https://github.com/jax-ml/jax/issues/23854.
I took advantage of working on this fix to try to document the expectations and
logic a little more.
",copybara-service[bot],2024-10-16 16:18:13+00:00,[],2024-10-18 12:56:23+00:00,2024-10-18 12:56:22+00:00,https://github.com/tensorflow/tensorflow/pull/78038,[],[],
2592382103,pull_request,closed,,Fix documentation ,"This pull request includes minor updates to the documentation files `CONTRIBUTING.md` and `SECURITY.md`. The changes correct formatting issues and clarify the text.

Documentation updates:

* [`CONTRIBUTING.md`](diffhunk://#diff-eca12c0a30e25b4b46522ebf89465a03ba72a03f540796c979137931d8f92055L236-R237): Fixed a formatting issue in the description of unsupported Docker images for development. (`tensorflow/tensorflow:devel` and `tensorflow/tensorflow:devel-gpu`) are no longer supported for development.
* [`SECURITY.md`](diffhunk://#diff-f6ed156e4bf5c791680662464b94ea5d753f219ee816b385f67870e2c0d7d4c7L169-R169): Corrected a typographical error in the section outlining the recognition of vulnerabilities.",ankur0904,2024-10-16 16:16:29+00:00,['gbaned'],2024-10-23 06:20:23+00:00,2024-10-23 06:20:23+00:00,https://github.com/tensorflow/tensorflow/pull/78037,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]","[{'comment_id': 2417301129, 'issue_id': 2592382103, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78037/checks?check_run_id=31627719927) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 16, 16, 16, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2424739263, 'issue_id': 2592382103, 'author': 'ankur0904', 'body': '@mihaimaruseac \r\nIs this PR ready for merge?', 'created_at': datetime.datetime(2024, 10, 20, 8, 46, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2425041316, 'issue_id': 2592382103, 'author': 'mihaimaruseac', 'body': 'Please see https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#how-to-become-a-contributor-and-submit-your-own-code\r\n\r\nIt is in the pipeline, needs to be reviewed by someone else internally.', 'created_at': datetime.datetime(2024, 10, 20, 15, 19, 52, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-16 16:16:35 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78037/checks?check_run_id=31627719927) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

ankur0904 (Issue Creator) on (2024-10-20 08:46:28 UTC): @mihaimaruseac 
Is this PR ready for merge?

mihaimaruseac on (2024-10-20 15:19:52 UTC): Please see https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md#how-to-become-a-contributor-and-submit-your-own-code

It is in the pipeline, needs to be reviewed by someone else internally.

"
2592286737,pull_request,closed,,Add platform constraint to tflite_gpu_extra_gles_deps config_setting(),"Add platform constraint to tflite_gpu_extra_gles_deps config_setting()
",copybara-service[bot],2024-10-16 15:44:12+00:00,[],2024-10-16 19:27:28+00:00,2024-10-16 19:27:28+00:00,https://github.com/tensorflow/tensorflow/pull/78036,[],[],
2592279705,pull_request,closed,,[XLA:MHLO] Use ConvertHloToStablehlo in HloToStablehloTranslateFunction,"[XLA:MHLO] Use ConvertHloToStablehlo in HloToStablehloTranslateFunction
",copybara-service[bot],2024-10-16 15:41:22+00:00,['GleasonK'],2024-10-17 22:58:57+00:00,2024-10-17 22:58:56+00:00,https://github.com/tensorflow/tensorflow/pull/78035,[],[],
2592171936,pull_request,closed,,Fix typo in batch_matmul op description,"Fix typo in batch_matmul op description
",copybara-service[bot],2024-10-16 15:02:48+00:00,[],2024-10-16 17:05:32+00:00,2024-10-16 17:05:31+00:00,https://github.com/tensorflow/tensorflow/pull/78034,[],[],
2591883549,pull_request,closed,,Make the lowering of no-op ReducePrecision ops actually a no-op.,"Make the lowering of no-op ReducePrecision ops actually a no-op.

Ideally we would just fold no-op ReducePrecision ops, but doing this breaks a
workaround used by JAX. So we just make sure that the lowering becomes a no-op.
",copybara-service[bot],2024-10-16 13:23:02+00:00,['akuegel'],2024-10-16 16:18:53+00:00,2024-10-16 16:18:52+00:00,https://github.com/tensorflow/tensorflow/pull/78033,[],[],
2591813890,pull_request,closed,,Update apply plugin tool to load and select from multiple shared lib files. Move apply plugin tool into tools/ and general cleanup.,"Update apply plugin tool to load and select from multiple shared lib files. Move apply plugin tool into tools/ and general cleanup.
",copybara-service[bot],2024-10-16 12:57:11+00:00,['LukeBoyer'],2024-10-17 02:55:14+00:00,2024-10-17 02:55:13+00:00,https://github.com/tensorflow/tensorflow/pull/78032,[],[],
2591636479,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 11:49:22+00:00,[],2024-10-16 11:49:22+00:00,,https://github.com/tensorflow/tensorflow/pull/78031,[],[],
2591630918,pull_request,closed,,Migrate experimental deps to equivalent non-experimental.,"Migrate experimental deps to equivalent non-experimental.
",copybara-service[bot],2024-10-16 11:47:24+00:00,[],2024-10-16 12:41:43+00:00,2024-10-16 12:41:41+00:00,https://github.com/tensorflow/tensorflow/pull/78030,[],[],
2591578633,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 11:28:25+00:00,[],2024-10-17 09:27:22+00:00,2024-10-17 09:27:16+00:00,https://github.com/tensorflow/tensorflow/pull/78029,[],[],
2591473824,pull_request,closed,,PR #17980: [ROCm] Fix pjrt_c_api_gpu_test for ROCm,"PR #17980: [ROCm] Fix pjrt_c_api_gpu_test for ROCm

Imported from GitHub PR https://github.com/openxla/xla/pull/17980


Copybara import of the project:

--
8054772340b44bb59d0a7c131316ddcc50bed31d by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Fix pjrt_c_api_gpu_test for ROCm

--
2e2f14cd3902fd81e2917601431c4a574f5e6d9e by jcaraban <jcaraban@amd.com>:

[ROCm] replace #if ROCm for AnyOf(cuda,rocm)

--
1b8cffce4b555d133106b86e5da7ae088a6317dc by jcaraban <jcaraban@amd.com>:

[ROCm] unify cuda/rocm testing of id/name to be consistent

Merging this change closes #17980

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17980 from ROCm:ci_fix_pjrt_test_20241007 1b8cffce4b555d133106b86e5da7ae088a6317dc
",copybara-service[bot],2024-10-16 10:49:53+00:00,[],2024-10-17 10:15:23+00:00,2024-10-17 10:15:22+00:00,https://github.com/tensorflow/tensorflow/pull/78028,[],[],
2591366566,pull_request,closed,,PR #18170: Cleanup hlo_extractor and hlo_bisect dependecies,"PR #18170: Cleanup hlo_extractor and hlo_bisect dependecies

Imported from GitHub PR https://github.com/openxla/xla/pull/18170

//xla/tools:hlo_extractor and //xla/tools/hlo_bisect:hlo_bisect_state depend on //xla/tests:test_utils. This dependency should not exist. Moving the relevant functions to //xla:literal_util.
Copybara import of the project:

--
133e566a2b3e82c81d014b289ddc60bea9c629de by Shraiysh Vaishay <svaishay@nvidia.com>:

Cleanup hlo_extractor and hlo_bisect dependecies

//xla/tools:hlo_extractor and //xla/tools/hlo_bisect:hlo_bisect_state
depend on //xla/tests:test_utils. This dependency should not exist.
Moving the relevant functions to //xla:literal_util.

Merging this change closes #18170

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18170 from shraiysh:cleanup_extractor_deps 133e566a2b3e82c81d014b289ddc60bea9c629de
",copybara-service[bot],2024-10-16 10:10:48+00:00,[],2024-10-16 10:42:20+00:00,2024-10-16 10:42:19+00:00,https://github.com/tensorflow/tensorflow/pull/78027,[],[],
2591363339,pull_request,closed,,[XLA:GPU] Do not count copies as missing instruction in PGLE checker.,"[XLA:GPU] Do not count copies as missing instruction in PGLE checker.
",copybara-service[bot],2024-10-16 10:09:22+00:00,[],2024-10-17 12:35:06+00:00,2024-10-17 12:35:05+00:00,https://github.com/tensorflow/tensorflow/pull/78026,[],[],
2591296722,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 09:45:37+00:00,[],2024-10-16 12:45:44+00:00,,https://github.com/tensorflow/tensorflow/pull/78025,[],[],
2591292888,pull_request,closed,,[xla:cpu] Fix tsan error in ThunkExecutorTest,"[xla:cpu] Fix tsan error in ThunkExecutorTest
",copybara-service[bot],2024-10-16 09:44:32+00:00,['ezhulenev'],2024-10-16 10:29:31+00:00,2024-10-16 10:29:30+00:00,https://github.com/tensorflow/tensorflow/pull/78024,[],[],
2591192292,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 09:09:18+00:00,[],2024-10-16 09:09:18+00:00,,https://github.com/tensorflow/tensorflow/pull/78023,[],[],
2591183294,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 09:06:33+00:00,[],2024-10-17 05:53:51+00:00,,https://github.com/tensorflow/tensorflow/pull/78022,[],[],
2591152261,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 08:56:03+00:00,[],2024-10-19 06:32:30+00:00,2024-10-19 06:32:29+00:00,https://github.com/tensorflow/tensorflow/pull/78021,[],[],
2591124729,pull_request,open,,Update GraphDef version to 2017.,"Update GraphDef version to 2017.
",copybara-service[bot],2024-10-16 08:46:32+00:00,[],2024-10-16 09:23:51+00:00,,https://github.com/tensorflow/tensorflow/pull/78020,[],[],
2590960941,pull_request,open,,PR #18170: Cleanup hlo_extractor and hlo_bisect dependecies,"PR #18170: Cleanup hlo_extractor and hlo_bisect dependecies

Imported from GitHub PR https://github.com/openxla/xla/pull/18170

//xla/tools:hlo_extractor and //xla/tools/hlo_bisect:hlo_bisect_state depend on //xla/tests:test_utils. This dependency should not exist. Moving the relevant functions to //xla:literal_util.
Copybara import of the project:

--
133e566a2b3e82c81d014b289ddc60bea9c629de by Shraiysh Vaishay <svaishay@nvidia.com>:

Cleanup hlo_extractor and hlo_bisect dependecies

//xla/tools:hlo_extractor and //xla/tools/hlo_bisect:hlo_bisect_state
depend on //xla/tests:test_utils. This dependency should not exist.
Moving the relevant functions to //xla:literal_util.

Merging this change closes #18170

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18170 from shraiysh:cleanup_extractor_deps 133e566a2b3e82c81d014b289ddc60bea9c629de
",copybara-service[bot],2024-10-16 07:43:22+00:00,[],2024-10-16 09:14:48+00:00,,https://github.com/tensorflow/tensorflow/pull/78019,[],[],
2590866722,pull_request,closed,,[XLA:GPU] Strip newline when dumping the ptxas warning.,"[XLA:GPU] Strip newline when dumping the ptxas warning.

The ptxas output contains trailing newline. Logger adds its own newline, which currently results in ugly empty lines in logs.
",copybara-service[bot],2024-10-16 07:05:22+00:00,[],2024-10-16 08:13:40+00:00,2024-10-16 08:13:39+00:00,https://github.com/tensorflow/tensorflow/pull/78018,[],[],
2590755780,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 06:12:39+00:00,[],2024-10-16 06:12:39+00:00,,https://github.com/tensorflow/tensorflow/pull/78017,[],[],
2590746551,pull_request,closed,,avoid optimization for different tiling case.,"avoid optimization for different tiling case.
",copybara-service[bot],2024-10-16 06:06:59+00:00,[],2024-10-16 21:58:39+00:00,2024-10-16 21:58:38+00:00,https://github.com/tensorflow/tensorflow/pull/78016,[],[],
2590645306,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 05:10:54+00:00,[],2024-10-16 10:05:16+00:00,2024-10-16 10:05:15+00:00,https://github.com/tensorflow/tensorflow/pull/78015,[],[],
2590632350,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 05:01:49+00:00,[],2024-10-16 05:01:49+00:00,,https://github.com/tensorflow/tensorflow/pull/78014,[],[],
2590544775,pull_request,closed,,rsqrt should report error when the input contains negative values,"rsqrt should report error when the input contains negative values

Due to the change of the behaviour, RsqrtNanInt{8,16} is now renamed to RsqrtNegativeInt{8,16}
",copybara-service[bot],2024-10-16 04:05:06+00:00,[],2024-10-17 05:52:15+00:00,2024-10-17 05:52:15+00:00,https://github.com/tensorflow/tensorflow/pull/78013,[],[],
2590490021,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:27:55+00:00,[],2024-10-18 08:59:42+00:00,2024-10-18 08:59:41+00:00,https://github.com/tensorflow/tensorflow/pull/78012,[],[],
2590487917,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:26:26+00:00,[],2024-10-16 03:26:26+00:00,,https://github.com/tensorflow/tensorflow/pull/78011,[],[],
2590487240,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:25:49+00:00,[],2024-10-17 03:58:32+00:00,2024-10-17 03:58:32+00:00,https://github.com/tensorflow/tensorflow/pull/78010,[],[],
2590487116,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:25:42+00:00,[],2024-10-16 03:25:42+00:00,,https://github.com/tensorflow/tensorflow/pull/78009,[],[],
2590486029,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:24:43+00:00,[],2024-10-16 03:24:43+00:00,,https://github.com/tensorflow/tensorflow/pull/78008,[],[],
2590484793,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:23:38+00:00,[],2024-10-18 07:07:04+00:00,2024-10-18 07:07:04+00:00,https://github.com/tensorflow/tensorflow/pull/78007,[],[],
2590483979,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:22:57+00:00,[],2024-10-16 03:22:57+00:00,,https://github.com/tensorflow/tensorflow/pull/78006,[],[],
2590483872,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:22:53+00:00,[],2024-10-16 03:22:53+00:00,,https://github.com/tensorflow/tensorflow/pull/78005,[],[],
2590482090,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:21:43+00:00,[],2024-10-22 09:43:37+00:00,2024-10-22 09:43:36+00:00,https://github.com/tensorflow/tensorflow/pull/78004,[],[],
2590476145,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-16 03:16:57+00:00,[],2024-10-18 04:30:09+00:00,2024-10-18 04:30:08+00:00,https://github.com/tensorflow/tensorflow/pull/78003,[],[],
2590461607,pull_request,closed,,Add a TFL Delegate based on the Dispatch API,"Add a TFL Delegate based on the Dispatch API

This delegate can be used to run models that have been precompiled, ahead of
time, for NPU acceleration.

For now the delegate assumes that an NPU binary is specified with a map between a tag and a (bytecode_addr, bytecode_size, function_name) tuple, where the tag is a string stored in the custom_option of a TFL custom op representing an NPU subgraph. This scheme will change in the future.
",copybara-service[bot],2024-10-16 03:07:14+00:00,[],2024-10-16 21:45:50+00:00,2024-10-16 21:45:50+00:00,https://github.com/tensorflow/tensorflow/pull/78002,[],[],
2590461096,pull_request,open,,Remove unneeded dependency on :gpu_types from :rocblas_plugin,"Remove unneeded dependency on :gpu_types from :rocblas_plugin
",copybara-service[bot],2024-10-16 03:06:45+00:00,[],2024-10-28 13:25:11+00:00,,https://github.com/tensorflow/tensorflow/pull/78001,[],[],
2590397666,pull_request,closed,,Update the apply plugin tool. Pull core logic into tools/ and add run cofig struct. Implement validation and stub out the functions.,"Update the apply plugin tool. Pull core logic into tools/ and add run cofig struct. Implement validation and stub out the functions.
",copybara-service[bot],2024-10-16 02:17:40+00:00,['LukeBoyer'],2024-10-16 19:41:15+00:00,2024-10-16 19:41:13+00:00,https://github.com/tensorflow/tensorflow/pull/78000,[],[],
2590370384,pull_request,closed,,Fix incorrect im2col size allocation with INT4 filter,"Fix incorrect im2col size allocation with INT4 filter
",copybara-service[bot],2024-10-16 01:56:07+00:00,['paulinesho'],2024-10-17 00:30:28+00:00,2024-10-17 00:30:25+00:00,https://github.com/tensorflow/tensorflow/pull/77999,[],[],
2590248035,pull_request,closed,,Refactor `CanPropagateThroughAtAggressiveLevel` in xla::ShardingPropagation.,"Refactor `CanPropagateThroughAtAggressiveLevel` in xla::ShardingPropagation.

Remove unused argument in `InferConvolutionShardingFromOperands`.
",copybara-service[bot],2024-10-16 00:32:12+00:00,[],2024-10-17 19:00:53+00:00,2024-10-17 19:00:52+00:00,https://github.com/tensorflow/tensorflow/pull/77998,[],[],
2590223632,pull_request,closed,,Fix tsan bug by avoiding string references after done callbacks have been invoked.,"Fix tsan bug by avoiding string references after done callbacks have been invoked.
Tsan bug: Done callback completes the RPC and destroys the request, releasing the underlying string (barrier_id). 

Fun fact: We already had a comment in coordination_service.cc that explicitly say to not reference `barrier_id`, but I did it anyway.

Reverts 7a976f8c802ede5aaaeba6db33a99c1ef352d30f
",copybara-service[bot],2024-10-16 00:10:44+00:00,[],2024-10-16 20:30:30+00:00,2024-10-16 20:30:29+00:00,https://github.com/tensorflow/tensorflow/pull/77997,[],[],
2590218644,pull_request,closed,,[XLA:GPU] allow multi-op async computations in HLO verifier if they only contain send/recv/parameter type of instructions,"[XLA:GPU] allow multi-op async computations in HLO verifier if they only contain send/recv/parameter type of instructions
",copybara-service[bot],2024-10-16 00:07:32+00:00,[],2024-10-17 17:03:05+00:00,2024-10-17 17:03:04+00:00,https://github.com/tensorflow/tensorflow/pull/77996,[],[],
2590199098,pull_request,closed,,Reduce the use of gpu_executor.h in CUDA & ROCm code to just the specific Executor classes.,"Reduce the use of gpu_executor.h in CUDA & ROCm code to just the specific Executor classes.
",copybara-service[bot],2024-10-15 23:54:56+00:00,[],2024-10-16 19:12:01+00:00,2024-10-16 19:12:00+00:00,https://github.com/tensorflow/tensorflow/pull/77995,[],[],
2590166681,pull_request,closed,,Use the plugin's preferred StableHLO version.,"Use the plugin's preferred StableHLO version.
",copybara-service[bot],2024-10-15 23:35:21+00:00,[],2024-10-21 15:06:54+00:00,2024-10-21 15:06:53+00:00,https://github.com/tensorflow/tensorflow/pull/77994,[],[],
2590151368,pull_request,closed,,Add helpful MSA debugging:,"Add helpful MSA debugging:

1)  MSA's runtime simulator now logs the following per-instruction data (with VLOG(1)): instruction schedule time (after MSA modifies the graph), instruction name, estimated instruction elapsed time, the cumulative number of bytes worth of unused default mem bandwidth up to that instruction, the instruction trip count, and how much alt mem is occupied during the instruction.

2)  Added AllocationSequenceDebugging::LogAltMemAllocationsAt() that logs all the current alt mem allocations at a given point in instruction time.

3)  Added MsaAlgorithm::MatchesPrefetchContext() which can be used to filter logging based on the prefetch context.

Example: 2+3 could be used to log what is allocated in alt mem when we failed to allocate a prefetch request, by calling something like:

```
if (MatchesPrefetchContext(
        context, ""producer_inst"", producer_shape_index,
        ""consumer_inst"")) {
    AllocationSequenceDebugging::LogAltMemAllocationsAt(
        *allocations_, producer_schedule_time);
}
```
",copybara-service[bot],2024-10-15 23:26:24+00:00,['sparc1998'],2024-10-21 23:38:17+00:00,2024-10-21 23:38:16+00:00,https://github.com/tensorflow/tensorflow/pull/77993,[],[],
2590128251,pull_request,closed,,Remove dependency on scoped_activate_context.h.  All uses in tensorflow/core have been replaced with StreamExecutor::Activate instead.,"Remove dependency on scoped_activate_context.h.  All uses in tensorflow/core have been replaced with StreamExecutor::Activate instead.
",copybara-service[bot],2024-10-15 23:06:18+00:00,[],2024-10-16 17:28:16+00:00,2024-10-16 17:28:14+00:00,https://github.com/tensorflow/tensorflow/pull/77992,[],[],
2590114824,pull_request,closed,,Fix device trace test crash triggered by cuda 12.6,"Fix device trace test crash triggered by cuda 12.6
",copybara-service[bot],2024-10-15 22:55:59+00:00,[],2024-10-16 17:43:14+00:00,2024-10-16 17:43:13+00:00,https://github.com/tensorflow/tensorflow/pull/77991,[],[],
2590088058,pull_request,closed,,"Move GpuDriver::GetMaxOccupiedBlocksPerCore into the appropriate Kernel class, and replace the use of GpuExecutor in Kernel classes with StreamExecutor.","Move GpuDriver::GetMaxOccupiedBlocksPerCore into the appropriate Kernel class, and replace the use of GpuExecutor in Kernel classes with StreamExecutor.
",copybara-service[bot],2024-10-15 22:38:52+00:00,[],2024-10-16 17:19:41+00:00,2024-10-16 17:19:40+00:00,https://github.com/tensorflow/tensorflow/pull/77990,[],[],
2590087783,pull_request,closed,,Add multi-recv attributes and add a new test case for CollectivePipeliner,"Add multi-recv attributes and add a new test case for CollectivePipeliner
",copybara-service[bot],2024-10-15 22:38:39+00:00,['seherellis'],2024-10-22 20:25:34+00:00,2024-10-22 20:25:33+00:00,https://github.com/tensorflow/tensorflow/pull/77989,[],[],
2590086609,pull_request,closed,,Lower verbosity of QNN logs,"Lower verbosity of QNN logs
",copybara-service[bot],2024-10-15 22:37:36+00:00,[],2024-10-16 00:37:48+00:00,2024-10-16 00:37:47+00:00,https://github.com/tensorflow/tensorflow/pull/77988,[],[],
2590076083,pull_request,closed,,Don't automatically make tests dependent on all .tflite files in test/testdata,"Don't automatically make tests dependent on all .tflite files in test/testdata

That way we won't need to copy all of those files when running tests on mobile
devices.
",copybara-service[bot],2024-10-15 22:32:32+00:00,[],2024-10-16 01:15:21+00:00,2024-10-16 01:15:19+00:00,https://github.com/tensorflow/tensorflow/pull/77987,[],[],
2590018274,pull_request,closed,,Internal testing framework change.,"Internal testing framework change.
",copybara-service[bot],2024-10-15 21:56:19+00:00,[],2024-10-15 22:23:13+00:00,2024-10-15 22:23:12+00:00,https://github.com/tensorflow/tensorflow/pull/77986,[],[],
2590009788,pull_request,closed,,Make cuda_dnn.cc/.h use StreamExecutor pointers rather than GpuExecutor pointers.,"Make cuda_dnn.cc/.h use StreamExecutor pointers rather than GpuExecutor pointers.
",copybara-service[bot],2024-10-15 21:51:11+00:00,[],2024-10-15 23:10:04+00:00,2024-10-15 23:10:03+00:00,https://github.com/tensorflow/tensorflow/pull/77985,[],[],
2589996413,pull_request,closed,,Change to new ML container for presubmit build. There was a merge conflict that didn't change the container build in the previous CL.,"Change to new ML container for presubmit build. There was a merge conflict that didn't change the container build in the previous CL.
",copybara-service[bot],2024-10-15 21:43:08+00:00,['quoctruong'],2024-10-28 17:57:50+00:00,2024-10-28 17:57:49+00:00,https://github.com/tensorflow/tensorflow/pull/77984,[],[],
2589993756,pull_request,closed,,Add collective matmul annotations.,"Add collective matmul annotations.
",copybara-service[bot],2024-10-15 21:41:41+00:00,['seherellis'],2024-10-16 19:19:40+00:00,2024-10-16 19:19:39+00:00,https://github.com/tensorflow/tensorflow/pull/77983,[],[],
2589932123,pull_request,closed,,[HLO Componentization] Create hlo/transforms sub-component (Phase I).,"[HLO Componentization] Create hlo/transforms sub-component (Phase I).
This CL takes care of
1. Migrating passes from xla/service/* --> xla/hlo/transforms/*
2. Setting up build aliases in xla/hlo/transforms/ ensuring external
dependencies are still satisfied.

Phase II will take care of migration of external projects dependencies from
xla/service --> xla/hlo/transforms
",copybara-service[bot],2024-10-15 21:06:11+00:00,['sdasgup3'],2024-10-17 22:22:36+00:00,2024-10-17 22:22:35+00:00,https://github.com/tensorflow/tensorflow/pull/77982,[],[],
2589929654,pull_request,closed,,Add python3.13 to new ML Build Container Dockerfile. Modify the installation order so python3.12 will be the default.,"Add python3.13 to new ML Build Container Dockerfile. Modify the installation order so python3.12 will be the default.
",copybara-service[bot],2024-10-15 21:05:15+00:00,['quoctruong'],2024-10-16 23:34:43+00:00,2024-10-16 23:34:42+00:00,https://github.com/tensorflow/tensorflow/pull/77981,[],[],
2589770102,pull_request,closed,,Adds a solver request callback.,"Adds a solver request callback.
",copybara-service[bot],2024-10-15 20:09:20+00:00,[],2024-10-16 03:20:08+00:00,2024-10-16 03:20:07+00:00,https://github.com/tensorflow/tensorflow/pull/77980,[],[],
2589711085,pull_request,closed,,[xla:gpu] Add a test for FFI handler + command buffer,"[xla:gpu] Add a test for FFI handler + command buffer

Correctly plumb FFI handler + traced stream to a custom call commad.
",copybara-service[bot],2024-10-15 19:40:14+00:00,['ezhulenev'],2024-10-15 21:50:37+00:00,2024-10-15 21:50:37+00:00,https://github.com/tensorflow/tensorflow/pull/77979,[],[],
2589706145,pull_request,open,,Rollback of the following changes:,"Rollback of the following changes:

Integrate LLVM at llvm/llvm-project@48bda00b281a
Updates LLVM usage to match
48bda00b281a

Reverts 9ce333a974fcc010765af713838d790ee04c5e77
",copybara-service[bot],2024-10-15 19:38:19+00:00,[],2024-10-15 19:38:19+00:00,,https://github.com/tensorflow/tensorflow/pull/77978,[],[],
2589690028,pull_request,closed,,Update fp8 cudnn fused attention tests to skip if not at least hopper,"Update fp8 cudnn fused attention tests to skip if not at least hopper
",copybara-service[bot],2024-10-15 19:31:20+00:00,[],2024-10-15 22:44:23+00:00,2024-10-15 22:44:23+00:00,https://github.com/tensorflow/tensorflow/pull/77977,[],[],
2589649781,pull_request,closed,,Introduce host_offload_utils::ComputeTypeIsHost to OSS.,"Introduce host_offload_utils::ComputeTypeIsHost to OSS.
",copybara-service[bot],2024-10-15 19:14:15+00:00,['SandSnip3r'],2024-10-16 20:51:49+00:00,2024-10-16 20:51:48+00:00,https://github.com/tensorflow/tensorflow/pull/77976,[],[],
2589629525,pull_request,closed,,An internal change.,"An internal change.
",copybara-service[bot],2024-10-15 19:03:13+00:00,[],2024-10-16 02:52:26+00:00,2024-10-16 02:52:25+00:00,https://github.com/tensorflow/tensorflow/pull/77975,[],[],
2589456823,pull_request,closed,,Add integration test folder,"Add integration test folder
",copybara-service[bot],2024-10-15 17:43:32+00:00,['LukeBoyer'],2024-10-15 18:28:10+00:00,2024-10-15 18:28:09+00:00,https://github.com/tensorflow/tensorflow/pull/77974,[],[],
2589422351,pull_request,closed,,Remove unused code from dnn.cc/.h,"Remove unused code from dnn.cc/.h
",copybara-service[bot],2024-10-15 17:28:26+00:00,[],2024-10-15 18:16:07+00:00,2024-10-15 18:16:06+00:00,https://github.com/tensorflow/tensorflow/pull/77973,[],[],
2589418372,pull_request,closed,,Remove the last few uses of RETURN_IF_ROCM_ERROR in favor of rocm::ToStatus and TF_RETURN_IF_ERROR.,"Remove the last few uses of RETURN_IF_ROCM_ERROR in favor of rocm::ToStatus and TF_RETURN_IF_ERROR.
",copybara-service[bot],2024-10-15 17:26:05+00:00,[],2024-10-15 20:27:13+00:00,2024-10-15 20:27:12+00:00,https://github.com/tensorflow/tensorflow/pull/77972,[],[],
2589387675,pull_request,closed,,[XLA:GPU] Add a check to horizontal loop fusion to no exceed unroll cost.,"[XLA:GPU] Add a check to horizontal loop fusion to no exceed unroll cost.

HorizontalLoopFusion doesn't have any limits on the number of instruction in the resulting fusion. This can cause performance cliffs when we can't unroll or start spilling registers. This change should prevent that.
",copybara-service[bot],2024-10-15 17:12:53+00:00,[],2024-10-16 12:53:18+00:00,2024-10-16 12:53:18+00:00,https://github.com/tensorflow/tensorflow/pull/77971,[],[],
2589183679,pull_request,closed,,Add os platform constraints to Linux config_setting() variants,"Add os platform constraints to Linux config_setting() variants
",copybara-service[bot],2024-10-15 15:41:57+00:00,[],2024-10-16 05:28:45+00:00,2024-10-16 05:28:43+00:00,https://github.com/tensorflow/tensorflow/pull/77970,[],[],
2589024490,pull_request,closed,,[XLA:GPU] move dot algorithms tests to a separate file,"[XLA:GPU] move dot algorithms tests to a separate file

The cl has no business logic changes
",copybara-service[bot],2024-10-15 14:50:03+00:00,[],2024-10-16 08:42:51+00:00,2024-10-16 08:42:50+00:00,https://github.com/tensorflow/tensorflow/pull/77969,[],[],
2588991271,pull_request,closed,,Fix typo in code logic of Conv3DTranspose(),"Hi, Team

It seems like there is typo error in the code logic of **Conv3DTranspose()** in the below line which is trying to combine padding values for **height** and **depth** dimensions so as far I know padding values should correspond to their respective dimensions in this case **depth** dimension not **height** so the padding calculation should only use the padding value relevant to the depth related padding values

I think it should be like below :
```
const int spatial_dim_1_padding_after =
      params.padding_values.depth + params.padding_values.depth_offset;
```

https://github.com/tensorflow/tensorflow/blob/d540fd62d027dbb86e9434f8c43802997c8ab29c/tensorflow/lite/kernels/internal/optimized/optimized_ops.h#L8220

If you've any suggestion or feedback or Am I missing something here please let me know ? Thank you
",gaikwadrahul8,2024-10-15 14:38:50+00:00,['gbaned'],2025-01-31 02:00:13+00:00,2025-01-31 02:00:07+00:00,https://github.com/tensorflow/tensorflow/pull/77968,"[('stale', 'This label marks the issue/pr stale - to be closed automatically if no activity'), ('comp:lite', 'TF Lite related issues'), ('size:XS', 'CL Change Size: Extra Small')]","[{'comment_id': 2431054300, 'issue_id': 2588991271, 'author': 'keerthanakadiri', 'body': 'Hi @Ferev, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 23, 6, 42, 50, tzinfo=datetime.timezone.utc)}, {'comment_id': 2432478863, 'issue_id': 2588991271, 'author': 'fergushenderson', 'body': 'Can you please also add a regression test that will exercise this case?', 'created_at': datetime.datetime(2024, 10, 23, 14, 47, 55, tzinfo=datetime.timezone.utc)}, {'comment_id': 2466273795, 'issue_id': 2588991271, 'author': 'gaikwadrahul8', 'body': ""Hi, @fergushenderson \r\n\r\nI apologize for the delayed response and thank you for your feedback, now I've added test cases If you've any suggestion or feedback or Am I missing something here please let me know ? Thank you"", 'created_at': datetime.datetime(2024, 11, 9, 16, 20, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2467697357, 'issue_id': 2588991271, 'author': 'fergushenderson', 'body': 'It looks like with your second commit, the following code snippet from the test is now duplicated. I think that would mean that those tests would unnecessarily get run twice?\r\n\r\n```\r\nINSTANTIATE_TEST_SUITE_P(Conv3dTransposeOpTest, Conv3dTransposeOpTest,\r\n                         ::testing::Values(TestType::kConst,\r\n                                           TestType::kDynamic));\r\n```', 'created_at': datetime.datetime(2024, 11, 11, 9, 51, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2493372079, 'issue_id': 2588991271, 'author': 'gaikwadrahul8', 'body': 'Hi, @fergushenderson \r\nThank you for bringing my oversight to my attention. I inadvertently placed the new test cases within an existing test case. I have now made the necessary modifications as per your suggestion. I appreciate your understanding and support.\r\n\r\nThank you for your cooperation.', 'created_at': datetime.datetime(2024, 11, 22, 9, 59, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566006713, 'issue_id': 2588991271, 'author': 'fergushenderson', 'body': 'It looks like some of the newly added tests are failing, e.g. `tensorflow/lite/kernels:conv3d_transpose_test`:\r\n\r\n```\r\n[ RUN      ] Conv3dTransposeOpTest/Conv3dTransposeOpTest.PaddingDepthDimensionTest/0\r\nERROR: third_party/tensorflow/lite/kernels/conv3d_transpose.cc:110 unused_out_height != SizeOfDimension(input, 2) (3 != 2)\r\nERROR: Node number 0 (CONV_3D_TRANSPOSE) failed to prepare.\r\nF1226 11:09:45.164343    6176 test_util.cc:291] Check failed: interpreter_->AllocateTensors() == kTfLiteOk Cannot allocate tensors\r\n*** Check failure stack trace: ***\r\n    @     0x7fb30154af1a  third_party/absl/log/internal/log_message.cc:555 absl::log_internal::LogMessage::PrepareToDie()\r\n    @     0x7fb30154a810  third_party/absl/log/internal/log_message.cc:573 absl::log_internal::LogMessage::SendToLog()\r\n    @     0x7fb30154969f  third_party/absl/log/internal/log_message.cc:489 absl::log_internal::LogMessage::Flush()\r\n    @     0x7fb30154c069  third_party/absl/log/internal/log_message.cc:671 absl::log_internal::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fb4004b1411  third_party/tensorflow/lite/kernels/test_util.cc:291 tflite::SingleOpModel::AllocateAndDelegate()\r\n    @     0x7fb4004b28dc  third_party/tensorflow/lite/kernels/test_util.cc:382 tflite::SingleOpModel::BuildInterpreter()\r\n    @     0x7fb4004b3c46  third_party/tensorflow/lite/kernels/test_util.cc:421 tflite::SingleOpModel::BuildInterpreter()\r\n    @     0x7fb406fabc4b  third_party/tensorflow/lite/kernels/conv3d_transpose_test.cc:91 tflite::(anonymous namespace)::Conv3dTransposeOpModel::Conv3dTransposeOpModel()\r\n    @     0x7fb406fbc9d9  third_party/tensorflow/lite/kernels/conv3d_transpose_test.cc:161 tflite::(anonymous namespace)::Conv3dTransposeOpTest_PaddingDepthDimensionTest_Test::TestBody()\r\n    @     0x7fb369d8e5b0  third_party/googletest/googletest/src/gtest.cc:0 testing::Test::Run()\r\n    @     0x7fb369d8fd93  third_party/googletest/googletest/src/gtest.cc:2883 testing::TestInfo::Run()\r\n    @     0x7fb369d91db1  third_party/googletest/googletest/src/gtest.cc:3061 testing::TestSuite::Run()\r\n    @     0x7fb369dab98c  third_party/googletest/googletest/src/gtest.cc:5994 testing::internal::UnitTestImpl::RunAllTests()\r\n    @     0x7fb369daaf58  third_party/googletest/googletest/src/gtest.cc:0 testing::UnitTest::Run()\r\n    @     0x7fb4069825dd  third_party/googletest/googletest/include/gtest/gtest.h:2349 main\r\n    @     0x7fb2e52d63d4  __libc_start_main\r\n    @     0x563694b637aa  ../sysdeps/x86_64/start.S:120 _start\r\n*** SIGABRT received by PID 6176 (TID 6176) on cpu 114 from PID 6176; ***\r\n```\r\n\r\nand\r\n\r\n`tensorflow/lite/delegates/utils/experimental/sample_stable_delegate:sample_stable_delegate_kernel_tests`:\r\n\r\n```\r\nF1226 11:13:01.677559    2677 test_util.h:989] Check failed: t No tensor with index 31751.\r\n*** Check failure stack trace: ***\r\n    @     0x7fe783245b8a  third_party/absl/log/internal/log_message.cc:555 absl::log_internal::LogMessage::PrepareToDie()\r\n    @     0x7fe783245330  third_party/absl/log/internal/log_message.cc:573 absl::log_internal::LogMessage::SendToLog()\r\n    @     0x7fe78324417f  third_party/absl/log/internal/log_message.cc:489 absl::log_internal::LogMessage::Flush()\r\n    @     0x7fe783246e89  third_party/absl/log/internal/log_message.cc:671 absl::log_internal::LogMessageFatal::~LogMessageFatal()\r\n    @     0x7fe888b1ec1f  ./third_party/tensorflow/lite/kernels/test_util.h:989 tflite::SingleOpModel::PopulateTensorImpl<>()\r\n    @     0x7fe889ef278f  ./third_party/tensorflow/lite/kernels/test_util.h:703 tflite::(anonymous namespace)::Conv3dTransposeOpTest_PaddingValueDepthTestWithBias_Test::TestBody()\r\n    @     0x7fe814988630  third_party/googletest/googletest/src/gtest.cc:0 testing::Test::Run()\r\n    @     0x7fe814989e13  third_party/googletest/googletest/src/gtest.cc:2883 testing::TestInfo::Run()\r\n    @     0x7fe81498be31  third_party/googletest/googletest/src/gtest.cc:3061 testing::TestSuite::Run()\r\n    @     0x7fe8149a5cac  third_party/googletest/googletest/src/gtest.cc:5994 testing::internal::UnitTestImpl::RunAllTests()\r\n    @     0x7fe8149a521d  third_party/googletest/googletest/src/gtest.cc:0 testing::UnitTest::Run()\r\n    @     0x7fe890b5af67  third_party/googletest/googletest/include/gtest/gtest.h:2349 main\r\n    @     0x7fe766a493d4  __libc_start_main\r\n    @     0x5640d11edc2a  ../sysdeps/x86_64/start.S:120 _start\r\n*** SIGABRT received by PID 2677 (TID 2677) on cpu 18 from PID 2677; ***\r\n```', 'created_at': datetime.datetime(2024, 12, 30, 23, 31, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2597275037, 'issue_id': 2588991271, 'author': 'github-actions[bot]', 'body': 'This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.', 'created_at': datetime.datetime(2025, 1, 17, 1, 58, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2626128499, 'issue_id': 2588991271, 'author': 'github-actions[bot]', 'body': ""This PR was closed because it has been inactive for 14 days since being marked as stale. Please reopen if you'd like to work on this further."", 'created_at': datetime.datetime(2025, 1, 31, 2, 0, 6, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-10-23 06:42:50 UTC): Hi @Ferev, Can you please review this PR? Thank you !

fergushenderson on (2024-10-23 14:47:55 UTC): Can you please also add a regression test that will exercise this case?

gaikwadrahul8 (Issue Creator) on (2024-11-09 16:20:38 UTC): Hi, @fergushenderson 

I apologize for the delayed response and thank you for your feedback, now I've added test cases If you've any suggestion or feedback or Am I missing something here please let me know ? Thank you

fergushenderson on (2024-11-11 09:51:57 UTC): It looks like with your second commit, the following code snippet from the test is now duplicated. I think that would mean that those tests would unnecessarily get run twice?

```
INSTANTIATE_TEST_SUITE_P(Conv3dTransposeOpTest, Conv3dTransposeOpTest,
                         ::testing::Values(TestType::kConst,
                                           TestType::kDynamic));
```

gaikwadrahul8 (Issue Creator) on (2024-11-22 09:59:02 UTC): Hi, @fergushenderson 
Thank you for bringing my oversight to my attention. I inadvertently placed the new test cases within an existing test case. I have now made the necessary modifications as per your suggestion. I appreciate your understanding and support.

Thank you for your cooperation.

fergushenderson on (2024-12-30 23:31:43 UTC): It looks like some of the newly added tests are failing, e.g. `tensorflow/lite/kernels:conv3d_transpose_test`:

```
[ RUN      ] Conv3dTransposeOpTest/Conv3dTransposeOpTest.PaddingDepthDimensionTest/0
ERROR: third_party/tensorflow/lite/kernels/conv3d_transpose.cc:110 unused_out_height != SizeOfDimension(input, 2) (3 != 2)
ERROR: Node number 0 (CONV_3D_TRANSPOSE) failed to prepare.
F1226 11:09:45.164343    6176 test_util.cc:291] Check failed: interpreter_->AllocateTensors() == kTfLiteOk Cannot allocate tensors
*** Check failure stack trace: ***
    @     0x7fb30154af1a  third_party/absl/log/internal/log_message.cc:555 absl::log_internal::LogMessage::PrepareToDie()
    @     0x7fb30154a810  third_party/absl/log/internal/log_message.cc:573 absl::log_internal::LogMessage::SendToLog()
    @     0x7fb30154969f  third_party/absl/log/internal/log_message.cc:489 absl::log_internal::LogMessage::Flush()
    @     0x7fb30154c069  third_party/absl/log/internal/log_message.cc:671 absl::log_internal::LogMessageFatal::~LogMessageFatal()
    @     0x7fb4004b1411  third_party/tensorflow/lite/kernels/test_util.cc:291 tflite::SingleOpModel::AllocateAndDelegate()
    @     0x7fb4004b28dc  third_party/tensorflow/lite/kernels/test_util.cc:382 tflite::SingleOpModel::BuildInterpreter()
    @     0x7fb4004b3c46  third_party/tensorflow/lite/kernels/test_util.cc:421 tflite::SingleOpModel::BuildInterpreter()
    @     0x7fb406fabc4b  third_party/tensorflow/lite/kernels/conv3d_transpose_test.cc:91 tflite::(anonymous namespace)::Conv3dTransposeOpModel::Conv3dTransposeOpModel()
    @     0x7fb406fbc9d9  third_party/tensorflow/lite/kernels/conv3d_transpose_test.cc:161 tflite::(anonymous namespace)::Conv3dTransposeOpTest_PaddingDepthDimensionTest_Test::TestBody()
    @     0x7fb369d8e5b0  third_party/googletest/googletest/src/gtest.cc:0 testing::Test::Run()
    @     0x7fb369d8fd93  third_party/googletest/googletest/src/gtest.cc:2883 testing::TestInfo::Run()
    @     0x7fb369d91db1  third_party/googletest/googletest/src/gtest.cc:3061 testing::TestSuite::Run()
    @     0x7fb369dab98c  third_party/googletest/googletest/src/gtest.cc:5994 testing::internal::UnitTestImpl::RunAllTests()
    @     0x7fb369daaf58  third_party/googletest/googletest/src/gtest.cc:0 testing::UnitTest::Run()
    @     0x7fb4069825dd  third_party/googletest/googletest/include/gtest/gtest.h:2349 main
    @     0x7fb2e52d63d4  __libc_start_main
    @     0x563694b637aa  ../sysdeps/x86_64/start.S:120 _start
*** SIGABRT received by PID 6176 (TID 6176) on cpu 114 from PID 6176; ***
```

and

`tensorflow/lite/delegates/utils/experimental/sample_stable_delegate:sample_stable_delegate_kernel_tests`:

```
F1226 11:13:01.677559    2677 test_util.h:989] Check failed: t No tensor with index 31751.
*** Check failure stack trace: ***
    @     0x7fe783245b8a  third_party/absl/log/internal/log_message.cc:555 absl::log_internal::LogMessage::PrepareToDie()
    @     0x7fe783245330  third_party/absl/log/internal/log_message.cc:573 absl::log_internal::LogMessage::SendToLog()
    @     0x7fe78324417f  third_party/absl/log/internal/log_message.cc:489 absl::log_internal::LogMessage::Flush()
    @     0x7fe783246e89  third_party/absl/log/internal/log_message.cc:671 absl::log_internal::LogMessageFatal::~LogMessageFatal()
    @     0x7fe888b1ec1f  ./third_party/tensorflow/lite/kernels/test_util.h:989 tflite::SingleOpModel::PopulateTensorImpl<>()
    @     0x7fe889ef278f  ./third_party/tensorflow/lite/kernels/test_util.h:703 tflite::(anonymous namespace)::Conv3dTransposeOpTest_PaddingValueDepthTestWithBias_Test::TestBody()
    @     0x7fe814988630  third_party/googletest/googletest/src/gtest.cc:0 testing::Test::Run()
    @     0x7fe814989e13  third_party/googletest/googletest/src/gtest.cc:2883 testing::TestInfo::Run()
    @     0x7fe81498be31  third_party/googletest/googletest/src/gtest.cc:3061 testing::TestSuite::Run()
    @     0x7fe8149a5cac  third_party/googletest/googletest/src/gtest.cc:5994 testing::internal::UnitTestImpl::RunAllTests()
    @     0x7fe8149a521d  third_party/googletest/googletest/src/gtest.cc:0 testing::UnitTest::Run()
    @     0x7fe890b5af67  third_party/googletest/googletest/include/gtest/gtest.h:2349 main
    @     0x7fe766a493d4  __libc_start_main
    @     0x5640d11edc2a  ../sysdeps/x86_64/start.S:120 _start
*** SIGABRT received by PID 2677 (TID 2677) on cpu 18 from PID 2677; ***
```

github-actions[bot] on (2025-01-17 01:58:47 UTC): This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.

github-actions[bot] on (2025-01-31 02:00:06 UTC): This PR was closed because it has been inactive for 14 days since being marked as stale. Please reopen if you'd like to work on this further.

"
2588821345,pull_request,open,,PR #14897: [Nvidia GPU] Add mechanism to detect nccl timeout and return error status,"PR #14897: [Nvidia GPU] Add mechanism to detect nccl timeout and return error status

Imported from GitHub PR https://github.com/openxla/xla/pull/14897

The current behavior crashes the program whenever a nccl async error has occured, timeout errors are also not detected for async events. This pr adds a mechanism to do:
1. poll statuses of async events and return timeout if status is pending for too long
2. return nccl async event status as xla status so a proper python exception can be thrown.
Copybara import of the project:

--
79f2058634fe24cda5ded45ef138d831eb9ea1f9 by TJ Xu <tjx@nvidia.com>:

Add mechanism to detect nccl timeout and return error status

--
bdeb35da41d4c6417989cd2cb40a5b2c63ee10c3 by TJ Xu <tjx@nvidia.com>:

move async status and queue management to gpu executable

--
4d936f4d11a01cc6a5d64e98c3577b0cc79fd0d5 by TJ <tjx@nvidia.com>:

Added e2e test for testing nccl timeout and error propagation

--
3d0e9792ed219dd2aee02d4454364487d5661ae1 by TJ <tjx@nvidia.com>:

address pr comments

--
26882703a6475b78d05121be96cc192ff5b7e93d by TJ <tjx@nvidia.com>:

changed back the formatting for xla/python/pjit.cc

--
6c83bd28ac3bcebe98d8bb80f1fc1e040e86422a by TJ Xu <tjx@nvidia.com>:

Added back the IsIdle api in gpu stream interface

--
ba7f02b4aeac46b1ed00ca8e487f5359b9d3384a by TJ Xu <tjx@nvidia.com>:

Fix ci failure

--
5ce2139bd184bc7a2b0ffd039603475123436609 by TJ Xu <tjx@nvidia.com>:

Add a grace period when async error happens so nccl has time to shut
down

--
4a72ac01ce58b3c279d53600159c721599f3dd92 by TJ Xu <tjx@nvidia.com>:

Added missing include in bazel rule

--
7064bcb2b75374f5bab64818f22cb4ec3010419d by TJ Xu <tjx@nvidia.com>:

remove the delay before exiting gpu executable
wait for the signal instead

--
83e80783faa593911a949ba27e0725f4dd3cb348 by TJ Xu <tjx@nvidia.com>:

add back IsStreamIdle api

--
98de0676a5b0486ab508ce5bca194297581887f6 by TJ Xu <tjx@nvidia.com>:

removed formatting changes in pjit.cc

Merging this change closes #14897

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14897 from Tixxx:tixxx/nccl_error_prop 98de0676a5b0486ab508ce5bca194297581887f6
",copybara-service[bot],2024-10-15 13:41:16+00:00,[],2024-10-15 13:41:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77967,[],[],
2588730984,pull_request,closed,,Move Dispatch API headers to /vendor/c/,"Move Dispatch API headers to /vendor/c/
",copybara-service[bot],2024-10-15 13:07:55+00:00,[],2024-10-15 19:19:52+00:00,2024-10-15 19:19:52+00:00,https://github.com/tensorflow/tensorflow/pull/77966,[],[],
2588665487,pull_request,closed,,Integrate LLVM at llvm/llvm-project@48bda00b281a,"Integrate LLVM at llvm/llvm-project@48bda00b281a

Updates LLVM usage to match
[48bda00b281a](https://github.com/llvm/llvm-project/commit/48bda00b281a)
",copybara-service[bot],2024-10-15 12:41:38+00:00,['d0k'],2024-10-15 13:45:01+00:00,2024-10-15 13:45:00+00:00,https://github.com/tensorflow/tensorflow/pull/77965,[],[],
2588645903,pull_request,closed,,[XLA:GPU] Extend ReduceScatterCombiner to combine pipelined collectives as much as possible.,"[XLA:GPU] Extend ReduceScatterCombiner to combine pipelined collectives as much as possible.

This is particularly useful in FSDP/HSDP where gradient propagation can be done fully in the i+1th iteration. It takes the responsibility of the user to set the `xla_gpu_all_gather_combine_threshold_bytes` by themselves.
",copybara-service[bot],2024-10-15 12:32:58+00:00,[],2024-10-21 09:59:40+00:00,2024-10-21 09:59:38+00:00,https://github.com/tensorflow/tensorflow/pull/77964,[],[],
2588621674,pull_request,closed,,[XLA:GPU] Fix includes in reduce_scatter_combiner.h,"[XLA:GPU] Fix includes in reduce_scatter_combiner.h
",copybara-service[bot],2024-10-15 12:22:51+00:00,[],2024-10-18 11:18:03+00:00,2024-10-18 11:18:02+00:00,https://github.com/tensorflow/tensorflow/pull/77963,[],[],
2588618927,pull_request,closed,,Add support for FP8 types to reshape_test,"Add support for FP8 types to reshape_test
",copybara-service[bot],2024-10-15 12:21:38+00:00,[],2024-10-15 13:55:07+00:00,2024-10-15 13:55:06+00:00,https://github.com/tensorflow/tensorflow/pull/77962,[],[],
2588617813,pull_request,closed,,[XLA:GPU][NFC] Expose grouping key extra args in reduce_scatter_combiner.,"[XLA:GPU][NFC] Expose grouping key extra args in reduce_scatter_combiner.

Brings up the functionality on par with all_gather_combiner.
",copybara-service[bot],2024-10-15 12:21:07+00:00,[],2024-10-17 17:25:03+00:00,2024-10-17 17:25:01+00:00,https://github.com/tensorflow/tensorflow/pull/77961,[],[],
2588606390,pull_request,closed,,Mark ReducePrecision op as supported for bf16.,"Mark ReducePrecision op as supported for bf16.

This is lowered with bit fiddling and operations on integers, so can be
supported directly on bf16.
",copybara-service[bot],2024-10-15 12:15:58+00:00,['akuegel'],2024-10-15 13:08:45+00:00,2024-10-15 13:08:44+00:00,https://github.com/tensorflow/tensorflow/pull/77960,[],[],
2588557655,pull_request,closed,,Fix internal test and roll-forward PR #16975: Add a few related optimization passes for fp8 gemm custom-calls.,"Fix internal test and roll-forward PR #16975: Add a few related optimization passes for fp8 gemm custom-calls.

Reverts 78dbc8c228a292f29bc8c791b80c615f41e412ab
",copybara-service[bot],2024-10-15 11:56:09+00:00,[],2024-10-15 13:20:53+00:00,2024-10-15 13:20:52+00:00,https://github.com/tensorflow/tensorflow/pull/77959,[],[],
2588314862,pull_request,closed,,[XLA:GPU] Limit the buffer drop logs in `cupti_tracer.cc`,"[XLA:GPU] Limit the buffer drop logs in `cupti_tracer.cc`
",copybara-service[bot],2024-10-15 10:20:12+00:00,[],2024-10-15 18:01:58+00:00,2024-10-15 18:01:58+00:00,https://github.com/tensorflow/tensorflow/pull/77957,[],[],
2588298932,pull_request,closed,,"[XLA:GPU] When parsing HLO text proto in the multihost runner, do not reset unset layouts to normalized.","[XLA:GPU] When parsing HLO text proto in the multihost runner, do not reset unset layouts to normalized.

Also updated a test which passed fusions as input HLO. Normally, fusions are not expected in the input HLO, and don't run through layout assignment. For that test, the .hlo file contains the explicit layouts now.
",copybara-service[bot],2024-10-15 10:13:01+00:00,[],2024-11-04 17:02:15+00:00,2024-11-04 17:02:13+00:00,https://github.com/tensorflow/tensorflow/pull/77956,[],[],
2588295442,pull_request,open,,Avoid no-op reduce-precision ops.,"Avoid no-op reduce-precision ops.

If reduce-precision ops don't actually change the mantissa and exponent bits,
they are a no-op. Let AlgebraicSimplifier remove them.
",copybara-service[bot],2024-10-15 10:11:30+00:00,['akuegel'],2024-10-15 10:11:31+00:00,,https://github.com/tensorflow/tensorflow/pull/77955,[],[],
2588287644,pull_request,closed,,[xla:cpu] Make sure that thunk executor continuation runs on TaskRunner,"[xla:cpu] Make sure that thunk executor continuation runs on TaskRunner

name                                     old cpu/op   new cpu/op   delta
BM_AsyncThunkExecutor/1/process_time     14.2µs ± 7%  14.1µs ± 8%    ~     
BM_AsyncThunkExecutor/2/process_time     14.4µs ±19%  14.6µs ±21%    ~     
BM_AsyncThunkExecutor/4/process_time     24.2µs ±16%  24.3µs ±21%    ~     
BM_AsyncThunkExecutor/8/process_time     57.7µs ± 9%  60.5µs ± 8%  +4.84%  
BM_AsyncThunkExecutor/16/process_time     106µs ±20%   106µs ±18%    ~     
BM_AsyncThunkExecutor/32/process_time     137µs ±12%   139µs ±13%    ~     
BM_AsyncThunkExecutor/64/process_time     200µs ± 8%   202µs ± 7%    ~     
BM_AsyncThunkExecutor/128/process_time    271µs ± 6%   273µs ± 6%    ~     
BM_AsyncThunkExecutor/256/process_time    392µs ± 5%   393µs ± 5%    ~     
BM_AsyncThunkExecutor/512/process_time    683µs ± 9%   689µs ± 6%    ~
",copybara-service[bot],2024-10-15 10:08:01+00:00,['ezhulenev'],2024-10-15 22:01:25+00:00,2024-10-15 22:01:24+00:00,https://github.com/tensorflow/tensorflow/pull/77954,[],[],
2588222611,pull_request,closed,,[XLA:GPU] Add a pass to rewrite dot_bf16_bf16_f32_x3 to 3 separate dots.,"[XLA:GPU] Add a pass to rewrite dot_bf16_bf16_f32_x3 to 3 separate dots.

We have the support for this algorithm on the Triton emitter level but it is slower than a rewrite to 3 dots with cublas.
",copybara-service[bot],2024-10-15 09:45:05+00:00,[],2024-10-21 13:26:54+00:00,2024-10-21 13:26:52+00:00,https://github.com/tensorflow/tensorflow/pull/77953,[],[],
2588200335,pull_request,closed,,[DO NOT MERGE] PR for CI test,,inemankov,2024-10-15 09:36:33+00:00,['gbaned'],2024-10-15 11:18:58+00:00,2024-10-15 10:34:16+00:00,https://github.com/tensorflow/tensorflow/pull/77952,"[('size:XL', 'CL Change Size:Extra Large'), ('invalid', 'Hacktoberfest spam PR')]","[{'comment_id': 2413459595, 'issue_id': 2588200335, 'author': 'keerthanakadiri', 'body': 'Hi @inemankov, Can you please resolve the conflicts? Thank you!', 'created_at': datetime.datetime(2024, 10, 15, 10, 6, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413608806, 'issue_id': 2588200335, 'author': 'mihaimaruseac', 'body': ""This is spam, please don't do it again"", 'created_at': datetime.datetime(2024, 10, 15, 11, 18, 35, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-10-15 10:06:09 UTC): Hi @inemankov, Can you please resolve the conflicts? Thank you!

mihaimaruseac on (2024-10-15 11:18:35 UTC): This is spam, please don't do it again

"
2588169644,pull_request,closed,,PR #18254: [XLA:GPU] Simplifies All-Reduce if they can be simplified or are degenerated.,"PR #18254: [XLA:GPU] Simplifies All-Reduce if they can be simplified or are degenerated.

Imported from GitHub PR https://github.com/openxla/xla/pull/18254

This PR adds back the AllReduceSimplifier pass to the GPU compiler as in some cases we see JAX programs will add some degenerated psum to the HLOs,

Code pointer in JAX:
1) https://cs.opensource.google/jax/jax/+/main:jax/experimental/shard_map.py;drc=875f44c63a6c0f082ef3b228559e86e1d0a398d1;l=1674
2) pbroadcast to psum conversions. 

The compiler should generally remove these unnecessary ARs so that it unblocks many optimizations like collective pipeliner. It also emits unncessary runtime thunks as well.
",copybara-service[bot],2024-10-15 09:24:44+00:00,[],2024-10-15 10:33:52+00:00,2024-10-15 10:33:51+00:00,https://github.com/tensorflow/tensorflow/pull/77951,[],[],
2588121590,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 09:05:42+00:00,[],2024-10-15 09:05:42+00:00,,https://github.com/tensorflow/tensorflow/pull/77949,[],[],
2588029316,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 08:29:22+00:00,[],2024-10-15 10:52:31+00:00,2024-10-15 10:52:30+00:00,https://github.com/tensorflow/tensorflow/pull/77947,[],[],
2587992445,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 08:11:59+00:00,[],2024-10-15 08:11:59+00:00,,https://github.com/tensorflow/tensorflow/pull/77945,[],[],
2587927524,pull_request,closed,,PR #18292: [XLA:GPU] Large dynamic update slice fusion due to inability to identify in place fusion,"PR #18292: [XLA:GPU] Large dynamic update slice fusion due to inability to identify in place fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/18292

```
fused_dynamic_update_slice {
  param_1.133 = bf16[32,1,4096,18432]{2,3,1,0} parameter(1)
  bitcast.8539.1 = bf16[32,1,18432,4096]{3,2,1,0} bitcast(param_1.133)
  param_0.168 = bf16[1,4096,18432]{1,0,2} parameter(0)
  bitcast.8543.1 = bf16[1,1,18432,4096]{3,2,1,0} bitcast(param_0.168)
  param_2.98 = s32[] parameter(2)
  constant_2153_8 = s32[] constant(0)
  compare.753.6 = pred[] compare(param_2.98, constant_2153_8), direction=LT
  constant_2154_12 = s32[] constant(96)
  add.950.6 = s32[] add(param_2.98, constant_2154_12)
  select.883.5 = s32[] select(compare.753.6, add.950.6, param_2.98)
  ROOT dynamic-update-slice.178.1 = bf16[32,1,18432,4096]{3,2,1,0} dynamic-update-slice(bitcast.8539.1, bitcast.8543.1, select.883.5, constant_2153_8, constant_2153_8, /*index=5*/constant_2153_8)
} // fused_dynamic_update_slice
```
`GetFusionInstructionInPlaceInputOutputPairs` isn't able to identify `param_1.133` to be aliased with `dynamic-update-slice.178.1` because there is a bitcast in between. Therefore, dus fusion happens out of place, resulting in large runtime overhead.

Could potentially be implemented in `FollowTupleIndirection`? I'm not sure if this beaks other things if done so.

Copybara import of the project:

--
978b4291eaf10ce75fcbe9051e218833669f92dd by cjkkkk <ske@nvidia.com>:

init

--
6a3b3c20505ef8171702e117b219520fcc14fd5e by cjkkkk <ske@nvidia.com>:

add unit test

Merging this change closes #18292

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18292 from Cjkkkk:fix_dus_fusion_alias_analysis 6a3b3c20505ef8171702e117b219520fcc14fd5e
",copybara-service[bot],2024-10-15 07:44:09+00:00,[],2024-10-21 09:52:33+00:00,2024-10-21 09:52:32+00:00,https://github.com/tensorflow/tensorflow/pull/77944,[],[],
2587919405,pull_request,closed,,[XLA] Make it possible to use our extended types with Array::FillRandomUniform,"[XLA] Make it possible to use our extended types with Array::FillRandomUniform
",copybara-service[bot],2024-10-15 07:40:34+00:00,['majnemer'],2024-10-15 16:56:18+00:00,2024-10-15 16:56:17+00:00,https://github.com/tensorflow/tensorflow/pull/77943,[],[],
2587880873,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 07:24:05+00:00,[],2024-10-16 07:59:08+00:00,2024-10-16 07:59:07+00:00,https://github.com/tensorflow/tensorflow/pull/77942,[],[],
2587859737,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 07:12:59+00:00,[],2024-10-15 10:32:53+00:00,,https://github.com/tensorflow/tensorflow/pull/77941,[],[],
2587858166,pull_request,closed,,Update pywrap_mlir.py,"Input Validation: Added validation for inputs such as graphdef, pass_pipeline, and input_names.
Improved Docstrings: Added detailed docstrings to explain the arguments, return values, and potential exceptions.
Pathlib Support: Replaced string-based file paths with Pathlib.Path for cross-platform compatibility.
Default Argument Handling: Updated default arguments for mutable lists (output_names).
Logging: Added logging functionality when show_debug_info is set to True.
Batch Processing: Added support for batch processing of multiple GraphDef objects using batch_import_graphdef.",Ame3yakatole,2024-10-15 07:12:04+00:00,['gbaned'],2024-12-10 08:11:21+00:00,2024-12-10 08:11:15+00:00,https://github.com/tensorflow/tensorflow/pull/77940,"[('size:L', 'CL Change Size: Large')]","[{'comment_id': 2413074924, 'issue_id': 2587858166, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77940/checks?check_run_id=31538623335) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 15, 7, 12, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413457542, 'issue_id': 2587858166, 'author': 'keerthanakadiri', 'body': 'Hi @Ame3yakatole , Can you please sign CLA , thank you', 'created_at': datetime.datetime(2024, 10, 15, 10, 5, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413612843, 'issue_id': 2587858166, 'author': 'mihaimaruseac', 'body': 'Someone from MLIR should review this', 'created_at': datetime.datetime(2024, 10, 15, 11, 20, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431057132, 'issue_id': 2587858166, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 23, 6, 44, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2530518945, 'issue_id': 2587858166, 'author': 'keerthanakadiri', 'body': 'Hi @Ame3yakatole , Can you please sign CLA , thank you', 'created_at': datetime.datetime(2024, 12, 10, 6, 0, 11, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-15 07:12:09 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77940/checks?check_run_id=31538623335) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

keerthanakadiri on (2024-10-15 10:05:11 UTC): Hi @Ame3yakatole , Can you please sign CLA , thank you

mihaimaruseac on (2024-10-15 11:20:36 UTC): Someone from MLIR should review this

keerthanakadiri on (2024-10-23 06:44:42 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

keerthanakadiri on (2024-12-10 06:00:11 UTC): Hi @Ame3yakatole , Can you please sign CLA , thank you

"
2587788329,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 06:38:42+00:00,[],2024-10-15 06:38:42+00:00,,https://github.com/tensorflow/tensorflow/pull/77939,[],[],
2587785823,pull_request,open,,Remove returning reference to the pass to assure consistency with the owning unique_ptr,"Remove returning reference to the pass to assure consistency with the owning unique_ptr
",copybara-service[bot],2024-10-15 06:37:09+00:00,[],2024-10-15 06:37:09+00:00,,https://github.com/tensorflow/tensorflow/pull/77938,[],[],
2587778763,pull_request,open,,Refactor HloPassPipeline to reduce cognitive complexity.,"Refactor HloPassPipeline to reduce cognitive complexity.
",copybara-service[bot],2024-10-15 06:32:56+00:00,[],2024-10-15 06:32:56+00:00,,https://github.com/tensorflow/tensorflow/pull/77937,[],[],
2587748052,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/72232 from shadchin:python313 846468dd25153e9a41f0a9da1ba1604ce819628d
",copybara-service[bot],2024-10-15 06:12:43+00:00,[],2024-10-15 06:54:36+00:00,,https://github.com/tensorflow/tensorflow/pull/77936,[],[],
2587734508,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 06:03:34+00:00,[],2024-10-15 06:03:34+00:00,,https://github.com/tensorflow/tensorflow/pull/77935,[],[],
2587734219,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 06:03:21+00:00,[],2024-10-18 05:51:55+00:00,,https://github.com/tensorflow/tensorflow/pull/77934,[],[],
2587727118,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 05:58:32+00:00,[],2024-10-17 09:08:01+00:00,2024-10-17 09:07:59+00:00,https://github.com/tensorflow/tensorflow/pull/77933,[],[],
2587726611,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 05:58:15+00:00,[],2024-10-17 04:31:47+00:00,2024-10-17 04:31:45+00:00,https://github.com/tensorflow/tensorflow/pull/77932,[],[],
2587726419,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 05:58:08+00:00,[],2024-10-15 05:58:08+00:00,,https://github.com/tensorflow/tensorflow/pull/77931,[],[],
2587722867,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 05:56:16+00:00,[],2024-10-15 05:56:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77930,[],[],
2587721277,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 05:55:19+00:00,[],2024-10-15 05:55:19+00:00,,https://github.com/tensorflow/tensorflow/pull/77929,[],[],
2587715926,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 05:52:14+00:00,[],2024-10-15 05:52:14+00:00,,https://github.com/tensorflow/tensorflow/pull/77928,[],[],
2587706712,pull_request,closed,,[oneDNN] upgrading oneDNN version to 3.6.2,"This PR upgrades oneDNN version from v3.5 to v3.6, this PR has been tested on several models across different platforms including cascade-lake, sapphire-rapids, and granite-rapids

Several bug fixes have been resolved in this version. Details can be found here https://github.com/oneapi-src/oneDNN/releases",ashiqimranintel,2024-10-15 05:46:48+00:00,['gbaned'],2025-01-28 10:13:32+00:00,2025-01-28 10:13:28+00:00,https://github.com/tensorflow/tensorflow/pull/77927,"[('size:S', 'CL Change Size: Small')]","[{'comment_id': 2417110191, 'issue_id': 2587706712, 'author': 'mihaimaruseac', 'body': 'There has been no change to the PR since my review yesterday, can I ask why was review requested again?', 'created_at': datetime.datetime(2024, 10, 16, 15, 6, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431842435, 'issue_id': 2587706712, 'author': 'mihaimaruseac', 'body': ""(you shouldn't have requested a new review, this was not changed since the last review)"", 'created_at': datetime.datetime(2024, 10, 23, 11, 41, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2475075883, 'issue_id': 2587706712, 'author': 'vpirogov', 'body': '> Please add the following to `_INCLUDE_LIST`:\r\n> \r\n\r\nThese headers are related to an opt-in experimental feature [`DNNL_EXPERIMENTAL_LOGGING`](https://oneapi-src.github.io/oneDNN/dev_guide_experimental.html#onednn-experimental-logging), which should not be used by TensorFlow.', 'created_at': datetime.datetime(2024, 11, 14, 0, 7, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2489083311, 'issue_id': 2587706712, 'author': 'ashiqimranintel', 'body': ""@penpornk , I added a new commit, could you restart the test? It seemed, it didn't trigger yet"", 'created_at': datetime.datetime(2024, 11, 20, 16, 43, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2573181354, 'issue_id': 2587706712, 'author': 'penpornk', 'body': '@ashiqimranintel Could you please help take a look at Linux x86 CPU CI failures? Here is the [log](https://btx.cloud.google.com/invocations/43a4dd35-900b-4a65-b751-35bd27d8013a/targets)', 'created_at': datetime.datetime(2025, 1, 6, 14, 5, 28, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605463397, 'issue_id': 2587706712, 'author': 'gzmkl', 'body': '@penpornk  Hi Penporn, PR owner is off for a while. I am looking at the CI failure (computation problem). \r\n\r\nQuick question: what does ""use_placeholder"" argument do in the python tests?\r\n\r\n[  FAILED  ] NonSquareLinearOperatorCompositionTest.test_composite_tensor_gradient__shape=(1, 3, 2),dtype=<dtype: \'float32\'>,use_placeholder=False\r\n\r\n( tensorflow/python/kernel_tests/linalg/linear_operator_composition_test.py).', 'created_at': datetime.datetime(2025, 1, 21, 18, 31, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605464844, 'issue_id': 2587706712, 'author': 'gzmkl', 'body': '@penpornk  I could reproduce the problem with TF tests.', 'created_at': datetime.datetime(2025, 1, 21, 18, 31, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605512366, 'issue_id': 2587706712, 'author': 'penpornk', 'body': '@gzmkl Thank you for covering for @ashiqimranintel!\r\n\r\n> Quick question: what does ""use_placeholder"" argument do in the python tests?\r\n> \r\n> [ FAILED ] NonSquareLinearOperatorCompositionTest.test_composite_tensor_gradient__shape=(1, 3, 2),dtype=<dtype: \'float32\'>,use_placeholder=False\r\n> \r\n> ( tensorflow/python/kernel_tests/linalg/linear_operator_composition_test.py).\r\n\r\nIt means using a [TF placeholder](https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder)\r\nhttps://github.com/tensorflow/tensorflow/blob/63323a38c3ba1e68b98db4541b52d11e2645fbef/tensorflow/python/kernel_tests/linalg/linear_operator_composition_test.py#L73-L76\r\n\r\nMore details here:\r\nhttps://github.com/tensorflow/tensorflow/blob/63323a38c3ba1e68b98db4541b52d11e2645fbef/tensorflow/python/ops/array_ops.py#L3031-L3078', 'created_at': datetime.datetime(2025, 1, 21, 18, 57, 52, tzinfo=datetime.timezone.utc)}, {'comment_id': 2605760735, 'issue_id': 2587706712, 'author': 'gzmkl', 'body': '@penpornk Thank you for the explanation!', 'created_at': datetime.datetime(2025, 1, 21, 21, 19, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2611115170, 'issue_id': 2587706712, 'author': 'gzmkl', 'body': '@penpornk Hi Penporn, my investigation found that oneDNN 3.6.2 contains bugs in brg_matmul implementation. oneDNN team now has a fix which partially addresses TensorFlow test failures (not ALL).   I will continue to work with oneDNN team to have a complete solution. \r\n\r\nSo this PR and related XLA PR cannot go in. THANKS!', 'created_at': datetime.datetime(2025, 1, 23, 22, 6, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2618561924, 'issue_id': 2587706712, 'author': 'penpornk', 'body': ""@gzmkl Thank you for the heads up! I'll close this PR for the time being then. Please feel free to reopen when the fix is ready."", 'created_at': datetime.datetime(2025, 1, 28, 10, 13, 28, tzinfo=datetime.timezone.utc)}]","mihaimaruseac on (2024-10-16 15:06:07 UTC): There has been no change to the PR since my review yesterday, can I ask why was review requested again?

mihaimaruseac on (2024-10-23 11:41:37 UTC): (you shouldn't have requested a new review, this was not changed since the last review)

vpirogov on (2024-11-14 00:07:56 UTC): These headers are related to an opt-in experimental feature [`DNNL_EXPERIMENTAL_LOGGING`](https://oneapi-src.github.io/oneDNN/dev_guide_experimental.html#onednn-experimental-logging), which should not be used by TensorFlow.

ashiqimranintel (Issue Creator) on (2024-11-20 16:43:42 UTC): @penpornk , I added a new commit, could you restart the test? It seemed, it didn't trigger yet

penpornk on (2025-01-06 14:05:28 UTC): @ashiqimranintel Could you please help take a look at Linux x86 CPU CI failures? Here is the [log](https://btx.cloud.google.com/invocations/43a4dd35-900b-4a65-b751-35bd27d8013a/targets)

gzmkl on (2025-01-21 18:31:01 UTC): @penpornk  Hi Penporn, PR owner is off for a while. I am looking at the CI failure (computation problem). 

Quick question: what does ""use_placeholder"" argument do in the python tests?

[  FAILED  ] NonSquareLinearOperatorCompositionTest.test_composite_tensor_gradient__shape=(1, 3, 2),dtype=<dtype: 'float32'>,use_placeholder=False

( tensorflow/python/kernel_tests/linalg/linear_operator_composition_test.py).

gzmkl on (2025-01-21 18:31:48 UTC): @penpornk  I could reproduce the problem with TF tests.

penpornk on (2025-01-21 18:57:52 UTC): @gzmkl Thank you for covering for @ashiqimranintel!


It means using a [TF placeholder](https://www.tensorflow.org/api_docs/python/tf/compat/v1/placeholder)
https://github.com/tensorflow/tensorflow/blob/63323a38c3ba1e68b98db4541b52d11e2645fbef/tensorflow/python/kernel_tests/linalg/linear_operator_composition_test.py#L73-L76

More details here:
https://github.com/tensorflow/tensorflow/blob/63323a38c3ba1e68b98db4541b52d11e2645fbef/tensorflow/python/ops/array_ops.py#L3031-L3078

gzmkl on (2025-01-21 21:19:16 UTC): @penpornk Thank you for the explanation!

gzmkl on (2025-01-23 22:06:51 UTC): @penpornk Hi Penporn, my investigation found that oneDNN 3.6.2 contains bugs in brg_matmul implementation. oneDNN team now has a fix which partially addresses TensorFlow test failures (not ALL).   I will continue to work with oneDNN team to have a complete solution. 

So this PR and related XLA PR cannot go in. THANKS!

penpornk on (2025-01-28 10:13:28 UTC): @gzmkl Thank you for the heads up! I'll close this PR for the time being then. Please feel free to reopen when the fix is ready.

"
2587609433,pull_request,closed,,Generate configuration_generated.h properly,"Generate configuration_generated.h properly

This change is a bug fix in the automatically generated code that was introduced by the new version of the flatbuffer generator that TensorFlow updated to in https://github.com/tensorflow/tensorflow/commit/c17d64df85a83c1bd0fd7dcc0b1230812b0d3d48 which includes the following change https://github.com/google/flatbuffers/pull/7813 which fixed the underlying flatbuffer code generator bug.
",copybara-service[bot],2024-10-15 04:38:21+00:00,[],2024-10-16 18:27:21+00:00,2024-10-16 18:27:21+00:00,https://github.com/tensorflow/tensorflow/pull/77926,[],[],
2587588095,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:18:19+00:00,[],2024-10-15 04:18:19+00:00,,https://github.com/tensorflow/tensorflow/pull/77925,[],[],
2587584049,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:14:23+00:00,[],2024-10-15 07:59:42+00:00,,https://github.com/tensorflow/tensorflow/pull/77924,[],[],
2587581970,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:12:22+00:00,[],2024-10-15 04:12:22+00:00,,https://github.com/tensorflow/tensorflow/pull/77923,[],[],
2587580406,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:10:46+00:00,[],2024-10-15 07:25:18+00:00,,https://github.com/tensorflow/tensorflow/pull/77922,[],[],
2587580369,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:10:43+00:00,[],2024-10-15 07:29:19+00:00,,https://github.com/tensorflow/tensorflow/pull/77921,[],[],
2587580120,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:10:26+00:00,[],2024-10-15 08:00:45+00:00,,https://github.com/tensorflow/tensorflow/pull/77920,[],[],
2587578722,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:09:09+00:00,[],2024-10-15 04:09:09+00:00,,https://github.com/tensorflow/tensorflow/pull/77919,[],[],
2587578679,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:09:06+00:00,[],2024-10-15 07:23:48+00:00,,https://github.com/tensorflow/tensorflow/pull/77918,[],[],
2587578250,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:08:37+00:00,[],2024-10-15 08:06:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77917,[],[],
2587577914,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:08:16+00:00,[],2024-10-15 08:22:34+00:00,,https://github.com/tensorflow/tensorflow/pull/77916,[],[],
2587577726,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:08:04+00:00,[],2024-10-15 08:22:49+00:00,2024-10-15 08:22:49+00:00,https://github.com/tensorflow/tensorflow/pull/77915,[],[],
2587576233,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:07:01+00:00,[],2024-10-15 06:17:51+00:00,,https://github.com/tensorflow/tensorflow/pull/77914,[],[],
2587575965,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:06:49+00:00,[],2024-10-15 08:34:09+00:00,2024-10-15 08:34:09+00:00,https://github.com/tensorflow/tensorflow/pull/77913,[],[],
2587574196,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:05:09+00:00,[],2024-10-15 04:05:09+00:00,,https://github.com/tensorflow/tensorflow/pull/77912,[],[],
2587569851,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 04:00:39+00:00,[],2024-10-15 04:00:39+00:00,,https://github.com/tensorflow/tensorflow/pull/77911,[],[],
2587567418,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 03:58:28+00:00,[],2024-10-15 03:58:28+00:00,,https://github.com/tensorflow/tensorflow/pull/77910,[],[],
2587566819,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 03:58:01+00:00,[],2024-10-15 03:58:01+00:00,,https://github.com/tensorflow/tensorflow/pull/77909,[],[],
2587566066,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 03:57:26+00:00,[],2024-10-15 03:57:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77908,[],[],
2587560887,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 03:54:20+00:00,[],2024-10-15 03:54:20+00:00,,https://github.com/tensorflow/tensorflow/pull/77907,[],[],
2587547976,pull_request,closed,,Internal change only,"Internal change only
",copybara-service[bot],2024-10-15 03:43:10+00:00,[],2024-10-16 23:22:28+00:00,2024-10-16 23:22:28+00:00,https://github.com/tensorflow/tensorflow/pull/77906,[],[],
2587535017,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 03:30:47+00:00,[],2024-10-15 03:30:47+00:00,,https://github.com/tensorflow/tensorflow/pull/77905,[],[],
2587533181,pull_request,closed,,* Implement capability to send dynamic hyperparameters (other than learning,"* Implement capability to send dynamic hyperparameters (other than learning
  rate) from the TensorCore to the TPUEmbedding.
* Implement frequency aware Adagrad optimizer for TPUEmbedding that uses the
  above capability.
",copybara-service[bot],2024-10-15 03:29:19+00:00,[],2024-10-18 02:07:15+00:00,2024-10-18 02:07:14+00:00,https://github.com/tensorflow/tensorflow/pull/77904,[],[],
2587531991,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 03:28:33+00:00,[],2024-10-15 03:28:33+00:00,,https://github.com/tensorflow/tensorflow/pull/77903,[],[],
2587508788,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-15 03:13:40+00:00,[],2024-10-15 03:13:40+00:00,,https://github.com/tensorflow/tensorflow/pull/77902,[],[],
2587412419,pull_request,closed,,Let XlaCompiler own the channel id counter instead of calling xla service.,"Let XlaCompiler own the channel id counter instead of calling xla service.
",copybara-service[bot],2024-10-15 01:45:01+00:00,[],2024-10-17 21:51:14+00:00,2024-10-17 21:51:14+00:00,https://github.com/tensorflow/tensorflow/pull/77901,[],[],
2587402196,pull_request,closed,,Move qnn dumping to its own internal tools/ folder,"Move qnn dumping to its own internal tools/ folder
",copybara-service[bot],2024-10-15 01:31:42+00:00,['LukeBoyer'],2024-10-15 19:29:32+00:00,2024-10-15 19:29:31+00:00,https://github.com/tensorflow/tensorflow/pull/77900,[],[],
2587398424,pull_request,closed,,Add const qualifier to IsPassPipeline(),"Add const qualifier to IsPassPipeline()
",copybara-service[bot],2024-10-15 01:26:45+00:00,[],2024-10-16 20:14:15+00:00,2024-10-16 20:14:13+00:00,https://github.com/tensorflow/tensorflow/pull/77899,[],[],
2587383345,pull_request,closed,,Finalize refactors for CompilerPlugin C++ wrapper,"Finalize refactors for CompilerPlugin C++ wrapper

* Move internal compiler plugin stuff to core/compiler_plugin
* don't put the algo logic to cc rather than header, rename the public functions
* Rename PluginManager -> CompilerPlugin
* Merge CompilerPluginApi impl with CompilerPlugin
* Incorporate feedback from earlier CLs to have CompilerPlugin manager the lifetimes of underlying LrtCompilerPlugin and dynamic lib.
* Update interface to be more concise and use C++ better, use LrtResult
* add dumping for CompilerPlugin
* Move dynamic loading dumping to tools/
* Move qnn dumping into its own tools/ folder
",copybara-service[bot],2024-10-15 01:08:20+00:00,['LukeBoyer'],2024-10-15 03:12:53+00:00,2024-10-15 03:12:52+00:00,https://github.com/tensorflow/tensorflow/pull/77898,[],[],
2587381609,pull_request,closed,,Add a private property to NamedSharding called `_logical_device_ids` which allows you to pass a custom `tile_assignment_devices()` equivalent.,"Add a private property to NamedSharding called `_logical_device_ids` which allows you to pass a custom `tile_assignment_devices()` equivalent.

This is because for Shardy, GSPMDSharding doesn't work, so `device_put` on a mesh with different device order needs `NamedSharding` support. Bonus is that the logic is now simplified wrt the previous version in `_different_device_order_reshard`.

This will also allow us to remove OpSharding usage in other projects which require such kind of permutation capabilities.
",copybara-service[bot],2024-10-15 01:06:15+00:00,['yashk2810'],2024-10-15 03:25:43+00:00,2024-10-15 03:25:42+00:00,https://github.com/tensorflow/tensorflow/pull/77897,[],[],
2587361503,pull_request,closed,,Explicitly copy string when processing coord service APIs to prevent races when string from the RPC request object is destroyed.,"Explicitly copy string when processing coord service APIs to prevent races when string from the RPC request object is destroyed.
",copybara-service[bot],2024-10-15 00:42:52+00:00,[],2024-10-15 19:41:49+00:00,2024-10-15 19:41:48+00:00,https://github.com/tensorflow/tensorflow/pull/77896,[],[],
2587338033,pull_request,closed,,Rollback of PR #77018 because it made the unit test `python/ops/ragged:ragged_range_op_test` to cause signed integer overflow.,"Rollback of PR #77018 because it made the unit test `python/ops/ragged:ragged_range_op_test` to cause signed integer overflow.

The error call stack was:
tensorflow/core/kernels/ragged_range_op.cc:144:15: runtime error: signed integer overflow: -713794229 + -1849827689 cannot be represented in type 'int'
    #0 0x55f036bf067a in 

tensorflow::RaggedRangeOp<int,long>::Compute(tensorflow::OpKernelContext*) 
tensorflow/core/kernels/ragged_range_op.cc:144:15

Reverts fb673632e8b7f4f525ac63378a42096053540683
",copybara-service[bot],2024-10-15 00:23:15+00:00,[],2024-10-15 00:56:43+00:00,2024-10-15 00:56:41+00:00,https://github.com/tensorflow/tensorflow/pull/77895,[],[],
2587331824,pull_request,closed,,Move dumping functions into tools/,"Move dumping functions into tools/
",copybara-service[bot],2024-10-15 00:18:43+00:00,['LukeBoyer'],2024-10-15 01:57:17+00:00,2024-10-15 01:57:16+00:00,https://github.com/tensorflow/tensorflow/pull/77894,[],[],
2587247560,pull_request,closed,,Combining more similarly configured tests.,"Combining more similarly configured tests.
",copybara-service[bot],2024-10-14 23:13:37+00:00,[],2024-10-16 18:57:43+00:00,2024-10-16 18:57:43+00:00,https://github.com/tensorflow/tensorflow/pull/77893,[],[],
2587242817,pull_request,open,,Integrate LLVM at llvm/llvm-project@1a787b3c8e71,"Integrate LLVM at llvm/llvm-project@1a787b3c8e71

Updates LLVM usage to match
[1a787b3c8e71](https://github.com/llvm/llvm-project/commit/1a787b3c8e71)
",copybara-service[bot],2024-10-14 23:09:50+00:00,[],2024-10-14 23:09:50+00:00,,https://github.com/tensorflow/tensorflow/pull/77892,[],[],
2587237715,pull_request,open,,Implement move and dstor for plugin manager,"Implement move and dstor for plugin manager
",copybara-service[bot],2024-10-14 23:04:33+00:00,['LukeBoyer'],2024-10-14 23:04:34+00:00,,https://github.com/tensorflow/tensorflow/pull/77891,[],[],
2587209639,pull_request,closed,,Use StreamExecutor::Activate instead of the ScopedActivateContext implementation detail.,"Use StreamExecutor::Activate instead of the ScopedActivateContext implementation detail.
",copybara-service[bot],2024-10-14 22:45:21+00:00,[],2024-10-15 00:05:25+00:00,2024-10-15 00:05:24+00:00,https://github.com/tensorflow/tensorflow/pull/77890,[],[],
2587204728,pull_request,closed,,[XLA] Add compilation effort flags.,"[XLA] Add compilation effort flags.
",copybara-service[bot],2024-10-14 22:40:58+00:00,[],2024-10-16 18:09:26+00:00,2024-10-16 18:09:24+00:00,https://github.com/tensorflow/tensorflow/pull/77889,[],[],
2587203439,pull_request,closed,,Use ModuleHandle for module management in Executor ,"Use ModuleHandle for module management in Executor 

We used to use void pointers to identify loaded GPU binaries. This change makes it use the `ModuleHandle` type. It avoids a bunch of `reinterpret_cast` and makes it also more clear what the void pointer represents.

In addition this is replacing the out parameters in a bunch of related functions by `absl::StatusOr<...>` return types.
",copybara-service[bot],2024-10-14 22:39:55+00:00,[],2024-10-16 00:25:49+00:00,2024-10-16 00:25:48+00:00,https://github.com/tensorflow/tensorflow/pull/77888,[],[],
2587186805,pull_request,closed,,Use StreamExecutor::Activate method to create the correct ActivateContext rather than using the ScopedActivateContext implementation detail.,"Use StreamExecutor::Activate method to create the correct ActivateContext rather than using the ScopedActivateContext implementation detail.
",copybara-service[bot],2024-10-14 22:29:05+00:00,[],2024-10-14 23:06:23+00:00,2024-10-14 23:06:22+00:00,https://github.com/tensorflow/tensorflow/pull/77887,[],[],
2587174311,pull_request,closed,,Add tests for CudaStream::WaitFor,"Add tests for CudaStream::WaitFor
",copybara-service[bot],2024-10-14 22:19:30+00:00,[],2024-10-30 09:53:09+00:00,2024-10-30 09:53:07+00:00,https://github.com/tensorflow/tensorflow/pull/77886,[],[],
2587172271,pull_request,closed,,Remove LeakCheckDisabler from CudaExecutor,"Remove LeakCheckDisabler from CudaExecutor

It appears the memory leak has been fixed.

Reverts fb673632e8b7f4f525ac63378a42096053540683
",copybara-service[bot],2024-10-14 22:17:26+00:00,[],2024-10-15 01:37:28+00:00,2024-10-15 01:37:27+00:00,https://github.com/tensorflow/tensorflow/pull/77885,[],[],
2587167431,pull_request,closed,,Use StreamExecutor::Activate method to create the correct ActivateContext rather than using the ScopedActivateContext implementation detail.,"Use StreamExecutor::Activate method to create the correct ActivateContext rather than using the ScopedActivateContext implementation detail.
",copybara-service[bot],2024-10-14 22:12:53+00:00,[],2024-10-15 20:05:48+00:00,2024-10-15 20:05:47+00:00,https://github.com/tensorflow/tensorflow/pull/77884,[],[],
2587163884,pull_request,closed,,More graceful handling AbslHashValue when hlo module doesn't have entry computation layout. Without the fix hash breaks on empty module such as absl:Hash(HloTestBase::CreateNewVerifiedModule()).,"More graceful handling AbslHashValue when hlo module doesn't have entry computation layout. Without the fix hash breaks on empty module such as absl:Hash(HloTestBase::CreateNewVerifiedModule()).
",copybara-service[bot],2024-10-14 22:09:24+00:00,[],2024-10-15 22:32:46+00:00,2024-10-15 22:32:45+00:00,https://github.com/tensorflow/tensorflow/pull/77883,[],[],
2587157762,pull_request,closed,,Use StreamExecutor::Activate in ROCm code.,"Use StreamExecutor::Activate in ROCm code.
",copybara-service[bot],2024-10-14 22:03:50+00:00,[],2024-10-15 19:06:05+00:00,2024-10-15 19:06:04+00:00,https://github.com/tensorflow/tensorflow/pull/77882,[],[],
2587128395,pull_request,closed,,"Add `AbslStringify` to most ""simple"" IFRT types","Add `AbslStringify` to most ""simple"" IFRT types

For some types, `AbslStringify` has been added for their common pointer types (such as `Device*` or `shared_ptr<const Sharding>`) so that printing works correctly for their typical use cases as well.

With this change, `DebugString()` is no longer a mockable method. This is because `AbslStringify` makes it too easy to accidentally call `DebugString()` or `ToString()` as part of GMock matcher's stringification, causing a deadlock (all matchers must be stateless and mock `DebugString()` violates this). I think this is a net win since now all mock users by default get somewhat meaningful `DebugString` (e.g., ""MockDevice"") rather than a pointer to the mock object.
",copybara-service[bot],2024-10-14 21:43:13+00:00,[],2024-10-15 01:21:10+00:00,2024-10-15 01:21:09+00:00,https://github.com/tensorflow/tensorflow/pull/77881,[],[],
2587124897,pull_request,closed,,Add public visibility for some tensorflow/compiler/mlir/lite targets.,"Add public visibility for some tensorflow/compiler/mlir/lite targets.
",copybara-service[bot],2024-10-14 21:40:59+00:00,['junjiang-lab'],2024-10-15 22:13:28+00:00,2024-10-15 22:13:27+00:00,https://github.com/tensorflow/tensorflow/pull/77880,[],[],
2587120424,pull_request,open,,PR #18254: [XLA:GPU] Simplifies All-Reduce if they can be simplified or are degenerated.,"PR #18254: [XLA:GPU] Simplifies All-Reduce if they can be simplified or are degenerated.

Imported from GitHub PR https://github.com/openxla/xla/pull/18254

This PR adds back the AllReduceSimplifier pass to the GPU compiler as in some cases we see JAX programs will add some degenerated psum to the HLOs,

Code pointer in JAX:
1) https://cs.opensource.google/jax/jax/+/main:jax/experimental/shard_map.py;drc=875f44c63a6c0f082ef3b228559e86e1d0a398d1;l=1674
2) pbroadcast to psum conversions. 

The compiler should generally remove these unnecessary ARs so that it unblocks many optimizations like collective pipeliner. It also emits unncessary runtime thunks as well.
Copybara import of the project:

--
b89df553bd260e60a472d4b69268be66fff478b6 by Yunlong Liu <yunlongl@x.ai>:

Removes degenerated all reduce.

--
055c409c51e9c4ef36f19da0c049cf6de8880b34 by Yunlong Liu <yunlongl@x.ai>:

Creates a new e2e test target for GPU.

--
93934eb15d4fd0571123965174f3713c19d183f5 by Yunlong Liu <yunlongl@x.ai>:

E2E test passed.

Merging this change closes #18254

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18254 from yliu120:ar-simplify 93934eb15d4fd0571123965174f3713c19d183f5
",copybara-service[bot],2024-10-14 21:39:05+00:00,[],2024-10-21 10:02:25+00:00,,https://github.com/tensorflow/tensorflow/pull/77879,[],[],
2587071063,pull_request,closed,,This is an internal change to update targets to use the latest qairt instead of a specific version.,"This is an internal change to update targets to use the latest qairt instead of a specific version.
",copybara-service[bot],2024-10-14 21:04:43+00:00,[],2024-10-16 04:45:46+00:00,2024-10-16 04:45:45+00:00,https://github.com/tensorflow/tensorflow/pull/77878,[],[],
2586941898,pull_request,closed,,Use StreamExecutor::Activate instead of directly creating ScopedActivateContexts in cuda code.,"Use StreamExecutor::Activate instead of directly creating ScopedActivateContexts in cuda code.
",copybara-service[bot],2024-10-14 20:09:32+00:00,[],2024-10-15 18:10:33+00:00,2024-10-15 18:10:33+00:00,https://github.com/tensorflow/tensorflow/pull/77877,[],[],
2586938728,pull_request,closed,,[Refactor] Remove unused ReportServiceErrorToTask method.,"[Refactor] Remove unused ReportServiceErrorToTask method.
",copybara-service[bot],2024-10-14 20:07:27+00:00,[],2024-10-14 20:55:35+00:00,2024-10-14 20:55:34+00:00,https://github.com/tensorflow/tensorflow/pull/77876,[],[],
2586928140,pull_request,closed,,Update HloModuleWrapper class to allow client own the HLO module instead transfer ownership,"Update HloModuleWrapper class to allow client own the HLO module instead transfer ownership
",copybara-service[bot],2024-10-14 20:00:34+00:00,['zzzaries'],2024-10-14 20:19:45+00:00,2024-10-14 20:19:45+00:00,https://github.com/tensorflow/tensorflow/pull/77875,[],[],
2586877346,pull_request,closed,,"Adds a python module for accessing XPlane, i.e., the profiling result from Xprof, programatically.","Adds a python module for accessing XPlane, i.e., the profiling result from Xprof, programatically.
",copybara-service[bot],2024-10-14 19:33:37+00:00,[],2024-10-14 23:55:26+00:00,2024-10-14 23:55:25+00:00,https://github.com/tensorflow/tensorflow/pull/77874,[],[],
2586846095,pull_request,closed,,Change the attribute name of `ici_weight_distribution_mlir_bridge_marker` to `_ici_weight_distribution_mlir_bridge_marker`,"Change the attribute name of `ici_weight_distribution_mlir_bridge_marker` to `_ici_weight_distribution_mlir_bridge_marker`
",copybara-service[bot],2024-10-14 19:18:07+00:00,[],2024-10-14 21:19:46+00:00,2024-10-14 21:19:46+00:00,https://github.com/tensorflow/tensorflow/pull/77873,[],[],
2586839069,pull_request,closed,,iota_test: Bump test timeout to allow it to run with internal test infra.,"iota_test: Bump test timeout to allow it to run with internal test infra.

The slowness of the CPU backend with this test can also be isolated to that
variant, so let's bump the nofastbuild tag there while we're at it.
",copybara-service[bot],2024-10-14 19:13:06+00:00,[],2024-10-15 15:00:10+00:00,2024-10-15 15:00:09+00:00,https://github.com/tensorflow/tensorflow/pull/77872,[],[],
2586836133,pull_request,closed,,Internal changes for LiteRT oss.,"Internal changes for LiteRT oss.
",copybara-service[bot],2024-10-14 19:11:03+00:00,['junjiang-lab'],2024-10-15 17:08:36+00:00,2024-10-15 17:08:35+00:00,https://github.com/tensorflow/tensorflow/pull/77871,[],[],
2586705865,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@e44958c8,"Integrate StableHLO at openxla/stablehlo@e44958c8
",copybara-service[bot],2024-10-14 17:58:29+00:00,['sdasgup3'],2024-10-14 20:10:51+00:00,2024-10-14 20:10:50+00:00,https://github.com/tensorflow/tensorflow/pull/77870,[],[],
2586697557,pull_request,closed,,Remove unused methods and members from Cuda- and RocmExecutor,"Remove unused methods and members from Cuda- and RocmExecutor

- Remove LoadModuleFromHsaco from CudaExecutor (only relevant for Rocm)
- Remove state management variables from CudaExecutor (only used by Rocm)
- Replace map types by flat_hash_map
",copybara-service[bot],2024-10-14 17:54:40+00:00,[],2024-10-15 00:24:08+00:00,2024-10-15 00:24:07+00:00,https://github.com/tensorflow/tensorflow/pull/77869,[],[],
2586675512,pull_request,open,,#sdy use setShardings in xla/shardy.,"#sdy use setShardings in xla/shardy.
",copybara-service[bot],2024-10-14 17:45:26+00:00,[],2024-10-14 17:45:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77868,[],[],
2586632798,pull_request,closed,,Suggest that preemption may be root cause of RPC issues.,"Suggest that preemption may be root cause of RPC issues.
",copybara-service[bot],2024-10-14 17:24:15+00:00,[],2024-10-14 21:12:17+00:00,2024-10-14 21:12:16+00:00,https://github.com/tensorflow/tensorflow/pull/77867,[],[],
2586466374,pull_request,closed,,[XLA:GPU] Fix includes for reduce_scatter_combiner.cc.,"[XLA:GPU] Fix includes for reduce_scatter_combiner.cc.
",copybara-service[bot],2024-10-14 16:01:23+00:00,[],2024-10-15 08:12:46+00:00,2024-10-15 08:12:46+00:00,https://github.com/tensorflow/tensorflow/pull/77866,[],[],
2586443150,pull_request,closed,,[xla:gatherExpander] Extend GatherToLoop transformation to generate correct,"[xla:gatherExpander] Extend GatherToLoop transformation to generate correct
code in the presence of explicit batch dimensions.

Explicit batch dimensions were recently added to gather instructions in
https://github.com/openxla/stablehlo/pull/2084.

This CL extends the pass to consider explicit operand batch dimensions when
computing the while-loop init-value shape and the degenerated slice shape.
",copybara-service[bot],2024-10-14 15:51:38+00:00,['bixia1'],2024-10-20 23:29:15+00:00,2024-10-20 23:29:14+00:00,https://github.com/tensorflow/tensorflow/pull/77865,[],[],
2586372766,pull_request,closed,,#sdy use setShardings in xla/shardy.,"#sdy use setShardings in xla/shardy.
",copybara-service[bot],2024-10-14 15:22:18+00:00,[],2024-10-14 17:42:27+00:00,2024-10-14 17:42:27+00:00,https://github.com/tensorflow/tensorflow/pull/77862,[],[],
2586234453,pull_request,closed,,[xla:gatherExpander] Extend GatherToBroadcast transformation to perform the,"[xla:gatherExpander] Extend GatherToBroadcast transformation to perform the
transformation in the presence of explicit batch dimensions.

Explicit batch dimensions were recently added to gather instructions in
https://github.com/openxla/stablehlo/pull/2084.

This CL extends GatherToBroadcast transformation to handle explicitly batch
dimensions in a similar way that slice-collapsed-dimensions are handled and
adds a test case.
",copybara-service[bot],2024-10-14 14:35:08+00:00,['bixia1'],2024-10-14 19:02:16+00:00,2024-10-14 19:02:14+00:00,https://github.com/tensorflow/tensorflow/pull/77861,[],[],
2586164653,pull_request,closed,,[XLA:GPU] Remove unused SuggestCombinerThreshold method.,"[XLA:GPU] Remove unused SuggestCombinerThreshold method.
",copybara-service[bot],2024-10-14 14:07:04+00:00,[],2024-10-14 14:37:47+00:00,2024-10-14 14:37:46+00:00,https://github.com/tensorflow/tensorflow/pull/77860,[],[],
2586146355,pull_request,closed,,Move stream handle from GpuStream to CudaStream and RocmStream,"Move stream handle from GpuStream to CudaStream and RocmStream

- `gpu_stream()` gets removed from `GpuStream`
- a new getter `stream_handle()` gets added to `CudaStream` and `RocmStream`
- Remaining users of `gpu_stream()` are getting migrated to `stream_handle()`
",copybara-service[bot],2024-10-14 13:59:49+00:00,[],2024-10-14 23:26:14+00:00,2024-10-14 23:26:13+00:00,https://github.com/tensorflow/tensorflow/pull/77859,[],[],
2585777322,pull_request,closed,,[XLA:GPU]: Pack non-scalar int4 constants.,"[XLA:GPU]: Pack non-scalar int4 constants.

When writing non-scalar constants as global constant, we need to pack them if
they have int4 type, because the code that loads int4 values expects them to be
packed.
",copybara-service[bot],2024-10-14 11:42:29+00:00,['akuegel'],2024-10-14 12:33:02+00:00,2024-10-14 12:33:01+00:00,https://github.com/tensorflow/tensorflow/pull/77858,[],[],
2585757278,pull_request,closed,,PR #18213: [NFC] Deduplicate default ShapeSizeBytesFunction and kPointerSize.,"PR #18213: [NFC] Deduplicate default ShapeSizeBytesFunction and kPointerSize.

Imported from GitHub PR https://github.com/openxla/xla/pull/18213


Copybara import of the project:

--
938433747a2037c8ae0d1978976006a12bd9a843 by Ilia Sergachev <isergachev@nvidia.com>:

[NFC] Deduplicate default ShapeSizeBytesFunction and kPointerSize.

Merging this change closes #18213

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18213 from openxla:cleanup_shape_size_fn 938433747a2037c8ae0d1978976006a12bd9a843
",copybara-service[bot],2024-10-14 11:35:11+00:00,[],2024-10-14 15:34:51+00:00,2024-10-14 15:34:50+00:00,https://github.com/tensorflow/tensorflow/pull/77857,[],[],
2585582395,pull_request,closed,,Reverts 27e96c90b98f49940109d3aa50ec87e289958f44,"Reverts 27e96c90b98f49940109d3aa50ec87e289958f44
",copybara-service[bot],2024-10-14 10:32:17+00:00,[],2024-10-14 11:02:33+00:00,2024-10-14 11:02:31+00:00,https://github.com/tensorflow/tensorflow/pull/77856,[],[],
2585538693,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 10:18:48+00:00,[],2024-10-15 04:33:44+00:00,2024-10-15 04:33:44+00:00,https://github.com/tensorflow/tensorflow/pull/77855,[],[],
2585461703,pull_request,open,,Integrate LLVM at llvm/llvm-project@1a787b3c8e71,"Integrate LLVM at llvm/llvm-project@1a787b3c8e71

Updates LLVM usage to match
[1a787b3c8e71](https://github.com/llvm/llvm-project/commit/1a787b3c8e71)
",copybara-service[bot],2024-10-14 09:50:23+00:00,['d0k'],2024-10-14 09:50:25+00:00,,https://github.com/tensorflow/tensorflow/pull/77852,[],[],
2585447028,pull_request,open,,PR #18062: [ROCm] Fix gemm_rewriter_test for AMD GCN Arch,"PR #18062: [ROCm] Fix gemm_rewriter_test for AMD GCN Arch

Imported from GitHub PR https://github.com/openxla/xla/pull/18062

https://github.com/openxla/xla/pull/16841 removes scaling factor constants in gemm_rewriter for FP8 data types. This patch address the same in the gemm_rewriter_test
Copybara import of the project:

--
be4da5b8de0785d43e18dbdb0773307870084e32 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Fix gemm_rewriter_test for AMD GCN Arch

https://github.com/openxla/xla/pull/16841 removes scaling factor
constants in gemm_rewriter for FP8 data types. This patch address
the same in the gemm_rewriter_test

Merging this change closes #18062

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18062 from ROCm:ci_fix_gemm_rewriter_fp8_tests_20241008 be4da5b8de0785d43e18dbdb0773307870084e32
",copybara-service[bot],2024-10-14 09:45:12+00:00,[],2024-10-14 16:12:19+00:00,,https://github.com/tensorflow/tensorflow/pull/77851,[],[],
2585384381,pull_request,closed,,Remove computation_partitioner -> GPU fusion analysis dependency.,"Remove computation_partitioner -> GPU fusion analysis dependency.

The analysis introduces a dependency on all sorts of GPU-specific things.
",copybara-service[bot],2024-10-14 09:22:42+00:00,[],2024-10-14 12:43:47+00:00,2024-10-14 12:43:45+00:00,https://github.com/tensorflow/tensorflow/pull/77850,[],[],
2585232783,pull_request,open,,PR #17259: Adding Strictness level to PGLE accuracy checker.,"PR #17259: Adding Strictness level to PGLE accuracy checker.

Imported from GitHub PR https://github.com/openxla/xla/pull/17259

Values for the new flag: `xla_gpu_pgle_accuracy_checker: {OFF, WARN, ERROR}`
Copybara import of the project:

--
73703e2580be63ed274c064c13243ba14f2db0fd by Shraiysh Vaishay <svaishay@nvidia.com>:

Add xla_gpu_pgle_accuracy_checker to set strictness levels

xla_gpu_pgle_accuracy_checker can take the values {OFF, WARN, ERROR}
and this flag decides what will be done when there are missing
instructions in PGLE profile: either do nothing (OFF), warn about it
(WARN) or halt compilation (ERROR)

Merging this change closes #17259

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17259 from shraiysh:pgle_strictness_levels 73703e2580be63ed274c064c13243ba14f2db0fd
",copybara-service[bot],2024-10-14 08:31:21+00:00,[],2024-10-24 09:06:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77847,[],[],
2585160430,pull_request,closed,,Split up matmul_utils.,"Split up matmul_utils.

matmul_utils depends on ROCm and BLAS, which we usually don't want if we just
care about indexing.
",copybara-service[bot],2024-10-14 08:05:27+00:00,[],2024-10-14 09:36:20+00:00,2024-10-14 09:36:20+00:00,https://github.com/tensorflow/tensorflow/pull/77846,[],[],
2584886756,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 06:14:59+00:00,[],2024-10-15 07:41:26+00:00,2024-10-15 07:41:25+00:00,https://github.com/tensorflow/tensorflow/pull/77845,[],[],
2584659399,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 03:51:23+00:00,[],2024-10-14 03:51:23+00:00,,https://github.com/tensorflow/tensorflow/pull/77842,[],[],
2584622338,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 03:13:06+00:00,[],2024-10-18 06:23:24+00:00,2024-10-18 06:23:23+00:00,https://github.com/tensorflow/tensorflow/pull/77841,[],[],
2584620601,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 03:11:01+00:00,[],2024-10-14 03:11:01+00:00,,https://github.com/tensorflow/tensorflow/pull/77840,[],[],
2584619037,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 03:09:11+00:00,[],2024-10-14 03:09:11+00:00,,https://github.com/tensorflow/tensorflow/pull/77839,[],[],
2584618215,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 03:08:10+00:00,[],2024-10-14 03:08:10+00:00,,https://github.com/tensorflow/tensorflow/pull/77838,[],[],
2584616172,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 03:05:43+00:00,[],2024-10-14 03:05:43+00:00,,https://github.com/tensorflow/tensorflow/pull/77837,[],[],
2584614006,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 03:04:00+00:00,[],2024-10-15 05:20:55+00:00,2024-10-15 05:20:54+00:00,https://github.com/tensorflow/tensorflow/pull/77836,[],[],
2584612451,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 03:02:02+00:00,[],2024-10-14 03:02:02+00:00,,https://github.com/tensorflow/tensorflow/pull/77835,[],[],
2584602955,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 02:57:44+00:00,[],2024-10-14 02:57:44+00:00,,https://github.com/tensorflow/tensorflow/pull/77834,[],[],
2584602749,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 02:57:29+00:00,[],2024-10-14 02:57:29+00:00,,https://github.com/tensorflow/tensorflow/pull/77833,[],[],
2584598638,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 02:55:03+00:00,[],2024-10-14 02:55:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77832,[],[],
2584597374,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 02:53:47+00:00,[],2024-10-14 02:53:47+00:00,,https://github.com/tensorflow/tensorflow/pull/77831,[],[],
2584523087,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-14 01:55:14+00:00,[],2024-10-14 01:55:14+00:00,,https://github.com/tensorflow/tensorflow/pull/77830,[],[],
2584294822,pull_request,closed,,OUT1,,lkeff,2024-10-13 21:40:39+00:00,['gbaned'],2024-10-14 12:12:56+00:00,2024-10-14 12:12:53+00:00,https://github.com/tensorflow/tensorflow/pull/77828,"[('size:M', 'CL Change Size: Medium'), ('invalid', 'Hacktoberfest spam PR')]","[{'comment_id': 2409141156, 'issue_id': 2584294822, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77828/checks?check_run_id=31471905775) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 13, 21, 40, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2410566339, 'issue_id': 2584294822, 'author': 'keerthanakadiri', 'body': 'Hi @lkeff, Can you please sign CLA , thank you !', 'created_at': datetime.datetime(2024, 10, 14, 9, 23, 47, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-13 21:40:43 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77828/checks?check_run_id=31471905775) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

keerthanakadiri on (2024-10-14 09:23:47 UTC): Hi @lkeff, Can you please sign CLA , thank you !

"
2584219021,pull_request,open,,Upgrade Abseil to latest LTS branch (lts_2024_07_22_0).,"Upgrade Abseil to latest LTS branch (lts_2024_07_22_0).
",copybara-service[bot],2024-10-13 19:41:18+00:00,['BrianWieder'],2024-10-13 20:29:56+00:00,,https://github.com/tensorflow/tensorflow/pull/77827,[],[],
2583774050,pull_request,closed,,Update CODE_OF_CONDUCT.md,"Hello there,

Previous CODE_OF_CONDUCT is version 1.4,
I updated CODE_OF_CONDUCT to version 2.1.

please review my PR and suggest me some changes if needed.",Anandha-Vihari,2024-10-13 08:15:03+00:00,['gbaned'],2024-10-14 16:50:42+00:00,2024-10-13 12:42:10+00:00,https://github.com/tensorflow/tensorflow/pull/77818,"[('size:M', 'CL Change Size: Medium')]","[{'comment_id': 2408886260, 'issue_id': 2583774050, 'author': 'Anandha-Vihari', 'body': '@gbaned can you merge my PR', 'created_at': datetime.datetime(2024, 10, 13, 8, 41, 39, tzinfo=datetime.timezone.utc)}]","Anandha-Vihari (Issue Creator) on (2024-10-13 08:41:39 UTC): @gbaned can you merge my PR

"
2583713884,pull_request,closed,,"Improve dataset transformations: added logging, fixed imports, and op…","Added logging throughout dataset transformations for better debugging and traceability.
Improved error handling with detailed exception messages and logging in dataset transformations and iterators.
Fixed undefined variable issue by importing the missing tensor_util module.
Refactored code for readability and maintainability, including improvements to map_and_batch, dense_to_sparse_batch, and iterator classes.
Introduced EnhancedDatasetIterator to provide better logging and handling during dataset iteration.",sanowl,2024-10-13 06:50:30+00:00,['gbaned'],2024-10-24 05:43:26+00:00,2024-10-22 10:21:54+00:00,https://github.com/tensorflow/tensorflow/pull/77817,"[('size:L', 'CL Change Size: Large'), ('invalid', 'Hacktoberfest spam PR'), ('python', 'Pull requests that update Python code')]","[{'comment_id': 2408850804, 'issue_id': 2583713884, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77817/checks?check_run_id=31459366657) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 13, 6, 50, 34, tzinfo=datetime.timezone.utc)}, {'comment_id': 2411124962, 'issue_id': 2583713884, 'author': 'keerthanakadiri', 'body': 'Hi @sanowl, Can you please sign CLA , thank you !', 'created_at': datetime.datetime(2024, 10, 14, 12, 41, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2417364308, 'issue_id': 2583713884, 'author': 'sanowl', 'body': 'yes sorry I will get on it been busy', 'created_at': datetime.datetime(2024, 10, 16, 16, 39, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431867424, 'issue_id': 2583713884, 'author': 'mihaimaruseac', 'body': 'This is starting to look like a spam PR, so I marked it as such', 'created_at': datetime.datetime(2024, 10, 23, 11, 50, 17, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-13 06:50:34 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77817/checks?check_run_id=31459366657) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

keerthanakadiri on (2024-10-14 12:41:12 UTC): Hi @sanowl, Can you please sign CLA , thank you !

sanowl (Issue Creator) on (2024-10-16 16:39:54 UTC): yes sorry I will get on it been busy

mihaimaruseac on (2024-10-23 11:50:17 UTC): This is starting to look like a spam PR, so I marked it as such

"
2583609406,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:43:15+00:00,[],2024-10-13 03:43:15+00:00,,https://github.com/tensorflow/tensorflow/pull/77816,[],[],
2583605653,pull_request,closed,,Refactor management of AHardwareBuffers,"Refactor management of AHardwareBuffers
",copybara-service[bot],2024-10-13 03:42:07+00:00,[],2024-10-15 01:07:12+00:00,2024-10-15 01:07:11+00:00,https://github.com/tensorflow/tensorflow/pull/77815,[],[],
2583605183,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:41:36+00:00,[],2024-10-18 06:49:12+00:00,2024-10-18 06:49:11+00:00,https://github.com/tensorflow/tensorflow/pull/77814,[],[],
2583603589,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:34:42+00:00,[],2024-10-13 03:34:42+00:00,,https://github.com/tensorflow/tensorflow/pull/77813,[],[],
2583603466,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:34:07+00:00,[],2024-10-13 03:34:07+00:00,,https://github.com/tensorflow/tensorflow/pull/77812,[],[],
2583602581,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:30:52+00:00,[],2024-10-13 03:30:52+00:00,,https://github.com/tensorflow/tensorflow/pull/77811,[],[],
2583601498,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:27:03+00:00,[],2024-10-13 03:27:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77810,[],[],
2583601230,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:26:00+00:00,[],2024-10-13 03:26:00+00:00,,https://github.com/tensorflow/tensorflow/pull/77809,[],[],
2583600689,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:24:08+00:00,[],2024-10-13 03:24:08+00:00,,https://github.com/tensorflow/tensorflow/pull/77808,[],[],
2583600453,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:23:08+00:00,[],2024-10-13 03:23:08+00:00,,https://github.com/tensorflow/tensorflow/pull/77807,[],[],
2583599734,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:20:29+00:00,[],2024-10-13 03:20:29+00:00,,https://github.com/tensorflow/tensorflow/pull/77806,[],[],
2583598848,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:17:10+00:00,[],2024-10-13 03:17:10+00:00,,https://github.com/tensorflow/tensorflow/pull/77805,[],[],
2583598376,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 03:15:21+00:00,[],2024-10-13 15:15:28+00:00,2024-10-13 15:15:27+00:00,https://github.com/tensorflow/tensorflow/pull/77804,[],[],
2583572874,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-13 02:09:42+00:00,[],2024-10-13 05:45:32+00:00,2024-10-13 05:45:31+00:00,https://github.com/tensorflow/tensorflow/pull/77803,[],[],
2583565878,pull_request,closed,,Add C++ wrapper classes for a few model-related types,"Add C++ wrapper classes for a few model-related types

Specifically for LrtElementType, LrtLayout, LrtRankedTensorType, LrtTensorBuffer, and LrtTensorBufferRequirements
",copybara-service[bot],2024-10-13 01:45:16+00:00,[],2024-10-15 14:10:37+00:00,2024-10-15 14:10:36+00:00,https://github.com/tensorflow/tensorflow/pull/77802,[],[],
2583456860,pull_request,closed,,Fix build break for Qualcomm on Android,"Fix build break for Qualcomm on Android
",copybara-service[bot],2024-10-12 22:30:15+00:00,[],2024-10-14 21:45:30+00:00,2024-10-14 21:45:30+00:00,https://github.com/tensorflow/tensorflow/pull/77801,[],[],
2583417541,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 21:05:52+00:00,[],2024-10-12 21:05:52+00:00,,https://github.com/tensorflow/tensorflow/pull/77800,[],[],
2583303827,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 18:03:00+00:00,[],2024-10-16 08:32:45+00:00,2024-10-16 08:32:43+00:00,https://github.com/tensorflow/tensorflow/pull/77799,[],[],
2583271168,pull_request,open,,Move GpuDriver PeerAccess functions into the appropriate Executor classes.,"Move GpuDriver PeerAccess functions into the appropriate Executor classes.
",copybara-service[bot],2024-10-12 17:21:14+00:00,[],2024-10-12 17:21:14+00:00,,https://github.com/tensorflow/tensorflow/pull/77798,[],[],
2583096312,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 14:30:12+00:00,[],2024-10-12 14:30:12+00:00,,https://github.com/tensorflow/tensorflow/pull/77796,[],[],
2583015451,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 13:28:26+00:00,[],2024-10-17 04:43:11+00:00,2024-10-17 04:43:10+00:00,https://github.com/tensorflow/tensorflow/pull/77795,[],[],
2583010095,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 13:23:36+00:00,[],2024-10-12 13:23:36+00:00,,https://github.com/tensorflow/tensorflow/pull/77794,[],[],
2583008623,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 13:22:15+00:00,[],2024-10-12 15:43:04+00:00,2024-10-12 15:43:03+00:00,https://github.com/tensorflow/tensorflow/pull/77793,[],[],
2582991523,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 13:07:05+00:00,[],2024-10-17 05:41:54+00:00,2024-10-17 05:41:53+00:00,https://github.com/tensorflow/tensorflow/pull/77792,[],[],
2582967416,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 12:51:48+00:00,[],2024-10-12 17:54:35+00:00,2024-10-12 17:54:35+00:00,https://github.com/tensorflow/tensorflow/pull/77791,[],[],
2582926078,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 12:15:13+00:00,[],2024-10-12 12:15:13+00:00,,https://github.com/tensorflow/tensorflow/pull/77790,[],[],
2582923880,pull_request,open,,[XLA:GPU] Strip newline when dumping the ptxas warning.,"[XLA:GPU] Strip newline when dumping the ptxas warning.

The ptxas output contains trailing newline. Logger adds its own newline, which currently results in ugly empty lines in logs.
",copybara-service[bot],2024-10-12 12:13:08+00:00,[],2024-10-16 08:12:46+00:00,,https://github.com/tensorflow/tensorflow/pull/77789,[],[],
2582912816,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 12:03:05+00:00,[],2024-10-13 21:02:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77788,[],[],
2582903971,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 11:56:03+00:00,[],2024-10-12 11:56:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77787,[],[],
2582886472,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 11:44:35+00:00,[],2024-10-12 13:14:34+00:00,2024-10-12 13:14:33+00:00,https://github.com/tensorflow/tensorflow/pull/77786,[],[],
2582873229,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 11:36:29+00:00,[],2024-10-12 14:33:10+00:00,,https://github.com/tensorflow/tensorflow/pull/77785,[],[],
2582779778,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 10:25:23+00:00,[],2024-10-15 10:41:38+00:00,2024-10-15 10:41:37+00:00,https://github.com/tensorflow/tensorflow/pull/77784,[],[],
2582724283,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 09:30:24+00:00,[],2024-10-12 09:30:24+00:00,,https://github.com/tensorflow/tensorflow/pull/77783,[],[],
2582713872,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 09:11:37+00:00,[],2024-10-12 13:23:31+00:00,,https://github.com/tensorflow/tensorflow/pull/77782,[],[],
2582713351,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 09:10:18+00:00,[],2024-10-12 09:10:18+00:00,,https://github.com/tensorflow/tensorflow/pull/77781,[],[],
2582711329,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 09:05:05+00:00,[],2024-10-12 09:05:05+00:00,,https://github.com/tensorflow/tensorflow/pull/77780,[],[],
2582710100,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 09:02:09+00:00,[],2024-10-12 16:16:46+00:00,2024-10-12 16:16:45+00:00,https://github.com/tensorflow/tensorflow/pull/77779,[],[],
2582709950,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 09:01:45+00:00,[],2024-10-12 15:02:02+00:00,,https://github.com/tensorflow/tensorflow/pull/77778,[],[],
2582709002,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 08:59:55+00:00,[],2024-10-12 08:59:55+00:00,,https://github.com/tensorflow/tensorflow/pull/77777,[],[],
2582707733,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 08:58:26+00:00,[],2024-10-12 15:25:52+00:00,,https://github.com/tensorflow/tensorflow/pull/77776,[],[],
2582707219,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 08:57:47+00:00,[],2024-10-15 10:06:30+00:00,2024-10-15 10:06:29+00:00,https://github.com/tensorflow/tensorflow/pull/77775,[],[],
2582681247,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 08:22:53+00:00,[],2024-10-12 10:43:21+00:00,,https://github.com/tensorflow/tensorflow/pull/77774,[],[],
2582677758,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 08:14:08+00:00,[],2024-10-16 08:52:26+00:00,2024-10-16 08:52:25+00:00,https://github.com/tensorflow/tensorflow/pull/77773,[],[],
2582628101,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 07:00:32+00:00,[],2024-10-12 07:00:32+00:00,,https://github.com/tensorflow/tensorflow/pull/77772,[],[],
2582627280,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 06:59:24+00:00,[],2024-10-12 10:18:42+00:00,,https://github.com/tensorflow/tensorflow/pull/77771,[],[],
2582623992,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 06:56:48+00:00,[],2024-10-12 06:56:48+00:00,,https://github.com/tensorflow/tensorflow/pull/77770,[],[],
2582613389,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 06:43:06+00:00,[],2024-10-12 06:43:06+00:00,,https://github.com/tensorflow/tensorflow/pull/77769,[],[],
2582612646,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 06:41:58+00:00,[],2024-10-12 16:27:59+00:00,2024-10-12 16:27:57+00:00,https://github.com/tensorflow/tensorflow/pull/77768,[],[],
2582598649,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 06:24:23+00:00,[],2024-10-12 13:29:53+00:00,2024-10-12 13:29:52+00:00,https://github.com/tensorflow/tensorflow/pull/77767,[],[],
2582560588,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 05:24:34+00:00,[],2024-10-12 08:11:38+00:00,,https://github.com/tensorflow/tensorflow/pull/77766,[],[],
2582516471,pull_request,closed,,[IFRT] Do not include devices while populating atom program metadata.,"[IFRT] Do not include devices while populating atom program metadata.
",copybara-service[bot],2024-10-12 04:38:58+00:00,[],2024-10-14 23:17:47+00:00,2024-10-14 23:17:46+00:00,https://github.com/tensorflow/tensorflow/pull/77765,[],[],
2582477073,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 04:07:22+00:00,[],2024-10-12 05:51:18+00:00,,https://github.com/tensorflow/tensorflow/pull/77764,[],[],
2582443379,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 03:19:39+00:00,[],2024-10-15 03:43:53+00:00,2024-10-15 03:43:52+00:00,https://github.com/tensorflow/tensorflow/pull/77763,[],[],
2582441569,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 03:14:42+00:00,[],2024-10-15 06:04:16+00:00,2024-10-15 06:04:15+00:00,https://github.com/tensorflow/tensorflow/pull/77762,[],[],
2582441383,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-12 03:14:14+00:00,[],2024-10-12 03:14:14+00:00,,https://github.com/tensorflow/tensorflow/pull/77761,[],[],
2582436632,pull_request,closed,,Automated Code Change.,"Automated Code Change.
",copybara-service[bot],2024-10-12 03:01:00+00:00,[],2024-10-21 16:55:18+00:00,2024-10-21 16:55:17+00:00,https://github.com/tensorflow/tensorflow/pull/77760,[],[],
2582401058,pull_request,closed,,Refactor test to directly use the distributed service API instead of the lower-level impl details.,"Refactor test to directly use the distributed service API instead of the lower-level impl details.
",copybara-service[bot],2024-10-12 01:39:36+00:00,[],2024-10-21 20:25:12+00:00,2024-10-21 20:25:11+00:00,https://github.com/tensorflow/tensorflow/pull/77758,[],[],
2582385675,pull_request,closed,,Convert reference variable to resource variable,"Convert reference variable to resource variable
",copybara-service[bot],2024-10-12 01:05:53+00:00,[],2024-10-14 05:38:00+00:00,2024-10-14 05:37:59+00:00,https://github.com/tensorflow/tensorflow/pull/77757,[],[],
2582384837,pull_request,open,,Reverts 4689b7aff63d1b63f4fdae2c619ae07049de85e6,"Reverts 4689b7aff63d1b63f4fdae2c619ae07049de85e6
",copybara-service[bot],2024-10-12 01:03:36+00:00,[],2024-10-14 21:21:27+00:00,,https://github.com/tensorflow/tensorflow/pull/77756,[],[],
2582384624,pull_request,closed,,[XLA:GPU] form async-start and async-done HLOs that contain multiple send and recv instructions,"[XLA:GPU] form async-start and async-done HLOs that contain multiple send and recv instructions
",copybara-service[bot],2024-10-12 01:03:01+00:00,[],2024-11-01 18:31:27+00:00,2024-11-01 18:31:26+00:00,https://github.com/tensorflow/tensorflow/pull/77755,[],[],
2582371867,pull_request,closed,,Tuple Util: add GetTupleInstructionAtIndex util.,"Tuple Util: add GetTupleInstructionAtIndex util.
",copybara-service[bot],2024-10-12 00:33:48+00:00,[],2024-10-22 00:47:14+00:00,2024-10-22 00:47:12+00:00,https://github.com/tensorflow/tensorflow/pull/77754,[],[],
2582352768,pull_request,closed,,Integrate LLVM at llvm/llvm-project@efcfa6e71168,"Integrate LLVM at llvm/llvm-project@efcfa6e71168

Updates LLVM usage to match
[efcfa6e71168](https://github.com/llvm/llvm-project/commit/efcfa6e71168)
",copybara-service[bot],2024-10-11 23:57:59+00:00,[],2024-10-14 03:58:59+00:00,2024-10-14 03:58:58+00:00,https://github.com/tensorflow/tensorflow/pull/77753,[],[],
2582338999,pull_request,closed,,Move SetName/GetName into CudaStream/RocmStream,"Move SetName/GetName into CudaStream/RocmStream

- Renames name() to GetName() and set_name() to SetName()
- Adds default implementations to StreamCommon
- Makes CudaStream override the default implementation of `SetName` because it also needs to call `tsl::profiler::NameStream`
- Don't do that for ROCm since it's only supported on CUDA
- Adds super basic unit test
",copybara-service[bot],2024-10-11 23:41:32+00:00,[],2024-10-14 22:00:18+00:00,2024-10-14 22:00:18+00:00,https://github.com/tensorflow/tensorflow/pull/77752,[],[],
2582321909,pull_request,closed,,Move GpuDriver::GetPointerAddressRange into the appropriate StreamExecutor classes.,"Move GpuDriver::GetPointerAddressRange into the appropriate StreamExecutor classes.
",copybara-service[bot],2024-10-11 23:24:33+00:00,[],2024-10-14 18:47:46+00:00,2024-10-14 18:47:45+00:00,https://github.com/tensorflow/tensorflow/pull/77751,[],[],
2582293883,pull_request,closed,,Move LaunchKernel into Cuda/RocmStream,"Move LaunchKernel into Cuda/RocmStream

- Moves the LaunchKernel function from GpuStream to Rocm/CudaStream
- Moves the corresponding GpuDriver functions into Rocm/CudaStream as well
- Adds a basic unit test
",copybara-service[bot],2024-10-11 22:47:10+00:00,[],2024-10-14 17:32:10+00:00,2024-10-14 17:32:09+00:00,https://github.com/tensorflow/tensorflow/pull/77750,[],[],
2582289049,pull_request,closed,,"[MHLO] Split canonicalizer and folder tests, alphabetize","[MHLO] Split canonicalizer and folder tests, alphabetize
",copybara-service[bot],2024-10-11 22:41:57+00:00,['GleasonK'],2024-10-14 16:12:12+00:00,2024-10-14 16:12:11+00:00,https://github.com/tensorflow/tensorflow/pull/77749,[],[],
2582272319,pull_request,closed,,Add vim to the ML Build Docker container.,"Add vim to the ML Build Docker container.
",copybara-service[bot],2024-10-11 22:25:19+00:00,['quoctruong'],2024-10-11 22:54:21+00:00,2024-10-11 22:54:20+00:00,https://github.com/tensorflow/tensorflow/pull/77748,[],[],
2582261175,pull_request,open,,Add OP mappings.,"Add OP mappings.
Add parameterized tests for example OPs.
Fix a typo in op_code.
Add I32, Bool to supported types.
Fix transpose OP file name.
Move none from variable to arguments in fully_connected OP.
",copybara-service[bot],2024-10-11 22:10:52+00:00,[],2024-10-11 22:10:52+00:00,,https://github.com/tensorflow/tensorflow/pull/77747,[],[],
2582260510,pull_request,closed,,Add requirements for running TF wheel API test with Numpy 1.x.x build.,"Add requirements for running TF wheel API test with Numpy 1.x.x build.
",copybara-service[bot],2024-10-11 22:09:57+00:00,[],2024-10-11 22:43:02+00:00,2024-10-11 22:43:01+00:00,https://github.com/tensorflow/tensorflow/pull/77746,[],[],
2582260078,pull_request,closed,,* Add option in LrtOp.,"* Add option in LrtOp.
* Add GetOptions* c APIs.
* Support test case covered builtin options.
* Add test cases for GetOptions* APIs.
",copybara-service[bot],2024-10-11 22:09:22+00:00,[],2024-10-15 04:42:39+00:00,2024-10-15 04:42:38+00:00,https://github.com/tensorflow/tensorflow/pull/77745,[],[],
2582251960,pull_request,closed,,Move GpuDriver HostAllocate and HostDeallocate functions into the proper Executor classes.,"Move GpuDriver HostAllocate and HostDeallocate functions into the proper Executor classes.
",copybara-service[bot],2024-10-11 21:59:39+00:00,[],2024-10-13 17:12:37+00:00,2024-10-13 17:12:36+00:00,https://github.com/tensorflow/tensorflow/pull/77744,[],[],
2582250686,pull_request,closed,,Move GpuDriver::GetPointerMemorySpace to the appropriate Executor classes.,"Move GpuDriver::GetPointerMemorySpace to the appropriate Executor classes.
",copybara-service[bot],2024-10-11 21:58:31+00:00,[],2024-10-13 01:19:32+00:00,2024-10-13 01:19:31+00:00,https://github.com/tensorflow/tensorflow/pull/77743,[],[],
2582250157,pull_request,closed,,Move GpuDriver SynchronousMemcpy functions to appropriate Executor classes.,"Move GpuDriver SynchronousMemcpy functions to appropriate Executor classes.
",copybara-service[bot],2024-10-11 21:58:04+00:00,[],2024-10-13 23:29:59+00:00,2024-10-13 23:29:58+00:00,https://github.com/tensorflow/tensorflow/pull/77742,[],[],
2582250056,pull_request,closed,,"Stop using gpu_types.h aliases where possible, and eliminate the aliases that are now unused.","Stop using gpu_types.h aliases where possible, and eliminate the aliases that are now unused.
",copybara-service[bot],2024-10-11 21:57:59+00:00,[],2024-10-14 00:17:53+00:00,2024-10-14 00:17:52+00:00,https://github.com/tensorflow/tensorflow/pull/77741,[],[],
2582249688,pull_request,closed,,Move GpuDriver::GetDeviceProperties to RocmExecutor.,"Move GpuDriver::GetDeviceProperties to RocmExecutor.
",copybara-service[bot],2024-10-11 21:57:39+00:00,[],2024-10-12 23:44:01+00:00,2024-10-12 23:44:00+00:00,https://github.com/tensorflow/tensorflow/pull/77740,[],[],
2582248957,pull_request,closed,,Move GpuDriver synchronous Memset functionality into proper Executor classes.,"Move GpuDriver synchronous Memset functionality into proper Executor classes.
",copybara-service[bot],2024-10-11 21:56:58+00:00,[],2024-10-13 21:53:13+00:00,2024-10-13 21:53:12+00:00,https://github.com/tensorflow/tensorflow/pull/77739,[],[],
2582248573,pull_request,closed,,Move GpuDriver HostRegister & Unregister into CudaExecutor.,"Move GpuDriver HostRegister & Unregister into CudaExecutor.
",copybara-service[bot],2024-10-11 21:56:38+00:00,[],2024-10-13 15:54:56+00:00,2024-10-13 15:54:55+00:00,https://github.com/tensorflow/tensorflow/pull/77738,[],[],
2582246701,pull_request,closed,,Move GpuDriver UnifiedMemory functions into appropriate Executor classes.,"Move GpuDriver UnifiedMemory functions into appropriate Executor classes.
",copybara-service[bot],2024-10-11 21:55:19+00:00,[],2024-10-15 12:05:33+00:00,2024-10-13 15:03:46+00:00,https://github.com/tensorflow/tensorflow/pull/77737,[],[],
2582246693,pull_request,closed,,Move GpuDriver::Init to the appropriate Platform objects.,"Move GpuDriver::Init to the appropriate Platform objects.
",copybara-service[bot],2024-10-11 21:55:19+00:00,[],2024-10-14 06:46:51+00:00,2024-10-14 06:46:50+00:00,https://github.com/tensorflow/tensorflow/pull/77736,[],[],
2582245909,pull_request,closed,,Add README.md to HLO transformation passes folders.,"Add README.md to HLO transformation passes folders.
",copybara-service[bot],2024-10-11 21:54:51+00:00,[],2024-10-14 19:45:25+00:00,2024-10-14 19:45:24+00:00,https://github.com/tensorflow/tensorflow/pull/77735,[],[],
2582245294,pull_request,closed,,Move GpuDriver::DeviceAllocate functionality into appropriate Executor classes.,"Move GpuDriver::DeviceAllocate functionality into appropriate Executor classes.
",copybara-service[bot],2024-10-11 21:54:25+00:00,[],2024-10-13 06:09:54+00:00,2024-10-13 06:09:53+00:00,https://github.com/tensorflow/tensorflow/pull/77734,[],[],
2582243236,pull_request,closed,,Move GpuDriver::GetPCIBusId into the appropriate Executor classes.,"Move GpuDriver::GetPCIBusId into the appropriate Executor classes.

This is the last use of GpuDeviceHandle in gpu_driver.h, so removing that type alias as well.
",copybara-service[bot],2024-10-11 21:52:56+00:00,[],2024-10-12 21:56:14+00:00,2024-10-12 21:56:13+00:00,https://github.com/tensorflow/tensorflow/pull/77733,[],[],
