id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2383009049,pull_request,closed,,[XLA:GPU] Move `triton_gpu.sparse_dot` conversion to LLVM pattern from Triton patch (`convert-triton-gpu-to-llvm` pass) to OpenXLA (`sparse-dot-to-llvm` pass).,"[XLA:GPU] Move `triton_gpu.sparse_dot` conversion to LLVM pattern from Triton patch (`convert-triton-gpu-to-llvm` pass) to OpenXLA (`sparse-dot-to-llvm` pass).

This relands a previous change, but this time the pattern is applied in a pass after `convert-triton-gpu-to-llvm` instead of before, which prevents an out-of-bounds access during axis analysis.

Reverts 80f36caf93bc5adf6591d381c8a5a68dbf441fc2
",copybara-service[bot],2024-07-01 06:57:49+00:00,['chsigg'],2024-07-01 10:30:49+00:00,2024-07-01 10:30:48+00:00,https://github.com/tensorflow/tensorflow/pull/70675,[],[],
2382964422,pull_request,closed,,Update google/fuzztest dependency.,"Update google/fuzztest dependency.
",copybara-service[bot],2024-07-01 06:32:29+00:00,[],2024-07-01 08:20:13+00:00,2024-07-01 08:20:11+00:00,https://github.com/tensorflow/tensorflow/pull/70674,[],[],
2382864052,pull_request,open,,PR #14266: [XLA:GPU] Add command buffer custom call targets recording for legacy custom call registry API,"PR #14266: [XLA:GPU] Add command buffer custom call targets recording for legacy custom call registry API

Imported from GitHub PR https://github.com/openxla/xla/pull/14266

This PR enabling lowering TE custom call kernels to command buffer through white list, this is a temporal support as 3rd library call should register command buffer support through FFI API, will remove this temporal support when TE has finished FFI API migration. 
Copybara import of the project:

--
32c3d05c00d10698730e5adea8b06c2a02af39d9 by Shawn Wang <shawnw@nvidia.com>:

Add legayc custom call targets registry to command buffer

--
df2e5adcca71df12839284e9028087755785fee5 by Shawn Wang <shawnw@nvidia.com>:

fix unit test fail

--
88edf99cdc93be473686a63d51c32de47017cdc1 by Shawn Wang <shawnw@nvidia.com>:

fix typos

Merging this change closes #14266
",copybara-service[bot],2024-07-01 05:29:11+00:00,[],2024-07-01 05:29:11+00:00,,https://github.com/tensorflow/tensorflow/pull/70671,[],[],
2382556081,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-01 01:01:15+00:00,[],2024-07-01 01:01:15+00:00,,https://github.com/tensorflow/tensorflow/pull/70669,[],[],
2382510952,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-01 00:03:06+00:00,[],2024-07-01 00:03:06+00:00,,https://github.com/tensorflow/tensorflow/pull/70668,[],[],
2382501136,pull_request,closed,,PR #14266: [XLA:GPU] Add command buffer custom call targets recording for legacy custom call registry API,"PR #14266: [XLA:GPU] Add command buffer custom call targets recording for legacy custom call registry API

Imported from GitHub PR https://github.com/openxla/xla/pull/14266

This PR enabling lowering TE custom call kernels to command buffer through white list, this is a temporal support as 3rd library call should register command buffer support through FFI API, will remove this temporal support when TE has finished FFI API migration. 
Copybara import of the project:

--
32c3d05c00d10698730e5adea8b06c2a02af39d9 by Shawn Wang <shawnw@nvidia.com>:

Add legayc custom call targets registry to command buffer

--
df2e5adcca71df12839284e9028087755785fee5 by Shawn Wang <shawnw@nvidia.com>:

fix unit test fail

--
88edf99cdc93be473686a63d51c32de47017cdc1 by Shawn Wang <shawnw@nvidia.com>:

fix typos

Merging this change closes #14266

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14266 from shawnwang18:shawnw/temporal_command_buffer_support_te 88edf99cdc93be473686a63d51c32de47017cdc1
",copybara-service[bot],2024-06-30 23:39:40+00:00,[],2024-07-02 13:09:17+00:00,2024-07-02 13:09:16+00:00,https://github.com/tensorflow/tensorflow/pull/70667,[],"[{'comment_id': 2198805860, 'issue_id': 2382501136, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70667/checks?check_run_id=26865465567) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 6, 30, 23, 39, 45, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-06-30 23:39:45 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70667/checks?check_run_id=26865465567) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2382494563,pull_request,closed,,[xla:ffi] Use lazy decoding for AnyBuffer,"[xla:ffi] Use lazy decoding for AnyBuffer

Make external AnyBuffer consistent with internal one.

name                old cpu/op   new cpu/op   delta
BM_AnyBufferArgX1   12.8ns ± 9%  11.9ns ±16%   -7.35%  (p=0.000 n=80+80)
BM_AnyBufferArgX4   19.5ns ± 6%  13.1ns ±12%  -32.89%  (p=0.000 n=80+79)
BM_BufferArgX1      13.1ns ± 6%  13.1ns ± 6%     ~     (p=0.616 n=80+79)
BM_BufferArgX4      20.3ns ± 7%  20.0ns ± 6%   -1.81%  (p=0.000 n=80+79)
BM_BufferArgX8      41.5ns ± 4%  36.6ns ± 6%  -11.78%  (p=0.000 n=79+80)
BM_TupleOfI32Attrs  66.2ns ± 2%  66.2ns ± 1%     ~     (p=0.250 n=62+59)
",copybara-service[bot],2024-06-30 23:20:35+00:00,['ezhulenev'],2024-07-03 22:07:15+00:00,2024-07-03 22:07:15+00:00,https://github.com/tensorflow/tensorflow/pull/70666,[],[],
2382457714,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-30 21:42:21+00:00,[],2024-06-30 21:42:21+00:00,,https://github.com/tensorflow/tensorflow/pull/70665,[],[],
2382335332,pull_request,closed,,In this change we rename GetShardedInstructionSize to ByteSizeOfShapeIfShardedAcrossDevices.,"In this change we rename GetShardedInstructionSize to ByteSizeOfShapeIfShardedAcrossDevices.
",copybara-service[bot],2024-06-30 16:46:22+00:00,[],2024-07-01 16:48:41+00:00,2024-07-01 16:48:39+00:00,https://github.com/tensorflow/tensorflow/pull/70663,[],[],
2382332511,pull_request,closed,,Update cpuinfo git version dependency,"Update cpuinfo git version dependency
",copybara-service[bot],2024-06-30 16:38:35+00:00,[],2024-11-18 20:57:58+00:00,2024-11-18 20:57:57+00:00,https://github.com/tensorflow/tensorflow/pull/70662,[],[],
2382324280,pull_request,closed,,Augmenting run_hlo_module to run StableHLO or MHLO programs.,"Augmenting run_hlo_module to run StableHLO or MHLO programs.
",copybara-service[bot],2024-06-30 16:16:52+00:00,['sdasgup3'],2024-06-30 22:39:26+00:00,2024-06-30 22:39:25+00:00,https://github.com/tensorflow/tensorflow/pull/70661,[],[],
2382251743,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-30 13:18:33+00:00,[],2024-06-30 13:18:33+00:00,,https://github.com/tensorflow/tensorflow/pull/70660,[],[],
2382164478,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-30 09:18:11+00:00,[],2024-06-30 09:18:11+00:00,,https://github.com/tensorflow/tensorflow/pull/70657,[],[],
2382157253,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-30 08:58:02+00:00,[],2024-06-30 08:58:02+00:00,,https://github.com/tensorflow/tensorflow/pull/70656,[],[],
2382156903,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-30 08:56:55+00:00,[],2024-06-30 08:56:55+00:00,,https://github.com/tensorflow/tensorflow/pull/70655,[],[],
2382154305,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-30 08:49:02+00:00,[],2024-06-30 08:49:02+00:00,,https://github.com/tensorflow/tensorflow/pull/70654,[],[],
2382044961,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-30 01:49:52+00:00,[],2024-06-30 01:49:52+00:00,,https://github.com/tensorflow/tensorflow/pull/70653,[],[],
2382019820,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-30 00:20:44+00:00,[],2024-06-30 00:20:44+00:00,,https://github.com/tensorflow/tensorflow/pull/70652,[],[],
2382012243,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 23:54:38+00:00,[],2024-06-29 23:54:38+00:00,,https://github.com/tensorflow/tensorflow/pull/70651,[],[],
2382005077,pull_request,closed,,[xla:ffi] NFC: Optimize arguments decoding check,"[xla:ffi] NFC: Optimize arguments decoding check

Use `&` instead of `&&` to reduce the number of branches as we don't care about performance of the error handling path.

name                old cpu/op   new cpu/op   delta
BM_AnyBufferArgX1   13.8ns ±11%  13.7ns ± 9%     ~     (p=0.909 n=80+80)
BM_AnyBufferArgX4   15.2ns ± 8%  15.1ns ± 8%     ~     (p=0.096 n=79+80)
BM_AnyBufferArgX8   20.0ns ± 3%  17.6ns ± 9%  -11.82%  (p=0.000 n=64+80)
BM_BufferArgX1      14.3ns ±11%  14.3ns ±10%     ~     (p=0.604 n=80+80)
BM_BufferArgX4      16.5ns ± 8%  16.5ns ± 7%     ~     (p=0.289 n=80+80)
BM_BufferArgX8      24.5ns ± 8%  22.6ns ± 7%   -7.57%  (p=0.000 n=80+80)
BM_TupleOfI32Attrs  67.9ns ± 1%  67.9ns ± 2%     ~     (p=0.961 n=66+68)
",copybara-service[bot],2024-06-29 23:15:13+00:00,['ezhulenev'],2024-07-03 21:28:24+00:00,2024-07-03 21:28:23+00:00,https://github.com/tensorflow/tensorflow/pull/70650,[],[],
2382001651,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 23:00:32+00:00,[],2024-07-02 08:25:57+00:00,2024-07-02 08:25:56+00:00,https://github.com/tensorflow/tensorflow/pull/70649,[],[],
2382001421,pull_request,closed,,"[xla:ffi] Use lazy decoding for Buffer<dtype, rank>","[xla:ffi] Use lazy decoding for Buffer<dtype, rank>

name                old cpu/op   new cpu/op   delta
BM_AnyBufferArgX1   14.0ns ±10%  13.7ns ±10%   -2.35%  (p=0.041 n=40+40)
BM_AnyBufferArgX4   15.0ns ± 7%  15.0ns ± 7%     ~     (p=0.862 n=40+40)
BM_AnyBufferArgX8   19.6ns ± 5%  19.6ns ± 6%     ~     (p=0.966 n=40+40)
BM_BufferArgX1      15.6ns ± 7%  14.2ns ± 9%   -9.48%  (p=0.000 n=40+40)
BM_BufferArgX4      27.0ns ± 4%  16.2ns ± 7%  -39.81%  (p=0.000 n=40+40)
BM_BufferArgX8      51.7ns ± 4%  24.2ns ±10%  -53.20%  (p=0.000 n=40+40)
BM_TupleOfI32Attrs  67.8ns ± 3%  67.5ns ± 3%     ~     (p=0.063 n=40+40)
",copybara-service[bot],2024-06-29 22:59:28+00:00,['ezhulenev'],2024-07-03 20:34:12+00:00,2024-07-03 20:34:11+00:00,https://github.com/tensorflow/tensorflow/pull/70648,[],[],
2381998263,pull_request,closed,,[xla:cpu] Pre-construct call frames for typed-FFI custom calls in the thunk runtime.,"[xla:cpu] Pre-construct call frames for typed-FFI custom calls in the thunk runtime.

Pre-contruct the call frame at compile time when creating the CustomCall thunk instead of constructing on-the-fly while running the thunk. Since only device memory addresses change at runtime, we can pre-populate a prototype call frame with attributes and other buffer information, then update the addresses when the thunk is executed.

Also add benchmarks to measure the difference. Must run with `XLA_FLAGS=--xla_cpu_use_thunk_runtime=true`.

Thunk runtime (this commit, ""new"") vs thunk runtime (previous commit, ""old""):
name                                        old cpu/op   new cpu/op   delta
BM_CustomCall_Minimal/process_time           944ns ± 3%   853ns ± 0%   -9.64%  (p=0.016 n=5+4)
BM_CustomCall_16IntAttributes/process_time  29.9µs ± 2%   1.0µs ± 5%  -96.58%  (p=0.008 n=5+5)
BM_CustomCall_16FloatBuffers/process_time   3.23µs ± 1%  2.79µs ± 2%  -13.44%  (p=0.008 n=5+5)

Thunk runtime (this commit, ""new"") vs classic runtime (""old""):
name                                        old cpu/op   new cpu/op   delta
BM_CustomCall_Minimal/process_time           852ns ± 4%   873ns ± 3%     ~     (p=0.151 n=5+5)
BM_CustomCall_16IntAttributes/process_time  30.1µs ± 2%   1.0µs ± 0%  -96.67%  (p=0.016 n=5+4)
BM_CustomCall_16FloatBuffers/process_time   3.27µs ± 5%  2.81µs ± 3%  -13.94%  (p=0.008 n=5+5)
",copybara-service[bot],2024-06-29 22:42:28+00:00,['penpornk'],2024-06-29 23:14:07+00:00,2024-06-29 23:14:06+00:00,https://github.com/tensorflow/tensorflow/pull/70647,[],[],
2381975015,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 21:34:16+00:00,[],2024-07-02 05:06:40+00:00,2024-07-02 05:06:39+00:00,https://github.com/tensorflow/tensorflow/pull/70646,[],[],
2381953442,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 20:44:57+00:00,[],2024-06-29 20:44:57+00:00,,https://github.com/tensorflow/tensorflow/pull/70645,[],[],
2381946286,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 20:15:38+00:00,[],2024-06-29 20:15:38+00:00,,https://github.com/tensorflow/tensorflow/pull/70644,[],[],
2381946140,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 20:15:05+00:00,[],2024-07-02 05:35:13+00:00,2024-07-02 05:35:13+00:00,https://github.com/tensorflow/tensorflow/pull/70643,[],[],
2381945920,pull_request,closed,,[xla:ffi] NFC: Use statically known buffer rank to compute size in bytes,"[xla:ffi] NFC: Use statically known buffer rank to compute size in bytes

name                old cpu/op   new cpu/op   delta
BM_AnyBufferArgX1   20.8ns ± 5%  20.5ns ± 6%   -1.45%  (p=0.024 n=39+40)
BM_AnyBufferArgX4   52.4ns ± 3%  52.4ns ± 2%     ~     (p=0.983 n=39+36)
BM_BufferArgX1      16.5ns ± 3%  15.5ns ± 6%   -6.32%  (p=0.000 n=38+40)
BM_BufferArgX4      35.6ns ± 3%  26.8ns ± 4%  -24.72%  (p=0.000 n=38+37)
BM_BufferArgX8      68.0ns ± 3%  52.0ns ± 5%  -23.54%  (p=0.000 n=38+40)
BM_TupleOfI32Attrs  67.8ns ± 2%  67.6ns ± 2%     ~     (p=0.218 n=37+39)
",copybara-service[bot],2024-06-29 20:14:10+00:00,['ezhulenev'],2024-07-01 22:17:39+00:00,2024-07-01 22:17:38+00:00,https://github.com/tensorflow/tensorflow/pull/70642,[],[],
2381909402,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 18:38:31+00:00,[],2024-06-29 18:38:31+00:00,,https://github.com/tensorflow/tensorflow/pull/70641,[],[],
2381830934,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 16:05:57+00:00,[],2024-06-29 16:05:57+00:00,,https://github.com/tensorflow/tensorflow/pull/70640,[],[],
2381763495,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 13:53:28+00:00,[],2024-06-29 13:53:28+00:00,,https://github.com/tensorflow/tensorflow/pull/70639,[],[],
2381689027,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 11:35:22+00:00,[],2024-06-29 11:35:22+00:00,,https://github.com/tensorflow/tensorflow/pull/70638,[],[],
2381666111,pull_request,closed,,Clean up reduction output indexing code.,"Clean up reduction output indexing code.

There's a lot of shared logic between row reduction and column
reduction. For input indexing, we already have the common parts
in the base class. With this CL, the same is done for output
indices.
",copybara-service[bot],2024-06-29 10:53:08+00:00,[],2024-07-01 09:58:56+00:00,2024-07-01 09:58:55+00:00,https://github.com/tensorflow/tensorflow/pull/70637,[],[],
2381650322,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 10:28:54+00:00,[],2024-07-02 04:47:28+00:00,2024-07-02 04:47:28+00:00,https://github.com/tensorflow/tensorflow/pull/70636,[],[],
2381593590,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 09:02:21+00:00,[],2024-06-29 09:38:03+00:00,,https://github.com/tensorflow/tensorflow/pull/70635,[],[],
2381588639,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 08:46:26+00:00,[],2024-07-01 06:40:17+00:00,2024-07-01 06:40:17+00:00,https://github.com/tensorflow/tensorflow/pull/70634,[],[],
2381584114,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 08:31:40+00:00,[],2024-06-29 08:31:40+00:00,,https://github.com/tensorflow/tensorflow/pull/70633,[],[],
2381566876,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 07:50:57+00:00,[],2024-06-29 10:09:07+00:00,2024-06-29 10:09:06+00:00,https://github.com/tensorflow/tensorflow/pull/70632,[],[],
2381541112,pull_request,closed,,[xla:ffi] Use lazy decoding for AnyBuffer,"[xla:ffi] Use lazy decoding for AnyBuffer

Make AnyBuffer API more consistent with other XLA APIs (xla::Literal). Also use lazy decoding to make expensive computations (i.e., size in byte) only if needed.

name                old cpu/op   new cpu/op   delta
BM_AnyBufferArgX1   20.6ns ± 7%  13.9ns ±11%  -32.54%  (p=0.000 n=39+40)
BM_AnyBufferArgX4   53.8ns ± 5%  15.0ns ± 8%  -72.05%  (p=0.000 n=40+40)
BM_AnyBufferArgX8   97.0ns ± 4%  19.8ns ± 7%  -79.60%  (p=0.000 n=39+40)
BM_BufferArgX1      15.6ns ± 7%  15.6ns ± 7%     ~     (p=0.781 n=39+40)
BM_BufferArgX4      28.4ns ±10%  27.0ns ± 5%   -5.00%  (p=0.000 n=40+39)
BM_BufferArgX8      51.9ns ± 6%  51.5ns ± 6%     ~     (p=0.145 n=39+40)
BM_TupleOfI32Attrs  67.9ns ± 2%  67.7ns ± 3%     ~     (p=0.249 n=40+39)
",copybara-service[bot],2024-06-29 06:56:26+00:00,['ezhulenev'],2024-07-02 00:11:28+00:00,2024-07-02 00:11:28+00:00,https://github.com/tensorflow/tensorflow/pull/70631,[],[],
2381508307,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 05:32:24+00:00,[],2024-06-29 05:32:24+00:00,,https://github.com/tensorflow/tensorflow/pull/70630,[],[],
2381496486,pull_request,closed,,Integrate LLVM at llvm/llvm-project@4713bd4ccc0c,"Integrate LLVM at llvm/llvm-project@4713bd4ccc0c

Updates LLVM usage to match
[4713bd4ccc0c](https://github.com/llvm/llvm-project/commit/4713bd4ccc0c)
",copybara-service[bot],2024-06-29 05:11:03+00:00,[],2024-06-29 19:08:49+00:00,2024-06-29 19:08:48+00:00,https://github.com/tensorflow/tensorflow/pull/70629,[],[],
2381488937,pull_request,closed,,[XLA:SPMD] Fix sharding propagation for kGetTupleElement not generating correct sharding shape with subgroup manual.,"[XLA:SPMD] Fix sharding propagation for kGetTupleElement not generating correct sharding shape with subgroup manual.
",copybara-service[bot],2024-06-29 05:00:06+00:00,['Tongfei-Guo'],2024-07-08 17:56:24+00:00,2024-07-08 17:56:24+00:00,https://github.com/tensorflow/tensorflow/pull/70628,[],[],
2381447631,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-29 03:57:50+00:00,[],2024-06-29 03:57:50+00:00,,https://github.com/tensorflow/tensorflow/pull/70627,[],[],
2381424937,pull_request,open,,Adds a dedicated constructor to CostGraph for testing.,"Adds a dedicated constructor to CostGraph for testing.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14274 from shawnwang18:shawnw/fix_cublaslt_lowering_bug 20168c29e824556e693f6fda6127ae16b3b391d4
",copybara-service[bot],2024-06-29 03:02:02+00:00,[],2024-06-29 03:02:02+00:00,,https://github.com/tensorflow/tensorflow/pull/70626,[],[],
2381417789,pull_request,closed,,[xla:ffi] NFC: Clean up XLA FFI type aliases,"[xla:ffi] NFC: Clean up XLA FFI type aliases

+ delete deprecated alias
+ replace Shape with Dimensions because xla::Shape is widely used and has a different meaning, this is too confusing to have two kinds of Shape
",copybara-service[bot],2024-06-29 02:37:48+00:00,['ezhulenev'],2024-07-01 21:43:51+00:00,2024-07-01 21:43:50+00:00,https://github.com/tensorflow/tensorflow/pull/70625,[],[],
2381412552,pull_request,closed,,PR #14177: Fix missing entries of device description proto,"PR #14177: Fix missing entries of device description proto

Imported from GitHub PR https://github.com/openxla/xla/pull/14177

Add registers_per_core_limit and registers_per_block_limit which were missed before into device description proto.
Copybara import of the project:

--
17a52f950ec9958a9bdce58b6e1570822bde68f7 by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

fix missing entries of device description proto

--
a881d59e3431b911176c326d38e7077090fc0a0f by Zhou, Lingzhi <lingzhi.zhou@intel.com>:

use new tag number

Merging this change closes #14177

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14177 from lingzhi98:lingzhi/device_description a881d59e3431b911176c326d38e7077090fc0a0f
",copybara-service[bot],2024-06-29 02:21:59+00:00,[],2024-06-29 04:47:39+00:00,2024-06-29 04:47:39+00:00,https://github.com/tensorflow/tensorflow/pull/70624,[],"[{'comment_id': 2197859923, 'issue_id': 2381412552, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70624/checks?check_run_id=26832800672) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 6, 29, 2, 22, 4, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-06-29 02:22:04 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70624/checks?check_run_id=26832800672) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2381360779,pull_request,closed,,"In this change we replaces calls to GetBytes with calls to ByteSizeOfShapeWithSharding or ByteSizeOfShape, and get rid of GetBytes.","In this change we replaces calls to GetBytes with calls to ByteSizeOfShapeWithSharding or ByteSizeOfShape, and get rid of GetBytes.
",copybara-service[bot],2024-06-29 01:10:09+00:00,[],2024-06-30 15:42:42+00:00,2024-06-30 15:42:42+00:00,https://github.com/tensorflow/tensorflow/pull/70623,[],[],
2381349217,pull_request,closed,,PR #14274: [XLA:GPU] Disable cublasLT tracing for cuda version < 12030,"PR #14274: [XLA:GPU] Disable cublasLT tracing for cuda version < 12030

Imported from GitHub PR https://github.com/openxla/xla/pull/14274


Copybara import of the project:

--
d88a0efc81b8b2c79d725efb4b2c415f21e88ab5 by Shawn Wang <shawnw@nvidia.com>:

Disable cublasLT tracing for cuda version < 12030

--
20168c29e824556e693f6fda6127ae16b3b391d4 by Shawn Wang <shawnw@nvidia.com>:

add cublaLT test

Merging this change closes #14274

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14274 from shawnwang18:shawnw/fix_cublaslt_lowering_bug 20168c29e824556e693f6fda6127ae16b3b391d4
",copybara-service[bot],2024-06-29 00:36:42+00:00,[],2024-06-29 02:58:45+00:00,2024-06-29 02:58:44+00:00,https://github.com/tensorflow/tensorflow/pull/70622,[],[],
2381331311,pull_request,closed,,Add a global mesh name constant,"Add a global mesh name constant
",copybara-service[bot],2024-06-29 00:01:38+00:00,[],2024-07-03 13:23:44+00:00,2024-07-03 13:23:43+00:00,https://github.com/tensorflow/tensorflow/pull/70621,[],[],
2381325002,pull_request,closed,,[XLA] Clarify and test the order preservation requirement of a tuple simplification.,"[XLA] Clarify and test the order preservation requirement of a tuple simplification.

The implementation already correct handles this requirement, but there was no test that verified this behavior.
",copybara-service[bot],2024-06-28 23:52:28+00:00,[],2024-06-29 02:41:20+00:00,2024-06-29 02:41:19+00:00,https://github.com/tensorflow/tensorflow/pull/70620,[],[],
2381319830,pull_request,closed,,Fix typo in function name.,"Fix typo in function name.
",copybara-service[bot],2024-06-28 23:40:52+00:00,['impjdi'],2024-07-04 14:11:19+00:00,2024-07-04 14:11:18+00:00,https://github.com/tensorflow/tensorflow/pull/70619,[],[],
2381319254,pull_request,closed,,Migrate TensorFlow on newest Hermetic Python set of rules,"Migrate TensorFlow on newest Hermetic Python set of rules

This makes Tensorflow consistent with JAX and XLA
",copybara-service[bot],2024-06-28 23:39:31+00:00,['vam-google'],2024-06-29 00:19:29+00:00,2024-06-29 00:19:28+00:00,https://github.com/tensorflow/tensorflow/pull/70618,[],[],
2381295635,pull_request,closed,,split macros into converter,"split macros into converter
",copybara-service[bot],2024-06-28 22:58:58+00:00,[],2024-07-08 16:07:19+00:00,2024-07-08 16:07:18+00:00,https://github.com/tensorflow/tensorflow/pull/70616,[],[],
2381293252,pull_request,closed,,Refactor C++ header replacements,"Refactor C++ header replacements
",copybara-service[bot],2024-06-28 22:54:49+00:00,['ddunl'],2024-07-01 18:03:30+00:00,2024-07-01 18:03:29+00:00,https://github.com/tensorflow/tensorflow/pull/70615,[],[],
2381260223,pull_request,closed,,[xla:ffi] Add benchmarks for internal XLA FFI implementation,"[xla:ffi] Add benchmarks for internal XLA FFI implementation

+ optimize forwarding absl::OkStatus() as nullptr XLA_FFI_Error* (success)
+ make XLA_FFI_ATTRIBUTE_ALWAYS_INLINE consistent with ABSL

(1) xla/ffi:ffi_test

-------------------------------------------------------------
Benchmark                   Time             CPU   Iterations
-------------------------------------------------------------
BM_AnyBufferArgX1        19.5 ns         19.5 ns     35774168
BM_AnyBufferArgX4        52.5 ns         52.5 ns     13172198
BM_BufferArgX1           15.8 ns         15.8 ns     44010886
BM_BufferArgX4           34.1 ns         34.1 ns     20746753
BM_BufferArgX8           64.5 ns         64.5 ns     10999725
BM_TupleOfI32Attrs       65.8 ns         65.8 ns     10447148

(2) xla/ffi/api:ffi_test

-------------------------------------------------------------
Benchmark                   Time             CPU   Iterations
-------------------------------------------------------------
BM_AnyBufferArgX1        12.0 ns         12.0 ns     58216698
BM_AnyBufferArgX4        18.8 ns         18.8 ns     38334028
BM_BufferArgX1           12.3 ns         12.3 ns     49226385
BM_BufferArgX4           19.1 ns         19.1 ns     37307319
BM_BufferArgX8           37.4 ns         37.4 ns     18814343
BM_TupleOfI32Attrs       67.2 ns         67.2 ns     10336533
",copybara-service[bot],2024-06-28 22:05:11+00:00,['ezhulenev'],2024-06-29 23:38:42+00:00,2024-06-29 23:38:42+00:00,https://github.com/tensorflow/tensorflow/pull/70614,[],[],
2381256518,pull_request,closed,,Reverts a0faa3ba625bf4a2010960e8c783b88216abb38a,"Reverts a0faa3ba625bf4a2010960e8c783b88216abb38a

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14086 from apivovarov:fix_PadEmptyTensor 2d1c4062030ffd2ef184204339ce2f6d045bd02d
",copybara-service[bot],2024-06-28 22:00:22+00:00,[],2024-06-28 23:34:28+00:00,2024-06-28 23:34:28+00:00,https://github.com/tensorflow/tensorflow/pull/70613,[],[],
2381187702,pull_request,closed,,Fix brittle test that does string comparing.,"Fix brittle test that does string comparing.

The current error message is-
```
'tf.CustomAdd' op is neither a custom op nor a flex op
see current operation: %1 = ""tf.CustomAdd""(%arg0, %arg1) {device = """"} : (tensor<1x16x16x3xf32>, tensor<1x16x16x3xf32>) -> tensor<*xf32>
Error code: ERROR_NEEDS_CUSTOM_OPS
```

Expected is-
```
'tf.CustomAdd' op is neither a custom op nor a flex op
Error code: ERROR_NEEDS_CUSTOM_OPS
```
",copybara-service[bot],2024-06-28 20:57:40+00:00,['vamsimanchala'],2024-06-28 22:41:12+00:00,2024-06-28 22:41:12+00:00,https://github.com/tensorflow/tensorflow/pull/70612,[],[],
2381174855,pull_request,closed,,[xla] Add a test for HLO deduplication + execution threads,"[xla] Add a test for HLO deduplication + execution threads

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/13668 from nouiz:multihost_hlo_runner 079af37c3c95bda62857cdb0d43d64ee2e188ddb
",copybara-service[bot],2024-06-28 20:49:53+00:00,['ezhulenev'],2024-06-29 00:05:06+00:00,2024-06-29 00:05:06+00:00,https://github.com/tensorflow/tensorflow/pull/70611,[],[],
2381129281,pull_request,closed,,PR #14090: Propagate memory space from MLIR to the compiler on GPUs,"PR #14090: Propagate memory space from MLIR to the compiler on GPUs

Imported from GitHub PR https://github.com/openxla/xla/pull/14090

Let us propagate memory space annotations on parameters and result from MLIR module to Hlo using existing utils functions (which are currently only used by TPUs). While we are there, we also hook up the layout mode annotations.
Copybara import of the project:

--
8f613f2284134619232da4fcef08c5f3e88025e3 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Propagate memory space from MLIR args to HLO args

--
f5ee969e4b3fc5204b984ae82def4d9527d6f5c2 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Variable rename

--
7603449a17cf7389568cc658e9165905f08151be by Jaroslav Sevcik <jsevcik@nvidia.com>:

Rename to CompileInternal, pass result layout in options

--
351f18ceb2427d0721b43096f506676fc10a48b9 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Add comment

--
3072686dfb63837c2106b5e3c7df366661e88734 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Avoid returning Status from tests

--
4b22c5818fb3c5c4b2c5919739a132774fab03ef by Jaroslav Sevcik <jsevcik@nvidia.com>:

Support setting argument layouts from options


Merging this change closes #14090

Reverts 1f6b4e9733885c1bcb89b2d84d693a72bcf9197c

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14090 from jaro-sevcik:compile-argument-memory-kinds-from-mlir 4b22c5818fb3c5c4b2c5919739a132774fab03ef
",copybara-service[bot],2024-06-28 20:22:34+00:00,[],2024-07-03 09:57:59+00:00,2024-07-03 09:57:58+00:00,https://github.com/tensorflow/tensorflow/pull/70610,[],[],
2381111109,pull_request,closed,,[XLA:GPU] Set minimum concat fragment size to 64,"[XLA:GPU] Set minimum concat fragment size to 64
",copybara-service[bot],2024-06-28 20:12:52+00:00,['anlunx'],2024-06-29 06:08:33+00:00,2024-06-29 06:08:33+00:00,https://github.com/tensorflow/tensorflow/pull/70609,[],[],
2381087610,pull_request,closed,,[xla] Add more details to HLO verifier error message,"[xla] Add more details to HLO verifier error message
",copybara-service[bot],2024-06-28 19:57:59+00:00,['ezhulenev'],2024-06-28 21:10:09+00:00,2024-06-28 21:10:09+00:00,https://github.com/tensorflow/tensorflow/pull/70608,[],[],
2381083091,pull_request,closed,,PR #14168: [DOC] Add more elem-wise binary ops to doc,"PR #14168: [DOC] Add more elem-wise binary ops to doc

Imported from GitHub PR https://github.com/openxla/xla/pull/14168

This PR adds the following elem-wise binary ops to `docs/operation_semantics.md` document:

- Atan2
- Complex
- Pow
- ShiftLeft
- ShiftRightArithmetic
- ShiftRightLogical
Copybara import of the project:

--
a3cbf368adad2d0b4257080a76f0c9dfa6af0861 by Alexander Pivovarov <pivovaa@amazon.com>:

Add more elem-wise binary ops to doc

Merging this change closes #14168

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14168 from apivovarov:doc_binary_ops a3cbf368adad2d0b4257080a76f0c9dfa6af0861
",copybara-service[bot],2024-06-28 19:54:21+00:00,[],2024-06-29 03:17:26+00:00,2024-06-29 03:17:26+00:00,https://github.com/tensorflow/tensorflow/pull/70607,[],[],
2381037661,pull_request,closed,,"Roll back cl/647677220 ""[XLA:GPU] Move `triton_gpu.sparse_dot` to LLVM pattern...""","Roll back cl/647677220 ""[XLA:GPU] Move `triton_gpu.sparse_dot` to LLVM pattern...""

Reverts 5204ea787098c86e2104a255a6ce17dcb72e68c4
",copybara-service[bot],2024-06-28 19:20:52+00:00,[],2024-06-28 21:29:40+00:00,2024-06-28 21:29:40+00:00,https://github.com/tensorflow/tensorflow/pull/70606,[],[],
2381028377,pull_request,closed,,PR #14086: [MLIR][MHLO] Fix PadEmptyTensor pattern to return success(),"PR #14086: [MLIR][MHLO] Fix PadEmptyTensor pattern to return success()

Imported from GitHub PR https://github.com/openxla/xla/pull/14086

Currently, the `PadEmptyTensor` and `DynamicPadEmptyTensor` patterns incorrectly return `failure()` after `rewriter.replaceOpWithNewOp`. This appears to be a typo, as the usual practice is to return `success()` following `rewriter.replaceOpWithNewOp`.
Copybara import of the project:

--
2d1c4062030ffd2ef184204339ce2f6d045bd02d by Alexander Pivovarov <pivovaa@amazon.com>:

Fix PadEmptyTensor pattern to return success()

Merging this change closes #14086

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14086 from apivovarov:fix_PadEmptyTensor 2d1c4062030ffd2ef184204339ce2f6d045bd02d
",copybara-service[bot],2024-06-28 19:15:19+00:00,[],2024-06-28 21:56:04+00:00,2024-06-28 21:56:04+00:00,https://github.com/tensorflow/tensorflow/pull/70605,[],[],
2380995945,pull_request,closed,,[xla:ffi] NFC: Update documentation,"[xla:ffi] NFC: Update documentation

Explain the difference between ""external"" and ""internal"" XLA FFI versions.

Reverts 5204ea787098c86e2104a255a6ce17dcb72e68c4
",copybara-service[bot],2024-06-28 18:55:00+00:00,['ezhulenev'],2024-06-28 22:21:34+00:00,2024-06-28 22:21:34+00:00,https://github.com/tensorflow/tensorflow/pull/70604,[],[],
2380898951,pull_request,closed,,PR #13668: [DOC] Add example how to use the multihost_hlo_runner,"PR #13668: [DOC] Add example how to use the multihost_hlo_runner

Imported from GitHub PR https://github.com/openxla/xla/pull/13668

Add example how to use the multihost_hlo_runner
Also have an example to replay the *after_optimizations.txt files.
Copybara import of the project:

--
80a31ed481494e49d3b4006c9dfc7af3bfb0f88a by Frederic Bastien <fbastien@nvidia.com>:

Add more examples on how to use multihost_hlo_runner

--
a0c296c8e5106e6e4e6f9a009bd474b8b456abc5 by Frederic Bastien <fbastien@nvidia.com>:

Fix extract

--
434d2123309c114bd38b28e464ac37e4736b76c9 by Frederic Bastien <fbastien@nvidia.com>:

...

--
981dcb3e7b2c3ce517115ff846dc63d61dc5f857 by Frederic Bastien <fbastien@nvidia.com>:

...

--
ca0aed7fb66957ae25867e29c39170621846a6cf by Frederic Bastien <fbastien@nvidia.com>:

Move doc to where it will be shown on the web site.

--
5e50e68ae9d81ca02376e3941214350f28eb3e6a by Frederic Bastien <fbastien@nvidia.com>:

Update old documentation to point to the new one.

--
f3944bfcb23e340fcf543d7354ecc9874713be9a by Frederic Bastien <fbastien@nvidia.com>:

Update following code review.

--
e9a3a99d88709a631b7b38a6fda8a03a6cf1ce20 by Frederic Bastien <fbastien@nvidia.com>:

Add warning about the specific container instructions

Merging this change closes #13668

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/13668 from nouiz:multihost_hlo_runner 079af37c3c95bda62857cdb0d43d64ee2e188ddb
",copybara-service[bot],2024-06-28 17:46:49+00:00,[],2024-06-28 21:02:31+00:00,2024-06-28 21:02:30+00:00,https://github.com/tensorflow/tensorflow/pull/70602,[],[],
2380877896,pull_request,closed,,[xla:cpu] Add FFI custom call thunk runtime support to PJRT CPU client.,"[xla:cpu] Add FFI custom call thunk runtime support to PJRT CPU client.

Also add a benchmark that uses PJRT CPU Client.
",copybara-service[bot],2024-06-28 17:33:58+00:00,['penpornk'],2024-06-29 08:49:13+00:00,2024-06-29 08:49:12+00:00,https://github.com/tensorflow/tensorflow/pull/70601,[],[],
2380831957,pull_request,closed,,"r2.17 cherry-pick: 2d72742d40f ""Add tensorflow support for 16k page sizes on arm64""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/2d72742d40f1d3121c895f8584ec8882d1e97fc8,tensorflow-jenkins,2024-06-28 17:02:26+00:00,[],2024-06-28 17:52:53+00:00,2024-06-28 17:52:51+00:00,https://github.com/tensorflow/tensorflow/pull/70600,[],[],
2380831572,pull_request,closed,,split definitions from reduced_precision_support.h into reduced_precision_metadata.h,"split definitions from reduced_precision_support.h into reduced_precision_metadata.h
",copybara-service[bot],2024-06-28 17:02:11+00:00,[],2024-07-03 22:25:46+00:00,2024-07-03 22:25:46+00:00,https://github.com/tensorflow/tensorflow/pull/70599,[],[],
2380801673,pull_request,closed,,[xla:cpu] Port concatenate instruction to Thunks,"[xla:cpu] Port concatenate instruction to Thunks

When eligible, uses a fast concatenate implementation.

Parallel Concatenate performance:
- overall improvement by about 4%
- roughly 11% better on just CPU time

Fast Concatenate (no parallel) performance:
- overall degradation by about 0.1%
- roughly 0.11% worse on just CPU time

Benchmark name: BM_ConcatenateTwoR3F32

Fast Concat/No thunks
--------------------------------------------------------------
Batch  Width  Height  Axis        Time         CPU  Iterations
--------------------------------------------------------------
  256    128      64     0  1677243 ns  1683151 ns         385
   64    256     128     0  1751223 ns  1758320 ns         392
  128     64     256     0  1644130 ns  1650217 ns         420
  256    128      64     1  1638290 ns  1644817 ns         372
   64    256     128     1  1578509 ns  1585332 ns         428
  128     64     256     1  1658181 ns  1665104 ns         446
  256    128      64     2  2739451 ns  2747959 ns         242
   64    256     128     2  2920943 ns  2930953 ns         239
  128     64     256     2  2614209 ns  2624596 ns         264

Fast Concat/Thunks
--------------------------------------------------------------
Batch  Width  Height  Axis        Time         CPU  Iterations
--------------------------------------------------------------
  256    128      64     0  1666792 ns  1672576 ns         432
   64    256     128     0  1770431 ns  1778012 ns         403
  128     64     256     0  1640484 ns  1649199 ns         391
  256    128      64     1  1666010 ns  1671653 ns         409
   64    256     128     1  1730291 ns  1737002 ns         463
  128     64     256     1  1644462 ns  1651148 ns         437
  256    128      64     2  2652464 ns  2662518 ns         272
   64    256     128     2  2741487 ns  2753330 ns         255
  128     64     256     2  2598024 ns  2607371 ns         270

Parallel Concat/No thunks
--------------------------------------------------------------
Batch  Width  Height  Axis        Time         CPU  Iterations
--------------------------------------------------------------
  256    128      64     0  1360991 ns  5086698 ns         100
   64    256     128     0  1242223 ns  4502829 ns         143
  128     64     256     0  1335563 ns  4809744 ns         158
  256    128      64     1  1265563 ns  4621591 ns         166
   64    256     128     1  1378242 ns  4822920 ns         161
  128     64     256     1  1131324 ns  4076193 ns         173
  256    128      64     2  1249790 ns  4490278 ns         159
   64    256     128     2  1563307 ns  5192482 ns         100
  128     64     256     2  1170933 ns  4261332 ns         159

Parallel Concat/Thunks
--------------------------------------------------------------
Batch  Width  Height  Axis        Time         CPU  Iterations
--------------------------------------------------------------
  256    128      64     0  1077677 ns  3701758 ns         174
   64    256     128     0  1162517 ns  3919815 ns         174
  128     64     256     0  1191528 ns  4004124 ns         190
  256    128      64     1  1299133 ns  4435552 ns         157
   64    256     128     1  1292533 ns  4265436 ns         180
  128     64     256     1  1164511 ns  3939443 ns         143
  256    128      64     2  1295687 ns  4340861 ns         167
   64    256     128     2  1327148 ns  4080642 ns         165
  128     64     256     2  1333025 ns  4369473 ns         171
",copybara-service[bot],2024-06-28 16:45:14+00:00,[],2024-07-05 14:15:28+00:00,2024-07-05 14:15:28+00:00,https://github.com/tensorflow/tensorflow/pull/70598,[],"[{'comment_id': 2197296992, 'issue_id': 2380801673, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70598/checks?check_run_id=26819009605) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 6, 28, 16, 45, 19, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-06-28 16:45:19 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70598/checks?check_run_id=26819009605) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2380783510,pull_request,open,,[XLA:GPU][NFC] Rename `gpu_version_` to `compute_capability_` in `gemm_fusion`.,"[XLA:GPU][NFC] Rename `gpu_version_` to `compute_capability_` in `gemm_fusion`.
",copybara-service[bot],2024-06-28 16:32:24+00:00,[],2024-06-28 16:32:24+00:00,,https://github.com/tensorflow/tensorflow/pull/70597,[],[],
2380771186,pull_request,open,,moving TF/lite/toco/toco_flags.proto to TF/compiler/mlir/lite,"moving TF/lite/toco/toco_flags.proto to TF/compiler/mlir/lite

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14086 from apivovarov:fix_PadEmptyTensor 2d1c4062030ffd2ef184204339ce2f6d045bd02d
",copybara-service[bot],2024-06-28 16:25:17+00:00,[],2024-06-28 21:55:54+00:00,,https://github.com/tensorflow/tensorflow/pull/70596,[],[],
2380764377,pull_request,closed,,[IFRT] Include input_specs in RemapPlan::DebugString(),"[IFRT] Include input_specs in RemapPlan::DebugString()

`RemapPlan::DebugString()` was missing `input_specs` dump in the output. This change includes it similar to `output_specs`.
",copybara-service[bot],2024-06-28 16:21:30+00:00,[],2024-06-28 21:48:59+00:00,2024-06-28 21:48:59+00:00,https://github.com/tensorflow/tensorflow/pull/70595,[],[],
2380742895,pull_request,closed,,PR #14268: [PJRT:GPU] Implement copying buffers to pinned host memory space,"PR #14268: [PJRT:GPU] Implement copying buffers to pinned host memory space

Imported from GitHub PR https://github.com/openxla/xla/pull/14268


Copybara import of the project:

--
d93dff7a0ffe8a68e1d943d53778b8dc70da5cbc by Jaroslav Sevcik <jsevcik@nvidia.com>:

Support copying to pinned host memory space

Merging this change closes #14268

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14268 from jaro-sevcik:device-put-memory-kind-sharding d93dff7a0ffe8a68e1d943d53778b8dc70da5cbc
",copybara-service[bot],2024-06-28 16:07:34+00:00,[],2024-06-28 18:36:59+00:00,2024-06-28 18:36:57+00:00,https://github.com/tensorflow/tensorflow/pull/70594,[],[],
2380734715,pull_request,closed,,Rename `experimental_weight_cache_file_path` XNNPack delegate option to `weight_cache_file_path`.,"Rename `experimental_weight_cache_file_path` XNNPack delegate option to `weight_cache_file_path`.
",copybara-service[bot],2024-06-28 16:02:07+00:00,['qukhan'],2024-07-01 16:55:41+00:00,2024-07-01 16:55:40+00:00,https://github.com/tensorflow/tensorflow/pull/70593,[],[],
2380718841,pull_request,closed,,Add mesh summary test to summary_v2_test.py,,Mirgahney,2024-06-28 15:51:22+00:00,['gbaned'],2024-06-28 15:54:10+00:00,2024-06-28 15:53:26+00:00,https://github.com/tensorflow/tensorflow/pull/70592,"[('size:S', 'CL Change Size: Small')]","[{'comment_id': 2197222033, 'issue_id': 2380718841, 'author': 'Mirgahney', 'body': 'I will merge it with the another request.', 'created_at': datetime.datetime(2024, 6, 28, 15, 54, 9, tzinfo=datetime.timezone.utc)}]","Mirgahney (Issue Creator) on (2024-06-28 15:54:09 UTC): I will merge it with the another request.

"
2380718447,pull_request,open,,Add mesh summary to tb_summary.py,,Mirgahney,2024-06-28 15:51:06+00:00,['gbaned'],2025-01-16 10:01:28+00:00,,https://github.com/tensorflow/tensorflow/pull/70591,"[('awaiting review', 'Pull request awaiting review'), ('size:M', 'CL Change Size: Medium'), ('python', 'Pull requests that update Python code')]","[{'comment_id': 2220139553, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 7, 10, 10, 31, 1, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228173949, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 7, 15, 10, 26, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244340923, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 7, 23, 6, 19, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2270847020, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 8, 6, 9, 41, 13, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298040077, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 8, 20, 6, 8, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2311701589, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 8, 27, 6, 46, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326284211, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 9, 3, 11, 29, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2357863556, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 9, 18, 8, 44, 39, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401402778, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 9, 6, 16, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431559629, 'issue_id': 2380718447, 'author': 'keerthanakadiri', 'body': 'Hi @fionalang, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 23, 9, 51, 24, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-07-10 10:31:01 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-07-15 10:26:07 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-07-23 06:19:02 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-08-06 09:41:13 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-08-20 06:08:24 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-08-27 06:46:43 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-09-03 11:29:12 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-09-18 08:44:39 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-09 06:16:15 UTC): Hi @fionalang, Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-23 09:51:24 UTC): Hi @fionalang, Can you please review this PR? Thank you !

"
2380714631,pull_request,closed,,[XLA:FFI] Catch exceptions in user FFI calls.,"[XLA:FFI] Catch exceptions in user FFI calls.

This change adds a defensive try/catch when calling user code via that FFI interface to convert C++ exceptions to an absl status, allowing more graceful failure.
",copybara-service[bot],2024-06-28 15:48:29+00:00,[],2024-07-01 18:11:22+00:00,2024-07-01 18:11:22+00:00,https://github.com/tensorflow/tensorflow/pull/70590,[],[],
2380645375,pull_request,closed,,Break circular dependency between gpu_stream.cc and gpu_event.cc.,"Break circular dependency between gpu_stream.cc and gpu_event.cc.
",copybara-service[bot],2024-06-28 15:07:20+00:00,[],2024-06-28 15:57:17+00:00,2024-06-28 15:57:16+00:00,https://github.com/tensorflow/tensorflow/pull/70589,[],[],
2380630717,pull_request,closed,,Clean up tile size computation for row reductions.,"Clean up tile size computation for row reductions.

Also don't attempt to peel the vectorized dimension.
",copybara-service[bot],2024-06-28 14:58:45+00:00,[],2024-06-28 16:35:10+00:00,2024-06-28 16:35:10+00:00,https://github.com/tensorflow/tensorflow/pull/70588,[],[],
2380516356,pull_request,closed,,Unify indexing map computation for reduction emitters.,"Unify indexing map computation for reduction emitters.

Currently, we have similar overlapping logic all over the place.
This can all be unified in a single function.
",copybara-service[bot],2024-06-28 14:02:45+00:00,[],2024-06-28 14:31:45+00:00,2024-06-28 14:31:44+00:00,https://github.com/tensorflow/tensorflow/pull/70587,[],[],
2380358917,pull_request,closed,,Move client creation to a separate file (NFC).,"Move client creation to a separate file (NFC).

This allows to depend on functions that are provided by FunctionalHloRunner
without pulling in GPU dependencies.
",copybara-service[bot],2024-06-28 12:45:57+00:00,['akuegel'],2024-07-01 09:18:02+00:00,2024-07-01 09:18:01+00:00,https://github.com/tensorflow/tensorflow/pull/70586,[],[],
2380307771,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-28 12:19:48+00:00,[],2024-06-28 12:19:48+00:00,,https://github.com/tensorflow/tensorflow/pull/70585,[],[],
2380306926,pull_request,closed,,Standardize patch format to work with internal tooling.,"Standardize patch format to work with internal tooling.
",copybara-service[bot],2024-06-28 12:19:21+00:00,['gflegar'],2024-07-03 10:23:26+00:00,2024-07-03 10:23:25+00:00,https://github.com/tensorflow/tensorflow/pull/70584,[],[],
2380289147,pull_request,closed,,Clean up some duplication and dead code in reduction emitter.,"Clean up some duplication and dead code in reduction emitter.

I want to make some changes to certain reduction launch grids,
but right now it's very hard.
",copybara-service[bot],2024-06-28 12:09:07+00:00,[],2024-06-28 13:09:39+00:00,2024-06-28 13:09:38+00:00,https://github.com/tensorflow/tensorflow/pull/70583,[],[],
2380273822,pull_request,closed,,Reverts bac9d71747c1be50b56bd43b9529026b2dc822ed,"Reverts bac9d71747c1be50b56bd43b9529026b2dc822ed
",copybara-service[bot],2024-06-28 12:01:05+00:00,[],2024-06-28 12:49:37+00:00,2024-06-28 12:49:37+00:00,https://github.com/tensorflow/tensorflow/pull/70582,[],[],
2380184051,pull_request,closed,,Remove unused GetBinaryDir function.,"Remove unused GetBinaryDir function.
",copybara-service[bot],2024-06-28 11:15:44+00:00,[],2024-06-28 11:44:50+00:00,2024-06-28 11:44:50+00:00,https://github.com/tensorflow/tensorflow/pull/70580,[],[],
2380161385,pull_request,closed,,[XLA] Prohibit defining `Literal::AbslHashValue` as it cannot be made consistent.,"[XLA] Prohibit defining `Literal::AbslHashValue` as it cannot be made consistent.
",copybara-service[bot],2024-06-28 11:02:21+00:00,[],2024-06-28 12:01:52+00:00,2024-06-28 12:01:52+00:00,https://github.com/tensorflow/tensorflow/pull/70579,[],[],
2380129579,pull_request,closed,,[XLA:GPU] Move `triton_gpu.sparse_dot` to LLVM pattern from Triton patch (`convert-triton-gpu-to-llvm` pass) to OpenXLA (`sparse-convert-layout-op` pass).,"[XLA:GPU] Move `triton_gpu.sparse_dot` to LLVM pattern from Triton patch (`convert-triton-gpu-to-llvm` pass) to OpenXLA (`sparse-convert-layout-op` pass).
",copybara-service[bot],2024-06-28 10:43:29+00:00,['chsigg'],2024-06-28 15:03:00+00:00,2024-06-28 15:03:00+00:00,https://github.com/tensorflow/tensorflow/pull/70578,[],[],
2380113569,pull_request,closed,,Update XNNPack version.,"Update XNNPack version.
",copybara-service[bot],2024-06-28 10:33:50+00:00,['qukhan'],2024-06-28 16:46:09+00:00,2024-06-28 16:46:07+00:00,https://github.com/tensorflow/tensorflow/pull/70577,[],[],
2380095508,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-28 10:22:54+00:00,[],2024-07-02 08:50:44+00:00,2024-07-02 08:50:44+00:00,https://github.com/tensorflow/tensorflow/pull/70576,[],[],
2379979652,pull_request,open,,compat: Update forward compatibility horizon to 2024-06-28,"compat: Update forward compatibility horizon to 2024-06-28
",copybara-service[bot],2024-06-28 09:19:50+00:00,[],2024-06-28 09:19:50+00:00,,https://github.com/tensorflow/tensorflow/pull/70575,[],[],
2379965085,pull_request,closed,,Only depend on the tpu related jit targets.,"Only depend on the tpu related jit targets.

It doesn't look like tpu_global_init needs to depend on CPU or GPU jit targets.
",copybara-service[bot],2024-06-28 09:12:14+00:00,['akuegel'],2024-07-01 05:50:16+00:00,2024-07-01 05:50:16+00:00,https://github.com/tensorflow/tensorflow/pull/70574,[],[],
2379964051,pull_request,closed,,Reverts 03816bce65879c7921578ed6aaf39280897257a4,"Reverts 03816bce65879c7921578ed6aaf39280897257a4
",copybara-service[bot],2024-06-28 09:11:40+00:00,[],2024-06-28 10:09:08+00:00,2024-06-28 10:09:08+00:00,https://github.com/tensorflow/tensorflow/pull/70573,[],[],
2379937540,pull_request,closed,,Updated API docs for tf.quantization.fake_quant_with_min_max_vars with Example code.,"Updated API docs for tf.quantization.fake_quant_with_min_max_vars with Example code.
",copybara-service[bot],2024-06-28 08:57:43+00:00,[],2024-07-03 07:59:03+00:00,2024-07-03 07:59:02+00:00,https://github.com/tensorflow/tensorflow/pull/70572,[],[],
2379911189,pull_request,closed,,Explicitly disallow duplicated devices during array construction,"Explicitly disallow duplicated devices during array construction

`jax.make_array_from_single_device_arrays` should not allow passing more than one array on the same device as that would lead to an invalid array. While some of this case is already detected by later checks (e.g., `ArrayImpl._check_and_rearrange`), this CL explicitly checks the device list before calling IFRT so that we don't create an invalid IFRT array to begin with.
",copybara-service[bot],2024-06-28 08:42:51+00:00,[],2024-06-28 20:20:55+00:00,2024-06-28 20:20:54+00:00,https://github.com/tensorflow/tensorflow/pull/70571,[],[],
2379876353,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-28 08:22:37+00:00,[],2024-06-28 11:09:17+00:00,,https://github.com/tensorflow/tensorflow/pull/70570,[],[],
2379841872,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-06-28 08:02:44+00:00,[],2024-06-28 08:02:44+00:00,,https://github.com/tensorflow/tensorflow/pull/70569,[],[],
2379809112,pull_request,closed,,PR #14254: Fix symbolic_tile_analysis_test.cc build,"PR #14254: Fix symbolic_tile_analysis_test.cc build

Imported from GitHub PR https://github.com/openxla/xla/pull/14254

This PR fixed the following build error in file `symbolic_tile_analysis_test.cc`. (used GCC-13)

```c
xla/service/gpu/model/symbolic_tile_analysis_test.cc:468:7: error: 'IsOkAndHolds' was not declared in this scope; did you mean 'tsl::testing::IsOkAndHolds'?
  468 |       IsOkAndHolds(false));
```

Benjamin, Alexander, can you have a look? @bchetioui @pifon2a 
Copybara import of the project:

--
a6dc8fa12d2038c745d8b3e632002f549f5a0832 by Alexander Pivovarov <pivovaa@amazon.com>:

Fix symbolic_tile_analysis_test.cc build

Merging this change closes #14254

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14254 from apivovarov:symbolic_tile_analysis_test a6dc8fa12d2038c745d8b3e632002f549f5a0832
",copybara-service[bot],2024-06-28 07:43:16+00:00,[],2024-06-28 08:34:06+00:00,2024-06-28 08:34:05+00:00,https://github.com/tensorflow/tensorflow/pull/70568,[],[],
2379780987,pull_request,closed,,Don't refactor dependencies into a bzl file.,"Don't refactor dependencies into a bzl file.

This breaks the usage of tools for editing BUILD files.
Also rename tests so that they end in a _test suffix.
",copybara-service[bot],2024-06-28 07:25:51+00:00,['akuegel'],2024-06-28 10:37:07+00:00,2024-06-28 10:37:06+00:00,https://github.com/tensorflow/tensorflow/pull/70567,[],[],
