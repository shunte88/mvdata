id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2831482229,pull_request,open,,Create GitHub Actions based L4 GPU CI job,"Create GitHub Actions based L4 GPU CI job
",copybara-service[bot],2025-02-04 23:15:20+00:00,['ddunl'],2025-02-07 19:07:08+00:00,,https://github.com/tensorflow/tensorflow/pull/86591,[],[],
2831429602,pull_request,closed,,Install free threaded python3.13t to the ml_build x86 docker image,"Install free threaded python3.13t to the ml_build x86 docker image

python3.13-nogil is a free-threaded build of python3.13.
",copybara-service[bot],2025-02-04 22:31:16+00:00,['kanglant'],2025-02-05 20:25:14+00:00,2025-02-05 20:25:13+00:00,https://github.com/tensorflow/tensorflow/pull/86590,[],[],
2831428749,pull_request,open,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-02-04 22:30:36+00:00,['ddunl'],2025-02-04 22:30:37+00:00,,https://github.com/tensorflow/tensorflow/pull/86589,[],[],
2831422718,pull_request,closed,,Add a heuristic to avoid constant folding operations that may result in large constants,"Add a heuristic to avoid constant folding operations that may result in large constants
",copybara-service[bot],2025-02-04 22:25:47+00:00,['vamsimanchala'],2025-02-06 21:54:52+00:00,2025-02-06 21:54:51+00:00,https://github.com/tensorflow/tensorflow/pull/86588,[],[],
2831420054,pull_request,open,,[XLA:CPU] Undo make loop unrolling on by default in IrCompiler.,"[XLA:CPU] Undo make loop unrolling on by default in IrCompiler.

Reverts 1e7976e5c5869d34eac64352d411dfb2c8ca4966
",copybara-service[bot],2025-02-04 22:23:44+00:00,['grasskin'],2025-02-04 22:23:45+00:00,,https://github.com/tensorflow/tensorflow/pull/86587,[],[],
2831417419,pull_request,open,,PR #22041: Enable xla_ignore_channel_id flag by default,"PR #22041: Enable xla_ignore_channel_id flag by default

Imported from GitHub PR https://github.com/openxla/xla/pull/22041

Rename `xla_experimental_ignore_channel_id` flag as `xla_ignore_channel_id flag` and enable it by default.

cc @frgossen 
Copybara import of the project:

--
94baa4a5f32ff9421709471fc880fe59a0e164c6 by Sevin Varoglu <svaroglu@nvidia.com>:

Enable xla_ignore_channel_id flag by default

--
d63c6c022aa7b4c81c1bd38a07419da08fc6e3b9 by Sevin Varoglu <svaroglu@nvidia.com>:

Fix error

--
335de387e78559e37a9a018aa1b2c367a208a97e by Sevin Varoglu <svaroglu@nvidia.com>:

Fix format

Merging this change closes #22041

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22041 from sfvaroglu:sevin/channel_id_flag 335de387e78559e37a9a018aa1b2c367a208a97e
",copybara-service[bot],2025-02-04 22:21:45+00:00,[],2025-02-05 15:16:22+00:00,,https://github.com/tensorflow/tensorflow/pull/86586,[],[],
2831417135,pull_request,open,,Create LiteRT pre-submit CI to GitHub actions.,"Create LiteRT pre-submit CI to GitHub actions.
",copybara-service[bot],2025-02-04 22:21:32+00:00,['ecalubaquib'],2025-02-04 22:21:33+00:00,,https://github.com/tensorflow/tensorflow/pull/86585,[],[],
2831395704,pull_request,open,,[XLA] Make the compiler respond to the new optimization_level and memory_fitting_level options when available.,"[XLA] Make the compiler respond to the new optimization_level and memory_fitting_level options when available.

We temporarily continue to respect the legacy exec_time_optimization_effort option if the new one is not specified. This will be phased out once all users have been migrated away from the old option.
",copybara-service[bot],2025-02-04 22:06:09+00:00,[],2025-02-05 18:36:55+00:00,,https://github.com/tensorflow/tensorflow/pull/86584,[],[],
2831377929,pull_request,closed,,Return arrays from `ArrayImpl._check_and_rearrange`.,"Return arrays from `ArrayImpl._check_and_rearrange`.

This is in preparation for a larger change, so that input buffers can be checked before Array creation in XLA and the user gets more helpful JAX error messages instead of XLA errors.

Reverts 135a67d02fc6282a323fc4ad42ef7d8a687995e6
",copybara-service[bot],2025-02-04 21:54:04+00:00,[],2025-02-05 17:32:53+00:00,2025-02-05 17:32:51+00:00,https://github.com/tensorflow/tensorflow/pull/86583,[],[],
2831364538,pull_request,closed,,Add HloRunnerPjRt support for output tuples w/ mixed array and non-array shapes.,"Add HloRunnerPjRt support for output tuples w/ mixed array and non-array shapes.

Prior to this change, `HloRunnerPjRt` would fail during execution of
`FfiCustomCallTest.Tokens` (on CPU) because the `GenerateExecutionOptions`
function called `ComputationLayout::FlattenedResultLayouts`. This function
returns an error if any of the subshapes of the tuple are not arrays.

While it is possible to adapt the implementation of this particular function to
return only array shapes and skip over the non-array shapes, it would also
require changes in how the output buffers are allocated in the CPU compiler.
",copybara-service[bot],2025-02-04 21:46:06+00:00,[],2025-02-06 00:57:57+00:00,2025-02-06 00:57:56+00:00,https://github.com/tensorflow/tensorflow/pull/86582,[],[],
2831312711,pull_request,closed,,Mark tf_dialect_to_executor as deprecated.,"Mark tf_dialect_to_executor as deprecated.
",copybara-service[bot],2025-02-04 21:14:03+00:00,['rocketas'],2025-02-04 21:45:46+00:00,2025-02-04 21:45:45+00:00,https://github.com/tensorflow/tensorflow/pull/86581,[],[],
2831281978,pull_request,open,,[XLA] Introduce discrete scheme for execution time optimization and memory fitting effort.,"[XLA] Introduce discrete scheme for execution time optimization and memory fitting effort.

This will replace the previously introduced floating-point effort levels, which will soon be removed.
",copybara-service[bot],2025-02-04 20:55:44+00:00,[],2025-02-04 20:55:44+00:00,,https://github.com/tensorflow/tensorflow/pull/86580,[],[],
2831243298,pull_request,open,,Update Eigen to commit:b73bb766a57f872b4fe376c4818cd9b17dc1a761,"Update Eigen to commit:b73bb766a57f872b4fe376c4818cd9b17dc1a761
",copybara-service[bot],2025-02-04 20:36:36+00:00,['cantonios'],2025-02-05 00:45:43+00:00,,https://github.com/tensorflow/tensorflow/pull/86579,[],[],
2831230728,pull_request,closed,,Integrate Triton up to [b39c1e14](https://github.com/openai/triton/commits/b39c1e14b8f2029bc6a8798e4914d2692edf97d8),"Integrate Triton up to [b39c1e14](https://github.com/openai/triton/commits/b39c1e14b8f2029bc6a8798e4914d2692edf97d8)
",copybara-service[bot],2025-02-04 20:31:42+00:00,[],2025-02-07 09:40:19+00:00,2025-02-07 09:40:18+00:00,https://github.com/tensorflow/tensorflow/pull/86578,[],[],
2831164737,pull_request,open,,Stop modifying the TraceEventsContainer in DoStoreAsLevelDbTable. This behavior,"Stop modifying the TraceEventsContainer in DoStoreAsLevelDbTable. This behavior
is not intuitive (modifying a const value that was passed in) and unnecessary.

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805
",copybara-service[bot],2025-02-04 19:55:53+00:00,[],2025-02-05 03:19:44+00:00,,https://github.com/tensorflow/tensorflow/pull/86577,[],[],
2831085458,pull_request,open,,[xla:copy_insertion] Avoid adding a redundant control dependence from a,"[xla:copy_insertion] Avoid adding a redundant control dependence from a
pipelined RecvDone to its previous Recv in a while-loop.

When we add a copy of the RecvDone, we also add a control dependence from the
copy to the Recv. If the copy is later on remove, the control dependence from
the RecvDone to the Recv becomes the only side effect of the pass, which is not
intended.
",copybara-service[bot],2025-02-04 19:13:28+00:00,['bixia1'],2025-02-04 19:13:29+00:00,,https://github.com/tensorflow/tensorflow/pull/86576,[],[],
2831079597,pull_request,closed,,PR #22248: Pass CC 10.0 to Triton for sm_120.,"PR #22248: Pass CC 10.0 to Triton for sm_120.

Imported from GitHub PR https://github.com/openxla/xla/pull/22248

Workaround to avoid spurious failures in Triton when compiling for sm_120.
Copybara import of the project:

--
a5be158483e775ba461f81b888558d15fdb70b36 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Pass CC 10.0 to Triton for sm_120.

--
725c24702021fb04428060b8143cae65da24ce2d by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Address review comments.

Merging this change closes #22248

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22248 from dimvar:triton-workaround-for-sm120 725c24702021fb04428060b8143cae65da24ce2d
",copybara-service[bot],2025-02-04 19:11:09+00:00,[],2025-02-04 20:12:01+00:00,2025-02-04 20:12:00+00:00,https://github.com/tensorflow/tensorflow/pull/86575,[],[],
2831060155,pull_request,closed,,"litert: Strip symbols for compiler plugin, dispatch API","litert: Strip symbols for compiler plugin, dispatch API
",copybara-service[bot],2025-02-04 19:00:21+00:00,['terryheo'],2025-02-04 21:23:15+00:00,2025-02-04 21:23:14+00:00,https://github.com/tensorflow/tensorflow/pull/86574,[],[],
2831054626,pull_request,open,,[XLA:GPU] Add support for multiple updates per replica in RaggedAllToAll.,"[XLA:GPU] Add support for multiple updates per replica in RaggedAllToAll.

A recent proposal suggested to extend the API of ra2a to allow to send multiple updates in one op. Before we would need to emit multiple chained ra2a to achieve the same effect.
",copybara-service[bot],2025-02-04 18:57:28+00:00,[],2025-02-04 18:57:28+00:00,,https://github.com/tensorflow/tensorflow/pull/86573,[],[],
2831043611,pull_request,open,,"Add `--xnnpack_slinky_disable_schedule`, `--xnnpack_slinky_no_checks`, `--xnnpack_slinky_concrete_bounds` flags","Add `--xnnpack_slinky_disable_schedule`, `--xnnpack_slinky_no_checks`, `--xnnpack_slinky_concrete_bounds` flags
",copybara-service[bot],2025-02-04 18:51:34+00:00,[],2025-02-04 18:51:34+00:00,,https://github.com/tensorflow/tensorflow/pull/86572,[],[],
2830917494,pull_request,closed,,Reverting to investigate test issue.,"Reverting to investigate test issue.

Reverts 6b431d3ca515c8afc08b1bdfaf4253adf4234b19
",copybara-service[bot],2025-02-04 17:50:22+00:00,['thomasjoerg'],2025-02-04 19:12:48+00:00,2025-02-04 19:12:47+00:00,https://github.com/tensorflow/tensorflow/pull/86571,[],[],
2830848337,pull_request,open,,[xla:gpu:triton] Extract more functions into IterableInput,"[xla:gpu:triton] Extract more functions into IterableInput

This is the last of the refactors that extracts the logic necessary to emit TMA versus tensor pointer loads.  In the next CL, I override some of these functions for TMA for a simpler & more seamless transition, allowing the tma logic to be in one place).

This allows brings in functionality to allow one input to be associated with more than one inter_arg in the ForLoop. This is important for the implementation of TMA, but for now just sets the count to 1.

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22258 from openxla:schedule_vlog 025352635a155e447559d83c471369559aad5981
",copybara-service[bot],2025-02-04 17:15:40+00:00,[],2025-02-05 12:17:40+00:00,,https://github.com/tensorflow/tensorflow/pull/86570,[],[],
2830809203,pull_request,open,,[XLA] tool to print indexing map of operands,"[XLA] tool to print indexing map of operands

example output

```
Output 0 operand 0:
(d0) -> (d0), domain: d0 in [0, 1023]
Output 0 operand 1:
(d0) -> (), domain: d0 in [0, 1023]
Output 1 operand 0:
(d0) -> (d0), domain: d0 in [0, 1023]
Output 1 operand 1:
(d0) -> (), domain: d0 in [0, 1023]
Output 1 operand 2:
(d0) -> (d0), domain: d0 in [0, 1023]
```
",copybara-service[bot],2025-02-04 16:56:41+00:00,['metaflow'],2025-02-04 16:56:42+00:00,,https://github.com/tensorflow/tensorflow/pull/86569,[],[],
2830791183,pull_request,open,,[pjrt] Removed deprecated `PjRtBuffer::CopyToDevice`,"[pjrt] Removed deprecated `PjRtBuffer::CopyToDevice`

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22258 from openxla:schedule_vlog 025352635a155e447559d83c471369559aad5981
",copybara-service[bot],2025-02-04 16:48:22+00:00,['superbobry'],2025-02-05 10:58:56+00:00,,https://github.com/tensorflow/tensorflow/pull/86568,[],[],
2830750752,pull_request,closed,,Fixes crash during model loading for tensors with empty shape.,"Fixes crash during model loading for tensors with empty shape.
",copybara-service[bot],2025-02-04 16:29:32+00:00,[],2025-02-04 20:03:12+00:00,2025-02-04 20:03:11+00:00,https://github.com/tensorflow/tensorflow/pull/86567,[],[],
2830679194,pull_request,open,,[XLA] fail if the change bit reported by a pass does not agree with HLO hash comparison,"[XLA] fail if the change bit reported by a pass does not agree with HLO hash comparison

Usually we trust that pass truthfully reports if it did update the HLO.
Shockingly there are cases, e.g. algsimp, that wrongly report ""unchanged"" pass result.
Having a flag makes it easier to detect existing and new cases of such bugs.
",copybara-service[bot],2025-02-04 16:01:07+00:00,['metaflow'],2025-02-07 18:43:51+00:00,,https://github.com/tensorflow/tensorflow/pull/86566,[],[],
2830661167,pull_request,open,,[XLA] Add const reference versions of `ForEachInstructionWithPred` and `ForEachInstructionWithOpcode`.,"[XLA] Add const reference versions of `ForEachInstructionWithPred` and `ForEachInstructionWithOpcode`.

These are more permissive and semantically equivalent.
",copybara-service[bot],2025-02-04 15:54:10+00:00,[],2025-02-05 09:52:38+00:00,,https://github.com/tensorflow/tensorflow/pull/86565,[],[],
2830580714,pull_request,closed,,[XLA:GPU] Move collectives related code under `transforms/collectives/`.,"[XLA:GPU] Move collectives related code under `transforms/collectives/`.
",copybara-service[bot],2025-02-04 15:22:25+00:00,[],2025-02-04 17:10:51+00:00,2025-02-04 17:10:50+00:00,https://github.com/tensorflow/tensorflow/pull/86564,[],[],
2830468519,pull_request,closed,,PR #22061: [GPU][NFC] Cleanup.,"PR #22061: [GPU][NFC] Cleanup.

Imported from GitHub PR https://github.com/openxla/xla/pull/22061


Copybara import of the project:

--
c492d7adb8422c6c23a5d1b4dbcd816f9739a079 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU][NFC] Cleanup.

Merging this change closes #22061

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22061 from openxla:cleanup_predicate c492d7adb8422c6c23a5d1b4dbcd816f9739a079
",copybara-service[bot],2025-02-04 14:40:34+00:00,[],2025-02-04 15:25:05+00:00,2025-02-04 15:25:05+00:00,https://github.com/tensorflow/tensorflow/pull/86563,[],[],
2830458542,pull_request,closed,,PR #22238: [GPU] Dump PTX before compiling it.,"PR #22238: [GPU] Dump PTX before compiling it.

Imported from GitHub PR https://github.com/openxla/xla/pull/22238

This helps debugging uncompilable modules.
Copybara import of the project:

--
62074b787bff9ad14fc1576d60e53ed0f85e7d64 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Dump PTX before compiling it.

This helps debugging uncompilable modules.

Merging this change closes #22238

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22238 from openxla:dump_ptx 62074b787bff9ad14fc1576d60e53ed0f85e7d64
",copybara-service[bot],2025-02-04 14:37:30+00:00,[],2025-02-04 15:12:59+00:00,2025-02-04 15:12:57+00:00,https://github.com/tensorflow/tensorflow/pull/86562,[],[],
2830428063,pull_request,open,,Integrate LLVM at llvm/llvm-project@f8287f6c373f,"Integrate LLVM at llvm/llvm-project@f8287f6c373f

Updates LLVM usage to match
[f8287f6c373f](https://github.com/llvm/llvm-project/commit/f8287f6c373f)
",copybara-service[bot],2025-02-04 14:26:52+00:00,[],2025-02-05 12:34:02+00:00,,https://github.com/tensorflow/tensorflow/pull/86561,[],[],
2830416651,pull_request,open,,Integrate LLVM at llvm/llvm-project@f6578c3d809b,"Integrate LLVM at llvm/llvm-project@f6578c3d809b

Updates LLVM usage to match
[f6578c3d809b](https://github.com/llvm/llvm-project/commit/f6578c3d809b)
",copybara-service[bot],2025-02-04 14:22:15+00:00,[],2025-02-04 14:22:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86560,[],[],
2830414366,pull_request,open,,[XLA] Support different operand and result types in AlgebraicSimplifierVisitor::HandlePad.,"[XLA] Support different operand and result types in AlgebraicSimplifierVisitor::HandlePad.

I checked that none of the other cases in HandlePad require any adjustments.
",copybara-service[bot],2025-02-04 14:21:20+00:00,[],2025-02-05 08:06:37+00:00,,https://github.com/tensorflow/tensorflow/pull/86559,[],[],
2829999100,pull_request,closed,,[XLA:GPU] Add helper function to dry-run the scheduler and collect sync collectives.,"[XLA:GPU] Add helper function to dry-run the scheduler and collect sync collectives.

We will use the function to maximally combine sync collectives.
",copybara-service[bot],2025-02-04 11:56:14+00:00,[],2025-02-04 16:31:06+00:00,2025-02-04 16:31:04+00:00,https://github.com/tensorflow/tensorflow/pull/86558,[],[],
2829993489,pull_request,closed,,[NFC] Add a VLOG for tiled HLO computations,"[NFC] Add a VLOG for tiled HLO computations

Useful for debugging the kind of tiling each op in the fusion ends up using.
",copybara-service[bot],2025-02-04 11:54:39+00:00,['gflegar'],2025-02-04 13:04:08+00:00,2025-02-04 13:04:07+00:00,https://github.com/tensorflow/tensorflow/pull/86557,[],[],
2829747032,pull_request,closed,,[xla] test_utils: delete IsMlirLoweringEnabled helper,"[xla] test_utils: delete IsMlirLoweringEnabled helper

Refers to an implementation that was removed some time ago.
Delete it.
",copybara-service[bot],2025-02-04 10:32:57+00:00,['cota'],2025-02-04 11:24:32+00:00,2025-02-04 11:24:31+00:00,https://github.com/tensorflow/tensorflow/pull/86556,[],[],
2829731841,pull_request,open,,PR #19834: [ds-fusion]Add support for async dynamic slice fusion,"PR #19834: [ds-fusion]Add support for async dynamic slice fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/19834

This patch adds async handling to dynamic slice fusion when the hero operation is a collective operation. Currently, only reduce-scatter is supported as a hero operation in dynamic slice thunk, so this patch also follows the same.

Added a test with compute, to ensure that communication and compute overlap in the thunks emitted.
Copybara import of the project:

--
0969da183643b80889f4a3604be38dadc1a01d58 by Shraiysh Vaishay <svaishay@nvidia.com>:

Add support for async dynamic slice fusion

This patch adds async handling to dynamic slice fusion when the hero
operation is a collective operation. Currently, only reduce-scatter is
supported as a hero operation in dynamic slice thunk, so this patch also
follows the same.

Added a test with compute, to ensure that communication and compute
overlap in the thunks emitted.

--
b8f89c0aad1c52d463c921f41659abf96faae088 by Shraiysh Vaishay <svaishay@nvidia.com>:

Addressed comments.

--
25c13ec2399ee3bbdee696d1cd63575814bcfa32 by Shraiysh Vaishay <svaishay@nvidia.com>:

Rebase and fix build errors

--
883d5d6c177f171c17411d530edfb06f774b7057 by Shraiysh Vaishay <svaishay@nvidia.com>:

Rebase

--
881837429d32b4f59076f280f6ec579c607a6462 by Shraiysh Vaishay <svaishay@nvidia.com>:

Addressed comments

--
d19cb52fdb7f7d673c0edaf3970a0828812e117c by Shraiysh Vaishay <svaishay@nvidia.com>:

Address comments

Merging this change closes #19834

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19834 from shraiysh:async-dynamic-slice-fusion d19cb52fdb7f7d673c0edaf3970a0828812e117c
",copybara-service[bot],2025-02-04 10:26:51+00:00,[],2025-02-04 10:26:51+00:00,,https://github.com/tensorflow/tensorflow/pull/86555,[],[],
2829704110,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 10:15:16+00:00,[],2025-02-04 11:05:32+00:00,,https://github.com/tensorflow/tensorflow/pull/86554,[],[],
2829690023,pull_request,closed,,Support Qualcomm Op Builders for LiteRT,"# WHAT
- Support Op implementations based on the wrappers.
- Use `TensorPool` to manage the intermediate tensors, `TensorPool` can be abstract or change to allocator if need.
- All builders are functions which receive `TensorPool`, input output `TensorWrapper`, and the op-specific parameters.
- All builders are functions which return `std::vector<OpWrapper>`
- The interface of all builders is open to change based on the requirement.
- Make these builders independent to LiteRT/tflite, use c++ primitive types as parameters.
- Only dependent on QNN and `Wrappers`.


# Supported Op 
| Supported Op | 
| --- | 
| Add |
| And |
| Cast  |
| Concat  |
| Cos |
| Div |
| Sin |
| Greater |
| Less |
| Mul |
| Rsqrt |
| Square |
| SquareDifference |
| Sub |
| EmbeddingLookUp |
| FullyConnected |
| Gather |
| GeLu |
| BatchMatMul |
| Mean |
| Quantize |
| Sum |
| Reshape |
| Select |
| SelectV2 |
| Slice |
| Softmax |
| Split |
| Tanh |
| Transpose |",weilhuan-quic,2025-02-04 10:09:09+00:00,['gbaned'],2025-02-07 20:53:57+00:00,2025-02-07 20:53:54+00:00,https://github.com/tensorflow/tensorflow/pull/86553,"[('size:XL', 'CL Change Size:Extra Large')]",[],
2829649916,pull_request,closed,,[pjrt] Deprecated `PjRtBuffer::CopyToDevice`,"[pjrt] Deprecated `PjRtBuffer::CopyToDevice`

It now has a default implementation which delegates to `CopyToMemorySpace`.
I will update all usages and remove `CopyToDevice` in a follow up.
",copybara-service[bot],2025-02-04 09:52:08+00:00,['superbobry'],2025-02-04 14:02:47+00:00,2025-02-04 14:02:46+00:00,https://github.com/tensorflow/tensorflow/pull/86552,[],[],
2829647542,pull_request,closed,,[XLA:GPU] Inline `is_nop` into `GpuConvertAsyncCollectivesToSync`.,"[XLA:GPU] Inline `is_nop` into `GpuConvertAsyncCollectivesToSync`.

I intend to reuse `GpuConvertAsyncCollectivesToSync` and would like to avoid having to keep the `is_nop` predicates in sync.
",copybara-service[bot],2025-02-04 09:51:05+00:00,[],2025-02-04 12:10:45+00:00,2025-02-04 12:10:44+00:00,https://github.com/tensorflow/tensorflow/pull/86551,[],[],
2829643971,pull_request,closed,,[XLA:CPU] Enable more flexible layout assignment in DotThunk.,"[XLA:CPU] Enable more flexible layout assignment in DotThunk.
",copybara-service[bot],2025-02-04 09:49:32+00:00,[],2025-02-06 15:07:52+00:00,2025-02-06 15:07:41+00:00,https://github.com/tensorflow/tensorflow/pull/86550,[],[],
2829634559,pull_request,closed,,PR #21708: NUMA-pin host memory buffers for D2H/H2D transfers,"PR #21708: NUMA-pin host memory buffers for D2H/H2D transfers

Imported from GitHub PR https://github.com/openxla/xla/pull/21708

This ensures that the pinned host buffers used for transfers between host and device are pinned to the NUMA node closest to the device. It had a previous life as https://github.com/openxla/xla/pull/15216.

In a benchmark that triggers large, concurrent, copies from all devices to the host then achieved D2H throughput is around 33 GiB/s with NUMA pinning on a DGX H100 node (2xCPU, 8xH100). Without pinning, the achieved throughput is around 13.5 GiB/s from the same benchmark.

While it is already possible to achieve the correct NUMA pinning in process-per-GPU and process-per-NUMA-node configurations using `numactl` or similar, achieving correct pinning in process-per-node configuration requires logic inside XLA.
Copybara import of the project:

--
0eab66c25a49d2c360f5fc5251f08ac8cce4c3ac by Olli Lupton <olupton@nvidia.com>:

NUMA-pin host memory buffers for D2H/H2D transfers

--
57a46645d6716a55dc3617ff0ad613d31c267804 by Olli Lupton <olupton@nvidia.com>:

256 byte alignment for host allocations when NUMA is not enabled

--
ad2895a795d8f60512f164d85607510eb45c1b6a by Olli Lupton <olupton@nvidia.com>:

Address review comments

--
629777ec4b2230909a2f98d48c9e726006ec09e8 by Olli Lupton <olupton@nvidia.com>:

std::string_view -> absl::string_view

--
21587a5fcf1f57743388256ef28c214ac5b50a23 by Olli Lupton <olupton@nvidia.com>:

Apply @beckerhe's suggested Bazel changes

--
175c5f6a5ae9c30cca3ac23131744ef1cabfd228 by Olli Lupton <olupton@nvidia.com>:

add missing dependency

Merging this change closes #21708

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21708 from olupton:numa 175c5f6a5ae9c30cca3ac23131744ef1cabfd228
",copybara-service[bot],2025-02-04 09:45:28+00:00,[],2025-02-07 11:11:16+00:00,2025-02-07 11:11:16+00:00,https://github.com/tensorflow/tensorflow/pull/86549,[],[],
2829608062,pull_request,closed,,PR #22259: [NFC] Fix VLOG statements in cuDNN FMHA graph builder,"PR #22259: [NFC] Fix VLOG statements in cuDNN FMHA graph builder

Imported from GitHub PR https://github.com/openxla/xla/pull/22259

Remove ""if (VLOG_IS_ON(x))"" wrappers around VLOG, as they're useless.

This PR also fixes use-after-move of the ""graph"" local variable, which was previously not discovered, as it only happened when VLOG was enabled. (so not quite NFC)
Copybara import of the project:

--
defd81ed2ba416b2013d0000283c5925cf3d9137 by Sergey Kozub <skozub@nvidia.com>:

[NFC] Fix VLOG statements in cuDNN FMHA graph builder

Merging this change closes #22259

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22259 from openxla:skozub/fmha_vlog defd81ed2ba416b2013d0000283c5925cf3d9137
",copybara-service[bot],2025-02-04 09:34:24+00:00,[],2025-02-04 12:20:19+00:00,2025-02-04 12:20:18+00:00,https://github.com/tensorflow/tensorflow/pull/86548,[],[],
2829572217,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:18:53+00:00,[],2025-02-04 11:51:05+00:00,,https://github.com/tensorflow/tensorflow/pull/86547,[],[],
2829569223,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:17:31+00:00,[],2025-02-04 09:17:31+00:00,,https://github.com/tensorflow/tensorflow/pull/86546,[],[],
2829568875,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:17:21+00:00,[],2025-02-04 12:16:36+00:00,,https://github.com/tensorflow/tensorflow/pull/86545,[],[],
2829568837,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22258 from openxla:schedule_vlog 025352635a155e447559d83c471369559aad5981
",copybara-service[bot],2025-02-04 09:17:20+00:00,[],2025-02-05 11:18:50+00:00,,https://github.com/tensorflow/tensorflow/pull/86544,[],[],
2829568671,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:17:16+00:00,[],2025-02-04 09:17:16+00:00,,https://github.com/tensorflow/tensorflow/pull/86543,[],[],
2829568243,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:17:04+00:00,[],2025-02-04 11:51:54+00:00,,https://github.com/tensorflow/tensorflow/pull/86542,[],[],
2829567751,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:16:50+00:00,[],2025-02-04 13:02:36+00:00,,https://github.com/tensorflow/tensorflow/pull/86541,[],[],
2829567421,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:16:42+00:00,[],2025-02-04 13:30:29+00:00,,https://github.com/tensorflow/tensorflow/pull/86540,[],[],
2829566638,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805
",copybara-service[bot],2025-02-04 09:16:21+00:00,[],2025-02-05 04:51:08+00:00,,https://github.com/tensorflow/tensorflow/pull/86539,[],[],
2829566143,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805
",copybara-service[bot],2025-02-04 09:16:08+00:00,[],2025-02-05 04:34:02+00:00,,https://github.com/tensorflow/tensorflow/pull/86538,[],[],
2829565714,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:15:56+00:00,[],2025-02-04 11:41:00+00:00,,https://github.com/tensorflow/tensorflow/pull/86537,[],[],
2829565161,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805
",copybara-service[bot],2025-02-04 09:15:40+00:00,[],2025-02-05 09:28:16+00:00,,https://github.com/tensorflow/tensorflow/pull/86536,[],[],
2829564925,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:15:33+00:00,[],2025-02-04 12:13:20+00:00,,https://github.com/tensorflow/tensorflow/pull/86535,[],[],
2829564447,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:15:20+00:00,[],2025-02-04 09:15:20+00:00,,https://github.com/tensorflow/tensorflow/pull/86534,[],[],
2829564333,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:15:17+00:00,[],2025-02-04 13:05:59+00:00,,https://github.com/tensorflow/tensorflow/pull/86533,[],[],
2829564242,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:15:14+00:00,[],2025-02-04 12:59:10+00:00,,https://github.com/tensorflow/tensorflow/pull/86532,[],[],
2829564170,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:15:12+00:00,[],2025-02-04 14:06:09+00:00,,https://github.com/tensorflow/tensorflow/pull/86531,[],[],
2829563865,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805
",copybara-service[bot],2025-02-04 09:15:05+00:00,[],2025-02-05 04:19:42+00:00,,https://github.com/tensorflow/tensorflow/pull/86530,[],[],
2829563729,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:15:02+00:00,[],2025-02-04 13:00:14+00:00,,https://github.com/tensorflow/tensorflow/pull/86529,[],[],
2829563573,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:14:58+00:00,[],2025-02-04 13:30:36+00:00,,https://github.com/tensorflow/tensorflow/pull/86528,[],[],
2829563317,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22259 from openxla:skozub/fmha_vlog defd81ed2ba416b2013d0000283c5925cf3d9137
",copybara-service[bot],2025-02-04 09:14:51+00:00,[],2025-02-04 12:20:43+00:00,,https://github.com/tensorflow/tensorflow/pull/86527,[],[],
2829563073,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:14:44+00:00,[],2025-02-04 12:12:48+00:00,,https://github.com/tensorflow/tensorflow/pull/86526,[],[],
2829562807,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:14:37+00:00,[],2025-02-04 12:39:32+00:00,,https://github.com/tensorflow/tensorflow/pull/86525,[],[],
2829561436,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:13:58+00:00,[],2025-02-04 11:49:39+00:00,,https://github.com/tensorflow/tensorflow/pull/86524,[],[],
2829561120,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:13:49+00:00,[],2025-02-04 11:44:43+00:00,,https://github.com/tensorflow/tensorflow/pull/86523,[],[],
2829560365,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:13:28+00:00,[],2025-02-04 11:04:22+00:00,2025-02-04 11:04:21+00:00,https://github.com/tensorflow/tensorflow/pull/86522,[],[],
2829560341,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:13:27+00:00,[],2025-02-04 12:47:28+00:00,,https://github.com/tensorflow/tensorflow/pull/86521,[],[],
2829560340,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:13:27+00:00,[],2025-02-04 09:13:27+00:00,,https://github.com/tensorflow/tensorflow/pull/86520,[],[],
2829559518,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:13:05+00:00,[],2025-02-04 10:17:49+00:00,,https://github.com/tensorflow/tensorflow/pull/86519,[],[],
2829559311,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:12:59+00:00,[],2025-02-04 09:12:59+00:00,,https://github.com/tensorflow/tensorflow/pull/86518,[],[],
2829558338,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805
",copybara-service[bot],2025-02-04 09:12:31+00:00,[],2025-02-05 04:56:42+00:00,,https://github.com/tensorflow/tensorflow/pull/86517,[],[],
2829557779,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:12:14+00:00,[],2025-02-04 12:42:16+00:00,,https://github.com/tensorflow/tensorflow/pull/86516,[],[],
2829557364,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:12:02+00:00,[],2025-02-04 09:12:02+00:00,,https://github.com/tensorflow/tensorflow/pull/86515,[],[],
2829556951,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 09:11:49+00:00,[],2025-02-04 09:11:49+00:00,,https://github.com/tensorflow/tensorflow/pull/86514,[],[],
2829519987,pull_request,closed,,Remove unused dependencies.,"Remove unused dependencies.

The dependencies may have been needed before, but some passes have been moved.
",copybara-service[bot],2025-02-04 08:54:45+00:00,['akuegel'],2025-02-04 10:03:58+00:00,2025-02-04 10:03:57+00:00,https://github.com/tensorflow/tensorflow/pull/86513,[],[],
2829496273,pull_request,open,,Integrate LLVM at llvm/llvm-project@8f025f2a93ee,"Integrate LLVM at llvm/llvm-project@8f025f2a93ee

Updates LLVM usage to match
[8f025f2a93ee](https://github.com/llvm/llvm-project/commit/8f025f2a93ee)
",copybara-service[bot],2025-02-04 08:43:10+00:00,[],2025-02-04 08:43:10+00:00,,https://github.com/tensorflow/tensorflow/pull/86512,[],[],
2829172910,pull_request,open,,Add TensorAdapter for dynamic loading of Google Tensor Compiler API,"Add TensorAdapter for dynamic loading of Google Tensor Compiler API

This commit introduces the `Adapter` class, which provides an abstraction for dynamically loading and interfacing with the Google Tensor Compiler API. The adapter uses `dlopen` and `dlsym` to load the shared library at runtime and expose the `CompileFlatbuffer` function for compiling TFLite buffers.

1. Supports dynamic loading to decouple client code from the compiler implementation.
2. Provides a C++ interface to interact with the compiler API.
3. Utilizes C-style linkage for compatibility and to avoid name mangling.
4. Includes error handling for library loading and symbol resolution.

This change ensures modularity, allowing flexibility in loading different versions of the compiler without recompiling the client code.
",copybara-service[bot],2025-02-04 05:27:51+00:00,[],2025-02-06 21:06:30+00:00,,https://github.com/tensorflow/tensorflow/pull/86511,[],[],
2829159886,pull_request,closed,,Add support for lowering mhlo.fft with ranks > 3 to tfl.rfft2d.,"Add support for lowering mhlo.fft with ranks > 3 to tfl.rfft2d.
",copybara-service[bot],2025-02-04 05:16:22+00:00,['vamsimanchala'],2025-02-04 20:43:47+00:00,2025-02-04 20:43:46+00:00,https://github.com/tensorflow/tensorflow/pull/86510,[],[],
2829150459,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-04 05:08:32+00:00,[],2025-02-04 05:08:32+00:00,,https://github.com/tensorflow/tensorflow/pull/86509,[],[],
2829142483,pull_request,closed,,Log status of timeout_fn in checkpoints_iterator.,"Log status of timeout_fn in checkpoints_iterator.

Previously, nothing was logged if a timeout_fn was provided and it indicated timeout.
",copybara-service[bot],2025-02-04 05:01:35+00:00,[],2025-02-04 18:12:39+00:00,2025-02-04 18:12:37+00:00,https://github.com/tensorflow/tensorflow/pull/86508,[],[],
2829055804,pull_request,closed,,Add memcpy implementation of ragged-all-to-all.,"Add memcpy implementation of ragged-all-to-all.

The implementation is similar to the memcpy implementation of all-to-all.
",copybara-service[bot],2025-02-04 03:48:58+00:00,['reedwm'],2025-02-06 01:45:49+00:00,2025-02-06 01:45:49+00:00,https://github.com/tensorflow/tensorflow/pull/86507,[],[],
2829018435,pull_request,closed,,"Add a c-api extension for raw buffers. Right now, only supports: creation, h2d and d2h.","Add a c-api extension for raw buffers. Right now, only supports: creation, h2d and d2h.
",copybara-service[bot],2025-02-04 03:11:19+00:00,['pschuh'],2025-02-06 20:03:00+00:00,2025-02-06 20:02:59+00:00,https://github.com/tensorflow/tensorflow/pull/86505,[],[],
2829009801,pull_request,closed,,Fix collective-permute host memory not being unregistered.,"Fix collective-permute host memory not being unregistered.

CUDA host memory was registered in Initialize() and unregistered in Cleanup() but Cleanup() is not called. Now instead store host memory as a steam_executor::MemoryAllocation object, which automatically unregisters it in the destructor.
",copybara-service[bot],2025-02-04 03:03:37+00:00,['reedwm'],2025-02-04 23:35:48+00:00,2025-02-04 23:35:48+00:00,https://github.com/tensorflow/tensorflow/pull/86504,[],[],
2828937683,pull_request,closed,,Integrate LLVM at llvm/llvm-project@f8287f6c373f,"Integrate LLVM at llvm/llvm-project@f8287f6c373f

Updates LLVM usage to match
[f8287f6c373f](https://github.com/llvm/llvm-project/commit/f8287f6c373f)
",copybara-service[bot],2025-02-04 02:00:30+00:00,[],2025-02-05 22:17:12+00:00,2025-02-05 22:17:11+00:00,https://github.com/tensorflow/tensorflow/pull/86503,[],[],
2828931427,pull_request,closed,,It is difficult to parse allocation results in the MSA logs because we print them twice and at neither point are the allocations finalized.,"It is difficult to parse allocation results in the MSA logs because we print them twice and at neither point are the allocations finalized.

So, the following changes were made:
1) Allocations are logged when they are finalized, and the logs indicate that they are finalized.
2) The ""--Allocations List Begin--"" logging has been removed, being replaced by 1.
3) The logging of allocations (along with bytes accessed values), in inefficient allocation site processing, has been labeled and indented to indicate that it is part of inefficient allocation site processing.
",copybara-service[bot],2025-02-04 01:53:49+00:00,['sparc1998'],2025-02-06 01:35:57+00:00,2025-02-06 01:35:56+00:00,https://github.com/tensorflow/tensorflow/pull/86502,[],[],
2828930382,pull_request,closed,,Tag `//xla/pjrt/distributed:client_server_test` and `//xla/tests:dynamic_ops_test_cpu` as `not_run:arm`,"Tag `//xla/pjrt/distributed:client_server_test` and `//xla/tests:dynamic_ops_test_cpu` as `not_run:arm`

These are failing and it's not totally clear what the culprit is.
",copybara-service[bot],2025-02-04 01:52:37+00:00,['ddunl'],2025-02-04 02:59:14+00:00,2025-02-04 02:59:13+00:00,https://github.com/tensorflow/tensorflow/pull/86501,[],[],
2828896737,pull_request,closed,,Fix two bugs in NcclAllToAllStartThunk.,"Fix two bugs in NcclAllToAllStartThunk.

The first bug is that all-to-all ops with multiple replica groups did not work, because the thunk stored a map from local_id to some temporary memory used by the a2a implementation, where local_id was relative to the start of the replica_group. But this means devices of different groups would use the same temporary memory, overwriting each other's results. The fix is to change the map's key from local_id to StreamExecutor*.

The second bug is that the temporary memory mentioned above is registered as host memory but never deregistered. It is deregistered in NcclAllToAllStartThunk::Cleanup(), but Cleanup() is never called. If Cleanup() were to be called, it would fix the bug, but cause the memory to registered and deregistered every run of the executable, which is unacceptably slow. The fix is to deregister the memory in the thunk destructor instead, which is implicitly done by storing a se::MemoryAllocation instead of a int64_t* in the map.

Since the two fixes affect the exact same code, I'm putting them in a single change instead of two separate changes.
",copybara-service[bot],2025-02-04 01:17:53+00:00,['reedwm'],2025-02-04 04:44:47+00:00,2025-02-04 04:44:46+00:00,https://github.com/tensorflow/tensorflow/pull/86500,[],[],
2828892428,pull_request,closed,,"Today there is no sign in the logs when we start processing a new buffer (tied to an HloValue). Our best log that prints the buffer is ""Creating AllocationValues for""; however, we don't always print that line.","Today there is no sign in the logs when we start processing a new buffer (tied to an HloValue). Our best log that prints the buffer is ""Creating AllocationValues for""; however, we don't always print that line.

So, 2 changes were made.
1) We indicate with VLOG(3) when we start processing a new buffer, and we print that buffer.
2) Since, we're print the buffer in 1, we no longer need to print it when printing ""Creating AllocationValues for""
",copybara-service[bot],2025-02-04 01:14:10+00:00,['sparc1998'],2025-02-06 00:24:48+00:00,2025-02-06 00:24:47+00:00,https://github.com/tensorflow/tensorflow/pull/86499,[],[],
2828866704,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-02-04 00:47:59+00:00,['ddunl'],2025-02-04 18:29:00+00:00,2025-02-04 18:28:58+00:00,https://github.com/tensorflow/tensorflow/pull/86498,[],[],
2828849609,pull_request,closed,,[XLA] Create documentation page for XLA terminology.,"[XLA] Create documentation page for XLA terminology.
",copybara-service[bot],2025-02-04 00:30:51+00:00,[],2025-02-04 16:19:48+00:00,2025-02-04 16:19:46+00:00,https://github.com/tensorflow/tensorflow/pull/86497,[],[],
2828838776,pull_request,open,,Install free threaded python3.13t to the ml_build x86 and arm64 cpu docker images,"Install free threaded python3.13t to the ml_build x86 and arm64 cpu docker images

python3.13-nogil is a free-threaded build of python3.13.
",copybara-service[bot],2025-02-04 00:20:38+00:00,['kanglant'],2025-02-04 00:20:39+00:00,,https://github.com/tensorflow/tensorflow/pull/86496,[],[],
2828802025,pull_request,closed,,Make a continuous only Github Actions based TensorFlow CPU build,"Make a continuous only Github Actions based TensorFlow CPU build

In the future this will be promoted to presubmit

Passing run here: https://github.com/openxla/xla/actions/runs/13185352502/job/36806036630?pr=22264
",copybara-service[bot],2025-02-03 23:49:34+00:00,['ddunl'],2025-02-06 20:17:24+00:00,2025-02-06 20:17:23+00:00,https://github.com/tensorflow/tensorflow/pull/86495,[],[],
2828796795,pull_request,closed,,Fix segfault when loading metadata buffers with offset.,"Fix segfault when loading metadata buffers with offset.
",copybara-service[bot],2025-02-03 23:44:39+00:00,['LukeBoyer'],2025-02-04 00:45:43+00:00,2025-02-04 00:45:42+00:00,https://github.com/tensorflow/tensorflow/pull/86494,[],[],
2828795487,pull_request,open,,[xla:cpu] fusion emitters: do not fuse inside computations called from scatter,"[xla:cpu] fusion emitters: do not fuse inside computations called from scatter

The scatter fusion emitter won't be able to handle fusions inside
computations called from the scatter instruction. Pave the way for
the scatter fusion emitter by forbidding those fusions.
",copybara-service[bot],2025-02-03 23:43:26+00:00,['cota'],2025-02-07 01:29:27+00:00,,https://github.com/tensorflow/tensorflow/pull/86493,[],[],
2828782535,pull_request,closed,,Refactor `FindRotateRightPattern` and `FindPadWithWrapPattern` for concat operations in SPMD partitioner.,"Refactor `FindRotateRightPattern` and `FindPadWithWrapPattern` for concat operations in SPMD partitioner.
",copybara-service[bot],2025-02-03 23:32:14+00:00,[],2025-02-04 05:24:29+00:00,2025-02-04 05:24:28+00:00,https://github.com/tensorflow/tensorflow/pull/86492,[],[],
2828747457,pull_request,closed,,Rename neuron adapter to neuron adapter api in mediatek code.,"Rename neuron adapter to neuron adapter api in mediatek code.
",copybara-service[bot],2025-02-03 23:04:04+00:00,['LukeBoyer'],2025-02-04 01:10:43+00:00,2025-02-04 01:10:43+00:00,https://github.com/tensorflow/tensorflow/pull/86491,[],[],
2828746171,pull_request,open,,Internal change for mtk code.,"Internal change for mtk code.
",copybara-service[bot],2025-02-03 23:03:04+00:00,['LukeBoyer'],2025-02-06 00:54:48+00:00,,https://github.com/tensorflow/tensorflow/pull/86490,[],[],
2828743401,pull_request,closed,,build defs to manage mediatek object files within google3 (for linux). Add test to check api can be initialized.,"build defs to manage mediatek object files within google3 (for linux). Add test to check api can be initialized.
",copybara-service[bot],2025-02-03 23:01:01+00:00,['LukeBoyer'],2025-02-06 01:05:27+00:00,2025-02-06 01:05:26+00:00,https://github.com/tensorflow/tensorflow/pull/86489,[],[],
2828740043,pull_request,closed,,Use the actual neuron adapter header in mediatek code,"Use the actual neuron adapter header in mediatek code
",copybara-service[bot],2025-02-03 22:58:23+00:00,['LukeBoyer'],2025-02-06 00:11:05+00:00,2025-02-06 00:11:04+00:00,https://github.com/tensorflow/tensorflow/pull/86488,[],[],
2828717560,pull_request,open,,Extend Dispatch API to report HW-specific metrics,"Extend Dispatch API to report HW-specific metrics
",copybara-service[bot],2025-02-03 22:40:31+00:00,[],2025-02-03 23:32:03+00:00,,https://github.com/tensorflow/tensorflow/pull/86487,[],[],
2828704505,pull_request,closed,,Switch tsl::OkStatus usage to absl::OkStatus.,"Switch tsl::OkStatus usage to absl::OkStatus.
",copybara-service[bot],2025-02-03 22:32:58+00:00,[],2025-02-05 19:34:48+00:00,2025-02-05 19:34:48+00:00,https://github.com/tensorflow/tensorflow/pull/86486,[],[],
2828661659,pull_request,closed,,Make compiled model async execution explicit,"Make compiled model async execution explicit

This is accomplished by introducing new functions.
",copybara-service[bot],2025-02-03 22:14:46+00:00,[],2025-02-04 19:23:33+00:00,2025-02-04 19:23:32+00:00,https://github.com/tensorflow/tensorflow/pull/86485,[],[],
2828573564,pull_request,open,,Propagate source ranges in location.,"Propagate source ranges in location.

Previously only the line info was propagated. Given the new source range location support, propagate source range.
",copybara-service[bot],2025-02-03 21:33:56+00:00,['jpienaar'],2025-02-03 21:33:57+00:00,,https://github.com/tensorflow/tensorflow/pull/86484,[],[],
2828566679,pull_request,closed,,"[xla:python] Add a mechanism for ""batch partitioning"" of FFI calls.","[xla:python] Add a mechanism for ""batch partitioning"" of FFI calls.

This is the first in a series of changes to add a simple API for supporting a set of common sharding and partitioning patterns for FFI calls. The high level motivation is that custom calls (including FFI calls) are opaque to the SPMD partitioner, and the only ways to customize the partitioning behavior is to (a) explicitly register an `xla::CustomCallPartitoner` with XLA, or (b) use the `jax.experimental.custom_partitioning` APIs. Option (a) isn't generally practical for most use cases where the FFI handler lives in an external binary. Option (b) is flexible, and supports all common use cases, but it requires embedding Python callbacks in to the HLO, which can lead to issues including cache misses. Furthermore, `custom_partitioning` is overpowered for many use cases, where only (what I will call) ""batch partitioning"" is supported.

In this case, ""batch partitioning"" refers to the behavior of many FFI calls where they can be trivially partitioned on some number of (leading) dimensions, with the same call being executed independently on each shard of data. If the data are sharded on non-batch dimensions, partitioning will still re-shard the data to be replicated on the non-batch dimensions. This kind of partitioning logic applies to all the LAPACK/cuSOLVER/etc.-backed linear algebra functions in jaxlib, as well as some external users of `custom_partitioning`.

The approach I'm taking here is to add a new registration function to the XLA client, which let's a user label their FFI call as batch partitionable. Then, when lowering the custom call, the user passes the number of batch dimensions as a frontend attribute, which is then interpreted by the SPMD partitioner.

In parallel with this change, shardy has added support for sharding propagation across custom calls using a string representation that is similar in spirit to this approach, but somewhat more general. However, the shardy implementation still requires a Python callback for the partitioning step, so it doesn't (yet!) solve all of the relevant problems with the `custom_partitioning` approach. Ultimately, it should be possible to have the partitioner parse the shardy sharding rule representation, but I wanted to start with the minimal implementation.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22454 from yliu120:create_dump_dir d5bb15865b5601b6082ae871616b9611405e844e
",copybara-service[bot],2025-02-03 21:29:47+00:00,[],2025-02-07 17:31:20+00:00,2025-02-07 17:31:19+00:00,https://github.com/tensorflow/tensorflow/pull/86483,[],[],
2828485911,pull_request,closed,,Remove unused deprecated constructor of HloCollectiveInstruction,"Remove unused deprecated constructor of HloCollectiveInstruction
",copybara-service[bot],2025-02-03 20:42:56+00:00,[],2025-02-04 03:09:38+00:00,2025-02-04 03:09:37+00:00,https://github.com/tensorflow/tensorflow/pull/86482,[],[],
2828484276,pull_request,closed,,[SHARDY] Remove outdated dependency on mlir_hlo,"[SHARDY] Remove outdated dependency on mlir_hlo
",copybara-service[bot],2025-02-03 20:42:02+00:00,[],2025-02-03 21:56:17+00:00,2025-02-03 21:56:16+00:00,https://github.com/tensorflow/tensorflow/pull/86481,[],[],
2828416603,pull_request,open,,Add host offloading rewriter to despecializer,"Add host offloading rewriter to despecializer
",copybara-service[bot],2025-02-03 20:06:19+00:00,[],2025-02-03 20:06:19+00:00,,https://github.com/tensorflow/tensorflow/pull/86480,[],[],
2828405622,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 20:00:12+00:00,[],2025-02-03 20:39:32+00:00,2025-02-03 20:39:30+00:00,https://github.com/tensorflow/tensorflow/pull/86479,[],[],
2828402796,pull_request,closed,,Replace LITERT_ASSERT_STATUS_OK with LITERT_ASSERT_OK to fix the broken TAP.,"Replace LITERT_ASSERT_STATUS_OK with LITERT_ASSERT_OK to fix the broken TAP.
",copybara-service[bot],2025-02-03 19:58:33+00:00,[],2025-02-03 21:47:28+00:00,2025-02-03 21:47:27+00:00,https://github.com/tensorflow/tensorflow/pull/86478,[],[],
2828397696,pull_request,closed,,[XLA:GPU] Re-enable CubSortPairs test on Hopper.,"[XLA:GPU] Re-enable CubSortPairs test on Hopper.

This test has been disabled for key value pairs of types U16, F64. The test passes at head and can thus be re-enabled.
",copybara-service[bot],2025-02-03 19:55:49+00:00,['thomasjoerg'],2025-02-04 13:42:12+00:00,2025-02-04 13:42:11+00:00,https://github.com/tensorflow/tensorflow/pull/86477,[],[],
2828392163,pull_request,open,,Update and/or wrap `Executable` when calling into `HloRunnerInterface`.,"Update and/or wrap `Executable` when calling into `HloRunnerInterface`.
",copybara-service[bot],2025-02-03 19:52:59+00:00,[],2025-02-03 20:18:16+00:00,,https://github.com/tensorflow/tensorflow/pull/86476,[],[],
2828390252,pull_request,closed,,Add fake `OpaqueExecutable` and update HLO runner interface to use it.,"Add fake `OpaqueExecutable` and update HLO runner interface to use it.

We want to migrate all uses of `xla::Executable` that interact with the HLO
runners to `xla::OpaqueExecutable`. This will be a new class that is not a
member of the `xla::Executable` class hierarchy. The plan is for this class to
have no public fields or accessors and for it to solely be used for wrapping
runner-specific executables within.

This is step 1/3.
",copybara-service[bot],2025-02-03 19:51:58+00:00,[],2025-02-05 17:44:21+00:00,2025-02-05 17:44:20+00:00,https://github.com/tensorflow/tensorflow/pull/86475,[],[],
2828365225,pull_request,closed,,Fix includes in `HloRunnerInterface` implementations.,"Fix includes in `HloRunnerInterface` implementations.
",copybara-service[bot],2025-02-03 19:37:45+00:00,[],2025-02-04 20:21:55+00:00,2025-02-04 20:21:54+00:00,https://github.com/tensorflow/tensorflow/pull/86474,[],[],
2828342336,pull_request,open,,[HLO-OPT] Tool : register HWI passes fro hlo/transforms/ directory,"[HLO-OPT] Tool : register HWI passes fro hlo/transforms/ directory
",copybara-service[bot],2025-02-03 19:25:00+00:00,[],2025-02-03 20:04:10+00:00,,https://github.com/tensorflow/tensorflow/pull/86473,[],[],
2828292085,pull_request,closed,,"Move the many options for printing of instructions into separate file,","Move the many options for printing of instructions into separate file,
as this header file is too long already.
",copybara-service[bot],2025-02-03 18:59:47+00:00,[],2025-02-03 22:57:16+00:00,2025-02-03 22:57:15+00:00,https://github.com/tensorflow/tensorflow/pull/86472,[],[],
2828264977,pull_request,closed,,Stop passing absl::string_view objects as const references.,"Stop passing absl::string_view objects as const references.

clang-tidy warns it's more efficient to pass them by value.
",copybara-service[bot],2025-02-03 18:46:56+00:00,[],2025-02-04 19:35:34+00:00,2025-02-04 19:35:33+00:00,https://github.com/tensorflow/tensorflow/pull/86471,[],[],
2828248462,pull_request,open,,PR #21375: [ds-fusion] Get While loop analysis with copy fusion,"PR #21375: [ds-fusion] Get While loop analysis with copy fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/21375

In later stages of optimization, there are instances of copy fusion on the parameter of the while body. With this, we need to allow inlining of fusions while getting the induction variable index, otherwise we cannot deduce the tuple index.
Copybara import of the project:

--
3147ec926aa1c6fdfa2f4376668434c9a2fbeb87 by Shraiysh Vaishay <svaishay@nvidia.com>:

[ds-fusion] Get While loop analysis with copy fusion

In later stages of optimization, there are instances of copy fusion on
the parameter of the while body. With this, we need to allow inlining of
fusions while getting the induction variable index, otherwise we cannot
deduce the tuple index.

--
a435fbd2eadc17269d7bccbe141dcf7a21cc20e8 by Shraiysh Vaishay <svaishay@nvidia.com>:

Relay control dependencies while converting fusion to call (extractor)


Merging this change closes #21375

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21375 from shraiysh:while_loop_analysis a435fbd2eadc17269d7bccbe141dcf7a21cc20e8
",copybara-service[bot],2025-02-03 18:39:01+00:00,[],2025-02-05 09:42:13+00:00,,https://github.com/tensorflow/tensorflow/pull/86470,[],[],
2828226137,pull_request,open,,Add GL buffer type to LiteRT.,"Add GL buffer type to LiteRT.
",copybara-service[bot],2025-02-03 18:27:33+00:00,[],2025-02-07 21:49:06+00:00,,https://github.com/tensorflow/tensorflow/pull/86469,[],[],
2828210302,pull_request,open,,PR #21708: NUMA-pin host memory buffers for D2H/H2D transfers,"PR #21708: NUMA-pin host memory buffers for D2H/H2D transfers

Imported from GitHub PR https://github.com/openxla/xla/pull/21708

This ensures that the pinned host buffers used for transfers between host and device are pinned to the NUMA node closest to the device. It had a previous life as https://github.com/openxla/xla/pull/15216.

In a benchmark that triggers large, concurrent, copies from all devices to the host then achieved D2H throughput is around 33 GiB/s with NUMA pinning on a DGX H100 node (2xCPU, 8xH100). Without pinning, the achieved throughput is around 13.5 GiB/s from the same benchmark.

While it is already possible to achieve the correct NUMA pinning in process-per-GPU and process-per-NUMA-node configurations using `numactl` or similar, achieving correct pinning in process-per-node configuration requires logic inside XLA.
Copybara import of the project:

--
0eab66c25a49d2c360f5fc5251f08ac8cce4c3ac by Olli Lupton <olupton@nvidia.com>:

NUMA-pin host memory buffers for D2H/H2D transfers

--
57a46645d6716a55dc3617ff0ad613d31c267804 by Olli Lupton <olupton@nvidia.com>:

256 byte alignment for host allocations when NUMA is not enabled

--
ad2895a795d8f60512f164d85607510eb45c1b6a by Olli Lupton <olupton@nvidia.com>:

Address review comments

--
629777ec4b2230909a2f98d48c9e726006ec09e8 by Olli Lupton <olupton@nvidia.com>:

std::string_view -> absl::string_view

--
21587a5fcf1f57743388256ef28c214ac5b50a23 by Olli Lupton <olupton@nvidia.com>:

Apply @beckerhe's suggested Bazel changes

--
175c5f6a5ae9c30cca3ac23131744ef1cabfd228 by Olli Lupton <olupton@nvidia.com>:

add missing dependency

Merging this change closes #21708

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21708 from olupton:numa 175c5f6a5ae9c30cca3ac23131744ef1cabfd228
",copybara-service[bot],2025-02-03 18:19:28+00:00,[],2025-02-05 15:36:05+00:00,,https://github.com/tensorflow/tensorflow/pull/86468,[],[],
2828204135,pull_request,open,,Use a smart pointer to store profiler and use `DumpProtoToDirectory` to store XSpace,"Use a smart pointer to store profiler and use `DumpProtoToDirectory` to store XSpace
to create directories automatically for when `xla_gpu_dump_xspace_to` doesnt exist
",copybara-service[bot],2025-02-03 18:16:08+00:00,['juliagmt-google'],2025-02-03 20:42:31+00:00,,https://github.com/tensorflow/tensorflow/pull/86467,[],[],
2828191646,pull_request,closed,,Stop using some tsl aliases to absl types in XLA.,"Stop using some tsl aliases to absl types in XLA.
",copybara-service[bot],2025-02-03 18:09:33+00:00,[],2025-02-03 23:03:40+00:00,2025-02-03 23:03:39+00:00,https://github.com/tensorflow/tensorflow/pull/86466,[],[],
2828186912,pull_request,closed,,Integrate LLVM at llvm/llvm-project@386af4a5c64a,"Integrate LLVM at llvm/llvm-project@386af4a5c64a

Updates LLVM usage to match
[386af4a5c64a](https://github.com/llvm/llvm-project/commit/386af4a5c64a)
",copybara-service[bot],2025-02-03 18:07:03+00:00,[],2025-02-03 21:14:40+00:00,2025-02-03 21:14:39+00:00,https://github.com/tensorflow/tensorflow/pull/86465,[],[],
2828171599,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@7775e3e2,"Integrate StableHLO at openxla/stablehlo@7775e3e2
",copybara-service[bot],2025-02-03 17:58:55+00:00,[],2025-02-03 19:10:17+00:00,2025-02-03 19:10:16+00:00,https://github.com/tensorflow/tensorflow/pull/86464,[],[],
2828050842,pull_request,open,,"Parse XLA_FLAGS environment variable every time, conditionally on xla_flags_reset flag.","Parse XLA_FLAGS environment variable every time, conditionally on xla_flags_reset flag.

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805
",copybara-service[bot],2025-02-03 16:58:18+00:00,[],2025-02-05 09:44:31+00:00,,https://github.com/tensorflow/tensorflow/pull/86463,[],[],
2827877458,pull_request,open,,1. Renamed google_tensor_compiler_plugin to compiler_plugin as it is already inside the google_tensor/compiler,"1. Renamed google_tensor_compiler_plugin to compiler_plugin as it is already inside the google_tensor/compiler
2. Updated the CompileSinglePartition Method in compiler_plugin
3. Reactivated the CompileMulSubgraph Test
",copybara-service[bot],2025-02-03 15:44:17+00:00,[],2025-02-06 21:19:52+00:00,,https://github.com/tensorflow/tensorflow/pull/86462,[],[],
2827866088,pull_request,closed,,PR #22215: make host callback error really an error,"PR #22215: make host callback error really an error

Imported from GitHub PR https://github.com/openxla/xla/pull/22215


Copybara import of the project:

--
99693747b52b6f13683f9b120e4670c824ed748f by Yunlong Liu <yliu120@users.noreply.github.com>:

make host callback error really an error

Merging this change closes #22215

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22215 from yliu120:cudastream 99693747b52b6f13683f9b120e4670c824ed748f
",copybara-service[bot],2025-02-03 15:39:32+00:00,[],2025-02-03 16:23:14+00:00,2025-02-03 16:23:13+00:00,https://github.com/tensorflow/tensorflow/pull/86461,[],[],
2827851886,pull_request,closed,,Fix copy-and-paste error in copybara transformation for hwloc.h,"Fix copy-and-paste error in copybara transformation for hwloc.h

The transformation deals with `third_party/hwloc/hwloc-master/include/hwloc.h` as if it was a prefix for a whole subdirectory of includes. This changes fixes that.
",copybara-service[bot],2025-02-03 15:33:55+00:00,[],2025-02-03 17:20:08+00:00,2025-02-03 17:20:06+00:00,https://github.com/tensorflow/tensorflow/pull/86460,[],[],
2827844550,pull_request,open,,[Cleanup] Use CHECK_NE nullptr,"[Cleanup] Use CHECK_NE nullptr
",copybara-service[bot],2025-02-03 15:30:59+00:00,['frgossen'],2025-02-06 15:55:29+00:00,,https://github.com/tensorflow/tensorflow/pull/86459,[],[],
2827703654,pull_request,open,,[xla:cpu] fusion emitters: add loop and scatter emitters,"[xla:cpu] fusion emitters: add loop and scatter emitters

Note that they are disabled for now. We will enable them
in follow-up CLs as our confidence on their correctness grows.
",copybara-service[bot],2025-02-03 14:37:13+00:00,['cota'],2025-02-06 18:33:58+00:00,,https://github.com/tensorflow/tensorflow/pull/86458,[],[],
2827482817,pull_request,open,,[xla:emitters] add FusionWrapperBase,"[xla:emitters] add FusionWrapperBase

And have XLA:GPU use it. This base class will soon be shared
with XLA:CPU.
",copybara-service[bot],2025-02-03 13:12:21+00:00,['cota'],2025-02-03 14:18:24+00:00,,https://github.com/tensorflow/tensorflow/pull/86457,[],[],
2827477573,pull_request,closed,,PR #21998: Add kCall to GetFusibleComputations,"PR #21998: Add kCall to GetFusibleComputations

Imported from GitHub PR https://github.com/openxla/xla/pull/21998

Previously, we had issues with the stream annotation being applied to non-Gemm operations, and having the compilation fail at IR emitter stage. Operations that normally should've been fused weren't getting fused inside the async computation. This PR is intended to fix this issue by including the call computations when searching for fusible computations.

This was suggested by @jreiffers 
Copybara import of the project:

--
939f105c3f053eaa14f119e67b5c92ab9e0b3aca by chaser <chaser@nvidia.com>:

Add kCall to GetFusibleComputations

--
1ef97c83e26cb61dc222bd9982f58a140c5d97a9 by chaser <chaser@nvidia.com>:

Add test to priority_fusion, edits based on comments

Merging this change closes #21998

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21998 from chaserileyroberts:chase/fusions_in_async_computation 1ef97c83e26cb61dc222bd9982f58a140c5d97a9
",copybara-service[bot],2025-02-03 13:10:10+00:00,[],2025-02-03 13:48:25+00:00,2025-02-03 13:48:23+00:00,https://github.com/tensorflow/tensorflow/pull/86456,[],[],
2827460051,pull_request,open,,Integrate LLVM at llvm/llvm-project@386af4a5c64a,"Integrate LLVM at llvm/llvm-project@386af4a5c64a

Updates LLVM usage to match
[386af4a5c64a](https://github.com/llvm/llvm-project/commit/386af4a5c64a)
",copybara-service[bot],2025-02-03 13:02:36+00:00,[],2025-02-03 13:02:36+00:00,,https://github.com/tensorflow/tensorflow/pull/86455,[],[],
2827373387,pull_request,closed,,[pjrt] Removed the deprecated overloads of `BufferFromHostBuffer`,"[pjrt] Removed the deprecated overloads of `BufferFromHostBuffer`
",copybara-service[bot],2025-02-03 12:28:26+00:00,['superbobry'],2025-02-04 09:10:54+00:00,2025-02-04 09:10:53+00:00,https://github.com/tensorflow/tensorflow/pull/86454,[],[],
2827368746,pull_request,closed,,"[pjrt] Removed unused ""interpreter"" PjRt client","[pjrt] Removed unused ""interpreter"" PjRt client
",copybara-service[bot],2025-02-03 12:26:25+00:00,['superbobry'],2025-02-04 09:52:34+00:00,2025-02-04 09:52:33+00:00,https://github.com/tensorflow/tensorflow/pull/86453,[],[],
2827260400,pull_request,open,,[XLA:GPU] Rename `IsSyncCollective` and move to a GPU specific file.,"[XLA:GPU] Rename `IsSyncCollective` and move to a GPU specific file.

The implementation is specific to the GPU backend.

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22258 from openxla:schedule_vlog 025352635a155e447559d83c471369559aad5981
",copybara-service[bot],2025-02-03 11:36:56+00:00,[],2025-02-05 12:55:32+00:00,,https://github.com/tensorflow/tensorflow/pull/86451,[],[],
2827259690,pull_request,closed,,[XLA:GPU] Delete passes and rewriters related to cuDNN FMHA.,"[XLA:GPU] Delete passes and rewriters related to cuDNN FMHA.

The custom call remains registered in the frontend, and remains explicitly
callable from input HLO. JAX users can use the dedicated attention API to
target cuDNN explicitly.

The related flag is also deprecated, but remains part of the command-line
options for the time being. A future change will delete that as well.
",copybara-service[bot],2025-02-03 11:36:37+00:00,[],2025-02-03 13:08:08+00:00,2025-02-03 13:08:06+00:00,https://github.com/tensorflow/tensorflow/pull/86450,[],[],
2827244773,pull_request,closed,,PR #21962: [NFC] Clarify HLO runner status message when execution is disabled.,"PR #21962: [NFC] Clarify HLO runner status message when execution is disabled.

Imported from GitHub PR https://github.com/openxla/xla/pull/21962


Copybara import of the project:

--
847e797822a494d6b95039fd756cf0963028ce38 by Ilia Sergachev <isergachev@nvidia.com>:

[NFC] Clarify HLO runner status message when execution is disabled.

Merging this change closes #21962

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21962 from openxla:fix_runner_message 847e797822a494d6b95039fd756cf0963028ce38
",copybara-service[bot],2025-02-03 11:29:35+00:00,[],2025-02-03 12:02:37+00:00,2025-02-03 12:02:36+00:00,https://github.com/tensorflow/tensorflow/pull/86449,[],[],
2827219725,pull_request,closed,,Integrate Triton up to [199da94e](https://github.com/openai/triton/commits/47c730b33a4dfe6d38f9a80b98801917199da94e),"Integrate Triton up to [199da94e](https://github.com/openai/triton/commits/47c730b33a4dfe6d38f9a80b98801917199da94e)
",copybara-service[bot],2025-02-03 11:18:22+00:00,[],2025-02-03 15:58:27+00:00,2025-02-03 15:58:26+00:00,https://github.com/tensorflow/tensorflow/pull/86448,[],[],
2827212840,pull_request,closed,,PR #22117: [XLA:GPU] Fix FMHA unit tests to not use FMHA rewriter,"PR #22117: [XLA:GPU] Fix FMHA unit tests to not use FMHA rewriter

Imported from GitHub PR https://github.com/openxla/xla/pull/22117

* use FMHA custom call directly instead of calling rewriter.
Copybara import of the project:

--
f0a8e4242edaf16df2d42ba490cdad6573aefc95 by cjkkkk <ske@nvidia.com>:

fix

--
9edd2c7f6047a648e4f83d851dd279042e60c41a by cjkkkk <ske@nvidia.com>:

fix format

Merging this change closes #22117

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22117 from Cjkkkk:fix_fmha_rewriter 9edd2c7f6047a648e4f83d851dd279042e60c41a
",copybara-service[bot],2025-02-03 11:15:18+00:00,[],2025-02-03 12:17:59+00:00,2025-02-03 12:17:59+00:00,https://github.com/tensorflow/tensorflow/pull/86447,[],[],
2827119872,pull_request,open,,Update KleidiAI version to `v1.3.0`.,"Update KleidiAI version to `v1.3.0`.
",copybara-service[bot],2025-02-03 10:34:57+00:00,[],2025-02-03 10:34:57+00:00,,https://github.com/tensorflow/tensorflow/pull/86446,[],[],
2827040246,pull_request,closed,,PR #22164: [GPU] Fix sharded autotuning compatibility with result caching.,"PR #22164: [GPU] Fix sharded autotuning compatibility with result caching.

Imported from GitHub PR https://github.com/openxla/xla/pull/22164

The algorithm before this change was:
 - collect unique non-cached fusions
 - shard them
 - autotune the shard
 - publish the shard
 - read the other shards
 - merge them into the local cache

This did not work when the ranks observed the cache(s) in different states - sharding requires the set of autotuned fusions to be exactly the same.

The new algorithm is:
 - collect unique fusions ignoring the caches
 - shard them
 - skip fusions present in the local caches of the rank
 - autotune the remainder
 - publish cached + new autotuned results comprising the shard
 - read the other shards
 - merge them into the local cache overwriting on conflicts
Copybara import of the project:

--
80e2579255e43fa693c481d3a5775251cffb6335 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix sharded autotuning compatibility with result caching.

The algorithm before this change was:
 - collect unique non-cached fusions
 - shard them
 - autotune the shard
 - publish the shard
 - read the other shards
 - merge them into the local cache

This did not work when the ranks observed the cache(s) in different
states - sharding requires the set of autotuned fusions to be exactly
the same.

The new algorithm is:
 - collect unique fusions ignoring the caches
 - shard them
 - skip fusions present in the local caches of the rank
 - autotune the remainder
 - publish cached + new autotuned results comprising the shard
 - read the other shards
 - merge them into the local cache overwriting on conflicts

Merging this change closes #22164

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22164 from openxla:fix_sharded_autotuning_with_caching 80e2579255e43fa693c481d3a5775251cffb6335
",copybara-service[bot],2025-02-03 10:01:32+00:00,[],2025-02-03 10:35:34+00:00,2025-02-03 10:35:34+00:00,https://github.com/tensorflow/tensorflow/pull/86445,[],[],
2826908167,pull_request,open,,Use custom HLO serialization for HloUnoptimizedSnapshot.,"Use custom HLO serialization for HloUnoptimizedSnapshot.

This change makes it possible to dump HloUnoptimizedSnapshot protos that are over 2GiB in size (the proto binary serialization limit).
",copybara-service[bot],2025-02-03 09:21:37+00:00,[],2025-02-07 15:32:11+00:00,,https://github.com/tensorflow/tensorflow/pull/86444,[],[],
2826893701,pull_request,open,,[XLA:GPU] move DotDecompose out of simplification pipeline,"[XLA:GPU] move DotDecompose out of simplification pipeline

That seems to be a better approach then moving TransposeFold to simplification-2 in 961e5c25fbd4082a1ac4f2e0865ad28163d12f7d:

1. There is a report that previous change has resulted in perf degradation https://github.com/openxla/xla/pull/22081

2. I have found another case when DotDecompose is competing with algsimp. Added a test for that.

Overall, having an pass that expands operation together with passes that are trying to do the simplification asks for such infinite loops.

---

For archeologists:  

passes DotDimensionSorter and DotDecomposer were added along with GpuAlgebraicSimplifier as it previously could have added multiple contracting dimensions to dot. But cudnn does not support dots with 2+ dimensions, forcing us to use a less efficient loop emitter. - That what ""// AlgebraicSimplifier may add contracting dimensions to a dot."" comment was about.

After a while simplifier started to use supports_non_canonical_dots to guard against this case. So it should be safe to remove dot decomposer and friends.

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22258 from openxla:schedule_vlog 025352635a155e447559d83c471369559aad5981
",copybara-service[bot],2025-02-03 09:16:59+00:00,['metaflow'],2025-02-05 13:01:46+00:00,,https://github.com/tensorflow/tensorflow/pull/86443,[],[],
2826841156,pull_request,closed,,Integrate LLVM at llvm/llvm-project@f0d05b099daf,"Integrate LLVM at llvm/llvm-project@f0d05b099daf

Updates LLVM usage to match
[f0d05b099daf](https://github.com/llvm/llvm-project/commit/f0d05b099daf)
",copybara-service[bot],2025-02-03 09:01:00+00:00,[],2025-02-03 10:59:36+00:00,2025-02-03 10:59:35+00:00,https://github.com/tensorflow/tensorflow/pull/86442,[],[],
2826755162,pull_request,open,,PR #22164: [GPU] Fix sharded autotuning compatibility with result caching.,"PR #22164: [GPU] Fix sharded autotuning compatibility with result caching.

Imported from GitHub PR https://github.com/openxla/xla/pull/22164

The algorithm before this change was:
 - collect unique non-cached fusions
 - shard them
 - autotune the shard
 - publish the shard
 - read the other shards
 - merge them into the local cache

This did not work when the ranks observed the cache(s) in different states - sharding requires the set of autotuned fusions to be exactly the same.

The new algorithm is:
 - collect unique fusions ignoring the caches
 - shard them
 - skip fusions present in the local caches of the rank
 - autotune the remainder
 - publish cached + new autotuned results comprising the shard
 - read the other shards
 - merge them into the local cache overwriting on conflicts
Copybara import of the project:

--
80e2579255e43fa693c481d3a5775251cffb6335 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix sharded autotuning compatibility with result caching.

The algorithm before this change was:
 - collect unique non-cached fusions
 - shard them
 - autotune the shard
 - publish the shard
 - read the other shards
 - merge them into the local cache

This did not work when the ranks observed the cache(s) in different
states - sharding requires the set of autotuned fusions to be exactly
the same.

The new algorithm is:
 - collect unique fusions ignoring the caches
 - shard them
 - skip fusions present in the local caches of the rank
 - autotune the remainder
 - publish cached + new autotuned results comprising the shard
 - read the other shards
 - merge them into the local cache overwriting on conflicts

Merging this change closes #22164

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22164 from openxla:fix_sharded_autotuning_with_caching 80e2579255e43fa693c481d3a5775251cffb6335
",copybara-service[bot],2025-02-03 08:32:17+00:00,[],2025-02-03 10:59:25+00:00,,https://github.com/tensorflow/tensorflow/pull/86441,[],[],
2826692184,pull_request,closed,,Separate collective_permute_cycle for cycle management from SourceTargetPairs container.,"Separate collective_permute_cycle for cycle management from SourceTargetPairs container.
",copybara-service[bot],2025-02-03 08:03:15+00:00,[],2025-02-07 22:29:26+00:00,2025-02-07 22:29:24+00:00,https://github.com/tensorflow/tensorflow/pull/86440,[],[],
2826610083,pull_request,closed,,Fixed broken link in create.md,"Hello Team,
I found 01 broken documentation link for [TensorFlow Lite Model Maker for text Classfication](https://www.tensorflow.org/lite/models/modify/model_maker/text_classification)  hyperlinks in create.md file.  So I have updated those links to functional links.

Please review and merge this change as appropriate.

Thank you!",tilakrayal,2025-02-03 07:16:05+00:00,['gbaned'],2025-02-03 16:50:42+00:00,2025-02-03 16:50:41+00:00,https://github.com/tensorflow/tensorflow/pull/86439,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2826578716,pull_request,closed,,Performance of all casts is now close to raw static_cast and order of magnitude faster than dynamic_cast.,"Performance of all casts is now close to raw static_cast and order of magnitude faster than dynamic_cast.
",copybara-service[bot],2025-02-03 06:57:38+00:00,[],2025-02-07 19:42:38+00:00,2025-02-07 19:42:37+00:00,https://github.com/tensorflow/tensorflow/pull/86438,[],[],
2826544918,pull_request,closed,,Introduce (de)serialisation of `HloUnoptimizedSnapshot`. The snapshot is serialized in the following format:,"Introduce (de)serialisation of `HloUnoptimizedSnapshot`. The snapshot is serialized in the following format:

* Metadata
* Raw arguments

The metadata is `HloUnoptimizedSnapshot` with `HloModuleProto` and a descriptor for each argument.
The descriptor specifies the size of the argument in bytes.
The raw arguments are serialized in the same format as `Literal::Serialize`.

I Updated the `HloUnoptimizedSnapshot` proto structure to store the metadata; introduced `CodedStreamInput(/Output)Iterator` -- interface for iterators over protobuf CodedStreams. This allows to use already existing `Literal::[De]Serialize` functions.
",copybara-service[bot],2025-02-03 06:36:04+00:00,[],2025-02-07 11:22:45+00:00,2025-02-07 11:22:44+00:00,https://github.com/tensorflow/tensorflow/pull/86437,[],[],
2826335709,pull_request,closed,,Update execute.cc for #58676,,amitorko,2025-02-03 03:58:26+00:00,['gbaned'],2025-02-03 14:31:49+00:00,2025-02-03 14:31:47+00:00,https://github.com/tensorflow/tensorflow/pull/86436,"[('size:S', 'CL Change Size: Small'), ('comp:core', 'issues related to core part of tensorflow'), ('invalid', 'Hacktoberfest spam PR')]","[{'comment_id': 2629848354, 'issue_id': 2826335709, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/86436/checks?check_run_id=36561084254) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2025, 2, 3, 3, 58, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2629848633, 'issue_id': 2826335709, 'author': 'amitorko', 'body': 'Update execute.cc for #58676', 'created_at': datetime.datetime(2025, 2, 3, 3, 58, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2630534666, 'issue_id': 2826335709, 'author': 'keerthanakadiri', 'body': 'Hi @amitorko , Can you please sign the CLA, Thank you!', 'created_at': datetime.datetime(2025, 2, 3, 10, 24, 14, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2025-02-03 03:58:30 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/86436/checks?check_run_id=36561084254) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

amitorko (Issue Creator) on (2025-02-03 03:58:51 UTC): Update execute.cc for #58676

keerthanakadiri on (2025-02-03 10:24:14 UTC): Hi @amitorko , Can you please sign the CLA, Thank you!

"
2826327489,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 03:51:13+00:00,[],2025-02-03 05:33:31+00:00,2025-02-03 05:33:30+00:00,https://github.com/tensorflow/tensorflow/pull/86435,[],[],
2826276033,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 03:04:11+00:00,[],2025-02-04 09:39:00+00:00,2025-02-04 09:38:59+00:00,https://github.com/tensorflow/tensorflow/pull/86433,[],[],
2826275347,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 03:03:24+00:00,[],2025-02-03 03:03:24+00:00,,https://github.com/tensorflow/tensorflow/pull/86432,[],[],
2826275089,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 03:03:08+00:00,[],2025-02-04 05:12:33+00:00,2025-02-04 05:12:32+00:00,https://github.com/tensorflow/tensorflow/pull/86431,[],[],
2826274843,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 03:02:53+00:00,[],2025-02-03 05:45:04+00:00,2025-02-03 05:45:03+00:00,https://github.com/tensorflow/tensorflow/pull/86430,[],[],
2826272737,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 03:00:42+00:00,[],2025-02-03 03:00:42+00:00,,https://github.com/tensorflow/tensorflow/pull/86429,[],[],
2826267215,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:55:04+00:00,[],2025-02-06 09:33:03+00:00,2025-02-06 09:33:03+00:00,https://github.com/tensorflow/tensorflow/pull/86428,[],[],
2826266525,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:54:24+00:00,[],2025-02-03 10:46:28+00:00,2025-02-03 10:46:26+00:00,https://github.com/tensorflow/tensorflow/pull/86427,[],[],
2826265982,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:53:50+00:00,[],2025-02-03 02:53:50+00:00,,https://github.com/tensorflow/tensorflow/pull/86426,[],[],
2826265458,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:53:14+00:00,[],2025-02-04 05:06:54+00:00,2025-02-04 05:06:53+00:00,https://github.com/tensorflow/tensorflow/pull/86425,[],[],
2826264843,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:52:35+00:00,[],2025-02-03 02:52:35+00:00,,https://github.com/tensorflow/tensorflow/pull/86424,[],[],
2826263910,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:51:42+00:00,[],2025-02-03 02:51:42+00:00,,https://github.com/tensorflow/tensorflow/pull/86423,[],[],
2826263891,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:51:41+00:00,[],2025-02-03 02:51:41+00:00,,https://github.com/tensorflow/tensorflow/pull/86422,[],[],
2826263040,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:50:50+00:00,[],2025-02-03 13:20:23+00:00,2025-02-03 13:20:22+00:00,https://github.com/tensorflow/tensorflow/pull/86421,[],[],
2826261818,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:49:35+00:00,[],2025-02-03 02:49:35+00:00,,https://github.com/tensorflow/tensorflow/pull/86420,[],[],
2826261424,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:49:12+00:00,[],2025-02-03 02:49:12+00:00,,https://github.com/tensorflow/tensorflow/pull/86419,[],[],
2826260524,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:48:21+00:00,[],2025-02-06 07:21:20+00:00,2025-02-06 07:21:19+00:00,https://github.com/tensorflow/tensorflow/pull/86418,[],[],
2826257957,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:45:47+00:00,[],2025-02-03 02:45:47+00:00,,https://github.com/tensorflow/tensorflow/pull/86417,[],[],
2826256497,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:44:23+00:00,[],2025-02-07 07:20:55+00:00,2025-02-07 07:20:54+00:00,https://github.com/tensorflow/tensorflow/pull/86416,[],[],
2826251921,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:39:52+00:00,[],2025-02-03 02:39:52+00:00,,https://github.com/tensorflow/tensorflow/pull/86415,[],[],
2826250547,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-03 02:38:29+00:00,[],2025-02-03 02:38:29+00:00,,https://github.com/tensorflow/tensorflow/pull/86414,[],[],
2826217924,pull_request,open,,nvrtc-builtins are private don't link to them,"This is a small patch to help with cuda compatibility. I do'nt think this is necessary and links to `lib/libnvrtc-builtins.so.12.6.85` which is not compatible accross different versions of cuda.

xref: https://github.com/conda-forge/tensorflow-feedstock/pull/414#issuecomment-2629135833",hmaarrfk,2025-02-03 02:08:34+00:00,['gbaned'],2025-02-06 22:19:34+00:00,,https://github.com/tensorflow/tensorflow/pull/86413,"[('awaiting review', 'Pull request awaiting review'), ('comp:gpu', 'GPU related issues'), ('size:XS', 'CL Change Size: Extra Small')]","[{'comment_id': 2630163385, 'issue_id': 2826217924, 'author': 'ehfd', 'body': 'I guess this is why I get a dependency hell while trying to blend in PyTorch and TensorFlow in pip.', 'created_at': datetime.datetime(2025, 2, 3, 7, 26, 20, tzinfo=datetime.timezone.utc)}]","ehfd on (2025-02-03 07:26:20 UTC): I guess this is why I get a dependency hell while trying to blend in PyTorch and TensorFlow in pip.

"
2826194673,pull_request,open,,always use fusion emitters,"always use fusion emitters
",copybara-service[bot],2025-02-03 01:46:18+00:00,['cota'],2025-02-07 01:35:04+00:00,,https://github.com/tensorflow/tensorflow/pull/86412,[],[],
2826128194,pull_request,open,,[ODML] StablehloUnfuseBatchNormPass: Migrate from MHLO -> StableHLO.,"[ODML] StablehloUnfuseBatchNormPass: Migrate from MHLO -> StableHLO.
",copybara-service[bot],2025-02-03 00:33:03+00:00,[],2025-02-07 23:10:58+00:00,,https://github.com/tensorflow/tensorflow/pull/86411,[],[],
2825961575,pull_request,closed,,[XLA:FFI] Add an FFI compatible implementation of tsl::CountDownAsyncValueRef.,"[XLA:FFI] Add an FFI compatible implementation of tsl::CountDownAsyncValueRef.

This supports the common pattern of enqueuing a specific number of async tasks within an FFI handler.
",copybara-service[bot],2025-02-02 19:09:52+00:00,[],2025-02-03 01:52:45+00:00,2025-02-03 01:52:44+00:00,https://github.com/tensorflow/tensorflow/pull/86409,[],[],
2825818449,pull_request,closed,,Update XNNPACK version.,"Update XNNPACK version.
",copybara-service[bot],2025-02-02 14:02:08+00:00,[],2025-02-03 13:59:47+00:00,2025-02-03 13:59:46+00:00,https://github.com/tensorflow/tensorflow/pull/86408,[],[],
2825595819,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 04:28:48+00:00,[],2025-02-02 04:28:48+00:00,,https://github.com/tensorflow/tensorflow/pull/86404,[],[],
2825577048,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 03:18:35+00:00,[],2025-02-03 01:26:03+00:00,2025-02-03 01:26:02+00:00,https://github.com/tensorflow/tensorflow/pull/86403,[],[],
2825567186,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:48:08+00:00,[],2025-02-06 06:13:11+00:00,2025-02-06 06:13:10+00:00,https://github.com/tensorflow/tensorflow/pull/86402,[],[],
2825567121,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:47:48+00:00,[],2025-02-07 08:01:57+00:00,2025-02-07 08:01:56+00:00,https://github.com/tensorflow/tensorflow/pull/86401,[],[],
2825567014,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:47:28+00:00,[],2025-02-02 02:47:28+00:00,,https://github.com/tensorflow/tensorflow/pull/86400,[],[],
2825566601,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:45:53+00:00,[],2025-02-06 11:33:08+00:00,2025-02-06 11:33:07+00:00,https://github.com/tensorflow/tensorflow/pull/86399,[],[],
2825565993,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:43:49+00:00,[],2025-02-07 06:57:57+00:00,2025-02-07 06:57:56+00:00,https://github.com/tensorflow/tensorflow/pull/86398,[],[],
2825565967,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:43:43+00:00,[],2025-02-02 04:22:57+00:00,2025-02-02 04:22:56+00:00,https://github.com/tensorflow/tensorflow/pull/86397,[],[],
2825565914,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:43:33+00:00,[],2025-02-06 10:46:48+00:00,2025-02-06 10:46:47+00:00,https://github.com/tensorflow/tensorflow/pull/86396,[],[],
2825565773,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:43:15+00:00,[],2025-02-06 06:28:44+00:00,2025-02-06 06:28:43+00:00,https://github.com/tensorflow/tensorflow/pull/86395,[],[],
2825565053,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:40:43+00:00,[],2025-02-02 02:40:43+00:00,,https://github.com/tensorflow/tensorflow/pull/86394,[],[],
2825564947,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:40:21+00:00,[],2025-02-07 06:38:42+00:00,2025-02-07 06:38:41+00:00,https://github.com/tensorflow/tensorflow/pull/86393,[],[],
2825563341,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:36:39+00:00,[],2025-02-06 06:37:24+00:00,2025-02-06 06:37:23+00:00,https://github.com/tensorflow/tensorflow/pull/86392,[],[],
2825563201,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:36:07+00:00,[],2025-02-02 02:36:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86391,[],[],
2825563008,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:35:44+00:00,[],2025-02-02 12:54:29+00:00,,https://github.com/tensorflow/tensorflow/pull/86390,[],[],
2825560402,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:29:05+00:00,[],2025-02-08 04:47:13+00:00,,https://github.com/tensorflow/tensorflow/pull/86389,[],[],
2825560360,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:28:58+00:00,[],2025-02-02 02:28:58+00:00,,https://github.com/tensorflow/tensorflow/pull/86388,[],[],
2825560198,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:28:26+00:00,[],2025-02-02 02:28:26+00:00,,https://github.com/tensorflow/tensorflow/pull/86387,[],[],
2825559370,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:26:15+00:00,[],2025-02-02 02:26:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86386,[],[],
2825559183,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:25:33+00:00,[],2025-02-02 02:25:33+00:00,,https://github.com/tensorflow/tensorflow/pull/86385,[],[],
2825558931,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-02 02:24:41+00:00,[],2025-02-07 05:16:46+00:00,,https://github.com/tensorflow/tensorflow/pull/86384,[],[],
2825535121,pull_request,closed,,"Remove unused/rarely used functions from HloOpCode. Parametarize test for HloOpCode. Change `HloOpcodeArity` return type to `int8_t`, since `kHloOpcodeMaxArity` is 31.","Remove unused/rarely used functions from HloOpCode. Parametarize test for HloOpCode. Change `HloOpcodeArity` return type to `int8_t`, since `kHloOpcodeMaxArity` is 31.
",copybara-service[bot],2025-02-02 01:11:56+00:00,[],2025-02-06 18:59:17+00:00,2025-02-06 18:59:16+00:00,https://github.com/tensorflow/tensorflow/pull/86383,[],[],
2825534103,pull_request,closed,,Remove unnecessary pointers in CollectiveDeviceList.,"Remove unnecessary pointers in CollectiveDeviceList.
",copybara-service[bot],2025-02-02 01:08:05+00:00,[],2025-02-07 17:46:15+00:00,2025-02-07 17:46:14+00:00,https://github.com/tensorflow/tensorflow/pull/86382,[],[],
2825267856,pull_request,closed,,[XLA:GPU] pass builder explicitly for better Emitter Loc annotations of the generated triton.,"[XLA:GPU] pass builder explicitly for better Emitter Loc annotations of the generated triton.

This fix helps us understand from which line and by which function a specific triton instruction was submitted.
",copybara-service[bot],2025-02-01 15:23:06+00:00,[],2025-02-03 09:42:24+00:00,2025-02-03 09:42:24+00:00,https://github.com/tensorflow/tensorflow/pull/86381,[],[],
2825187035,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 12:32:38+00:00,[],2025-02-01 12:32:38+00:00,,https://github.com/tensorflow/tensorflow/pull/86380,[],[],
2825141311,pull_request,open,,[xla:cpu] introduce FusionWrapper pass,"[xla:cpu] introduce FusionWrapper pass

This pass wraps scatter ops with a fusion, so that the fusion emitter
will be able to do its thing.
",copybara-service[bot],2025-02-01 10:55:13+00:00,['cota'],2025-02-03 13:37:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86379,[],[],
2825128471,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 10:27:47+00:00,[],2025-02-01 10:27:47+00:00,,https://github.com/tensorflow/tensorflow/pull/86377,[],[],
2825119538,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 10:08:03+00:00,[],2025-02-01 10:08:03+00:00,,https://github.com/tensorflow/tensorflow/pull/86376,[],[],
2825107329,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:43:07+00:00,[],2025-02-01 09:43:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86375,[],[],
2825104231,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:36:02+00:00,[],2025-02-01 09:36:02+00:00,,https://github.com/tensorflow/tensorflow/pull/86374,[],[],
2825102376,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:31:51+00:00,[],2025-02-01 09:31:51+00:00,,https://github.com/tensorflow/tensorflow/pull/86373,[],[],
2825096761,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:20:15+00:00,[],2025-02-01 09:20:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86372,[],[],
2825096301,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:19:12+00:00,[],2025-02-01 13:09:54+00:00,,https://github.com/tensorflow/tensorflow/pull/86371,[],[],
2825095923,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:18:23+00:00,[],2025-02-01 09:18:23+00:00,,https://github.com/tensorflow/tensorflow/pull/86370,[],[],
2825095144,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:16:33+00:00,[],2025-02-01 18:35:45+00:00,2025-02-01 18:35:45+00:00,https://github.com/tensorflow/tensorflow/pull/86369,[],[],
2825095097,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:16:28+00:00,[],2025-02-01 09:16:28+00:00,,https://github.com/tensorflow/tensorflow/pull/86368,[],[],
2825095050,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:16:24+00:00,[],2025-02-01 09:16:24+00:00,,https://github.com/tensorflow/tensorflow/pull/86367,[],[],
2825095043,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:16:23+00:00,[],2025-02-01 09:16:23+00:00,,https://github.com/tensorflow/tensorflow/pull/86366,[],[],
2825094534,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:15:21+00:00,[],2025-02-01 09:15:21+00:00,,https://github.com/tensorflow/tensorflow/pull/86365,[],[],
2825094069,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:14:21+00:00,[],2025-02-01 12:42:56+00:00,,https://github.com/tensorflow/tensorflow/pull/86364,[],[],
2825093929,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:14:04+00:00,[],2025-02-01 23:06:12+00:00,2025-02-01 23:06:11+00:00,https://github.com/tensorflow/tensorflow/pull/86363,[],[],
2825093884,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:13:58+00:00,[],2025-02-01 09:13:58+00:00,,https://github.com/tensorflow/tensorflow/pull/86362,[],[],
2825093812,pull_request,open,,compat: Update forward compatibility horizon to 2025-02-01,"compat: Update forward compatibility horizon to 2025-02-01
",copybara-service[bot],2025-02-01 09:13:49+00:00,[],2025-02-01 09:13:49+00:00,,https://github.com/tensorflow/tensorflow/pull/86361,[],[],
2825093780,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:13:45+00:00,[],2025-02-01 09:13:45+00:00,,https://github.com/tensorflow/tensorflow/pull/86360,[],[],
2825093361,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:12:54+00:00,[],2025-02-01 09:12:54+00:00,,https://github.com/tensorflow/tensorflow/pull/86359,[],[],
2825093316,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:12:50+00:00,[],2025-02-01 09:12:50+00:00,,https://github.com/tensorflow/tensorflow/pull/86358,[],[],
2825093058,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:12:16+00:00,[],2025-02-01 09:12:16+00:00,,https://github.com/tensorflow/tensorflow/pull/86357,[],[],
2825090714,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:07:15+00:00,[],2025-02-01 09:07:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86356,[],[],
2825089242,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 09:04:20+00:00,[],2025-02-01 09:04:20+00:00,,https://github.com/tensorflow/tensorflow/pull/86355,[],[],
2825078266,pull_request,closed,,Bump the github-actions group with 8 updates,"Bumps the github-actions group with 8 updates:

| Package | From | To |
| --- | --- | --- |
| [google/osv-scanner-action](https://github.com/google/osv-scanner-action) | `1.9.0` | `1.9.2` |
| [actions/setup-python](https://github.com/actions/setup-python) | `5.3.0` | `5.4.0` |
| [peter-evans/create-pull-request](https://github.com/peter-evans/create-pull-request) | `7.0.5` | `7.0.6` |
| [actions/upload-artifact](https://github.com/actions/upload-artifact) | `4.4.3` | `4.6.0` |
| [github/codeql-action](https://github.com/github/codeql-action) | `3.27.5` | `3.28.8` |
| [docker/setup-buildx-action](https://github.com/docker/setup-buildx-action) | `3.7.1` | `3.8.0` |
| [docker/build-push-action](https://github.com/docker/build-push-action) | `6.10.0` | `6.13.0` |
| [actions/stale](https://github.com/actions/stale) | `9.0.0` | `9.1.0` |

Updates `google/osv-scanner-action` from 1.9.0 to 1.9.2
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/google/osv-scanner-action/releases"">google/osv-scanner-action's releases</a>.</em></p>
<blockquote>
<h2>v1.9.2</h2>
<h2>What's Changed</h2>
<ul>
<li>Update to v1.9.2 by <a href=""https://github.com/hogo6002""><code>@hogo6002</code></a> in <a href=""https://redirect.github.com/google/osv-scanner-action/pull/53"">google/osv-scanner-action#53</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/google/osv-scanner-action/compare/v1.9.1...v1.9.2"">https://github.com/google/osv-scanner-action/compare/v1.9.1...v1.9.2</a></p>
<h2>v1.9.1</h2>
<h2>What's Changed</h2>
<ul>
<li>Update to use osv-scanner v1.9.1</li>
<li>chore(deps): update workflows by <a href=""https://github.com/renovate-bot""><code>@renovate-bot</code></a> in <a href=""https://redirect.github.com/google/osv-scanner-action/pull/47"">google/osv-scanner-action#47</a></li>
<li>Update to v1.9.1 by <a href=""https://github.com/another-rex""><code>@another-rex</code></a> in <a href=""https://redirect.github.com/google/osv-scanner-action/pull/49"">google/osv-scanner-action#49</a></li>
<li>chore(deps): update workflows by <a href=""https://github.com/renovate-bot""><code>@renovate-bot</code></a> in <a href=""https://redirect.github.com/google/osv-scanner-action/pull/48"">google/osv-scanner-action#48</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/google/osv-scanner-action/compare/v1.9.0...v1.9.1"">https://github.com/google/osv-scanner-action/compare/v1.9.0...v1.9.1</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/google/osv-scanner-action/commit/764c91816374ff2d8fc2095dab36eecd42d61638""><code>764c918</code></a> Merge pull request <a href=""https://redirect.github.com/google/osv-scanner-action/issues/53"">#53</a> from google/update-to-v1.9.2</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/af3118a5b1dbae8508190183589820cf9e39b606""><code>af3118a</code></a> Update unified workflow example to point to v1.9.2 reusable workflows</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/e994fd8ab13fe1394942045f5945cd39c6c2d68e""><code>e994fd8</code></a> Update reusable workflows to point to v1.9.2 actions</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/f8115f2f28022984d4e8070d2f0f85abcf6f3458""><code>f8115f2</code></a> Update actions to use v1.9.2 osv-scanner image</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/daa2c68f50d845057895a9c300e42478481c1d26""><code>daa2c68</code></a> Merge pull request <a href=""https://redirect.github.com/google/osv-scanner-action/issues/48"">#48</a> from renovate-bot/renovate/workflows</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/af00d40d228d79c6d674e1a34d04aeefb2df3286""><code>af00d40</code></a> chore(deps): update workflows</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/c411404a6c37528d821d2851028dd3856bebe8b9""><code>c411404</code></a> Merge pull request <a href=""https://redirect.github.com/google/osv-scanner-action/issues/49"">#49</a> from google/update-to-v1.9.1</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/1ab2a619b8518d496398ebf8a547172236f14491""><code>1ab2a61</code></a> Update unified workflow example to point to v1.9.1 reusable workflows</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/8bd1ce1c4be9d98053ffd9e6e14585276a36762c""><code>8bd1ce1</code></a> Update reusable workflows to point to v1.9.1 actions</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/cbb0295db259bba04d38625792c18646ed18bc89""><code>cbb0295</code></a> Update actions to use v1.9.1 osv-scanner image</li>
<li>Additional commits viewable in <a href=""https://github.com/google/osv-scanner-action/compare/v1.9.0...v1.9.2"">compare view</a></li>
</ul>
</details>
<br />

Updates `actions/setup-python` from 5.3.0 to 5.4.0
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/setup-python/releases"">actions/setup-python's releases</a>.</em></p>
<blockquote>
<h2>v5.4.0</h2>
<h2>What's Changed</h2>
<h3>Enhancements:</h3>
<ul>
<li>Update cache error message by <a href=""https://github.com/aparnajyothi-y""><code>@aparnajyothi-y</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/968"">actions/setup-python#968</a></li>
<li>Enhance Workflows: Add Ubuntu-24, Remove Python 3.8  by <a href=""https://github.com/priya-kinthali""><code>@priya-kinthali</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/985"">actions/setup-python#985</a></li>
<li>Configure Dependabot settings by <a href=""https://github.com/HarithaVattikuti""><code>@HarithaVattikuti</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1008"">actions/setup-python#1008</a></li>
</ul>
<h3>Documentation changes:</h3>
<ul>
<li>Readme update - recommended permissions by <a href=""https://github.com/benwells""><code>@benwells</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1009"">actions/setup-python#1009</a></li>
<li>Improve Advanced Usage examples by <a href=""https://github.com/lrq3000""><code>@lrq3000</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/645"">actions/setup-python#645</a></li>
</ul>
<h3>Dependency updates:</h3>
<ul>
<li>Upgrade <code>undici</code> from 5.28.4 to 5.28.5 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1012"">actions/setup-python#1012</a></li>
<li>Upgrade <code>urllib3</code> from 1.25.9 to 1.26.19 in /<strong>tests</strong>/data by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/895"">actions/setup-python#895</a></li>
<li>Upgrade <code>actions/publish-immutable-action</code> from 0.0.3 to 0.0.4 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1014"">actions/setup-python#1014</a></li>
<li>Upgrade <code>@actions/http-client</code> from 2.2.1 to 2.2.3 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1020"">actions/setup-python#1020</a></li>
<li>Upgrade <code>requests</code> from 2.24.0 to 2.32.2 in /<strong>tests</strong>/data by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1019"">actions/setup-python#1019</a></li>
<li>Upgrade <code>@actions/cache</code> to <code>^4.0.0</code> by <a href=""https://github.com/priyagupta108""><code>@priyagupta108</code></a> in <a href=""https://redirect.github.com/actions/setup-python/pull/1007"">actions/setup-python#1007</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/benwells""><code>@benwells</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/1009"">actions/setup-python#1009</a></li>
<li><a href=""https://github.com/HarithaVattikuti""><code>@HarithaVattikuti</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/1008"">actions/setup-python#1008</a></li>
<li><a href=""https://github.com/lrq3000""><code>@lrq3000</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/setup-python/pull/645"">actions/setup-python#645</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/setup-python/compare/v5...v5.4.0"">https://github.com/actions/setup-python/compare/v5...v5.4.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/setup-python/commit/42375524e23c412d93fb67b49958b491fce71c38""><code>4237552</code></a> Improve Advanced Usage examples (<a href=""https://redirect.github.com/actions/setup-python/issues/645"">#645</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/709bfa58ba5a9cefd64220decb43e45cc2a85775""><code>709bfa5</code></a> Bump requests from 2.24.0 to 2.32.2 in /<strong>tests</strong>/data (<a href=""https://redirect.github.com/actions/setup-python/issues/1019"">#1019</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/ceb20b242df24c1f8bf064b3c943c31c2555ddd8""><code>ceb20b2</code></a> Bump <code>@actions/http-client</code> from 2.2.1 to 2.2.3 (<a href=""https://redirect.github.com/actions/setup-python/issues/1020"">#1020</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/0dc2d2cf0c96a1befa4c9f1803d3b9eb03458031""><code>0dc2d2c</code></a> Bump actions/publish-immutable-action from 0.0.3 to 0.0.4 (<a href=""https://redirect.github.com/actions/setup-python/issues/1014"">#1014</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/feb9c6e7c63362340a8853582968731d6adb0454""><code>feb9c6e</code></a> Bump urllib3 from 1.25.9 to 1.26.19 in /<strong>tests</strong>/data (<a href=""https://redirect.github.com/actions/setup-python/issues/895"">#895</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/d0b4fc497a1daddb64da40799d80949aa3a0c559""><code>d0b4fc4</code></a> Bump undici from 5.28.4 to 5.28.5 (<a href=""https://redirect.github.com/actions/setup-python/issues/1012"">#1012</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/e3dfaac0fd011839eef87186e3b48165c3ba0162""><code>e3dfaac</code></a> Configure Dependabot settings (<a href=""https://redirect.github.com/actions/setup-python/issues/1008"">#1008</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/b8cf3eb1ebc9c7f906e4ca96fcdf2e289e25d230""><code>b8cf3eb</code></a> Use the new cache service: upgrade <code>@actions/cache</code> to <code>^4.0.0</code> (<a href=""https://redirect.github.com/actions/setup-python/issues/1007"">#1007</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/1928ae624dc06094d8c65f021a4700ea8fa56b9d""><code>1928ae6</code></a> Update README.md (<a href=""https://redirect.github.com/actions/setup-python/issues/1009"">#1009</a>)</li>
<li><a href=""https://github.com/actions/setup-python/commit/3fddbee7870211eda9047db10474808be43c71ec""><code>3fddbee</code></a> Enhance Workflows: Add Ubuntu-24, Remove Python 3.8  (<a href=""https://redirect.github.com/actions/setup-python/issues/985"">#985</a>)</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/setup-python/compare/0b93645e9fea7318ecaed2b359559ac225c90a2b...42375524e23c412d93fb67b49958b491fce71c38"">compare view</a></li>
</ul>
</details>
<br />

Updates `peter-evans/create-pull-request` from 7.0.5 to 7.0.6
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/peter-evans/create-pull-request/releases"">peter-evans/create-pull-request's releases</a>.</em></p>
<blockquote>
<h2>Create Pull Request v7.0.6</h2>
<p> Fixes an issue with commit signing where unicode characters in file paths were not preserved.</p>
<h2>What's Changed</h2>
<ul>
<li>build(deps-dev): bump <code>@vercel/ncc</code> from 0.38.1 to 0.38.2 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3365"">peter-evans/create-pull-request#3365</a></li>
<li>Update distribution by <a href=""https://github.com/actions-bot""><code>@actions-bot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3370"">peter-evans/create-pull-request#3370</a></li>
<li>build(deps): bump <code>@octokit/plugin-rest-endpoint-methods</code> from 13.2.4 to 13.2.5 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3375"">peter-evans/create-pull-request#3375</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.50 to 18.19.54 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3376"">peter-evans/create-pull-request#3376</a></li>
<li>build(deps): bump <code>@octokit/plugin-paginate-rest</code> from 11.3.3 to 11.3.5 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3377"">peter-evans/create-pull-request#3377</a></li>
<li>Update distribution by <a href=""https://github.com/actions-bot""><code>@actions-bot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3388"">peter-evans/create-pull-request#3388</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.54 to 18.19.55 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3400"">peter-evans/create-pull-request#3400</a></li>
<li>build(deps): bump <code>@actions/core</code> from 1.10.1 to 1.11.1 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3401"">peter-evans/create-pull-request#3401</a></li>
<li>build(deps): bump <code>@octokit/plugin-rest-endpoint-methods</code> from 13.2.5 to 13.2.6 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3403"">peter-evans/create-pull-request#3403</a></li>
<li>build(deps-dev): bump eslint-plugin-import from 2.30.0 to 2.31.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3402"">peter-evans/create-pull-request#3402</a></li>
<li>build(deps): bump <code>@octokit/plugin-throttling</code> from 9.3.1 to 9.3.2 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3404"">peter-evans/create-pull-request#3404</a></li>
<li>Update distribution by <a href=""https://github.com/actions-bot""><code>@actions-bot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3423"">peter-evans/create-pull-request#3423</a></li>
<li>build(deps-dev): bump typescript from 5.6.2 to 5.6.3 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3441"">peter-evans/create-pull-request#3441</a></li>
<li>build(deps): bump undici from 6.19.8 to 6.20.1 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3442"">peter-evans/create-pull-request#3442</a></li>
<li>Update distribution by <a href=""https://github.com/actions-bot""><code>@actions-bot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3451"">peter-evans/create-pull-request#3451</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.55 to 18.19.58 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3457"">peter-evans/create-pull-request#3457</a></li>
<li>build(deps-dev): bump <code>@types/jest</code> from 29.5.13 to 29.5.14 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3462"">peter-evans/create-pull-request#3462</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.58 to 18.19.60 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3463"">peter-evans/create-pull-request#3463</a></li>
<li>chore: don't bundle undici by <a href=""https://github.com/benmccann""><code>@benmccann</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3475"">peter-evans/create-pull-request#3475</a></li>
<li>Update distribution by <a href=""https://github.com/actions-bot""><code>@actions-bot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3478"">peter-evans/create-pull-request#3478</a></li>
<li>chore: use node-fetch-native support for proxy env vars by <a href=""https://github.com/peter-evans""><code>@peter-evans</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3483"">peter-evans/create-pull-request#3483</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.60 to 18.19.64 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3488"">peter-evans/create-pull-request#3488</a></li>
<li>build(deps-dev): bump undici from 6.20.1 to 6.21.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3499"">peter-evans/create-pull-request#3499</a></li>
<li>build(deps-dev): bump <code>@vercel/ncc</code> from 0.38.2 to 0.38.3 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3500"">peter-evans/create-pull-request#3500</a></li>
<li>docs: note <code>push-to-repo</code> classic PAT <code>workflow</code> scope requirement by <a href=""https://github.com/scop""><code>@scop</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3511"">peter-evans/create-pull-request#3511</a></li>
<li>docs: spelling fixes by <a href=""https://github.com/scop""><code>@scop</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3512"">peter-evans/create-pull-request#3512</a></li>
<li>build(deps-dev): bump typescript from 5.6.3 to 5.7.2 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3516"">peter-evans/create-pull-request#3516</a></li>
<li>build(deps-dev): bump prettier from 3.3.3 to 3.4.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3517"">peter-evans/create-pull-request#3517</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.64 to 18.19.66 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3518"">peter-evans/create-pull-request#3518</a></li>
<li>docs(README): clarify that an existing open PR is managed by <a href=""https://github.com/caugner""><code>@caugner</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3498"">peter-evans/create-pull-request#3498</a></li>
<li>Update distribution by <a href=""https://github.com/actions-bot""><code>@actions-bot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3529"">peter-evans/create-pull-request#3529</a></li>
<li>build(deps): bump <code>@octokit/plugin-paginate-rest</code> from 11.3.5 to 11.3.6 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3542"">peter-evans/create-pull-request#3542</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.66 to 18.19.67 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3543"">peter-evans/create-pull-request#3543</a></li>
<li>build(deps-dev): bump prettier from 3.4.0 to 3.4.1 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3544"">peter-evans/create-pull-request#3544</a></li>
<li>build(deps-dev): bump eslint-import-resolver-typescript from 3.6.3 to 3.7.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3559"">peter-evans/create-pull-request#3559</a></li>
<li>build(deps-dev): bump prettier from 3.4.1 to 3.4.2 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3560"">peter-evans/create-pull-request#3560</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.67 to 18.19.68 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3570"">peter-evans/create-pull-request#3570</a></li>
<li>build(deps): bump p-limit from 6.1.0 to 6.2.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3578"">peter-evans/create-pull-request#3578</a></li>
<li>Update distribution by <a href=""https://github.com/actions-bot""><code>@actions-bot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3583"">peter-evans/create-pull-request#3583</a></li>
<li>fix: preserve unicode in filepaths when commit signing by <a href=""https://github.com/peter-evans""><code>@peter-evans</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3588"">peter-evans/create-pull-request#3588</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/benmccann""><code>@benmccann</code></a> made their first contribution in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3475"">peter-evans/create-pull-request#3475</a></li>
<li><a href=""https://github.com/scop""><code>@scop</code></a> made their first contribution in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3511"">peter-evans/create-pull-request#3511</a></li>
<li><a href=""https://github.com/caugner""><code>@caugner</code></a> made their first contribution in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3498"">peter-evans/create-pull-request#3498</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/67ccf781d68cd99b580ae25a5c18a1cc84ffff1f""><code>67ccf78</code></a> fix: preserve unicode in filepaths when commit signing (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3588"">#3588</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/bb88e27d3f9cc69c8bc689eba126096c6fe3dded""><code>bb88e27</code></a> build: update distribution (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3583"">#3583</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/b378ed537a3374cbb7642141277ace10488f9318""><code>b378ed5</code></a> build(deps): bump p-limit from 6.1.0 to 6.2.0 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3578"">#3578</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/fa9200e5b4f0d3fe4adc6d4a980fdb27ca333ed2""><code>fa9200e</code></a> build(deps-dev): bump <code>@types/node</code> from 18.19.67 to 18.19.68 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3570"">#3570</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/16e0059bfd236716f0191bfcfa63d9ded4cf325f""><code>16e0059</code></a> build(deps-dev): bump prettier from 3.4.1 to 3.4.2 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3560"">#3560</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/5bffd5ae80c9e3cdce3fdaba74ba437193643add""><code>5bffd5a</code></a> build(deps-dev): bump eslint-import-resolver-typescript (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3559"">#3559</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/a22a0ddc2127a4161a9f144623d1e51be98d81aa""><code>a22a0dd</code></a> build(deps-dev): bump prettier from 3.4.0 to 3.4.1 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3544"">#3544</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/b27ce378c8a71596550fb729c05c9a998f8ff26f""><code>b27ce37</code></a> build(deps-dev): bump <code>@types/node</code> from 18.19.66 to 18.19.67 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3543"">#3543</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/4e0cc19e22f9071762b3542aa9fa90a1d682dd32""><code>4e0cc19</code></a> build(deps): bump <code>@octokit/plugin-paginate-rest</code> from 11.3.5 to 11.3.6 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3542"">#3542</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/25b6871a4ebe4c3585f47c7a687ac6fd0ec0e32d""><code>25b6871</code></a> docs: update scopes for push-to-fork</li>
<li>Additional commits viewable in <a href=""https://github.com/peter-evans/create-pull-request/compare/5e914681df9dc83aa4e4905692ca88beb2f9e91f...67ccf781d68cd99b580ae25a5c18a1cc84ffff1f"">compare view</a></li>
</ul>
</details>
<br />

Updates `actions/upload-artifact` from 4.4.3 to 4.6.0
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/upload-artifact/releases"">actions/upload-artifact's releases</a>.</em></p>
<blockquote>
<h2>v4.6.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Expose env vars to control concurrency and timeout by <a href=""https://github.com/yacaovsnc""><code>@yacaovsnc</code></a> in <a href=""https://redirect.github.com/actions/upload-artifact/pull/662"">actions/upload-artifact#662</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/upload-artifact/compare/v4...v4.6.0"">https://github.com/actions/upload-artifact/compare/v4...v4.6.0</a></p>
<h2>v4.5.0</h2>
<h2>What's Changed</h2>
<ul>
<li>fix: deprecated <code>Node.js</code> version in action by <a href=""https://github.com/hamirmahal""><code>@hamirmahal</code></a> in <a href=""https://redirect.github.com/actions/upload-artifact/pull/578"">actions/upload-artifact#578</a></li>
<li>Add new <code>artifact-digest</code> output by <a href=""https://github.com/bdehamer""><code>@bdehamer</code></a> in <a href=""https://redirect.github.com/actions/upload-artifact/pull/656"">actions/upload-artifact#656</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/hamirmahal""><code>@hamirmahal</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/upload-artifact/pull/578"">actions/upload-artifact#578</a></li>
<li><a href=""https://github.com/bdehamer""><code>@bdehamer</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/upload-artifact/pull/656"">actions/upload-artifact#656</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/upload-artifact/compare/v4.4.3...v4.5.0"">https://github.com/actions/upload-artifact/compare/v4.4.3...v4.5.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/upload-artifact/commit/65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08""><code>65c4c4a</code></a> Merge pull request <a href=""https://redirect.github.com/actions/upload-artifact/issues/662"">#662</a> from actions/yacaovsnc/add_variable_for_concurrency_a...</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/020761922861c5b0a0a9b98ae4adccf1f675862c""><code>0207619</code></a> move files back to satisfy licensed ci</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/1ecca81102de35b6c140e930a09ea6144c27abf1""><code>1ecca81</code></a> licensed cache updates</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/97422693d3a0493fc2d725fe8c0ac1c1097e9128""><code>9742269</code></a> Expose env vars to controll concurrency and timeout</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/6f51ac03b9356f520e9adb1b1b7802705f340c2b""><code>6f51ac0</code></a> Merge pull request <a href=""https://redirect.github.com/actions/upload-artifact/issues/656"">#656</a> from bdehamer/bdehamer/artifact-digest</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/c40c16d999899d3642ba1597014ba7ef8ff611e7""><code>c40c16d</code></a> add new artifact-digest output</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/735efb4a0a50bb1a533b000483f2d0a23effbd26""><code>735efb4</code></a> bump <code>@actions/artifact</code> from 2.1.11 to 2.2.0</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/184d73b71b93c222403b2e7f1ffebe4508014249""><code>184d73b</code></a> Merge pull request <a href=""https://redirect.github.com/actions/upload-artifact/issues/578"">#578</a> from hamirmahal/fix/deprecated-nodejs-usage-in-action</li>
<li><a href=""https://github.com/actions/upload-artifact/commit/b4a0a984a056f94abb1db07895e844b9422e1e41""><code>b4a0a98</code></a> Merge branch 'main' into fix/deprecated-nodejs-usage-in-action</li>
<li>See full diff in <a href=""https://github.com/actions/upload-artifact/compare/b4b15b8c7c6ac21ea08fcf65892d2ee8f75cf882...65c4c4a1ddee5b72f698fdd19549f0f0fb45cf08"">compare view</a></li>
</ul>
</details>
<br />

Updates `github/codeql-action` from 3.27.5 to 3.28.8
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/releases"">github/codeql-action's releases</a>.</em></p>
<blockquote>
<h2>v3.28.8</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.8 - 29 Jan 2025</h2>
<ul>
<li>Enable support for Kotlin 2.1.10 when running with CodeQL CLI v2.20.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2744"">#2744</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.8/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.7</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.7 - 29 Jan 2025</h2>
<p>No user facing changes.</p>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.7/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.6</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.6 - 27 Jan 2025</h2>
<ul>
<li>Re-enable debug artifact upload for CLI versions 2.20.3 or greater. <a href=""https://redirect.github.com/github/codeql-action/pull/2726"">#2726</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.6/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.5</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.5 - 24 Jan 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.20.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2717"">#2717</a></li>
</ul>
<p>See the full <a href=""https://github.com/github/codeql-action/blob/v3.28.5/CHANGELOG.md"">CHANGELOG.md</a> for more information.</p>
<h2>v3.28.4</h2>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>3.28.4 - 23 Jan 2025</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p>
<blockquote>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<h2>[UNRELEASED]</h2>
<p>No user facing changes.</p>
<h2>3.28.8 - 29 Jan 2025</h2>
<ul>
<li>Enable support for Kotlin 2.1.10 when running with CodeQL CLI v2.20.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2744"">#2744</a></li>
</ul>
<h2>3.28.7 - 29 Jan 2025</h2>
<p>No user facing changes.</p>
<h2>3.28.6 - 27 Jan 2025</h2>
<ul>
<li>Re-enable debug artifact upload for CLI versions 2.20.3 or greater. <a href=""https://redirect.github.com/github/codeql-action/pull/2726"">#2726</a></li>
</ul>
<h2>3.28.5 - 24 Jan 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.20.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2717"">#2717</a></li>
</ul>
<h2>3.28.4 - 23 Jan 2025</h2>
<p>No user facing changes.</p>
<h2>3.28.3 - 22 Jan 2025</h2>
<ul>
<li>Update default CodeQL bundle version to 2.20.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2707"">#2707</a></li>
<li>Fix an issue downloading the CodeQL Bundle from a GitHub Enterprise Server instance which occurred when the CodeQL Bundle had been synced to the instance using the <a href=""https://github.com/github/codeql-action-sync-tool"">CodeQL Action sync tool</a> and the Actions runner did not have Zstandard installed. <a href=""https://redirect.github.com/github/codeql-action/pull/2710"">#2710</a></li>
<li>Uploading debug artifacts for CodeQL analysis is temporarily disabled. <a href=""https://redirect.github.com/github/codeql-action/pull/2712"">#2712</a></li>
</ul>
<h2>3.28.2 - 21 Jan 2025</h2>
<p>No user facing changes.</p>
<h2>3.28.1 - 10 Jan 2025</h2>
<ul>
<li>CodeQL Action v2 is now deprecated, and is no longer updated or supported. For better performance, improved security, and new features, upgrade to v3. For more information, see <a href=""https://github.blog/changelog/2025-01-10-code-scanning-codeql-action-v2-is-now-deprecated/"">this changelog post</a>. <a href=""https://redirect.github.com/github/codeql-action/pull/2677"">#2677</a></li>
<li>Update default CodeQL bundle version to 2.20.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2678"">#2678</a></li>
</ul>
<h2>3.28.0 - 20 Dec 2024</h2>
<ul>
<li>Bump the minimum CodeQL bundle version to 2.15.5. <a href=""https://redirect.github.com/github/codeql-action/pull/2655"">#2655</a></li>
<li>Don't fail in the unusual case that a file is on the search path. <a href=""https://redirect.github.com/github/codeql-action/pull/2660"">#2660</a>.</li>
</ul>
<h2>3.27.9 - 12 Dec 2024</h2>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/github/codeql-action/commit/dd746615b3b9d728a6a37ca2045b68ca76d4841a""><code>dd74661</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2746"">#2746</a> from github/update-v3.28.8-a91a3f767</li>
<li><a href=""https://github.com/github/codeql-action/commit/3210a3cda6446234a897a079af1b684aa4c73326""><code>3210a3c</code></a> Fix Kotlin version in changelog</li>
<li><a href=""https://github.com/github/codeql-action/commit/72f9d0296b7b9c91564f67ddf9def81c815ce0c6""><code>72f9d02</code></a> Update changelog for v3.28.8</li>
<li><a href=""https://github.com/github/codeql-action/commit/a91a3f76789881261b540fb7aa8a527214f8ac01""><code>a91a3f7</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2744"">#2744</a> from github/igfoo/kot2.1.10</li>
<li><a href=""https://github.com/github/codeql-action/commit/c520fb59d4c28e13147ed378b4c12599df187412""><code>c520fb5</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2745"">#2745</a> from github/mergeback/v3.28.7-to-main-6e545590</li>
<li><a href=""https://github.com/github/codeql-action/commit/3879c5766041d8b2b7504c5c4b2d6dbd289f7634""><code>3879c57</code></a> Add changelog entry</li>
<li><a href=""https://github.com/github/codeql-action/commit/0c2193725f360a9b0adcad3a71ce0d9cd4acb219""><code>0c21937</code></a> Run &quot;npm run build&quot;</li>
<li><a href=""https://github.com/github/codeql-action/commit/5a61bf07fab8324ecda8ebb1d817463b17b717d9""><code>5a61bf0</code></a> Kotlin: The 2.20.3 release supports Kotlin 2.1.10.</li>
<li><a href=""https://github.com/github/codeql-action/commit/163d1195df65a0e49551cd9b4fa0383e68d64a39""><code>163d119</code></a> Update checked-in dependencies</li>
<li><a href=""https://github.com/github/codeql-action/commit/bcf5cecbc6b147de017e1841778fa8d8644bf8a2""><code>bcf5cec</code></a> Update changelog and version after v3.28.7</li>
<li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/f09c1c0a94de965c15400f5634aa42fac8fb8f88...dd746615b3b9d728a6a37ca2045b68ca76d4841a"">compare view</a></li>
</ul>
</details>
<br />

Updates `docker/setup-buildx-action` from 3.7.1 to 3.8.0
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/docker/setup-buildx-action/releases"">docker/setup-buildx-action's releases</a>.</em></p>
<blockquote>
<h2>v3.8.0</h2>
<ul>
<li>Make cloud prefix optional to download buildx if driver is cloud by <a href=""https://github.com/crazy-max""><code>@crazy-max</code></a> in <a href=""https://redirect.github.com/docker/setup-buildx-action/pull/390"">docker/setup-buildx-action#390</a></li>
<li>Bump <code>@actions/core</code> from 1.10.1 to 1.11.1 in <a href=""https://redirect.github.com/docker/setup-buildx-action/pull/370"">docker/setup-buildx-action#370</a></li>
<li>Bump <code>@docker/actions-toolkit</code> from 0.39.0 to 0.48.0 in <a href=""https://redirect.github.com/docker/setup-buildx-action/pull/389"">docker/setup-buildx-action#389</a></li>
<li>Bump cross-spawn from 7.0.3 to 7.0.6 in <a href=""https://redirect.github.com/docker/setup-buildx-action/pull/382"">docker/setup-buildx-action#382</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/setup-buildx-action/compare/v3.7.1...v3.8.0"">https://github.com/docker/setup-buildx-action/compare/v3.7.1...v3.8.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/6524bf65af31da8d45b59e8c27de4bd072b392f5""><code>6524bf6</code></a> Merge pull request <a href=""https://redirect.github.com/docker/setup-buildx-action/issues/390"">#390</a> from crazy-max/buildx-cloud-latest</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/8d5e0747fc81adde3c75a11c4ab1cd6e831c45b5""><code>8d5e074</code></a> chore: update generated content</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/7199e57b3551d377384de4d86bb21b747aea8ae4""><code>7199e57</code></a> make cloud prefix optional to download buildx if driver is cloud</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/db63cee3de03c9e9f201f1b6213e29b58eaa560d""><code>db63cee</code></a> Merge pull request <a href=""https://redirect.github.com/docker/setup-buildx-action/issues/381"">#381</a> from docker/dependabot/github_actions/codecov/codecov...</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/043ebe137fb9440c054da78ea0d12b4770d51bb0""><code>043ebe1</code></a> Merge pull request <a href=""https://redirect.github.com/docker/setup-buildx-action/issues/389"">#389</a> from docker/dependabot/npm_and_yarn/docker/actions-to...</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/686da9073d5e9e34c27fc99d06023785a093b3b2""><code>686da90</code></a> chore: update generated content</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/a3d74876b8fd9bd06b520ed90e4838a3ab637302""><code>a3d7487</code></a> Merge pull request <a href=""https://redirect.github.com/docker/setup-buildx-action/issues/382"">#382</a> from docker/dependabot/npm_and_yarn/cross-spawn-7.0.6</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/4dcdbcec48953cab044a8e7d13f601ffd1926c08""><code>4dcdbce</code></a> build(deps): bump <code>@docker/actions-toolkit</code> from 0.39.0 to 0.48.0</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/1a8ac74316906cd182c3b1e6361b0648f1800ecc""><code>1a8ac74</code></a> ci: fix deprecated input for codecov-action</li>
<li><a href=""https://github.com/docker/setup-buildx-action/commit/e827ebe8ba8bcef11893610e158210f4ce7c2ded""><code>e827ebe</code></a> build(deps): bump cross-spawn from 7.0.3 to 7.0.6</li>
<li>Additional commits viewable in <a href=""https://github.com/docker/setup-buildx-action/compare/c47758b77c9736f4b2ef4073d4d51994fabfe349...6524bf65af31da8d45b59e8c27de4bd072b392f5"">compare view</a></li>
</ul>
</details>
<br />

Updates `docker/build-push-action` from 6.10.0 to 6.13.0
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/docker/build-push-action/releases"">docker/build-push-action's releases</a>.</em></p>
<blockquote>
<h2>v6.13.0</h2>
<ul>
<li>Bump <code>@docker/actions-toolkit</code> from 0.51.0 to 0.53.0 in <a href=""https://redirect.github.com/docker/build-push-action/pull/1308"">docker/build-push-action#1308</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/build-push-action/compare/v6.12.0...v6.13.0"">https://github.com/docker/build-push-action/compare/v6.12.0...v6.13.0</a></p>
<h2>v6.12.0</h2>
<ul>
<li>Bump <code>@docker/actions-toolkit</code> from 0.49.0 to 0.51.0 in <a href=""https://redirect.github.com/docker/build-push-action/pull/1300"">docker/build-push-action#1300</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/build-push-action/compare/v6.11.0...v6.12.0"">https://github.com/docker/build-push-action/compare/v6.11.0...v6.12.0</a></p>
<h2>v6.11.0</h2>
<ul>
<li>Handlebar <code>defaultContext</code> support for <code>build-contexts</code> input by <a href=""https://github.com/crazy-max""><code>@crazy-max</code></a> in <a href=""https://redirect.github.com/docker/build-push-action/pull/1283"">docker/build-push-action#1283</a></li>
<li>Bump <code>@docker/actions-toolkit</code> from 0.46.0 to 0.49.0 in <a href=""https://redirect.github.com/docker/build-push-action/pull/1281"">docker/build-push-action#1281</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/build-push-action/compare/v6.10.0...v6.11.0"">https://github.com/docker/build-push-action/compare/v6.10.0...v6.11.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/docker/build-push-action/commit/ca877d9245402d1537745e0e356eab47c3520991""><code>ca877d9</code></a> Merge pull request <a href=""https://redirect.github.com/docker/build-push-action/issues/1308"">#1308</a> from docker/dependabot/npm_and_yarn/docker/actions-t...</li>
<li><a href=""https://github.com/docker/build-push-action/commit/d2fe919bb5012a6186426dc91c361c4980d10c2d""><code>d2fe919</code></a> chore: update generated content</li>
<li><a href=""https://github.com/docker/build-push-action/commit/f0fc9ece82cf2ace13ec8f35687697ae511bdf74""><code>f0fc9ec</code></a> chore(deps): Bump <code>@docker/actions-toolkit</code> from 0.51.0 to 0.53.0</li>
<li><a href=""https://github.com/docker/build-push-action/commit/67a2d409c0a876cbe6b11854e3e25193efe4e62d""><code>67a2d40</code></a> Merge pull request <a href=""https://redirect.github.com/docker/build-push-action/issues/1300"">#1300</a> from docker/dependabot/npm_and_yarn/docker/actions-t...</li>
<li><a href=""https://github.com/docker/build-push-action/commit/0b1b1c9c43ec788c199860037a0545356ea03d26""><code>0b1b1c9</code></a> chore: update generated content</li>
<li><a href=""https://github.com/docker/build-push-action/commit/b6a7c2c4eec8151a4dbcd3823747fe1b77d5b280""><code>b6a7c2c</code></a> chore(deps): Bump <code>@docker/actions-toolkit</code> from 0.49.0 to 0.51.0</li>
<li><a href=""https://github.com/docker/build-push-action/commit/31ca4e5d51253d7e4a2317bfe74699cbe3a398a9""><code>31ca4e5</code></a> Merge pull request <a href=""https://redirect.github.com/docker/build-push-action/issues/1296"">#1296</a> from crazy-max/bake-v6</li>
<li><a href=""https://github.com/docker/build-push-action/commit/e613db9d5a93dda4d07aeb81991e80164577ae4a""><code>e613db9</code></a> update bake-action to v6</li>
<li><a href=""https://github.com/docker/build-push-action/commit/b32b51a8eda65d6793cd0494a773d4f6bcef32dc""><code>b32b51a</code></a> Merge pull request <a href=""https://redirect.github.com/docker/build-push-action/issues/1281"">#1281</a> from docker/dependabot/npm_and_yarn/docker/actions-t...</li>
<li><a href=""https://github.com/docker/build-push-action/commit/594bf46f0f6d32fd8bd98a553127950004165c96""><code>594bf46</code></a> Merge pull request <a href=""https://redirect.github.com/docker/build-push-action/issues/1294"">#1294</a> from crazy-max/fix-e2e</li>
<li>Additional commits viewable in <a href=""https://github.com/docker/build-push-action/compare/48aba3b46d1b1fec4febb7c5d0c644b249a11355...ca877d9245402d1537745e0e356eab47c3520991"">compare view</a></li>
</ul>
</details>
<br />

Updates `actions/stale` from 9.0.0 to 9.1.0
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/stale/releases"">actions/stale's releases</a>.</em></p>
<blockquote>
<h2>v9.1.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Documentation update by <a href=""https://github.com/Marukome0743""><code>@Marukome0743</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1116"">actions/stale#1116</a></li>
<li>Add workflow file for publishing releases to immutable action package by <a href=""https://github.com/Jcambass""><code>@Jcambass</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1179"">actions/stale#1179</a></li>
<li>Update undici from 5.28.2 to 5.28.4 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1150"">actions/stale#1150</a></li>
<li>Update actions/checkout from 3 to 4 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1091"">actions/stale#1091</a></li>
<li>Update actions/publish-action from 0.2.2 to 0.3.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1147"">actions/stale#1147</a></li>
<li>Update ts-jest from 29.1.1 to 29.2.5 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1175"">actions/stale#1175</a></li>
<li>Update <code>@actions/core</code> from 1.10.1 to 1.11.1 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1191"">actions/stale#1191</a></li>
<li>Update <code>@types/jest</code> from 29.5.11 to 29.5.14 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1193"">actions/stale#1193</a></li>
<li>Update <code>@actions/cache</code> from 3.2.2 to 4.0.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/stale/pull/1194"">actions/stale#1194</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/Marukome0743""><code>@Marukome0743</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/stale/pull/1116"">actions/stale#1116</a></li>
<li><a href=""https://github.com/Jcambass""><code>@Jcambass</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/stale/pull/1179"">actions/stale#1179</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/stale/compare/v9...v9.1.0"">https://github.com/actions/stale/compare/v9...v9.1.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/stale/commit/5bef64f19d7facfb25b37b414482c7164d639639""><code>5bef64f</code></a> build(deps): bump <code>@actions/cache</code> from 3.2.2 to 4.0.0 (<a href=""https://redirect.github.com/actions/stale/issues/1194"">#1194</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/fa77dfddd04682b7d96dbc4e016318e681fdc10e""><code>fa77dfd</code></a> build(deps-dev): bump <code>@types/jest</code> from 29.5.11 to 29.5.14 (<a href=""https://redirect.github.com/actions/stale/issues/1193"">#1193</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/f04443dce335c74ba15c65f4cbb3688e6cb6a6ec""><code>f04443d</code></a> build(deps): bump <code>@actions/core</code> from 1.10.1 to 1.11.1 (<a href=""https://redirect.github.com/actions/stale/issues/1191"">#1191</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/5c715b0513651880806e14d529f014b12fdd50eb""><code>5c715b0</code></a> build(deps-dev): bump ts-jest from 29.1.1 to 29.2.5 (<a href=""https://redirect.github.com/actions/stale/issues/1175"">#1175</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/f69122271d990fd11f5594ccff2296f00ff59b49""><code>f691222</code></a> build(deps): bump actions/publish-action from 0.2.2 to 0.3.0 (<a href=""https://redirect.github.com/actions/stale/issues/1147"">#1147</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/df990c2cf5ae92c90653c9485d6882a0a09feac7""><code>df990c2</code></a> build(deps): bump actions/checkout from 3 to 4 (<a href=""https://redirect.github.com/actions/stale/issues/1091"">#1091</a>)</li>
<li><a href=""https://github.com/actions/stale/commit/6e472ce44ab4197b0154601c59c54a75b73b340b""><code>6e472ce</code></a> Merge pull request <a href=""https://redirect.github.com/actions/stale/issues/1179"">#1179</a> from actions/Jcambass-patch-1</li>
<li><a href=""https://github.com/actions/stale/commit/d10ba64261d965f75165f74c55cd3ffbf690d442""><code>d10ba64</code></a> Merge pull request <a href=""https://redirect.github.com/actions/stale/issues/1150"">#1150</a> from actions/dependabot/npm_and_yarn/undici-5.28.4</li>
<li><a href=""https://github.com/actions/stale/commit/bbf3da5f64eebd003932d93293857400f7f7e18d""><code>bbf3da5</code></a> resolve check failures</li>
<li><a href=""https://github.com/actions/stale/commit/6a2e61d18b155e538f85ef1bf7bd0470775e9703""><code>6a2e61d</code></a> Add workflow file for publishing releases to immutable action package</li>
<li>Additional commits viewable in <a href=""https://github.com/actions/stale/compare/28ca1036281a5e5922ead5184a1bbf96e5fc984e...5bef64f19d7facfb25b37b414482c7164d639639"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore <dependency name> major version` will close this group update PR and stop Dependabot creating any more for the specific dependency's major version (unless you unignore this specific dependency's major version or upgrade to it yourself)
- `@dependabot ignore <dependency name> minor version` will close this group update PR and stop Dependabot creating any more for the specific dependency's minor version (unless you unignore this specific dependency's minor version or upgrade to it yourself)
- `@dependabot ignore <dependency name>` will close this group update PR and stop Dependabot creating any more for the specific dependency (unless you unignore this specific dependency or upgrade to it yourself)
- `@dependabot unignore <dependency name>` will remove all of the ignore conditions of the specified dependency
- `@dependabot unignore <dependency name> <ignore condition>` will remove the ignore condition of the specified dependency and ignore conditions


</details>",dependabot[bot],2025-02-01 08:42:19+00:00,['gbaned'],2025-02-03 11:39:15+00:00,2025-02-03 11:39:14+00:00,https://github.com/tensorflow/tensorflow/pull/86354,"[('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small'), ('dependencies', 'Pull requests that update a dependency file'), ('github_actions', 'Pull requests that update GitHub Actions code')]",[],
2825076116,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 08:37:36+00:00,[],2025-02-01 08:37:36+00:00,,https://github.com/tensorflow/tensorflow/pull/86353,[],[],
2825033380,pull_request,open,,Remove the is_last_transfer parameter,"Remove the is_last_transfer parameter
",copybara-service[bot],2025-02-01 07:28:16+00:00,[],2025-02-06 06:10:34+00:00,,https://github.com/tensorflow/tensorflow/pull/86352,[],[],
2825028650,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 07:18:26+00:00,[],2025-02-01 07:18:26+00:00,,https://github.com/tensorflow/tensorflow/pull/86351,[],[],
2825015454,pull_request,open,,fix(kernels): Handle empty values with non-empty row splits in RaggedTensorToTensor,"This commit addresses a segmentation fault in the `RaggedTensorToTensor` op when processing empty values with non-empty row splits:
- Checking for empty values before processing.
- Ensuring consistent handling of dimension sizes.
- Providing clear error messages for invalid input configurations.

Might fix #85240.",harshaljanjani,2025-02-01 06:51:34+00:00,['gbaned'],2025-02-06 13:24:17+00:00,,https://github.com/tensorflow/tensorflow/pull/86349,"[('ready to pull', 'PR ready for merge process'), ('size:M', 'CL Change Size: Medium'), ('comp:core', 'issues related to core part of tensorflow')]","[{'comment_id': 2631202976, 'issue_id': 2825015454, 'author': 'harshaljanjani', 'body': ""> Please make sure to not include irrelevant spacing changes.\n\nUnderstood, it's my first time contributing here; thanks for the information! Will take care of the linting next time around."", 'created_at': datetime.datetime(2025, 2, 3, 14, 44, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2639821999, 'issue_id': 2825015454, 'author': 'harshaljanjani', 'body': ""> Can you please make sure to run all tests and make sure they pass?\r\n\r\nHello @mihaimaruseac, thanks for the reply.\r\n\r\nActually, I'm not quite able to figure out why my local setup's failing with these `bash -r not found` errors. Besides, I tried converting the CRLF endings to LF endings (given that I'm running the bazel tests in WSL). I wished to ask if there's a better way to set up and run tests locally that you'd recommend with WSL, as I've read the CONTRIBUTING.md file and set it up to the tee but am still facing these issues that impede my progress; thanks!"", 'created_at': datetime.datetime(2025, 2, 6, 13, 24, 14, tzinfo=datetime.timezone.utc)}]","harshaljanjani (Issue Creator) on (2025-02-03 14:44:41 UTC): Understood, it's my first time contributing here; thanks for the information! Will take care of the linting next time around.

harshaljanjani (Issue Creator) on (2025-02-06 13:24:14 UTC): Hello @mihaimaruseac, thanks for the reply.

Actually, I'm not quite able to figure out why my local setup's failing with these `bash -r not found` errors. Besides, I tried converting the CRLF endings to LF endings (given that I'm running the bazel tests in WSL). I wished to ask if there's a better way to set up and run tests locally that you'd recommend with WSL, as I've read the CONTRIBUTING.md file and set it up to the tee but am still facing these issues that impede my progress; thanks!

"
2824963629,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 05:16:02+00:00,[],2025-02-01 05:16:02+00:00,,https://github.com/tensorflow/tensorflow/pull/86348,[],[],
2824955221,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-02-01 05:08:07+00:00,[],2025-02-01 05:08:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86347,[],[],
2824750946,pull_request,closed,,Internal only change,"Internal only change
",copybara-service[bot],2025-02-01 02:16:01+00:00,['sirakiin'],2025-02-01 02:49:42+00:00,2025-02-01 02:49:41+00:00,https://github.com/tensorflow/tensorflow/pull/86346,[],[],
2824713417,pull_request,open,,"[xla:tsl] concurrency: tag xla_cpu_runtime_{srcs,hdrs} as non-prod-compatible","[xla:tsl] concurrency: tag xla_cpu_runtime_{srcs,hdrs} as non-prod-compatible
",copybara-service[bot],2025-02-01 01:33:31+00:00,['cota'],2025-02-01 01:33:32+00:00,,https://github.com/tensorflow/tensorflow/pull/86345,[],[],
2824712147,pull_request,open,,[xla:cpu] xla.proto: introduce xla_cpu_use_fusion_emitters flag,"[xla:cpu] xla.proto: introduce xla_cpu_use_fusion_emitters flag

The implementation is coming up next.
",copybara-service[bot],2025-02-01 01:32:21+00:00,['cota'],2025-02-01 10:20:50+00:00,,https://github.com/tensorflow/tensorflow/pull/86344,[],[],
2824701877,pull_request,open,,[xla:cpu] kernel_api_ir_builder: expose SetKernelFunctionAttributes,"[xla:cpu] kernel_api_ir_builder: expose SetKernelFunctionAttributes

So that fusion emitters will be able to set these same
attributes. The fusion emitters are landing soon.
",copybara-service[bot],2025-02-01 01:27:23+00:00,['cota'],2025-02-01 10:25:09+00:00,,https://github.com/tensorflow/tensorflow/pull/86343,[],[],
2824697901,pull_request,open,,[xla:cpu] kernel_api_ir_builder: expose helpers to get KernelParams,"[xla:cpu] kernel_api_ir_builder: expose helpers to get KernelParams

This paves the way for upcoming work.
",copybara-service[bot],2025-02-01 01:24:58+00:00,['cota'],2025-02-01 10:55:34+00:00,,https://github.com/tensorflow/tensorflow/pull/86342,[],[],
2824694016,pull_request,open,,"[xla:emitters] tag XLA, XLA:CPU and XLA:GPU dialects as non-prod-compatible","[xla:emitters] tag XLA, XLA:CPU and XLA:GPU dialects as non-prod-compatible

This paves the way for XLA:CPU fusion emitters.

Note that XLA:CPU is non-prod-compatible, whereas XLA:GPU is
not. The CPU fusion emitters will depend on the XLA, XLA:CPU
and XLA:GPU dialects, and given that the emitters' dependents
in XLA:CPU are non-prod-compatible, the three dialects have
to be as well.

XLA:CPU passes also have to be tagged. Crucially, thanks to
the parent CLs, XLA:GPU passes are not used anymore by any of
the above dialects nor by XLA:CPU passes, so XLA:GPU remains
essentially untouched; we just tag the XLA:GPU dialect.

Some common libraries in xla/codegen/emitters are also tagged.
",copybara-service[bot],2025-02-01 01:20:40+00:00,['cota'],2025-02-02 21:44:37+00:00,,https://github.com/tensorflow/tensorflow/pull/86341,[],[],
2824691045,pull_request,closed,,[xla:emitters] move LowerXlaToScfPass and LowerXlaLoopsToScfPass to xla/codegen/emitters,"[xla:emitters] move LowerXlaToScfPass and LowerXlaLoopsToScfPass to xla/codegen/emitters

Will be shared with the CPU pipeline.
Note that some GPU ops are also converted, but that's OK because
what we don't want is to depend on GPU passes from common bits;
depending on GPU ops is OK.

Reverts 6b431d3ca515c8afc08b1bdfaf4253adf4234b19
",copybara-service[bot],2025-02-01 01:16:50+00:00,['cota'],2025-02-04 19:51:37+00:00,2025-02-04 19:51:36+00:00,https://github.com/tensorflow/tensorflow/pull/86340,[],[],
2824689694,pull_request,closed,,[xla:emitters] move MergePointersToSameSlicePass to xla/codegen/emitters,"[xla:emitters] move MergePointersToSameSlicePass to xla/codegen/emitters

Will be shared with the CPU pipeline.
",copybara-service[bot],2025-02-01 01:15:07+00:00,['cota'],2025-02-04 16:46:32+00:00,2025-02-04 16:46:32+00:00,https://github.com/tensorflow/tensorflow/pull/86339,[],[],
2824663877,pull_request,closed,,Delete ARM64 Kokoro build now that Github Actions based build is blocking,"Delete ARM64 Kokoro build now that Github Actions based build is blocking
",copybara-service[bot],2025-02-01 00:53:07+00:00,['ddunl'],2025-02-03 22:47:13+00:00,2025-02-03 22:47:13+00:00,https://github.com/tensorflow/tensorflow/pull/86338,[],[],
2824634917,pull_request,open,,Integrate LLVM at llvm/llvm-project@6deee0d5b36c,"Integrate LLVM at llvm/llvm-project@6deee0d5b36c

Updates LLVM usage to match
[6deee0d5b36c](https://github.com/llvm/llvm-project/commit/6deee0d5b36c)
",copybara-service[bot],2025-02-01 00:28:43+00:00,[],2025-02-01 05:45:32+00:00,,https://github.com/tensorflow/tensorflow/pull/86337,[],[],
2824634891,pull_request,closed,,Update sha values for JAX cuda images,"Update sha values for JAX cuda images
",copybara-service[bot],2025-02-01 00:28:42+00:00,['kanglant'],2025-02-01 01:10:20+00:00,2025-02-01 01:10:19+00:00,https://github.com/tensorflow/tensorflow/pull/86336,[],[],
2824605626,pull_request,closed,,Add Q/DQ annotation interfaces in ai-edge-jax,"Add Q/DQ annotation interfaces in ai-edge-jax
",copybara-service[bot],2025-02-01 00:03:52+00:00,['majiddadashi'],2025-02-01 00:04:51+00:00,2025-02-01 00:04:51+00:00,https://github.com/tensorflow/tensorflow/pull/86335,[],[],
2824596597,pull_request,open,,"Return arrays from `ArrayImpl._check_and_rearrange`. Build IFRT shardings with both addressable and non-addressable devices, instead of only addressable devices.","Return arrays from `ArrayImpl._check_and_rearrange`. Build IFRT shardings with both addressable and non-addressable devices, instead of only addressable devices.

This is a roll-forward of two previous rollbacks after fixing breakages.
",copybara-service[bot],2025-01-31 23:55:17+00:00,[],2025-02-04 05:46:18+00:00,,https://github.com/tensorflow/tensorflow/pull/86334,[],[],
2824584370,pull_request,open,,Add Q/DQ annotation lowering support.,"Add Q/DQ annotation lowering support.

LowerQuantAnnotationsPass now supports quant.quantize and quant.dequantize composite lowering. These patterns make adjustments to the function signatures if necessary.
",copybara-service[bot],2025-01-31 23:45:56+00:00,['majiddadashi'],2025-02-04 23:08:49+00:00,,https://github.com/tensorflow/tensorflow/pull/86333,[],[],
2824577326,pull_request,closed,,Update RaggedAllToAll API to clarify supported shapes for offsets/sizes operands.,"Update RaggedAllToAll API to clarify supported shapes for offsets/sizes operands.
",copybara-service[bot],2025-01-31 23:38:37+00:00,[],2025-02-04 20:54:32+00:00,2025-02-04 20:54:31+00:00,https://github.com/tensorflow/tensorflow/pull/86332,[],[],
2824560545,pull_request,closed,,Reverts e05f2be59cd34b3f0b2291d91ba1353e90fb1c25,"Reverts e05f2be59cd34b3f0b2291d91ba1353e90fb1c25
",copybara-service[bot],2025-01-31 23:23:30+00:00,['reedwm'],2025-02-01 00:51:19+00:00,2025-02-01 00:51:18+00:00,https://github.com/tensorflow/tensorflow/pull/86331,[],[],
2824545470,pull_request,closed,,Add control dependencies to conflicting collectives when decomposing collective-permute into send/recv,"Add control dependencies to conflicting collectives when decomposing collective-permute into send/recv

This is to ensure that conflicting collectives are not scheduled in between the decomposed send/recv ops, which would cause deadlocks.
",copybara-service[bot],2025-01-31 23:07:34+00:00,['frgossen'],2025-02-05 20:53:55+00:00,2025-02-05 20:53:54+00:00,https://github.com/tensorflow/tensorflow/pull/86330,[],[],
2824545292,pull_request,closed,,Annotate decomposed send/recv and conflicting collectives to run them in parallel,"Annotate decomposed send/recv and conflicting collectives to run them in parallel

Find all collectives conflicting with the collective permutes that we want to decompose.
Annotate them to run them in parallel with non-conflicting collectives, e.g. those used on inner sharding strategies.
The annotation allows us to later execute them on a separate stream.
",copybara-service[bot],2025-01-31 23:07:20+00:00,['frgossen'],2025-02-06 15:16:56+00:00,2025-02-06 15:16:54+00:00,https://github.com/tensorflow/tensorflow/pull/86329,[],[],
2824513621,pull_request,closed,,[xla:cpu] Delete unused timeslice parameter from parallel loop runner,"[xla:cpu] Delete unused timeslice parameter from parallel loop runner
",copybara-service[bot],2025-01-31 22:37:36+00:00,['ezhulenev'],2025-02-01 01:22:34+00:00,2025-02-01 01:22:33+00:00,https://github.com/tensorflow/tensorflow/pull/86328,[],[],
2824508698,pull_request,closed,,PR #22073: Add a README file in the gpu_specs directory.,"PR #22073: Add a README file in the gpu_specs directory.

Imported from GitHub PR https://github.com/openxla/xla/pull/22073


Copybara import of the project:

--
659afd527c8cbe9e67dca813cb182c13c41889ef by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Add a README file in the gpu_specs directory.

--
9a8bf3a49eff2882c8fbbea60644ca1c8ad45333 by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Improved the README.

Merging this change closes #22073

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22073 from dimvar:add-readme-to-gpu_specs 9a8bf3a49eff2882c8fbbea60644ca1c8ad45333
",copybara-service[bot],2025-01-31 22:32:52+00:00,[],2025-01-31 23:17:15+00:00,2025-01-31 23:17:14+00:00,https://github.com/tensorflow/tensorflow/pull/86327,[],[],
2824494842,pull_request,closed,,Consider send/recv in IsNonFusionCollective,"Consider send/recv in IsNonFusionCollective
",copybara-service[bot],2025-01-31 22:20:29+00:00,['frgossen'],2025-02-03 18:35:26+00:00,2025-02-03 18:35:25+00:00,https://github.com/tensorflow/tensorflow/pull/86326,[],[],
2824407392,pull_request,open,,[DNS] Add StableHLO simplification passes to PJRT,"[DNS] Add StableHLO simplification passes to PJRT
",copybara-service[bot],2025-01-31 21:16:08+00:00,['GleasonK'],2025-02-04 23:04:47+00:00,,https://github.com/tensorflow/tensorflow/pull/86325,[],[],
2824401669,pull_request,closed,,Reverts 46f98fe577a1591a800d17cbb0c0b4000ff13f74,"Reverts 46f98fe577a1591a800d17cbb0c0b4000ff13f74
",copybara-service[bot],2025-01-31 21:12:04+00:00,[],2025-01-31 21:48:55+00:00,2025-01-31 21:48:55+00:00,https://github.com/tensorflow/tensorflow/pull/86324,[],[],
2824380171,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22107 from dimvar:fix-configure-file-for-blackwell a718233bcf95d047a11b1d18366133f08d3b1eee
",copybara-service[bot],2025-01-31 20:56:22+00:00,['ddunl'],2025-01-31 21:43:24+00:00,2025-01-31 21:43:23+00:00,https://github.com/tensorflow/tensorflow/pull/86323,[],[],
2824353291,pull_request,open,,Fix GPU memcpy a2a crash with multiple replica groups.,"Fix GPU memcpy a2a crash with multiple replica groups.

AllToAll with the flag --set_xla_gpu_use_memcpy_local_p2p=1 would previously crash or give incorrect results when there were multiple replica groups on GPUs. The issue is NcclAllToAllStartThunk had maps from the device ID to various buffers used for the all-to-all. The device ID was previously modded by the size of the current replica_group, which meant devices in different replica groups could share device IDs, causing them to use share buffers, causing incorrect results or crashes. The device ID is no longer modded by the size of the replica_group.
",copybara-service[bot],2025-01-31 20:36:16+00:00,['reedwm'],2025-01-31 21:48:21+00:00,,https://github.com/tensorflow/tensorflow/pull/86322,[],[],
2824332776,pull_request,open,,"nb::cast cannot actually cast to span for some reason, so just always","nb::cast cannot actually cast to span for some reason, so just always
leave as a nb::object.
",copybara-service[bot],2025-01-31 20:21:14+00:00,['pschuh'],2025-01-31 20:21:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86321,[],[],
2824268281,pull_request,closed,,Integrate LLVM at llvm/llvm-project@956c0707d909,"Integrate LLVM at llvm/llvm-project@956c0707d909

Updates LLVM usage to match
[956c0707d909](https://github.com/llvm/llvm-project/commit/956c0707d909)
",copybara-service[bot],2025-01-31 19:44:58+00:00,[],2025-01-31 21:34:13+00:00,2025-01-31 21:34:13+00:00,https://github.com/tensorflow/tensorflow/pull/86320,[],[],
2824267809,pull_request,closed,,[HLO] Use llvm::StringRef when building MHLO string attributes instead of relying on implicit casting,"[HLO] Use llvm::StringRef when building MHLO string attributes instead of relying on implicit casting
",copybara-service[bot],2025-01-31 19:44:39+00:00,['GleasonK'],2025-01-31 22:38:47+00:00,2025-01-31 22:38:47+00:00,https://github.com/tensorflow/tensorflow/pull/86319,[],[],
2824229025,pull_request,closed,,"#litert Remove `test_macros.h`, superseded by `litert_macros.h`","#litert Remove `test_macros.h`, superseded by `litert_macros.h`
",copybara-service[bot],2025-01-31 19:22:29+00:00,['qukhan'],2025-02-04 23:21:27+00:00,2025-02-04 23:21:26+00:00,https://github.com/tensorflow/tensorflow/pull/86318,[],[],
2824225177,pull_request,closed,,PR #22107: Change cuda_configure.bzl to handle blackwell ptx variants with accelerated features.,"PR #22107: Change cuda_configure.bzl to handle blackwell ptx variants with accelerated features.

Imported from GitHub PR https://github.com/openxla/xla/pull/22107


Copybara import of the project:

--
a718233bcf95d047a11b1d18366133f08d3b1eee by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Change cuda_configure.bzl to handle blackwell ptx variants with accelerated features.

Merging this change closes #22107

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22107 from dimvar:fix-configure-file-for-blackwell a718233bcf95d047a11b1d18366133f08d3b1eee
",copybara-service[bot],2025-01-31 19:20:51+00:00,[],2025-01-31 20:51:20+00:00,2025-01-31 20:51:19+00:00,https://github.com/tensorflow/tensorflow/pull/86317,[],[],
2824156545,pull_request,closed,,Reverts b77fc611f78c5511c3881060b5c695df9c72d3a8,"Reverts b77fc611f78c5511c3881060b5c695df9c72d3a8
",copybara-service[bot],2025-01-31 18:36:38+00:00,[],2025-01-31 20:27:51+00:00,2025-01-31 20:27:51+00:00,https://github.com/tensorflow/tensorflow/pull/86316,[],[],
2824151205,pull_request,closed,,[xla:cpu] Do not put moved-from XnnRuntime back into the pool,"[xla:cpu] Do not put moved-from XnnRuntime back into the pool
",copybara-service[bot],2025-01-31 18:33:03+00:00,['ezhulenev'],2025-01-31 20:06:38+00:00,2025-01-31 20:06:37+00:00,https://github.com/tensorflow/tensorflow/pull/86315,[],[],
2824126744,pull_request,open,,In Progress.,"In Progress.
Adds a minimal but viable implementation of string arrays (with `numpy.dtypes.StringDType`) in JAX. Currently this only supports making of a string array by means of either `jax.numpy.asarray` or `jax.device_put` and reading it back with `jax.device_get`.
",copybara-service[bot],2025-01-31 18:17:03+00:00,[],2025-01-31 18:55:50+00:00,,https://github.com/tensorflow/tensorflow/pull/86314,[],[],
2824123196,pull_request,closed,,Reverts 0e749daf4bcf5423c48534611927dd28e985dccc,"Reverts 0e749daf4bcf5423c48534611927dd28e985dccc
",copybara-service[bot],2025-01-31 18:14:45+00:00,[],2025-01-31 22:49:52+00:00,2025-01-31 22:49:52+00:00,https://github.com/tensorflow/tensorflow/pull/86313,[],[],
2824117224,pull_request,open,,[XLA] Clean up and refactor HeapSimulator.,"[XLA] Clean up and refactor HeapSimulator.
",copybara-service[bot],2025-01-31 18:10:55+00:00,[],2025-01-31 18:10:55+00:00,,https://github.com/tensorflow/tensorflow/pull/86312,[],[],
2824113373,pull_request,closed,,Display the flax_2b E2E benchmark results to show TTFT and E2E latency,"Display the flax_2b E2E benchmark results to show TTFT and E2E latency
",copybara-service[bot],2025-01-31 18:08:21+00:00,['juliagmt-google'],2025-01-31 19:49:17+00:00,2025-01-31 19:49:16+00:00,https://github.com/tensorflow/tensorflow/pull/86311,[],[],
2824089023,pull_request,closed,,Set absolute compiler path for hermetic CUDA repository.,"Set absolute compiler path for hermetic CUDA repository.

Addressed the bug https://github.com/pytorch/xla/issues/8577.
",copybara-service[bot],2025-01-31 17:53:17+00:00,[],2025-01-31 19:24:24+00:00,2025-01-31 19:24:23+00:00,https://github.com/tensorflow/tensorflow/pull/86309,[],[],
2824080829,pull_request,open,,PR #21886: [ROCM][NFC] BlasLt interface refactoring & simplifying: part I,"PR #21886: [ROCM][NFC] BlasLt interface refactoring & simplifying: part I

Imported from GitHub PR https://github.com/openxla/xla/pull/21886

After this PR https://github.com/tensorflow/tensorflow/pull/73926 is merged, we can remove unnecessary low-level DoMatmul functions from GpuBlasLt interface (which otherwise looks scary and unnecessarily complicated).

Furthermore, we can also remove **ValidateInputs** function from the interface and derived classes since a high-level **ExecuteOnStream** function already handles data-types correctly. This also greatly simplifies the code.

Also, I have packed the input arguments of ExecuteOnStream calls to a struct **MemoryArgs** to simplify arguments passing in derived classes and improve code readability.

Finally, in the original GpuBlasLt PR: https://github.com/openxla/xla/pull/5911, I made a sort of mistake by adding a reference to **blas_lt** to the MatmulPlan class [here](https://github.com/openxla/xla/blob/main/xla/stream_executor/rocm/hip_blas_lt.h#L135), thereby making MatmulPlans bound to a **particular BlasLt instance**. This resulted in some further bugfixes and, most importantly, complicated GpuBlasLt cache design in gpublas_lt_matmul_thunk.cc/.h. In this PR, I remove this reference again from MatmulPlan class and in the next NFC PR the cache mechanics can also be simplified. 

Unfortunately, this change also requires a tandem PR for Tensorflow: https://github.com/tensorflow/tensorflow/pull/85835

@xla-rotation Would you please have a look


Copybara import of the project:

--
e96bb2fbedab3f53b31ef0e1748582c76e9fb105 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

blaslt interface refactoring: removing blas_lt_ref

added cuda adaptions

cuda-side adaptions

cuda side adaptions

fix

fixing pointers

Merging this change closes #21886

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21886 from ROCm:ci_gpublas_lt_refactor_1 e96bb2fbedab3f53b31ef0e1748582c76e9fb105
",copybara-service[bot],2025-01-31 17:49:17+00:00,[],2025-01-31 17:49:17+00:00,,https://github.com/tensorflow/tensorflow/pull/86308,[],[],
2824076892,pull_request,closed,,[mlir][tosa] Update Tensorflow to match TOSA v1.0 specification (part 2),"We've been pushing TOSA v1.0 LLVM patches to upstream. This PR includes commits to keep the following operators to be aligned with LLVM:

Add NaN Propagation Mode Support:
https://github.com/llvm/llvm-project/pull/121951

Make TOSA MUL's Shift an Input:
https://github.com/llvm/llvm-project/pull/121953

Change the start and size of slice to tosa shape type
https://github.com/llvm/llvm-project/pull/124209",wonjeon,2025-01-31 17:47:20+00:00,['gbaned'],2025-02-06 17:58:25+00:00,2025-02-06 17:58:21+00:00,https://github.com/tensorflow/tensorflow/pull/86307,"[('size:L', 'CL Change Size: Large'), ('comp:lite-tosa', 'TFLite TOSA conversion issues')]","[{'comment_id': 2637522944, 'issue_id': 2824076892, 'author': 'Jerry-Ge', 'body': 'Approved', 'created_at': datetime.datetime(2025, 2, 5, 17, 6, 15, tzinfo=datetime.timezone.utc)}, {'comment_id': 2638210578, 'issue_id': 2824076892, 'author': 'wonjeon', 'body': ""Test result after rebase:\r\n\r\nINFO: Build option --test_env has changed, discarding analysis cache.\r\nINFO: Analyzed 33 targets (3 packages loaded, 32886 targets configured).\r\nINFO: Found 16 targets and 17 test targets...\r\nINFO: Elapsed time: 119.557s, Critical Path: 105.58s\r\nINFO: 886 processes: 26 disk cache hit, 51 internal, 809 local.\r\nINFO: Build completed successfully, 886 total actions\r\n//tensorflow/compiler/mlir/tosa/tests:convert-tfl-uint8.mlir.test        PASSED in 0.5s\r\n//tensorflow/compiler/mlir/tosa/tests:convert_metadata.mlir.test         PASSED in 0.4s\r\n//tensorflow/compiler/mlir/tosa/tests:fuse-bias-tf.mlir.test             PASSED in 0.4s\r\n//tensorflow/compiler/mlir/tosa/tests:lower-complex-types.mlir.test      PASSED in 0.4s\r\n//tensorflow/compiler/mlir/tosa/tests:multi_add.mlir.test                PASSED in 0.4s\r\n//tensorflow/compiler/mlir/tosa/tests:retain_call_once_funcs.mlir.test   PASSED in 0.4s\r\n//tensorflow/compiler/mlir/tosa/tests:strip-quant-types.mlir.test        PASSED in 0.5s\r\n//tensorflow/compiler/mlir/tosa/tests:strip_metadata.mlir.test           PASSED in 0.4s\r\n//tensorflow/compiler/mlir/tosa/tests:tf-tfl-to-tosa-pipeline.mlir.test  PASSED in 0.5s\r\n//tensorflow/compiler/mlir/tosa/tests:tf-to-tosa-pipeline.mlir.test      PASSED in 0.3s\r\n//tensorflow/compiler/mlir/tosa/tests:tf-unequal-ranks.mlir.test         PASSED in 0.2s\r\n//tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-dequantize_softmax.mlir.test PASSED in 0.4s\r\n//tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-pipeline-filtered.mlir.test PASSED in 0.5s\r\n//tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-pipeline.mlir.test     PASSED in 0.3s\r\n//tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-stateful.mlir.test     PASSED in 0.7s\r\n//tensorflow/compiler/mlir/tosa/tests:tfl-unequal-ranks.mlir.test        PASSED in 0.2s\r\n//tensorflow/compiler/mlir/tosa/tests:verify_fully_converted.mlir.test   PASSED in 0.4s\r\n\r\nExecuted 17 out of 17 tests: 17 tests pass.\r\nThere were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.\r\n+ set -e\r\n+ '[' 0 -gt 0 ']'\r\n+ '[' 0 -gt 0 ']'"", 'created_at': datetime.datetime(2025, 2, 5, 22, 49, 2, tzinfo=datetime.timezone.utc)}]","Jerry-Ge on (2025-02-05 17:06:15 UTC): Approved

wonjeon (Issue Creator) on (2025-02-05 22:49:02 UTC): Test result after rebase:

INFO: Build option --test_env has changed, discarding analysis cache.
INFO: Analyzed 33 targets (3 packages loaded, 32886 targets configured).
INFO: Found 16 targets and 17 test targets...
INFO: Elapsed time: 119.557s, Critical Path: 105.58s
INFO: 886 processes: 26 disk cache hit, 51 internal, 809 local.
INFO: Build completed successfully, 886 total actions
//tensorflow/compiler/mlir/tosa/tests:convert-tfl-uint8.mlir.test        PASSED in 0.5s
//tensorflow/compiler/mlir/tosa/tests:convert_metadata.mlir.test         PASSED in 0.4s
//tensorflow/compiler/mlir/tosa/tests:fuse-bias-tf.mlir.test             PASSED in 0.4s
//tensorflow/compiler/mlir/tosa/tests:lower-complex-types.mlir.test      PASSED in 0.4s
//tensorflow/compiler/mlir/tosa/tests:multi_add.mlir.test                PASSED in 0.4s
//tensorflow/compiler/mlir/tosa/tests:retain_call_once_funcs.mlir.test   PASSED in 0.4s
//tensorflow/compiler/mlir/tosa/tests:strip-quant-types.mlir.test        PASSED in 0.5s
//tensorflow/compiler/mlir/tosa/tests:strip_metadata.mlir.test           PASSED in 0.4s
//tensorflow/compiler/mlir/tosa/tests:tf-tfl-to-tosa-pipeline.mlir.test  PASSED in 0.5s
//tensorflow/compiler/mlir/tosa/tests:tf-to-tosa-pipeline.mlir.test      PASSED in 0.3s
//tensorflow/compiler/mlir/tosa/tests:tf-unequal-ranks.mlir.test         PASSED in 0.2s
//tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-dequantize_softmax.mlir.test PASSED in 0.4s
//tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-pipeline-filtered.mlir.test PASSED in 0.5s
//tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-pipeline.mlir.test     PASSED in 0.3s
//tensorflow/compiler/mlir/tosa/tests:tfl-to-tosa-stateful.mlir.test     PASSED in 0.7s
//tensorflow/compiler/mlir/tosa/tests:tfl-unequal-ranks.mlir.test        PASSED in 0.2s
//tensorflow/compiler/mlir/tosa/tests:verify_fully_converted.mlir.test   PASSED in 0.4s

Executed 17 out of 17 tests: 17 tests pass.
There were tests whose specified size is too big. Use the --test_verbose_timeout_warnings command line option to see which ones these are.
+ set -e
+ '[' 0 -gt 0 ']'
+ '[' 0 -gt 0 ']'

"
2824052569,pull_request,closed,,Move export_tf_dialect_op functionality to bridge owned transform utils.,"Move export_tf_dialect_op functionality to bridge owned transform utils.
",copybara-service[bot],2025-01-31 17:33:51+00:00,['rocketas'],2025-02-03 17:02:13+00:00,2025-02-03 17:02:12+00:00,https://github.com/tensorflow/tensorflow/pull/86306,[],"[{'comment_id': 2627874840, 'issue_id': 2824052569, 'author': 'review-notebook-app[bot]', 'body': 'Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/86306""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href=\'https://www.reviewnb.com/?utm_source=gh\'>ReviewNB</a></i>', 'created_at': datetime.datetime(2025, 1, 31, 17, 33, 57, tzinfo=datetime.timezone.utc)}]","review-notebook-app[bot] on (2025-01-31 17:33:57 UTC): Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/86306""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 See visual diffs & provide feedback on Jupyter Notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>

"
2824051452,pull_request,open,,Integrate LLVM at llvm/llvm-project@de7438e47283,"Integrate LLVM at llvm/llvm-project@de7438e47283

Updates LLVM usage to match
[de7438e47283](https://github.com/llvm/llvm-project/commit/de7438e47283)
",copybara-service[bot],2025-01-31 17:33:07+00:00,[],2025-01-31 17:33:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86305,[],[],
2824044274,pull_request,open,,Integrate LLVM at llvm/llvm-project@956c0707d909,"Integrate LLVM at llvm/llvm-project@956c0707d909

Updates LLVM usage to match
[956c0707d909](https://github.com/llvm/llvm-project/commit/956c0707d909)

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/63959 from tensorflow:LakshmiKalaKadali-patch-3 bc8a6549529194af0ed5d5e86d93fe8d0652c10e
",copybara-service[bot],2025-01-31 17:29:26+00:00,[],2025-01-31 17:29:32+00:00,,https://github.com/tensorflow/tensorflow/pull/86304,[],"[{'comment_id': 2627866062, 'issue_id': 2824044274, 'author': 'review-notebook-app[bot]', 'body': 'Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/86304""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href=\'https://www.reviewnb.com/?utm_source=gh\'>ReviewNB</a></i>', 'created_at': datetime.datetime(2025, 1, 31, 17, 29, 31, tzinfo=datetime.timezone.utc)}]","review-notebook-app[bot] on (2025-01-31 17:29:31 UTC): Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/86304""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 See visual diffs & provide feedback on Jupyter Notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>

"
2824043983,pull_request,open,,PR #21746: [NVIDIA GPU] Add collective-permute combiner,"PR #21746: [NVIDIA GPU] Add collective-permute combiner

Imported from GitHub PR https://github.com/openxla/xla/pull/21746

For collective-permutes with small message sizes, it is beneficial to combine them into a single collective because
1. it gets rid of some kernel launch overhead, and allows NCCL to do some message fusion;
2. fewer collectives make it easier for LHS to make better decision.

On top of the multi-operand collective-permute added in https://github.com/openxla/xla/pull/18838, this PR adds a combiner for collective-permutes.
Copybara import of the project:

--
c03a8fb5bd42cf3a365e1684537e78544a75a937 by Terry Sun <tesun@nvidia.com>:

add collective permute combiner

--
6a3159e89444ea342c25d8d996c994accd68a30d by Terry Sun <tesun@nvidia.com>:

polishing and doc string updates

Merging this change closes #21746

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21746 from terryysun:terryysun/combine_collective_permute 9de30a2ee252cf546ebda371e3b6aec852b6167d
",copybara-service[bot],2025-01-31 17:29:15+00:00,[],2025-01-31 17:29:22+00:00,,https://github.com/tensorflow/tensorflow/pull/86303,[],"[{'comment_id': 2627865752, 'issue_id': 2824043983, 'author': 'review-notebook-app[bot]', 'body': 'Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/86303""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href=\'https://www.reviewnb.com/?utm_source=gh\'>ReviewNB</a></i>', 'created_at': datetime.datetime(2025, 1, 31, 17, 29, 21, tzinfo=datetime.timezone.utc)}]","review-notebook-app[bot] on (2025-01-31 17:29:21 UTC): Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/86303""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 See visual diffs & provide feedback on Jupyter Notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>

"
2824028462,pull_request,open,,Bump XLA extension version number to fix the build.,"Bump XLA extension version number to fix the build.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/63959 from tensorflow:LakshmiKalaKadali-patch-3 bc8a6549529194af0ed5d5e86d93fe8d0652c10e
",copybara-service[bot],2025-01-31 17:19:41+00:00,[],2025-01-31 17:19:48+00:00,,https://github.com/tensorflow/tensorflow/pull/86302,[],"[{'comment_id': 2627849793, 'issue_id': 2824028462, 'author': 'review-notebook-app[bot]', 'body': 'Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/86302""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href=\'https://www.reviewnb.com/?utm_source=gh\'>ReviewNB</a></i>', 'created_at': datetime.datetime(2025, 1, 31, 17, 19, 47, tzinfo=datetime.timezone.utc)}]","review-notebook-app[bot] on (2025-01-31 17:19:47 UTC): Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/86302""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 See visual diffs & provide feedback on Jupyter Notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>

"
2823950044,pull_request,closed,,[XLA:CPU] Align JitCompiler config used in kernel tests inline with that used in main pipeline,"[XLA:CPU] Align JitCompiler config used in kernel tests inline with that used in main pipeline
",copybara-service[bot],2025-01-31 16:35:35+00:00,[],2025-02-03 10:24:05+00:00,2025-02-03 10:24:04+00:00,https://github.com/tensorflow/tensorflow/pull/86301,[],[],
2823933297,pull_request,closed,,[xla:hlo] Always print backend_config when deduplicating computations.,"[xla:hlo] Always print backend_config when deduplicating computations.
",copybara-service[bot],2025-01-31 16:27:37+00:00,[],2025-01-31 17:40:59+00:00,2025-01-31 17:40:58+00:00,https://github.com/tensorflow/tensorflow/pull/86300,[],[],
2823862356,pull_request,closed,,[xla:emitters] move UnswitchLoopsPass to xla/codegen/emitters,"[xla:emitters] move UnswitchLoopsPass to xla/codegen/emitters

Will be shared with the CPU pipeline.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22061 from openxla:cleanup_predicate c492d7adb8422c6c23a5d1b4dbcd816f9739a079
",copybara-service[bot],2025-01-31 15:55:57+00:00,['cota'],2025-02-04 15:49:19+00:00,2025-02-04 15:49:16+00:00,https://github.com/tensorflow/tensorflow/pull/86299,[],[],
2823819989,pull_request,closed,,[xla:emitters] move ConvertPureCallOpsPass to xla/codegen/emitters,"[xla:emitters] move ConvertPureCallOpsPass to xla/codegen/emitters

Will be shared with the CPU pipeline.
",copybara-service[bot],2025-01-31 15:35:41+00:00,['cota'],2025-02-04 14:37:10+00:00,2025-02-04 14:37:09+00:00,https://github.com/tensorflow/tensorflow/pull/86298,[],[],
2823817407,pull_request,closed,,[xla:emitters] move SimplifyAffinePass to xla/codegen/emitters,"[xla:emitters] move SimplifyAffinePass to xla/codegen/emitters

Will be shared with the CPU pipeline.
",copybara-service[bot],2025-01-31 15:34:27+00:00,['cota'],2025-02-04 14:18:54+00:00,2025-02-04 14:18:45+00:00,https://github.com/tensorflow/tensorflow/pull/86297,[],[],
2823806502,pull_request,closed,,[XLA:GPU] minor refactoring of the MatMulEmitterHelper functions for the better readability.,"[XLA:GPU] minor refactoring of the MatMulEmitterHelper functions for the better readability.

It is a noop change.
",copybara-service[bot],2025-01-31 15:29:17+00:00,[],2025-02-01 14:56:38+00:00,2025-02-01 14:56:37+00:00,https://github.com/tensorflow/tensorflow/pull/86296,[],[],
2823756940,pull_request,closed,,[xla:emitters] move PropagateSliceIndicesPass to xla/codegen/emitters,"[xla:emitters] move PropagateSliceIndicesPass to xla/codegen/emitters

Will be shared with the CPU pipeline.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22259 from openxla:skozub/fmha_vlog defd81ed2ba416b2013d0000283c5925cf3d9137
",copybara-service[bot],2025-01-31 15:08:42+00:00,['cota'],2025-02-04 13:15:49+00:00,2025-02-04 13:15:48+00:00,https://github.com/tensorflow/tensorflow/pull/86295,[],[],
2823718752,pull_request,open,,[xla:emitters] move PeelLoopsPass to xla/codegen/emitters,"[xla:emitters] move PeelLoopsPass to xla/codegen/emitters

Will be shared with the CPU pipeline.
",copybara-service[bot],2025-01-31 14:54:24+00:00,['cota'],2025-02-01 01:19:27+00:00,,https://github.com/tensorflow/tensorflow/pull/86294,[],[],
2823680367,pull_request,closed,,[XLA:CPU] Add debug flag to enable loop unrolling in LLVM IR optimization pipeline,"[XLA:CPU] Add debug flag to enable loop unrolling in LLVM IR optimization pipeline
",copybara-service[bot],2025-01-31 14:37:45+00:00,[],2025-01-31 17:47:03+00:00,2025-01-31 17:47:02+00:00,https://github.com/tensorflow/tensorflow/pull/86292,[],[],
2823675627,pull_request,closed,,[xla:emitters] move SimplifyArithPass to xla/codegen/emitters,"[xla:emitters] move SimplifyArithPass to xla/codegen/emitters

Will be shared with the CPU pipeline.
",copybara-service[bot],2025-01-31 14:35:27+00:00,['cota'],2025-02-04 12:05:06+00:00,2025-02-04 12:05:06+00:00,https://github.com/tensorflow/tensorflow/pull/86291,[],[],
2823604445,pull_request,closed,,[XLA:GPU] extract 3 different cases from the AddDimToTensorParams,"[XLA:GPU] extract 3 different cases from the AddDimToTensorParams

It is a noop change.

Reverts changelist 721389214
",copybara-service[bot],2025-01-31 14:07:35+00:00,[],2025-01-31 16:40:05+00:00,2025-01-31 16:40:03+00:00,https://github.com/tensorflow/tensorflow/pull/86290,[],[],
2823590425,pull_request,closed,,PR #22102: [ROCm] Add support for the collective memory allocator type,"PR #22102: [ROCm] Add support for the collective memory allocator type

Imported from GitHub PR https://github.com/openxla/xla/pull/22102

This pr introduces support for the collective memory allocator in rocm. Fixing the failing test due to the missing support.
Copybara import of the project:

--
68cb406def43250e7d3005452434ec938ca09e9b by Alexandros Theodoridis <atheodor@amd.com>:

Add support for the collective memory allocator type

--
35ad29769dd13b3f8430ed0e315e94d468af34f6 by Alexandros Theodoridis <atheodor@amd.com>:

Add test

Merging this change closes #22102

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22102 from ROCm:rocm_introduce_support_for_collective_memory_allocator_type 35ad29769dd13b3f8430ed0e315e94d468af34f6
",copybara-service[bot],2025-01-31 14:03:02+00:00,[],2025-01-31 16:49:10+00:00,2025-01-31 16:49:08+00:00,https://github.com/tensorflow/tensorflow/pull/86289,[],[],
2823578921,pull_request,closed,,[xla:emitters] move EraseDeadFunctionsPass to xla/codegen/emitters,"[xla:emitters] move EraseDeadFunctionsPass to xla/codegen/emitters

Will be shared with the CPU pipeline.

Note that the inlining test is a subset of the one in
xla/codegen/emitters/ir/tests/inlining.mlir; remove it.
",copybara-service[bot],2025-01-31 13:57:39+00:00,['cota'],2025-02-04 11:40:31+00:00,2025-02-04 11:40:30+00:00,https://github.com/tensorflow/tensorflow/pull/86288,[],[],
2823562725,pull_request,closed,,[pallas:triton] The lowering now uses PTX instead of Triton IR,"[pallas:triton] The lowering now uses PTX instead of Triton IR

This change improves the stability and backward compatibility of Pallas Triton
calls, because unlike PTX, the Triton dialect has no stability guarantees
and does change in practice.

See #25196.

A few notes

* Pallas Triton no longer delegates compilation to PTX to XLA:GPU. Instead,
  compilation is done via a new PjRt extension, which uses its own compilation
  pipeline mirrored after the one in the Triton Python bindings.
* The implementation of the old custom call used by Pallas Triton is
  deprecated and will be removed after 6 months as per
  [compatibility guarantees] [*]

[*]: https://jax.readthedocs.io/en/latest/export/export.html#compatibility-guarantees
",copybara-service[bot],2025-01-31 13:50:39+00:00,['superbobry'],2025-02-03 21:30:43+00:00,2025-02-03 21:30:42+00:00,https://github.com/tensorflow/tensorflow/pull/86287,[],[],
2823289120,pull_request,closed,,[XLA:CPU] Enable setting optimization level of testlib/KernelRunner,"[XLA:CPU] Enable setting optimization level of testlib/KernelRunner
",copybara-service[bot],2025-01-31 12:22:42+00:00,[],2025-01-31 12:54:18+00:00,2025-01-31 12:54:17+00:00,https://github.com/tensorflow/tensorflow/pull/86286,[],[],
2823274487,pull_request,closed,,Adds stablehlo_case op,Adds unit test for the same,amrinfathima-mcw,2025-01-31 12:17:52+00:00,['gbaned'],2025-02-03 02:48:56+00:00,2025-02-03 02:48:56+00:00,https://github.com/tensorflow/tensorflow/pull/86285,"[('size:XL', 'CL Change Size:Extra Large')]","[{'comment_id': 2627074589, 'issue_id': 2823274487, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/86285/checks?check_run_id=36477268178) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2025, 1, 31, 12, 17, 56, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2025-01-31 12:17:56 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/86285/checks?check_run_id=36477268178) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2823263010,pull_request,open,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-31 12:13:51+00:00,['ddunl'],2025-02-07 01:16:37+00:00,,https://github.com/tensorflow/tensorflow/pull/86284,[],[],
2823255929,pull_request,open,,[XLA:CPU] Enumerate thunks based on inheritance hierarchy,"[XLA:CPU] Enumerate thunks based on inheritance hierarchy
",copybara-service[bot],2025-01-31 12:11:17+00:00,[],2025-01-31 12:11:17+00:00,,https://github.com/tensorflow/tensorflow/pull/86283,[],[],
2823155097,pull_request,closed,,Integrate LLVM at llvm/llvm-project@4573c857da88,"Integrate LLVM at llvm/llvm-project@4573c857da88

Updates LLVM usage to match
[4573c857da88](https://github.com/llvm/llvm-project/commit/4573c857da88)
",copybara-service[bot],2025-01-31 11:33:18+00:00,[],2025-01-31 13:35:42+00:00,2025-01-31 13:35:41+00:00,https://github.com/tensorflow/tensorflow/pull/86282,[],[],
2823063831,pull_request,closed,,[XLA:GPU] Remove unused output_id parameters.,"[XLA:GPU] Remove unused output_id parameters.
",copybara-service[bot],2025-01-31 11:00:37+00:00,[],2025-02-01 12:32:06+00:00,2025-02-01 12:32:05+00:00,https://github.com/tensorflow/tensorflow/pull/86281,[],[],
