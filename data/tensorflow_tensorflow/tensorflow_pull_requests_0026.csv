id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2582243050,pull_request,closed,,Move GpuDriver::IsEccEnabled to CudaExecutor.,"Move GpuDriver::IsEccEnabled to CudaExecutor.
",copybara-service[bot],2024-10-11 21:52:47+00:00,[],2024-10-12 21:16:20+00:00,2024-10-12 21:16:20+00:00,https://github.com/tensorflow/tensorflow/pull/77732,[],[],
2582242150,pull_request,closed,,Create StreamExecutor::Activate method as a factory method for creating ActivateContexts.,"Create StreamExecutor::Activate method as a factory method for creating ActivateContexts.

This allows simplifying the creation of ScopedActivateContexts.
",copybara-service[bot],2024-10-11 21:51:59+00:00,[],2024-10-14 20:44:16+00:00,2024-10-14 20:44:15+00:00,https://github.com/tensorflow/tensorflow/pull/77731,[],[],
2582237666,pull_request,closed,,Use RunAndCheckHloRewrite in collective_permute_cycle_decomposer_test.cc,"Use RunAndCheckHloRewrite in collective_permute_cycle_decomposer_test.cc
",copybara-service[bot],2024-10-11 21:48:49+00:00,[],2024-10-12 02:01:33+00:00,2024-10-12 02:01:33+00:00,https://github.com/tensorflow/tensorflow/pull/77730,[],[],
2582199315,pull_request,closed,,Wrapping collectives which are happening on host memory as host compute.,"Wrapping collectives which are happening on host memory as host compute.
",copybara-service[bot],2024-10-11 21:18:41+00:00,['SandSnip3r'],2024-10-21 23:59:28+00:00,2024-10-21 23:59:26+00:00,https://github.com/tensorflow/tensorflow/pull/77728,[],[],
2582189749,pull_request,closed,,Bump timeouts across GitHub Actions,"Bump timeouts across GitHub Actions

Adding retries to these actions has made the buffer on timeout small, so increase to 6 minutes to avoid flakes
",copybara-service[bot],2024-10-11 21:08:24+00:00,['ddunl'],2024-10-11 22:16:26+00:00,2024-10-11 22:16:25+00:00,https://github.com/tensorflow/tensorflow/pull/77727,[],[],
2582188483,pull_request,closed,,[IFRT] Extend Sharding disassembly operations to distinguish between addressable-shards and all-shards processing,"[IFRT] Extend Sharding disassembly operations to distinguish between addressable-shards and all-shards processing

IFRT's assembly/disassembly operations
(`Client::AssembleArrayFromSingleDeviceArray`,
`Array::DisassembleIntoSingleDeviceArrays`, and related methods in `Sharding`)
treated all shards equally without distinguishing the addressability of the
device of the shards. This had practical problems:

* When the user only has single-device arrays for addressable devices, and
asssemble them into a multi-shard array, the user is forced to use a `Sharding`
that only contains addressable devices. However, with SPMD, it is common to use
a `Sharding` that can express both adressable/non-addressable shards (e.g.,
`HloSharding`).

* When the user has a multi-shard array that spans both
addressable/non-addressable devices, disassembling the array into single-device
arrays would create a single-device array with no addressable devices, which is
often not well supported in the user code because the user code sometimes makes
a strong assumption that any array contains at least one addressable device.

On the other hand, making assembly/diassembly handle only addressable shards is
not future proof. An MPMD setup (not all inputs use a single device mesh) can
see an array with no addressable devices. Thus, changing assembly/diassembly
sematics to handle only addressable shards is too restrictive.

To resolve this single-device array addressability issue, this change makes it
explicit whether only addressable shards will be processed or all shards will
be processed in assembly/disassembly operations.

This change focuses on extending `Sharding` interface and implementing
addressable-shards processing. The default behavior remains to be processing
all shards.

Using this new capability for `Array` assembly and disassembly is a separate
change that will be sent out soon.

It will also be done as subsequent changes to make the IFRT user code to
request only addressable devices.
",copybara-service[bot],2024-10-11 21:07:08+00:00,[],2024-10-14 21:02:47+00:00,2024-10-14 21:02:46+00:00,https://github.com/tensorflow/tensorflow/pull/77726,[],[],
2582122261,pull_request,closed,,Retry `go install` commands to prevent network flakes,"Retry `go install` commands to prevent network flakes

Also `bazel build --nobuild` ahead of querying in `bazel_tags.yml`
",copybara-service[bot],2024-10-11 20:17:03+00:00,['ddunl'],2024-10-11 20:37:35+00:00,2024-10-11 20:37:34+00:00,https://github.com/tensorflow/tensorflow/pull/77725,[],[],
2582119396,pull_request,closed,,Stop using GpuDeviceHandle type in Executor header files.,"Stop using GpuDeviceHandle type in Executor header files.
",copybara-service[bot],2024-10-11 20:14:25+00:00,[],2024-10-12 18:18:40+00:00,2024-10-12 18:18:40+00:00,https://github.com/tensorflow/tensorflow/pull/77724,[],[],
2582116614,pull_request,closed,,Move GpuDriver::GetTotalMemory to CudaExecutor.,"Move GpuDriver::GetTotalMemory to CudaExecutor.
",copybara-service[bot],2024-10-11 20:12:04+00:00,[],2024-10-12 19:04:42+00:00,2024-10-12 19:04:39+00:00,https://github.com/tensorflow/tensorflow/pull/77723,[],[],
2582111997,pull_request,closed,,[XLA:Collective] Expose a factory for constructing HLOSharding with explicit device ordering.,"[XLA:Collective] Expose a factory for constructing HLOSharding with explicit device ordering.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/77018 from mattbahr:fix-silent-overflow-in-range-v2 38579f8aa599bdd8f2499dbe5f1a69fc43f4eb2d
",copybara-service[bot],2024-10-11 20:08:19+00:00,['Tongfei-Guo'],2024-10-14 22:45:23+00:00,2024-10-14 22:45:22+00:00,https://github.com/tensorflow/tensorflow/pull/77722,[],[],
2582071244,pull_request,closed,,[IFRT] Add DeviceList::IsFullyAddressable(),"[IFRT] Add DeviceList::IsFullyAddressable()

`DeviceList::IsFullyAddressable()` is a convenient API to check if a
`DeviecList` contains only addressable devices. It will be used as a
precondition of operations that cannot process non-addressable devices/shards.
",copybara-service[bot],2024-10-11 19:41:34+00:00,[],2024-10-11 23:51:20+00:00,2024-10-11 23:51:19+00:00,https://github.com/tensorflow/tensorflow/pull/77721,[],[],
2582047992,pull_request,closed,,"[XLA:GPU][NFC] Slight cleanup in `triton_fusion_emitter.{cc,h}` and related tests.","[XLA:GPU][NFC] Slight cleanup in `triton_fusion_emitter.{cc,h}` and related tests.

* Rename the dialect alias `mt` to `ttir` and stop exporting it in `xla::gpu`;
* Rename the dialect alias `mt` to `arith`;
* Clean up includes.
",copybara-service[bot],2024-10-11 19:26:12+00:00,[],2024-11-10 15:03:07+00:00,2024-11-10 15:03:06+00:00,https://github.com/tensorflow/tensorflow/pull/77720,[],[],
2582047956,pull_request,closed,,Fix segfault in ExportXlaOp for DotGeneralOp when an algorithm is specified.,"Fix segfault in ExportXlaOp for DotGeneralOp when an algorithm is specified.

This fixes the issue reported in https://github.com/jax-ml/jax/issues/24236. The problem was that when the precision is not explicitly specified in the HLO, but the algorithm is, we were trying to call `set_algorithm` on a `nullptr`. I'm not 100% sure where the default precision config is being stripped between JAX lowering and here because JAX includes `precision = [DEFAULT, DEFAULT]` in the lowering, but it seems like a good idea to protect against this segfault regardless!
",copybara-service[bot],2024-10-11 19:26:11+00:00,[],2024-10-18 00:29:03+00:00,2024-10-18 00:29:02+00:00,https://github.com/tensorflow/tensorflow/pull/77719,[],[],
2582005111,pull_request,closed,,"[XLA:GPU][NFC] Delete dead code in `triton_fusion_analysis.{cc,h}`.","[XLA:GPU][NFC] Delete dead code in `triton_fusion_analysis.{cc,h}`.
",copybara-service[bot],2024-10-11 18:56:35+00:00,[],2024-10-11 20:10:08+00:00,2024-10-11 20:10:07+00:00,https://github.com/tensorflow/tensorflow/pull/77717,[],[],
2582004404,pull_request,closed,,[IFRT Proxy] Fix version bump and Client::addressable_devices() handling,"[IFRT Proxy] Fix version bump and Client::addressable_devices() handling

This updates the server max version that was missed in the
`Client::GetAllDevices()` support. Also this fixes handling of
`Client::addressable_devices()`, which should be returning addressable devices
*among primary devices* because this API still conforms to the legacy behavior
of selecting a subset of primary devices. The user of all devices should do
filtering on the result of `Client::GetAllDevices()` rather than using
`Client::addressable_devices()`.
",copybara-service[bot],2024-10-11 18:56:13+00:00,[],2024-10-11 19:47:38+00:00,2024-10-11 19:47:37+00:00,https://github.com/tensorflow/tensorflow/pull/77716,[],[],
2581975717,pull_request,closed,,PR #17890: [ROCM] Add nanoo fp8 support in type traits,"PR #17890: [ROCM] Add nanoo fp8 support in type traits

Imported from GitHub PR https://github.com/openxla/xla/pull/17890

We are trying to add NANOO FP8 support in TensorFlow. To achieve this, a small modification in the `type_traits.h` file on the XLA side is required, where the NANOO FP8 should also be classified as a simple type. This change will be utilized in tensor.cc within TensorFlow. You can find the relevant code here: [TensorFlow tensor.cc](https://github.com/tensorflow/tensorflow/blob/ba7f93b8dc32b64cc0bb5ddb44e75bd344ae67d0/tensorflow/core/framework/tensor.cc#L175).
Copybara import of the project:

--
1c27aebbc206559861ee8d5e5f44522a2a44858b by scxfjiang <xuefei.jiang@amd.com>:

add nanoo fp8 support in type traits

Merging this change closes #17890

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17890 from ROCm:ci_nanoo_fp8_in_type_traits 1c27aebbc206559861ee8d5e5f44522a2a44858b
",copybara-service[bot],2024-10-11 18:41:03+00:00,[],2024-10-11 19:25:17+00:00,2024-10-11 19:25:16+00:00,https://github.com/tensorflow/tensorflow/pull/77715,[],[],
2581972764,pull_request,closed,,"When inserting reshapes for resharding, if we cannot compute","When inserting reshapes for resharding, if we cannot compute
accurate intermediate shardings to perform a reshard, we use replicated
shardings by default.

This is strictly worse than not inserting any reshapes as this forces the
spmd_partitioner to replicate the tensor even when that is not needed. To fix
this, we instead leave such cases up to the spmd_partitioner. It can choose to
replicate the tensor if possible (in this case, that is not needed), rather than
making a premature and potentially bad decision to replicate ourselves.
",copybara-service[bot],2024-10-11 18:39:19+00:00,[],2024-10-11 19:37:18+00:00,2024-10-11 19:37:17+00:00,https://github.com/tensorflow/tensorflow/pull/77714,[],[],
2581889505,pull_request,open,,Add option to `CallInliner` to preserve composites.,"Add option to `CallInliner` to preserve composites.

This is useful for preserving composite ops that hardwares can support.
",copybara-service[bot],2024-10-11 17:44:30+00:00,['ghpvnist'],2024-10-11 17:44:31+00:00,,https://github.com/tensorflow/tensorflow/pull/77713,[],[],
2581848442,pull_request,closed,,Move DoHostCallback into CudaStream/RocmStream,"Move DoHostCallback into CudaStream/RocmStream

- Moves the DoHostCallbackWithStatus implementation into CudaStream and RocmStream
- Inlines the corresponding GpuDriver function
- Adds a basic unit test
",copybara-service[bot],2024-10-11 17:19:29+00:00,[],2024-10-14 16:56:07+00:00,2024-10-14 16:56:05+00:00,https://github.com/tensorflow/tensorflow/pull/77712,[],[],
2581834974,pull_request,closed,,Move GpuDriver PeerAccess functions into the appropriate Executor classes.,"Move GpuDriver PeerAccess functions into the appropriate Executor classes.
",copybara-service[bot],2024-10-11 17:10:06+00:00,[],2024-10-12 17:17:29+00:00,2024-10-12 17:17:29+00:00,https://github.com/tensorflow/tensorflow/pull/77711,[],[],
2581832838,pull_request,closed,,Move GpuDriver::DeviceGraphMemTrim to Executor classes.,"Move GpuDriver::DeviceGraphMemTrim to Executor classes.
",copybara-service[bot],2024-10-11 17:08:35+00:00,[],2024-10-12 16:07:06+00:00,2024-10-12 16:07:05+00:00,https://github.com/tensorflow/tensorflow/pull/77710,[],[],
2581741648,pull_request,closed,,Pass tensor type as a pointer when creating LrtTensorBuffers,"Pass tensor type as a pointer when creating LrtTensorBuffers

Plus some cosmetic variable renaming
",copybara-service[bot],2024-10-11 16:15:26+00:00,[],2024-10-11 21:18:55+00:00,2024-10-11 21:18:54+00:00,https://github.com/tensorflow/tensorflow/pull/77709,[],[],
2581700004,pull_request,closed,,Fix test breakage,"Fix test breakage
",copybara-service[bot],2024-10-11 15:53:05+00:00,[],2024-10-11 20:21:44+00:00,2024-10-11 20:21:44+00:00,https://github.com/tensorflow/tensorflow/pull/77708,[],[],
2581677254,pull_request,closed,,PR #18026: [XLA:GPU} Add DynamicSliceFusionCmd command to command buffer,"PR #18026: [XLA:GPU} Add DynamicSliceFusionCmd command to command buffer

Imported from GitHub PR https://github.com/openxla/xla/pull/18026


Copybara import of the project:

--
b7f3e5c7153fa80384aeca95eff841c09cc6462a by Shawn Wang <shawnw@nvidia.com>:

add dynamic slice update thunk support to command buffer

--
91a28306e911c3d8bcecec09768f6fdf4040fdf9 by Shawn Wang <shawnw@nvidia.com>:

refactoring

Merging this change closes #18026

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18026 from shawnwang18:shawnw/command_buffer_dynamic_slice 91a28306e911c3d8bcecec09768f6fdf4040fdf9
",copybara-service[bot],2024-10-11 15:42:21+00:00,[],2024-10-11 17:10:12+00:00,2024-10-11 17:10:11+00:00,https://github.com/tensorflow/tensorflow/pull/77707,[],[],
2581666519,pull_request,closed,,Add `tf_nightly` prefix to the local wheel inclusion list.,"Add `tf_nightly` prefix to the local wheel inclusion list.
",copybara-service[bot],2024-10-11 15:35:54+00:00,[],2024-10-11 16:49:37+00:00,2024-10-11 16:49:36+00:00,https://github.com/tensorflow/tensorflow/pull/77706,[],[],
2581629702,pull_request,closed,,Create internal directory to move core files to block new usage of non PJRT integration,"Create internal directory to move core files to block new usage of non PJRT integration
",copybara-service[bot],2024-10-11 15:17:44+00:00,['changm'],2024-10-16 22:11:55+00:00,2024-10-16 22:11:54+00:00,https://github.com/tensorflow/tensorflow/pull/77705,[],[],
2581560098,pull_request,closed,,[XLA:GPU] Move XlaTritonDialect to a separate file.,"[XLA:GPU] Move XlaTritonDialect to a separate file.
",copybara-service[bot],2024-10-11 14:45:22+00:00,[],2024-10-15 10:19:01+00:00,2024-10-15 10:19:00+00:00,https://github.com/tensorflow/tensorflow/pull/77703,[],[],
2581558439,pull_request,closed,,PR #16975: Add a few related optimization passes for fp8 gemm custom-calls.,"PR #16975: Add a few related optimization passes for fp8 gemm custom-calls.

Imported from GitHub PR https://github.com/openxla/xla/pull/16975

This caused convergence issue for fp8 training, tested on GPT3 models:

Before:
```
NETWORK             BACKEND MATH SDPA XLA_EXTRAS      GPUs STEPS/SEC     LOSS
WALLSECS
GPT5B                   XLA  fp8   FA    8     1.064 11.019     1571
[PAX STATUS]: Starting training loop.
[PAX STATUS] step_i: 100, training loss: 11.015041
[PAX STATUS] step_i: 200, training loss: 11.016165
[PAX STATUS] step_i: 300, training loss: 11.016386
[PAX STATUS] step_i: 400, training loss: 11.014653
[PAX STATUS] step_i: 500, training loss: 11.014734
[PAX STATUS] step_i: 600, training loss: 11.01613
[PAX STATUS] step_i: 700, training loss: 11.009399
[PAX STATUS] step_i: 800, training loss: 11.017071
[PAX STATUS] step_i: 900, training loss: 11.014582
[PAX STATUS] step_i: 1000, training loss: 11.013434
[PAX STATUS] step_i: 1100, training loss: 11.021271
[PAX STATUS] step_i: 1200, training loss: 11.008364
[PAX STATUS] step_i: 1300, training loss: 11.0198145
[PAX STATUS] step_i: 1400, training loss: 11.01253
[PAX STATUS] step_i: 1500, training loss: 11.019016
```

After:
```
NETWORK             BACKEND MATH SDPA GPUs STEPS/SEC  LOSS WALLSECS
GPT5B                   XLA  fp8   FA    8     1.020 3.797     1647
[PAX STATUS]: Starting training loop.
[PAX STATUS] step_i: 100, training loss: 6.150083
[PAX STATUS] step_i: 200, training loss: 5.8871064
[PAX STATUS] step_i: 300, training loss: 5.4491887
[PAX STATUS] step_i: 400, training loss: 5.6384015
[PAX STATUS] step_i: 500, training loss: 5.273538
[PAX STATUS] step_i: 600, training loss: 5.2011905
[PAX STATUS] step_i: 700, training loss: 4.903013
[PAX STATUS] step_i: 800, training loss: 4.62972
[PAX STATUS] step_i: 900, training loss: 4.507727
[PAX STATUS] step_i: 1000, training loss: 4.625259
[PAX STATUS] step_i: 1100, training loss: 4.428066
[PAX STATUS] step_i: 1200, training loss: 4.252451
[PAX STATUS] step_i: 1300, training loss: 3.8448389
[PAX STATUS] step_i: 1400, training loss: 3.8578327
[PAX STATUS] step_i: 1500, training loss: 3.796958
```
Copybara import of the project:

--
81af29c8667792fe9ed189ab55308ca6e83859d4 by Elfie Guo <elfieg@nvidia.com>:

Add a few related optimization pass for fp8 gemm rerwriter.

Merging this change closes #16975

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16975 from elfiegg:pass 81af29c8667792fe9ed189ab55308ca6e83859d4
",copybara-service[bot],2024-10-11 14:44:48+00:00,[],2024-10-12 09:58:18+00:00,2024-10-12 09:58:18+00:00,https://github.com/tensorflow/tensorflow/pull/77702,[],[],
2581551307,pull_request,closed,,Move Memcpy into Cuda/RocmStream,"Move Memcpy into Cuda/RocmStream

- Moves the 3 overloads into the subclasses
- Moves the corresponding GpuDriver functions
- Adds basic unit tests
",copybara-service[bot],2024-10-11 14:42:07+00:00,[],2024-10-12 00:44:38+00:00,2024-10-12 00:44:37+00:00,https://github.com/tensorflow/tensorflow/pull/77701,[],[],
2581482624,pull_request,closed,,PR #17222: [XLA:CPU] Allow convert natively on supported CPUs,"PR #17222: [XLA:CPU] Allow convert natively on supported CPUs

Imported from GitHub PR https://github.com/openxla/xla/pull/17222

The performance for some workloads dropped and git bisect points to this [commit](https://github.com/openxla/xla/commit/c48011a1cf55a3129f72ad2c25a2c138f7710cfd) on XLA to be causing the drop. The comments indicate that LLVM optimizations are being suppressed when converting from FP32-BF16 and back since it may cause performance degradation on other cpu's. Since, some cpu's can handle BF16 efficiently, this is not required and can be bypassed.
Copybara import of the project:

--
36d28839d38860dd4a222cba2da95f07083b74c1 by Kanvi Khanna <kanvi.khanna@intel.com>:

allow convert natively

--
a7f6f71a80e4848dce281aaf56cdc07de72cf7ee by Kanvi Khanna <kanvi.khanna@intel.com>:

Address comments

--
14225831b897ffcc47baefccef98b9d925cdfea1 by Kanvi Khanna <kanvi.khanna@intel.com>:

Add test

--
9693d9e90d89fef9c7c063aa9d9aa6c648915145 by Kanvi Khanna <kanvi.khanna@intel.com>:

address commment

Merging this change closes #17222

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17222 from Intel-tensorflow:kanvi/native_convert_support 9693d9e90d89fef9c7c063aa9d9aa6c648915145
",copybara-service[bot],2024-10-11 14:11:24+00:00,[],2024-10-11 16:31:15+00:00,2024-10-11 16:31:14+00:00,https://github.com/tensorflow/tensorflow/pull/77700,[],[],
2581466497,pull_request,closed,,[xla:gatherExpander:NFC] Tidy up GatherIsBroadcast.,"[xla:gatherExpander:NFC] Tidy up GatherIsBroadcast.

Change the return type from int64_t to bool. Use the routine in
InstructionMatchesPattern to avoid duplicating the code and help understanding.
",copybara-service[bot],2024-10-11 14:03:08+00:00,['bixia1'],2024-10-12 01:49:51+00:00,2024-10-12 01:49:50+00:00,https://github.com/tensorflow/tensorflow/pull/77699,[],[],
2581441870,pull_request,closed,,Expose IFRT IR Serdes to friends,"Expose IFRT IR Serdes to friends
",copybara-service[bot],2024-10-11 13:52:31+00:00,[],2024-10-17 12:13:26+00:00,2024-10-17 12:13:25+00:00,https://github.com/tensorflow/tensorflow/pull/77698,[],[],
2581392010,pull_request,closed,,PR #17999: [NVIDIA GPU] Added a predicate function to dot merger to determine eligibility,"PR #17999: [NVIDIA GPU] Added a predicate function to dot merger to determine eligibility

Imported from GitHub PR https://github.com/openxla/xla/pull/17999

Expose a predicate function interface through dot merger to pass in backend-specific compatibility check.
This is used in gpu compiler to avoid merging dots that are assigned with 2 different non-default stream ids as they will be optimized separately.
Copybara import of the project:

--
42c669b93ef7b933c41f4ce9998c933ba2630a41 by TJ Xu <tjx@nvidia.com>:

Added a predicate function to dot merger to determine eligibility

--
f67647cff14d7eed0d8763272ec9dae9eb67bbe9 by TJ Xu <tjx@nvidia.com>:

Changed the name to can_merge

Merging this change closes #17999

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17999 from Tixxx:tixxx/dot_merger_condition f67647cff14d7eed0d8763272ec9dae9eb67bbe9
",copybara-service[bot],2024-10-11 13:32:08+00:00,[],2024-10-14 08:54:06+00:00,2024-10-14 08:54:05+00:00,https://github.com/tensorflow/tensorflow/pull/77697,[],[],
2581381634,pull_request,closed,,[PJRT] Delete PjRtClient::runtime_type().,"[PJRT] Delete PjRtClient::runtime_type().

This field carries no useful information and does not exist in the PJRT C API.
",copybara-service[bot],2024-10-11 13:26:46+00:00,[],2024-10-21 14:56:03+00:00,2024-10-21 14:56:02+00:00,https://github.com/tensorflow/tensorflow/pull/77696,[],[],
2581379785,pull_request,open,,[XLA:GPU] Speed up layout normalization.,"[XLA:GPU] Speed up layout normalization.

In some cases the layout normalization pass takes too much time. That happens when we migrate the long list of users of one instruction to another one one by one. In this specific case we want to move all of them to a new producer except the newly inserted follow instruction.

Let's do that by swapping the entire users_ property between the old producer and the new producer.
",copybara-service[bot],2024-10-11 13:25:50+00:00,[],2024-10-13 06:36:01+00:00,,https://github.com/tensorflow/tensorflow/pull/77695,[],[],
2581265945,pull_request,closed,,Implement move and dstor for plugin manager,"Implement move and dstor for plugin manager
",copybara-service[bot],2024-10-11 12:28:22+00:00,['LukeBoyer'],2024-10-14 23:35:40+00:00,2024-10-14 23:35:40+00:00,https://github.com/tensorflow/tensorflow/pull/77692,[],[],
2581265140,pull_request,closed,,[XLA:GPU] Support effective scalar constants in Triton emitter.,"[XLA:GPU] Support effective scalar constants in Triton emitter.

Currently Triton emitter supports only scalar constant (that have rank 0). There is no strong reason why the emitter shouldn't support other shapes of constants that contain only 1 element.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18026 from shawnwang18:shawnw/command_buffer_dynamic_slice 91a28306e911c3d8bcecec09768f6fdf4040fdf9
",copybara-service[bot],2024-10-11 12:27:54+00:00,[],2024-10-11 18:04:57+00:00,2024-10-11 18:04:56+00:00,https://github.com/tensorflow/tensorflow/pull/77691,[],[],
2581222063,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 12:04:40+00:00,[],2024-10-12 14:07:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77690,[],[],
2581203006,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 11:54:26+00:00,[],2024-10-12 15:29:15+00:00,2024-10-12 15:29:14+00:00,https://github.com/tensorflow/tensorflow/pull/77689,[],[],
2581106151,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 11:10:37+00:00,[],2024-10-12 09:43:33+00:00,,https://github.com/tensorflow/tensorflow/pull/77688,[],[],
2581097110,pull_request,open,,Integrate LLVM at llvm/llvm-project@1276ce9e9713,"Integrate LLVM at llvm/llvm-project@1276ce9e9713

Updates LLVM usage to match
[1276ce9e9713](https://github.com/llvm/llvm-project/commit/1276ce9e9713)
",copybara-service[bot],2024-10-11 11:05:18+00:00,[],2024-10-11 11:05:18+00:00,,https://github.com/tensorflow/tensorflow/pull/77687,[],[],
2581073843,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 10:53:23+00:00,[],2024-10-12 07:52:26+00:00,2024-10-12 07:52:25+00:00,https://github.com/tensorflow/tensorflow/pull/77686,[],[],
2581069161,pull_request,closed,,use common mesh with symbol table,"use common mesh with symbol table
",copybara-service[bot],2024-10-11 10:51:24+00:00,[],2024-10-11 18:25:09+00:00,2024-10-11 18:25:09+00:00,https://github.com/tensorflow/tensorflow/pull/77685,[],[],
2581066498,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 10:50:09+00:00,[],2024-10-12 08:08:44+00:00,,https://github.com/tensorflow/tensorflow/pull/77684,[],[],
2581050398,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 10:42:39+00:00,[],2024-10-12 07:27:28+00:00,2024-10-12 07:27:27+00:00,https://github.com/tensorflow/tensorflow/pull/77683,[],[],
2581044475,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 10:39:35+00:00,[],2024-10-12 09:37:38+00:00,2024-10-12 09:37:37+00:00,https://github.com/tensorflow/tensorflow/pull/77682,[],[],
2581018601,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 10:26:23+00:00,[],2024-10-12 06:35:23+00:00,,https://github.com/tensorflow/tensorflow/pull/77681,[],[],
2580987557,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 10:09:20+00:00,[],2024-10-11 13:25:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77680,[],[],
2580923877,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 09:40:01+00:00,[],2024-10-11 11:45:55+00:00,,https://github.com/tensorflow/tensorflow/pull/77679,[],[],
2580904531,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 09:31:38+00:00,[],2024-10-12 09:35:35+00:00,,https://github.com/tensorflow/tensorflow/pull/77678,[],[],
2580897140,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 09:27:50+00:00,[],2024-10-12 06:52:13+00:00,,https://github.com/tensorflow/tensorflow/pull/77677,[],[],
2580856661,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 09:06:16+00:00,[],2024-10-12 11:11:49+00:00,,https://github.com/tensorflow/tensorflow/pull/77676,[],[],
2580848265,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 09:01:57+00:00,[],2024-10-11 09:01:57+00:00,,https://github.com/tensorflow/tensorflow/pull/77674,[],[],
2580848162,pull_request,closed,,#sdy support inlined meshes in MHLO export shardings.,"#sdy support inlined meshes in MHLO export shardings.

This is needed because that pass is used in sdy-round-trip export.

In addition, no need to add replicated manual axes in MHLO shard map import, since this is done in a separate Shardy import pass.
",copybara-service[bot],2024-10-11 09:01:53+00:00,[],2024-10-11 14:00:29+00:00,2024-10-11 14:00:29+00:00,https://github.com/tensorflow/tensorflow/pull/77673,[],[],
2580848067,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16975 from elfiegg:pass 81af29c8667792fe9ed189ab55308ca6e83859d4
",copybara-service[bot],2024-10-11 09:01:51+00:00,[],2024-10-12 10:05:22+00:00,,https://github.com/tensorflow/tensorflow/pull/77672,[],[],
2580839679,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 08:57:42+00:00,[],2024-10-12 07:04:32+00:00,,https://github.com/tensorflow/tensorflow/pull/77671,[],[],
2580837568,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 08:56:39+00:00,[],2024-10-12 11:45:10+00:00,2024-10-12 11:45:09+00:00,https://github.com/tensorflow/tensorflow/pull/77670,[],[],
2580821477,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 08:50:20+00:00,[],2024-10-12 10:40:34+00:00,,https://github.com/tensorflow/tensorflow/pull/77669,[],[],
2580815320,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 08:46:58+00:00,[],2024-10-12 11:55:27+00:00,2024-10-12 11:55:26+00:00,https://github.com/tensorflow/tensorflow/pull/77668,[],[],
2580779313,pull_request,closed,,Fix masking bug for s4 type.,"Fix masking bug for s4 type.

When we extend the scalar_value to s8, it would add additional leading 1 bits
to have a valid 2-complement for s8. We need to mask them out before ""or-ing""
with current_value.
",copybara-service[bot],2024-10-11 08:30:09+00:00,['akuegel'],2024-10-11 11:35:01+00:00,2024-10-11 11:35:00+00:00,https://github.com/tensorflow/tensorflow/pull/77667,[],[],
2580773490,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 08:27:01+00:00,[],2024-10-12 15:54:42+00:00,2024-10-12 15:54:41+00:00,https://github.com/tensorflow/tensorflow/pull/77666,[],[],
2580762546,pull_request,closed,,PR #18152: [XLA:GPU] Avoid fusion-wrapping copies,"PR #18152: [XLA:GPU] Avoid fusion-wrapping copies

Imported from GitHub PR https://github.com/openxla/xla/pull/18152

Fusion wrapping copies breaks the logic for detecting copies from copy-insertion in rematerialization pass.

This patch avoids wrapping copy instructions and instead emits them directly in IrEmitterUnnested.

This should fix https://github.com/openxla/xla/issues/17922
Copybara import of the project:

--
49daad1836186fd7abe2ad089aa8783f1125f605 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Avoid fusion-wrapping copies

Merging this change closes #18152

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18152 from jaro-sevcik:avoid-fusion-wrapping-copies 49daad1836186fd7abe2ad089aa8783f1125f605
",copybara-service[bot],2024-10-11 08:21:01+00:00,[],2024-10-15 11:53:07+00:00,2024-10-15 11:53:06+00:00,https://github.com/tensorflow/tensorflow/pull/77665,[],[],
2580754630,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 08:16:34+00:00,[],2024-10-12 06:51:34+00:00,,https://github.com/tensorflow/tensorflow/pull/77664,[],[],
2580732750,pull_request,closed,,Integrate LLVM at llvm/llvm-project@23309d7d9553,"Integrate LLVM at llvm/llvm-project@23309d7d9553

Updates LLVM usage to match
[23309d7d9553](https://github.com/llvm/llvm-project/commit/23309d7d9553)
",copybara-service[bot],2024-10-11 08:04:15+00:00,[],2024-10-11 09:35:12+00:00,2024-10-11 09:35:12+00:00,https://github.com/tensorflow/tensorflow/pull/77663,[],[],
2580713878,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 07:55:32+00:00,[],2024-10-11 12:33:55+00:00,2024-10-11 12:33:54+00:00,https://github.com/tensorflow/tensorflow/pull/77662,[],[],
2580694327,pull_request,open,,Consolidate all qnn code into vendors. Misc cleanup/re-styling.,"Consolidate all qnn code into vendors. Misc cleanup/re-styling.

* Always PascalCase for c++ functions/methods
* Use safer global singleton in dispatch api
* Break some targets in to smaller pieces
* Pull more init logic into QnnManager
* Surface element type mapping for other qnn code
* Fix logging
* Use alloca where useful
* Conditionally compile dlopen wrapper (android doesn't have RTLD_DEEPBIND)
* Make shared lib file names camelCase
* Fix bad types in testing/common
* use lrt::qnn namespace

Regarding qnn handle lifetimes:

The sdk will free when the lib unloads; its not a memory leak to not free qnn handles so its not ""required"". Eventually I will pull all create/free/handle into the QnnManager. I think it would be better to control these from a single point (e.g. only in dispatch_api) and to call them explicitly rather than putting in cstor/dstor. Otherwise its too hard to track whats happening.
",copybara-service[bot],2024-10-11 07:49:28+00:00,['akuegel'],2024-10-11 10:30:44+00:00,,https://github.com/tensorflow/tensorflow/pull/77661,[],[],
2580684591,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 07:45:48+00:00,[],2024-10-12 05:08:12+00:00,,https://github.com/tensorflow/tensorflow/pull/77660,[],[],
2580643345,pull_request,open,,PR #17222: [XLA:CPU] Allow convert natively on supported CPUs,"PR #17222: [XLA:CPU] Allow convert natively on supported CPUs

Imported from GitHub PR https://github.com/openxla/xla/pull/17222

The performance for some workloads dropped and git bisect points to this [commit](https://github.com/openxla/xla/commit/c48011a1cf55a3129f72ad2c25a2c138f7710cfd) on XLA to be causing the drop. The comments indicate that LLVM optimizations are being suppressed when converting from FP32-BF16 and back since it may cause performance degradation on other cpu's. Since, some cpu's can handle BF16 efficiently, this is not required and can be bypassed.
Copybara import of the project:

--
36d28839d38860dd4a222cba2da95f07083b74c1 by Kanvi Khanna <kanvi.khanna@intel.com>:

allow convert natively

--
a7f6f71a80e4848dce281aaf56cdc07de72cf7ee by Kanvi Khanna <kanvi.khanna@intel.com>:

Address comments

--
14225831b897ffcc47baefccef98b9d925cdfea1 by Kanvi Khanna <kanvi.khanna@intel.com>:

Add test

--
9693d9e90d89fef9c7c063aa9d9aa6c648915145 by Kanvi Khanna <kanvi.khanna@intel.com>:

address commment

Merging this change closes #17222

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17222 from Intel-tensorflow:kanvi/native_convert_support 9693d9e90d89fef9c7c063aa9d9aa6c648915145
",copybara-service[bot],2024-10-11 07:27:27+00:00,[],2024-10-11 12:57:40+00:00,,https://github.com/tensorflow/tensorflow/pull/77659,[],[],
2580625142,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 07:16:03+00:00,[],2024-10-12 04:47:59+00:00,,https://github.com/tensorflow/tensorflow/pull/77658,[],[],
2580618588,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 07:11:55+00:00,[],2024-10-12 07:10:00+00:00,,https://github.com/tensorflow/tensorflow/pull/77657,[],[],
2580548488,pull_request,open,,Integrate LLVM at llvm/llvm-project@23309d7d9553,"Integrate LLVM at llvm/llvm-project@23309d7d9553

Updates LLVM usage to match
[23309d7d9553](https://github.com/llvm/llvm-project/commit/23309d7d9553)
",copybara-service[bot],2024-10-11 06:30:29+00:00,[],2024-10-11 09:32:54+00:00,,https://github.com/tensorflow/tensorflow/pull/77656,[],[],
2580530991,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 06:17:05+00:00,[],2024-10-12 07:41:35+00:00,2024-10-12 07:41:34+00:00,https://github.com/tensorflow/tensorflow/pull/77655,[],[],
2580515472,pull_request,open,,PR #18152: [XLA:GPU] Avoid fusion-wrapping copies,"PR #18152: [XLA:GPU] Avoid fusion-wrapping copies

Imported from GitHub PR https://github.com/openxla/xla/pull/18152

Fusion wrapping copies breaks the logic for detecting copies from copy-insertion in rematerialization pass.

This patch avoids wrapping copy instructions and instead emits them directly in IrEmitterUnnested.

This should fix https://github.com/openxla/xla/issues/17922
Copybara import of the project:

--
49daad1836186fd7abe2ad089aa8783f1125f605 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Avoid fusion-wrapping copies

Merging this change closes #18152

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18152 from jaro-sevcik:avoid-fusion-wrapping-copies 49daad1836186fd7abe2ad089aa8783f1125f605
",copybara-service[bot],2024-10-11 06:04:02+00:00,[],2024-10-11 06:04:02+00:00,,https://github.com/tensorflow/tensorflow/pull/77654,[],[],
2580492447,pull_request,closed,,Add syntatic sugar class for LrtCompilerPlugins. Globs for possible shared library files and resolves symbols.,"Add syntatic sugar class for LrtCompilerPlugins. Globs for possible shared library files and resolves symbols.
",copybara-service[bot],2024-10-11 05:47:26+00:00,['LukeBoyer'],2024-10-14 08:43:13+00:00,2024-10-14 08:43:12+00:00,https://github.com/tensorflow/tensorflow/pull/77653,[],[],
2580487848,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 05:44:49+00:00,[],2024-10-12 17:35:15+00:00,2024-10-12 17:35:14+00:00,https://github.com/tensorflow/tensorflow/pull/77652,[],[],
2580465667,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 05:27:55+00:00,[],2024-10-12 11:11:37+00:00,,https://github.com/tensorflow/tensorflow/pull/77651,[],[],
2580462556,pull_request,closed,,Move GpuStream::MemZero into Cuda/RocmStream,"Move GpuStream::MemZero into Cuda/RocmStream

- Moves the MemZero function into CudaStream and RocmStream
- Moves the corresponding GpuDriver functions
- Adds a basic unit test
",copybara-service[bot],2024-10-11 05:24:36+00:00,[],2024-10-11 23:14:45+00:00,2024-10-11 23:14:44+00:00,https://github.com/tensorflow/tensorflow/pull/77650,[],[],
2580456983,pull_request,closed,,[xla:algebraicSimplifier] Extend ScatterAddCombine transformation to handle,"[xla:algebraicSimplifier] Extend ScatterAddCombine transformation to handle
batch dimensions.

Explicit batch dimensions were recently added to scatter instructions in
https://github.com/openxla/stablehlo/pull/2084.

This CL fixes the transformation that combines two scatter instructions feeding
into an add instruction into one scatter instruction to correctly handle batch
dimensions. In particular, corresponding batch dimensions from the two scatter instructions should be equal and batch dimensions can't be concatenated to support the transformation.
",copybara-service[bot],2024-10-11 05:18:32+00:00,['bixia1'],2024-10-14 00:27:00+00:00,2024-10-14 00:26:59+00:00,https://github.com/tensorflow/tensorflow/pull/77649,[],[],
2580439998,pull_request,closed,,"Move public compiler plugin header to vendors. Add ""compiler plugin api"" for dynamically loading a compiler plugin api library.","Move public compiler plugin header to vendors. Add ""compiler plugin api"" for dynamically loading a compiler plugin api library.
",copybara-service[bot],2024-10-11 05:00:06+00:00,['LukeBoyer'],2024-10-12 00:06:44+00:00,2024-10-12 00:06:44+00:00,https://github.com/tensorflow/tensorflow/pull/77648,[],[],
2580425997,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 04:50:27+00:00,[],2024-10-11 11:52:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77647,[],[],
2580425272,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 04:49:48+00:00,[],2024-10-11 12:02:24+00:00,,https://github.com/tensorflow/tensorflow/pull/77646,[],[],
2580417796,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 04:40:55+00:00,[],2024-10-11 04:40:55+00:00,,https://github.com/tensorflow/tensorflow/pull/77645,[],[],
2580402958,pull_request,closed,,allow to disable one broadcast optimization in algebraic_simplifier,"allow to disable one broadcast optimization in algebraic_simplifier
",copybara-service[bot],2024-10-11 04:29:36+00:00,[],2024-10-15 02:32:06+00:00,2024-10-15 02:32:05+00:00,https://github.com/tensorflow/tensorflow/pull/77644,[],[],
2580379389,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 04:01:49+00:00,[],2024-10-11 10:44:02+00:00,,https://github.com/tensorflow/tensorflow/pull/77643,[],[],
2580378702,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 04:01:13+00:00,[],2024-10-11 10:14:33+00:00,,https://github.com/tensorflow/tensorflow/pull/77642,[],[],
2580371701,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:55:34+00:00,[],2024-10-12 05:42:24+00:00,,https://github.com/tensorflow/tensorflow/pull/77641,[],[],
2580369042,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:53:22+00:00,[],2024-10-11 03:53:22+00:00,,https://github.com/tensorflow/tensorflow/pull/77640,[],[],
2580367943,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:52:26+00:00,[],2024-10-11 10:04:44+00:00,,https://github.com/tensorflow/tensorflow/pull/77639,[],[],
2580366050,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:50:47+00:00,[],2024-10-11 09:49:47+00:00,,https://github.com/tensorflow/tensorflow/pull/77638,[],[],
2580363144,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:48:47+00:00,[],2024-10-11 11:09:13+00:00,,https://github.com/tensorflow/tensorflow/pull/77637,[],[],
2580362474,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:48:27+00:00,[],2024-10-11 03:48:27+00:00,,https://github.com/tensorflow/tensorflow/pull/77636,[],[],
2580362073,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:48:14+00:00,[],2024-10-11 10:03:44+00:00,,https://github.com/tensorflow/tensorflow/pull/77635,[],[],
2580361941,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:48:10+00:00,[],2024-10-11 10:31:04+00:00,,https://github.com/tensorflow/tensorflow/pull/77634,[],[],
2580359229,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:46:33+00:00,[],2024-10-11 10:56:23+00:00,,https://github.com/tensorflow/tensorflow/pull/77633,[],[],
2580357373,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:44:13+00:00,[],2024-10-11 07:03:38+00:00,,https://github.com/tensorflow/tensorflow/pull/77632,[],[],
2580356709,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:43:22+00:00,[],2024-10-11 10:00:05+00:00,,https://github.com/tensorflow/tensorflow/pull/77631,[],[],
2580355842,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:42:17+00:00,[],2024-10-12 13:44:14+00:00,,https://github.com/tensorflow/tensorflow/pull/77630,[],[],
2580355010,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:41:08+00:00,[],2024-10-11 09:58:58+00:00,,https://github.com/tensorflow/tensorflow/pull/77629,[],[],
2580354029,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:40:17+00:00,[],2024-10-17 05:04:58+00:00,2024-10-17 05:04:57+00:00,https://github.com/tensorflow/tensorflow/pull/77628,[],[],
2580344973,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:33:53+00:00,[],2024-10-12 05:24:16+00:00,2024-10-12 05:24:15+00:00,https://github.com/tensorflow/tensorflow/pull/77627,[],[],
2580343492,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:31:57+00:00,[],2024-10-11 09:59:16+00:00,2024-10-11 09:59:15+00:00,https://github.com/tensorflow/tensorflow/pull/77626,[],[],
2580341676,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:29:40+00:00,[],2024-10-12 05:47:53+00:00,,https://github.com/tensorflow/tensorflow/pull/77625,[],[],
2580341037,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:28:51+00:00,[],2024-10-11 10:57:10+00:00,,https://github.com/tensorflow/tensorflow/pull/77624,[],[],
2580340130,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:27:45+00:00,[],2024-10-11 03:27:45+00:00,,https://github.com/tensorflow/tensorflow/pull/77623,[],[],
2580339666,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-11 03:27:12+00:00,[],2024-10-11 10:52:52+00:00,,https://github.com/tensorflow/tensorflow/pull/77622,[],[],
2580261036,pull_request,closed,,Allow the Run* methods in HloTestBase to take a module preprocessor for the test platform.,"Allow the Run* methods in HloTestBase to take a module preprocessor for the test platform.
",copybara-service[bot],2024-10-11 02:22:00+00:00,[],2024-10-11 05:14:40+00:00,2024-10-11 05:14:40+00:00,https://github.com/tensorflow/tensorflow/pull/77621,[],[],
2580259692,pull_request,closed,,Add use_lit_test_suite arg for compatibility with internal use.,"Add use_lit_test_suite arg for compatibility with internal use.
",copybara-service[bot],2024-10-11 02:20:48+00:00,[],2024-10-11 07:37:32+00:00,2024-10-11 07:37:31+00:00,https://github.com/tensorflow/tensorflow/pull/77620,[],[],
2580256610,pull_request,closed,,Complete i4 FullyConnected support for TFLite,"Complete i4 FullyConnected support for TFLite
",copybara-service[bot],2024-10-11 02:16:59+00:00,['paulinesho'],2024-10-15 02:18:18+00:00,2024-10-15 02:18:17+00:00,https://github.com/tensorflow/tensorflow/pull/77619,[],[],
2580225321,pull_request,closed,,[StableHLO] Add `get_compiler_ir(stage='stablehlo[_serialized]')` for dumping StableHLO from a TF function.,"[StableHLO] Add `get_compiler_ir(stage='stablehlo[_serialized]')` for dumping StableHLO from a TF function.
",copybara-service[bot],2024-10-11 01:53:42+00:00,['GleasonK'],2024-10-15 17:33:23+00:00,2024-10-15 17:33:21+00:00,https://github.com/tensorflow/tensorflow/pull/77617,[],[],
2580202093,pull_request,closed,,Remove error polling thread and just dispatch async RPC.,"Remove error polling thread and just dispatch async RPC.
",copybara-service[bot],2024-10-11 01:39:07+00:00,[],2024-10-11 18:51:35+00:00,2024-10-11 18:51:34+00:00,https://github.com/tensorflow/tensorflow/pull/77616,[],[],
2580184822,pull_request,open,,XLA Copy Insertion: Remove copies in the case when a parameter is input/output aliased and updated in place by a single HLO instruction.,"XLA Copy Insertion: Remove copies in the case when a parameter is input/output aliased and updated in place by a single HLO instruction.
",copybara-service[bot],2024-10-11 01:25:01+00:00,[],2024-10-14 22:06:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77615,[],[],
2580184601,pull_request,closed,,Add PjRt client registry factory getter for device shape size.,"Add PjRt client registry factory getter for device shape size.

Device shape size is a required parameter mainly for the validator. Adding this
to the PjRt client registry is the first step in a series of step towards
decoupling the HloTestBase from stream executor while retaining the existing
functionality.
",copybara-service[bot],2024-10-11 01:24:43+00:00,[],2024-10-17 22:16:42+00:00,2024-10-17 22:16:41+00:00,https://github.com/tensorflow/tensorflow/pull/77614,[],[],
2580151693,pull_request,open,,[MHLO] Remove unused definitions from hlo_utils.td,"[MHLO] Remove unused definitions from hlo_utils.td
",copybara-service[bot],2024-10-11 00:48:52+00:00,['GleasonK'],2024-10-11 00:48:53+00:00,,https://github.com/tensorflow/tensorflow/pull/77613,[],[],
2580110483,pull_request,closed,,Update TFRT dependency to use revision,"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/8e00ae114e65160da6f5719c45a79102735789c8.
",copybara-service[bot],2024-10-11 00:16:26+00:00,[],2024-10-11 03:24:15+00:00,2024-10-11 03:24:14+00:00,https://github.com/tensorflow/tensorflow/pull/77612,[],[],
2580095527,pull_request,closed,,"Don't run the `--nobuild` command for Tensorflow, MacOS builds","Don't run the `--nobuild` command for Tensorflow, MacOS builds

parallel unavailable on macos VM, TF has config issues that prevent this from working as intended
",copybara-service[bot],2024-10-11 00:00:33+00:00,['ddunl'],2024-10-11 17:37:52+00:00,2024-10-11 17:37:51+00:00,https://github.com/tensorflow/tensorflow/pull/77611,[],[],
2580089001,pull_request,closed,,Add option to `CallInliner` to preserve composites.,"Add option to `CallInliner` to preserve composites.

This is useful for preserving composite ops that hardwares can support.
",copybara-service[bot],2024-10-10 23:56:34+00:00,['ghpvnist'],2024-10-11 17:42:13+00:00,2024-10-11 17:42:12+00:00,https://github.com/tensorflow/tensorflow/pull/77610,[],[],
2580085145,pull_request,closed,,Update README.md,,i23hiratukatomoki,2024-10-10 23:52:59+00:00,['gbaned'],2024-10-11 09:57:11+00:00,2024-10-11 09:57:09+00:00,https://github.com/tensorflow/tensorflow/pull/77609,"[('size:M', 'CL Change Size: Medium')]","[{'comment_id': 2406244282, 'issue_id': 2580085145, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77609/checks?check_run_id=31383766258) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 10, 23, 53, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406561538, 'issue_id': 2580085145, 'author': 'keerthanakadiri', 'body': 'Hi @i23hiratukatomoki, Can you please sign CLA , thank you !', 'created_at': datetime.datetime(2024, 10, 11, 5, 5, 3, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-10 23:53:03 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77609/checks?check_run_id=31383766258) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

keerthanakadiri on (2024-10-11 05:05:03 UTC): Hi @i23hiratukatomoki, Can you please sign CLA , thank you !

"
2580081960,pull_request,open,,Integrate LLVM at llvm/llvm-project@07892aaf0403,"Integrate LLVM at llvm/llvm-project@07892aaf0403

Updates LLVM usage to match
[07892aaf0403](https://github.com/llvm/llvm-project/commit/07892aaf0403)
",copybara-service[bot],2024-10-10 23:50:42+00:00,[],2024-10-10 23:50:42+00:00,,https://github.com/tensorflow/tensorflow/pull/77608,[],[],
2580073906,pull_request,closed,,Complete support for INT4 Conv in TFLite.,"Complete support for INT4 Conv in TFLite.
",copybara-service[bot],2024-10-10 23:45:43+00:00,['paulinesho'],2024-10-11 00:52:33+00:00,2024-10-11 00:52:33+00:00,https://github.com/tensorflow/tensorflow/pull/77607,[],[],
2580072972,pull_request,closed,,"Migrate dtensor_graph_to_mlir_pass to ConvertGraphToTfExecutor. This is no-op, the underlying api is the same but ConvertGraphToMlir is deprecated and will be removed shortly.","Migrate dtensor_graph_to_mlir_pass to ConvertGraphToTfExecutor. This is no-op, the underlying api is the same but ConvertGraphToMlir is deprecated and will be removed shortly.
",copybara-service[bot],2024-10-10 23:45:17+00:00,['rocketas'],2024-10-11 00:09:58+00:00,2024-10-11 00:09:57+00:00,https://github.com/tensorflow/tensorflow/pull/77606,[],[],
2580044081,pull_request,closed,,sort_rewriter: Expose IsCubCompatibleSort to allow introspecting sort rewrites.,"sort_rewriter: Expose IsCubCompatibleSort to allow introspecting sort rewrites.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17222 from Intel-tensorflow:kanvi/native_convert_support 9693d9e90d89fef9c7c063aa9d9aa6c648915145
",copybara-service[bot],2024-10-10 23:26:12+00:00,[],2024-10-11 17:30:22+00:00,2024-10-11 17:30:21+00:00,https://github.com/tensorflow/tensorflow/pull/77605,[],[],
2579987476,pull_request,closed,,Add pluggable device types to visible_device_list,"Add pluggable device types to visible_device_list
",copybara-service[bot],2024-10-10 22:45:19+00:00,[],2024-10-11 23:24:27+00:00,2024-10-11 23:24:27+00:00,https://github.com/tensorflow/tensorflow/pull/77604,[],[],
2579975603,pull_request,closed,,Move creation of completed_event into Cuda/RocmStream::Create,"Move creation of completed_event into Cuda/RocmStream::Create

This way the event becomes a proper implementation of the stream as it should be.
",copybara-service[bot],2024-10-10 22:36:53+00:00,[],2024-10-11 19:04:29+00:00,2024-10-11 19:04:28+00:00,https://github.com/tensorflow/tensorflow/pull/77603,[],[],
2579975300,pull_request,closed,,autotuning: Append a Status payload to the autotuning cache miss error.,"autotuning: Append a Status payload to the autotuning cache miss error.

Doing so allows detecting this case from callers that might be out-of-process
to signal them to recompute the autotune DB. The other callers of Autotune() don't
mess with the returned Status, so we don't need to modify them directly.

The value is empty right now, as we don't have a need to actually examine it,
but if one is needed it should be a serialized proto.
",copybara-service[bot],2024-10-10 22:36:46+00:00,[],2024-10-15 15:16:15+00:00,2024-10-15 15:16:14+00:00,https://github.com/tensorflow/tensorflow/pull/77602,[],[],
2579966029,pull_request,closed,,Use `assertIn` instead of `assertContainsSubsequence` for substring checks.,"Use `assertIn` instead of `assertContainsSubsequence` for substring checks.
",copybara-service[bot],2024-10-10 22:27:31+00:00,[],2024-10-11 07:07:52+00:00,2024-10-11 07:07:52+00:00,https://github.com/tensorflow/tensorflow/pull/77601,[],[],
2579961481,pull_request,closed,,Migrate compile_mlir_util to use ConvertGraphToMlir.,"Migrate compile_mlir_util to use ConvertGraphToMlir.
",copybara-service[bot],2024-10-10 22:22:42+00:00,['rocketas'],2024-10-10 22:42:19+00:00,2024-10-10 22:42:18+00:00,https://github.com/tensorflow/tensorflow/pull/77600,[],[],
2579957776,pull_request,closed,,Move Memset32 from GpuStream to CudaStream and RocmStream.,"Move Memset32 from GpuStream to CudaStream and RocmStream.

- Moves Memset32 into CudaStream and RocmStream
- Inlines the corresponding GpuDriver call
- Adds basic unit tests

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18026 from shawnwang18:shawnw/command_buffer_dynamic_slice 91a28306e911c3d8bcecec09768f6fdf4040fdf9
",copybara-service[bot],2024-10-10 22:19:50+00:00,[],2024-10-11 17:56:59+00:00,2024-10-11 17:56:59+00:00,https://github.com/tensorflow/tensorflow/pull/77599,[],[],
2579947250,pull_request,closed,,Migrate mlir_graph_optimization_pass to use ConvertGraphToTfExecutor.,"Migrate mlir_graph_optimization_pass to use ConvertGraphToTfExecutor.
",copybara-service[bot],2024-10-10 22:11:50+00:00,['rocketas'],2024-10-10 22:30:40+00:00,2024-10-10 22:30:40+00:00,https://github.com/tensorflow/tensorflow/pull/77598,[],[],
2579940457,pull_request,closed,,Migrate tf_graph_optimization_pass to ConvertGraphToTfExecutor.,"Migrate tf_graph_optimization_pass to ConvertGraphToTfExecutor.
",copybara-service[bot],2024-10-10 22:06:02+00:00,['rocketas'],2024-10-10 22:19:26+00:00,2024-10-10 22:19:25+00:00,https://github.com/tensorflow/tensorflow/pull/77597,[],[],
2579893874,pull_request,closed,,Move GpuDriver::GetDevice to the proper Executor classes.,"Move GpuDriver::GetDevice to the proper Executor classes.
",copybara-service[bot],2024-10-10 21:37:09+00:00,[],2024-10-12 15:21:02+00:00,2024-10-12 15:21:01+00:00,https://github.com/tensorflow/tensorflow/pull/77596,[],[],
2579890929,pull_request,closed,,"[PJRT:GPU] Add a unit test for gpu hanging bug repro, disabled until fixed.","[PJRT:GPU] Add a unit test for gpu hanging bug repro, disabled until fixed.
",copybara-service[bot],2024-10-10 21:34:54+00:00,[],2024-10-10 23:57:22+00:00,2024-10-10 23:57:20+00:00,https://github.com/tensorflow/tensorflow/pull/77595,[],[],
2579877091,pull_request,closed,,XLA SPMD Partitioner. Merge two table lookup into one for offsets.,"XLA SPMD Partitioner. Merge two table lookup into one for offsets.

Before this cl, we generate the diff of two offsets with the pattern `table_lookup_1(partition_id) - table_lookup_2(partition_id)`. This cl simplifies it into a single `table_lookup(partition_id)`. This cl can ease the pattern matching in the post SPMD passes. 

Here is an example before partitioner.
```
ENTRY entry {
  p0 = f32[8,16] parameter(0), sharding={devices=[2,1,2]<=[4] last_tile_dim_replicate}
  ROOT root = f32[8,16] copy(p0), sharding={devices=[4,1]<=[4]}
}
```

Before this cl, the partitioner generates redundant table lookups
```
ENTRY %entry_spmd (param: f32[4,16]) -> f32[2,16] {
  %param = f32[4,16]{1,0} parameter(0), sharding={devices=[2,1,2]<=[4] last_tile_dim_replicate}
  %constant.3 = s32[4]{0} constant({0, 2, 4, 6})
  %partition-id = u32[] partition-id()
  %dynamic-slice.1 = s32[1]{0} dynamic-slice(s32[4]{0} %constant.3, u32[] %partition-id), dynamic_slice_sizes={1}
  %reshape.1 = s32[] reshape(s32[1]{0} %dynamic-slice.1)
  %constant.5 = s32[4]{0} constant({0, 0, 4, 4})
  %dynamic-slice.2 = s32[1]{0} dynamic-slice(s32[4]{0} %constant.5, u32[] %partition-id), dynamic_slice_sizes={1}
  %reshape.2 = s32[] reshape(s32[1]{0} %dynamic-slice.2)
  %subtract = s32[] subtract(s32[] %reshape.1, s32[] %reshape.2)
  %constant.4 = s32[] constant(0)
  %subtract.1 = s32[] subtract(s32[] %constant.4, s32[] %constant.4)
  %dynamic-slice.3 = f32[2,16]{1,0} dynamic-slice(f32[4,16]{1,0} %param, s32[] %subtract, s32[] %subtract.1), dynamic_slice_sizes={2,16}
  ROOT %root.1 = f32[2,16]{1,0} copy(f32[2,16]{1,0} %dynamic-slice.3)
}
```

With this cl, we remove the redundancy
```
ENTRY %entry_spmd (param: f32[4,16]) -> f32[2,16] {
  %param = f32[4,16]{1,0} parameter(0), sharding={devices=[2,1,2]<=[4] last_tile_dim_replicate}
  %constant.4 = s32[4]{0} constant({0, 2, 0, 2})
  %partition-id = u32[] partition-id()
  %dynamic-slice.1 = s32[1]{0} dynamic-slice(s32[4]{0} %constant.4, u32[] %partition-id), dynamic_slice_sizes={1}
  %reshape.1 = s32[] reshape(s32[1]{0} %dynamic-slice.1)
  %constant.3 = s32[] constant(0)
  %dynamic-slice.2 = f32[2,16]{1,0} dynamic-slice(f32[4,16]{1,0} %param, s32[] %reshape.1, s32[] %constant.3), dynamic_slice_sizes={2,16}
  ROOT %root.1 = f32[2,16]{1,0} copy(f32[2,16]{1,0} %dynamic-slice.2)
}
```
",copybara-service[bot],2024-10-10 21:28:28+00:00,[],2024-10-11 19:59:44+00:00,2024-10-11 19:59:44+00:00,https://github.com/tensorflow/tensorflow/pull/77594,[],[],
2579866312,pull_request,closed,,Simplify Cuda and RocmTimer,"Simplify Cuda and RocmTimer

- Moves DelayKernel handling from `CudaExecutor` into `CudaTimer`
- Moves event creation from the respective executors into `CudaTimer` and `RocmTimer`
- Adds basic unit tests
",copybara-service[bot],2024-10-10 21:20:49+00:00,[],2024-10-11 06:21:17+00:00,2024-10-11 06:21:16+00:00,https://github.com/tensorflow/tensorflow/pull/77593,[],[],
2579854252,pull_request,open,,Add dedicated thread pool for coordination service,"Add dedicated thread pool for coordination service
Prevents heartbeat errors due to thread starvation in the shared thread pool.
",copybara-service[bot],2024-10-10 21:11:41+00:00,[],2024-10-10 21:11:41+00:00,,https://github.com/tensorflow/tensorflow/pull/77592,[],[],
2579847377,pull_request,closed,,Extend the gRPC unrequested time-out to 1h for the TF gRPC server.,"Extend the gRPC unrequested time-out to 1h for the TF gRPC server.
",copybara-service[bot],2024-10-10 21:07:02+00:00,[],2024-10-11 02:25:01+00:00,2024-10-11 02:25:00+00:00,https://github.com/tensorflow/tensorflow/pull/77591,[],[],
2579830924,pull_request,closed,,Delete dead code.,"Delete dead code.
",copybara-service[bot],2024-10-10 20:58:15+00:00,[],2024-10-11 17:46:27+00:00,2024-10-11 17:46:27+00:00,https://github.com/tensorflow/tensorflow/pull/77590,[],[],
2579798380,pull_request,closed,,Update version numbers for TensorFlow 2.18.0-rc2,"Before merging this PR, please double check that it has correctly updated
`core/public/version.h`, `tools/pip_package/setup.py`, and
`tensorflow/tensorflow.bzl`. Also review the execution notes below:

```
Major: 2 -> 2
Minor: 18 -> 18
Patch: 0 -> 0

No lingering old version strings ""2.18.0-rc1"" found in source directory 
""tensorflow/"". Good.
No lingering old version strings ""2.18.0rc1"" found in source directory 
""tensorflow/"". Good.
```",tensorflow-jenkins,2024-10-10 20:40:25+00:00,[],2024-10-10 21:39:35+00:00,2024-10-10 21:39:34+00:00,https://github.com/tensorflow/tensorflow/pull/77589,[],[],
2579777401,pull_request,closed,,"Add an algebraic simplification pattern for add(broadcast(const_0), add(broadcast(const_1, conv(...)))) -> add(broadcast(add(const_0, const_1)), conv(...))","Add an algebraic simplification pattern for add(broadcast(const_0), add(broadcast(const_1, conv(...)))) -> add(broadcast(add(const_0, const_1)), conv(...))
",copybara-service[bot],2024-10-10 20:29:08+00:00,[],2024-10-10 22:53:00+00:00,2024-10-10 22:52:59+00:00,https://github.com/tensorflow/tensorflow/pull/77588,[],[],
2579759932,pull_request,closed,,[IFRT] Clarify the meaning of the runtime_type() field on ifrt::Client.,"[IFRT] Clarify the meaning of the runtime_type() field on ifrt::Client.

For PJRT-IFRT, return ""pjrt-ifrt"", rather than forwarding the PJRT Client's runtime type. This change is in preparation for removing PjRtClient::runtime_type(). PjRtClient::runtime_type() carries no meaningful information.

While we are here, switch code that used a downcast to the PjRt StreamExecutor implementation in the Python implementation to instead use public PJRT APIs. This allows us to break the dependency of the :py_client module on StreamExecutor.
",copybara-service[bot],2024-10-10 20:17:14+00:00,[],2024-10-11 19:15:10+00:00,2024-10-11 19:15:09+00:00,https://github.com/tensorflow/tensorflow/pull/77587,[],[],
2579752294,pull_request,closed,,Move a bunch of GPU query functions from GpuDriver to the appropriate Executor classes.,"Move a bunch of GPU query functions from GpuDriver to the appropriate Executor classes.
",copybara-service[bot],2024-10-10 20:12:04+00:00,[],2024-10-12 00:00:21+00:00,2024-10-12 00:00:20+00:00,https://github.com/tensorflow/tensorflow/pull/77586,[],[],
2579751143,pull_request,closed,,Move GpuDriver::GetGpuISAVersion into RocmExecutor.,"Move GpuDriver::GetGpuISAVersion into RocmExecutor.
",copybara-service[bot],2024-10-10 20:11:22+00:00,[],2024-10-11 20:47:45+00:00,2024-10-11 20:47:44+00:00,https://github.com/tensorflow/tensorflow/pull/77585,[],[],
2579748100,pull_request,closed,,Move GpuDriver::GetGpuGCNArchName to RocmExecutor.,"Move GpuDriver::GetGpuGCNArchName to RocmExecutor.
",copybara-service[bot],2024-10-10 20:09:16+00:00,[],2024-10-11 22:29:19+00:00,2024-10-11 22:29:18+00:00,https://github.com/tensorflow/tensorflow/pull/77584,[],[],
2579743816,pull_request,closed,,Update build.py with new JAX .bazelrc changes,"Update build.py with new JAX .bazelrc changes
",copybara-service[bot],2024-10-10 20:06:29+00:00,['nitins17'],2024-10-10 22:11:49+00:00,2024-10-10 22:11:47+00:00,https://github.com/tensorflow/tensorflow/pull/77583,[],[],
2579736776,pull_request,closed,,Add preliminary support for DCN sharding.,"Add preliminary support for DCN sharding.
",copybara-service[bot],2024-10-10 20:03:33+00:00,[],2024-10-15 06:58:53+00:00,2024-10-15 06:58:52+00:00,https://github.com/tensorflow/tensorflow/pull/77582,[],[],
2579736087,pull_request,closed,,Install python 3.13 to the new ML build Docker Container.,"Install python 3.13 to the new ML build Docker Container.
",copybara-service[bot],2024-10-10 20:03:13+00:00,['quoctruong'],2024-10-11 00:37:54+00:00,2024-10-11 00:37:53+00:00,https://github.com/tensorflow/tensorflow/pull/77581,[],[],
2579703431,pull_request,closed,,Add building TF wheel to Linux and MacOS presubmit jobs.,"Add building TF wheel to Linux and MacOS presubmit jobs.

Refactor shell scripts: replace `TF_PYTHON_VERSION` with `HERMETIC_PYTHON_VERSION`.
",copybara-service[bot],2024-10-10 19:50:00+00:00,[],2024-10-14 23:45:44+00:00,2024-10-14 23:45:43+00:00,https://github.com/tensorflow/tensorflow/pull/77580,[],[],
2579670945,pull_request,open,,PR #16975: Add a few related optimization passes for fp8 gemm custom-calls.,"PR #16975: Add a few related optimization passes for fp8 gemm custom-calls.

Imported from GitHub PR https://github.com/openxla/xla/pull/16975

This caused convergence issue for fp8 training, tested on GPT3 models:

Before:
```
NETWORK             BACKEND MATH SDPA XLA_EXTRAS      GPUs STEPS/SEC     LOSS
WALLSECS
GPT5B                   XLA  fp8   FA    8     1.064 11.019     1571
[PAX STATUS]: Starting training loop.
[PAX STATUS] step_i: 100, training loss: 11.015041
[PAX STATUS] step_i: 200, training loss: 11.016165
[PAX STATUS] step_i: 300, training loss: 11.016386
[PAX STATUS] step_i: 400, training loss: 11.014653
[PAX STATUS] step_i: 500, training loss: 11.014734
[PAX STATUS] step_i: 600, training loss: 11.01613
[PAX STATUS] step_i: 700, training loss: 11.009399
[PAX STATUS] step_i: 800, training loss: 11.017071
[PAX STATUS] step_i: 900, training loss: 11.014582
[PAX STATUS] step_i: 1000, training loss: 11.013434
[PAX STATUS] step_i: 1100, training loss: 11.021271
[PAX STATUS] step_i: 1200, training loss: 11.008364
[PAX STATUS] step_i: 1300, training loss: 11.0198145
[PAX STATUS] step_i: 1400, training loss: 11.01253
[PAX STATUS] step_i: 1500, training loss: 11.019016
```

After:
```
NETWORK             BACKEND MATH SDPA GPUs STEPS/SEC  LOSS WALLSECS
GPT5B                   XLA  fp8   FA    8     1.020 3.797     1647
[PAX STATUS]: Starting training loop.
[PAX STATUS] step_i: 100, training loss: 6.150083
[PAX STATUS] step_i: 200, training loss: 5.8871064
[PAX STATUS] step_i: 300, training loss: 5.4491887
[PAX STATUS] step_i: 400, training loss: 5.6384015
[PAX STATUS] step_i: 500, training loss: 5.273538
[PAX STATUS] step_i: 600, training loss: 5.2011905
[PAX STATUS] step_i: 700, training loss: 4.903013
[PAX STATUS] step_i: 800, training loss: 4.62972
[PAX STATUS] step_i: 900, training loss: 4.507727
[PAX STATUS] step_i: 1000, training loss: 4.625259
[PAX STATUS] step_i: 1100, training loss: 4.428066
[PAX STATUS] step_i: 1200, training loss: 4.252451
[PAX STATUS] step_i: 1300, training loss: 3.8448389
[PAX STATUS] step_i: 1400, training loss: 3.8578327
[PAX STATUS] step_i: 1500, training loss: 3.796958
```
Copybara import of the project:

--
81af29c8667792fe9ed189ab55308ca6e83859d4 by Elfie Guo <elfieg@nvidia.com>:

Add a few related optimization pass for fp8 gemm rerwriter.

Merging this change closes #16975

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16975 from elfiegg:pass 81af29c8667792fe9ed189ab55308ca6e83859d4
",copybara-service[bot],2024-10-10 19:33:54+00:00,[],2024-10-10 19:33:54+00:00,,https://github.com/tensorflow/tensorflow/pull/77579,[],[],
2579599923,pull_request,closed,,Add LSTM sentiment analysis feature and update documentation,"### Summary
This pull request adds a sentiment analysis example using TensorFlow and an LSTM network. The model classifies sentences as either positive or negative sentiment.

### Changes Made
- Added a new script `tensorflow_sentiment_analysis.py` that implements an LSTM-based sentiment analysis model.
- Updated the `README.md` file with instructions on how to run the new feature.

### How to Test
1. Install TensorFlow and NumPy.
2. Run the script with:
   ```bash
   python tensorflow_sentiment_analysis.py
",karthiknandam9,2024-10-10 18:54:34+00:00,['gbaned'],2024-10-11 09:56:21+00:00,2024-10-11 09:56:18+00:00,https://github.com/tensorflow/tensorflow/pull/77578,"[('size:M', 'CL Change Size: Medium')]","[{'comment_id': 2405824794, 'issue_id': 2579599923, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77578/checks?check_run_id=31372757415) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 10, 18, 54, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2406556922, 'issue_id': 2579599923, 'author': 'keerthanakadiri', 'body': 'Hi @karthiknandam9, Can you please sign CLA , thank you !', 'created_at': datetime.datetime(2024, 10, 11, 4, 59, 37, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-10 18:54:38 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77578/checks?check_run_id=31372757415) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

keerthanakadiri on (2024-10-11 04:59:37 UTC): Hi @karthiknandam9, Can you please sign CLA , thank you !

"
2579595244,pull_request,closed,,Internal testing framework change.,"Internal testing framework change.
",copybara-service[bot],2024-10-10 18:52:21+00:00,[],2024-10-10 23:13:11+00:00,2024-10-10 23:13:11+00:00,https://github.com/tensorflow/tensorflow/pull/77577,[],[],
2579567017,pull_request,closed,,"r2.18 cherry-pick: be4f646ec43 ""PR #17430: [ROCm] Use unique_ptr for TupleHandle in pjrt_se_client""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/be4f646ec43d09aba8c7ac09330228adbf5eca33,tensorflow-jenkins,2024-10-10 18:40:25+00:00,[],2024-10-10 20:20:10+00:00,2024-10-10 20:20:08+00:00,https://github.com/tensorflow/tensorflow/pull/77576,[],[],
2579552726,pull_request,closed,,Add a check of unsupported ops in bridge input validate passes for both session and function runtime pipeline,"Add a check of unsupported ops in bridge input validate passes for both session and function runtime pipeline
",copybara-service[bot],2024-10-10 18:33:03+00:00,[],2024-10-11 18:42:10+00:00,2024-10-11 18:42:09+00:00,https://github.com/tensorflow/tensorflow/pull/77575,[],[],
2579481924,pull_request,closed,,[XLA:GPU] Fix a bug that causes constants that are not supported by Triton to be fused.,"[XLA:GPU] Fix a bug that causes constants that are not supported by Triton to be fused.

Old code expected that `IsFusible` always returns `false` for Triton fusions. But that's not the case if the fusion is elementwise.
",copybara-service[bot],2024-10-10 17:52:35+00:00,[],2024-10-11 16:42:18+00:00,2024-10-11 16:42:17+00:00,https://github.com/tensorflow/tensorflow/pull/77574,[],[],
2579455386,pull_request,closed,,Run `bazel build --nobuild` ahead of `bazel query` in GitHub Actions,"Run `bazel build --nobuild` ahead of `bazel query` in GitHub Actions

Also update timeouts as these actions will take slightly longer now
",copybara-service[bot],2024-10-10 17:39:19+00:00,['ddunl'],2024-10-11 00:03:36+00:00,2024-10-11 00:03:35+00:00,https://github.com/tensorflow/tensorflow/pull/77573,[],[],
2579448754,pull_request,closed,,Replace deprecated `tensorflow::Status` with `absl::Status` in shape_inference_testutil.h,"Replace deprecated `tensorflow::Status` with `absl::Status` in shape_inference_testutil.h
",copybara-service[bot],2024-10-10 17:35:20+00:00,[],2024-10-10 18:20:22+00:00,2024-10-10 18:20:21+00:00,https://github.com/tensorflow/tensorflow/pull/77572,[],[],
2579392562,pull_request,closed,,Support legalizing embedding lookup composite with dynamic shapes,"Support legalizing embedding lookup composite with dynamic shapes
",copybara-service[bot],2024-10-10 17:03:27+00:00,['sirakiin'],2024-10-11 21:45:57+00:00,2024-10-11 21:45:56+00:00,https://github.com/tensorflow/tensorflow/pull/77571,[],[],
2579095074,pull_request,closed,,Move __HIP_DISABLE_CPP_FUNCTIONS__ to BUILD file,"Move __HIP_DISABLE_CPP_FUNCTIONS__ to BUILD file

This unbreaks the ROCm build which got broken by uncluding hip_runtime.h before rocm_driver_wrapper.h

Applying the preprocessor definition on the build system level should avoid the issue in the future.
",copybara-service[bot],2024-10-10 14:49:29+00:00,[],2024-10-10 15:56:54+00:00,2024-10-10 15:56:53+00:00,https://github.com/tensorflow/tensorflow/pull/77569,[],[],
2579013739,pull_request,open,,Integrate Triton up to [68aa962e67baa191cec5aac173255abdba80db1a](https://github.com/openai/triton/commits/68aa962e67baa191cec5aac173255abdba80db1a),"Integrate Triton up to [68aa962e67baa191cec5aac173255abdba80db1a](https://github.com/openai/triton/commits/68aa962e67baa191cec5aac173255abdba80db1a)
",copybara-service[bot],2024-10-10 14:20:29+00:00,[],2024-10-18 17:30:40+00:00,,https://github.com/tensorflow/tensorflow/pull/77568,[],[],
2578633206,pull_request,closed,,PR #17749: [NVIDIA] Added a flag to control the total number of collective resource in LHS,"PR #17749: [NVIDIA] Added a flag to control the total number of collective resource in LHS

Imported from GitHub PR https://github.com/openxla/xla/pull/17749

Added a flag to control the total number of collective resource in LHS, the goal is to allow the scheduler to overlap multiple collectives under a large compute:
```
  With xla_gpu_scheduler_parallel_collective_resource = 1:
     coll.1-start = collective(input)
     coll.1-done = collective(coll.1-start)
     coll.2-start = collective(input2)
     large_compute = compute(op)  // because only 1 collective is allowed in-flight, only schedule 1 start-done pair here
     coll.2-done = collective(coll.2-start)
   With xla_gpu_scheduler_parallel_collective_resource = 2:
     coll.1-start = collective(input)
     coll.2-start = collective(input2)
     large_compute = compute(op)  // 2 collectives can be schedule in-flight at once now, much better schedule
     coll.1-done = collective(coll.1-start)
     coll.2-done = collective(coll.2-start)

```

Note that since we only have 1 collective stream, collectives will be serialized anyway, but with more resource, some of them can start much earlier.
Copybara import of the project:

--
663ef44f40dca1251a99f86729407cdcce2848c3 by TJ Xu <tjx@nvidia.com>:

Added a flag to control the total number of collective resource in LHS

--
bd3c76c803d6d284b4294257b89032415054027e by TJ Xu <tjx@nvidia.com>:

Change flags to have more appropriate names

--
1cf262cf1624071fd14305d613b6bc3848eafe95 by TJ Xu <tjx@nvidia.com>:

Added a unit test for multiple async resource

--
88c84a8b1531db5bcf07ae864dfb175e593bd507 by TJ Xu <tjx@nvidia.com>:

added a check to make sure each individual collective resource wont
execeed the global resource

Merging this change closes #17749

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17749 from Tixxx:tixxx/collective_resource 88c84a8b1531db5bcf07ae864dfb175e593bd507
",copybara-service[bot],2024-10-10 11:56:51+00:00,[],2024-10-15 07:08:38+00:00,2024-10-15 07:08:37+00:00,https://github.com/tensorflow/tensorflow/pull/77567,[],[],
2578621222,pull_request,closed,,PR #18143: Add math tests for FP8 types,"PR #18143: Add math tests for FP8 types

Imported from GitHub PR https://github.com/openxla/xla/pull/18143

This PR also fixes the issues in `IsPosInf`, `IsNegInf`, `IsNegZero` implementations discovered by the tests.
Copybara import of the project:

--
0eda1a589bf392d9df259e86a880d186ad8f71d2 by Sergey Kozub <skozub@nvidia.com>:

Add math tests for FP8 types

Merging this change closes #18143

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18143 from openxla:skozub/math_test 0eda1a589bf392d9df259e86a880d186ad8f71d2
",copybara-service[bot],2024-10-10 11:52:22+00:00,[],2024-10-10 14:30:11+00:00,2024-10-10 14:30:10+00:00,https://github.com/tensorflow/tensorflow/pull/77566,[],[],
2578604642,pull_request,closed,,Add transpose fusion test case with two side outputs with in-place parameter.,"Add transpose fusion test case with two side outputs with in-place parameter.
",copybara-service[bot],2024-10-10 11:45:51+00:00,['akuegel'],2024-10-10 13:39:44+00:00,2024-10-10 13:39:42+00:00,https://github.com/tensorflow/tensorflow/pull/77565,[],[],
2578595932,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 11:42:29+00:00,[],2024-10-11 10:47:25+00:00,,https://github.com/tensorflow/tensorflow/pull/77564,[],[],
2578589741,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 11:39:57+00:00,[],2024-10-12 06:43:55+00:00,2024-10-12 06:43:54+00:00,https://github.com/tensorflow/tensorflow/pull/77563,[],[],
2578540560,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 11:21:27+00:00,[],2024-10-11 11:46:55+00:00,,https://github.com/tensorflow/tensorflow/pull/77562,[],[],
2578432286,pull_request,closed,,Integrate LLVM at llvm/llvm-project@527cd117b2cb,"Integrate LLVM at llvm/llvm-project@527cd117b2cb

Updates LLVM usage to match
[527cd117b2cb](https://github.com/llvm/llvm-project/commit/527cd117b2cb)
",copybara-service[bot],2024-10-10 10:47:01+00:00,[],2024-10-10 14:51:33+00:00,2024-10-10 14:51:32+00:00,https://github.com/tensorflow/tensorflow/pull/77561,[],[],
2578424147,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 10:44:14+00:00,[],2024-10-11 04:11:20+00:00,,https://github.com/tensorflow/tensorflow/pull/77560,[],[],
2578205413,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 09:23:42+00:00,[],2024-10-11 07:54:23+00:00,,https://github.com/tensorflow/tensorflow/pull/77558,[],[],
2578196788,pull_request,open,,compat: Update forward compatibility horizon to 2024-10-10,"compat: Update forward compatibility horizon to 2024-10-10
",copybara-service[bot],2024-10-10 09:19:39+00:00,[],2024-10-10 09:19:39+00:00,,https://github.com/tensorflow/tensorflow/pull/77557,[],[],
2578191426,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 09:17:11+00:00,[],2024-10-12 08:15:17+00:00,2024-10-12 08:15:17+00:00,https://github.com/tensorflow/tensorflow/pull/77556,[],[],
2578179685,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 09:11:51+00:00,[],2024-10-11 07:34:37+00:00,,https://github.com/tensorflow/tensorflow/pull/77555,[],[],
2578159193,pull_request,closed,,Removed legacy path for static_mean + updated XNNPACK version.,"Removed legacy path for static_mean + updated XNNPACK version.

Reverts 727250b5b40de9717f192055c27fd679d24458d6
",copybara-service[bot],2024-10-10 09:02:45+00:00,[],2024-10-11 12:19:50+00:00,2024-10-11 12:19:49+00:00,https://github.com/tensorflow/tensorflow/pull/77554,[],[],
2578139008,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:54:28+00:00,[],2024-10-11 07:11:13+00:00,,https://github.com/tensorflow/tensorflow/pull/77553,[],[],
2578135976,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:53:18+00:00,[],2024-10-11 03:32:27+00:00,,https://github.com/tensorflow/tensorflow/pull/77552,[],[],
2578130434,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:51:57+00:00,[],2024-10-11 05:31:47+00:00,,https://github.com/tensorflow/tensorflow/pull/77551,[],[],
2578129158,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:51:31+00:00,[],2024-10-11 08:36:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77550,[],[],
2578126444,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:50:29+00:00,[],2024-10-11 07:18:01+00:00,,https://github.com/tensorflow/tensorflow/pull/77549,[],[],
2578119461,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:47:58+00:00,[],2024-10-11 04:16:59+00:00,,https://github.com/tensorflow/tensorflow/pull/77548,[],[],
2578118853,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:47:44+00:00,[],2024-10-11 09:52:07+00:00,,https://github.com/tensorflow/tensorflow/pull/77547,[],[],
2578118165,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:47:26+00:00,[],2024-10-11 10:51:47+00:00,2024-10-11 10:51:46+00:00,https://github.com/tensorflow/tensorflow/pull/77546,[],[],
2578117942,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:47:20+00:00,[],2024-10-12 10:48:49+00:00,2024-10-12 10:48:48+00:00,https://github.com/tensorflow/tensorflow/pull/77545,[],[],
2578117605,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:47:10+00:00,[],2024-10-11 07:11:56+00:00,,https://github.com/tensorflow/tensorflow/pull/77544,[],[],
2578114607,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:45:53+00:00,[],2024-10-11 07:04:32+00:00,,https://github.com/tensorflow/tensorflow/pull/77543,[],[],
2578114589,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:45:53+00:00,[],2024-10-12 05:33:46+00:00,2024-10-12 05:33:44+00:00,https://github.com/tensorflow/tensorflow/pull/77542,[],[],
2578114402,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:45:47+00:00,[],2024-10-12 05:40:59+00:00,,https://github.com/tensorflow/tensorflow/pull/77541,[],[],
2578113604,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:45:25+00:00,[],2024-10-11 07:58:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77540,[],[],
2578112626,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:44:58+00:00,[],2024-10-12 07:08:14+00:00,,https://github.com/tensorflow/tensorflow/pull/77539,[],[],
2578112281,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:44:48+00:00,[],2024-10-12 05:44:41+00:00,2024-10-12 05:44:40+00:00,https://github.com/tensorflow/tensorflow/pull/77538,[],[],
2578111483,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:44:26+00:00,[],2024-10-11 08:45:20+00:00,,https://github.com/tensorflow/tensorflow/pull/77537,[],[],
2578110964,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:44:12+00:00,[],2024-10-12 03:34:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77536,[],[],
2578110932,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:44:12+00:00,[],2024-10-11 10:08:44+00:00,,https://github.com/tensorflow/tensorflow/pull/77535,[],[],
2578100959,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:41:38+00:00,[],2024-10-11 09:32:51+00:00,,https://github.com/tensorflow/tensorflow/pull/77534,[],[],
2578100512,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:41:29+00:00,[],2024-10-11 07:31:27+00:00,,https://github.com/tensorflow/tensorflow/pull/77533,[],[],
2578100176,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:41:23+00:00,[],2024-10-11 08:27:14+00:00,,https://github.com/tensorflow/tensorflow/pull/77532,[],[],
2578099816,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:41:17+00:00,[],2024-10-11 14:08:58+00:00,2024-10-11 14:08:56+00:00,https://github.com/tensorflow/tensorflow/pull/77531,[],[],
2578097945,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:40:41+00:00,[],2024-10-11 09:46:23+00:00,,https://github.com/tensorflow/tensorflow/pull/77530,[],[],
2578094502,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:39:27+00:00,[],2024-10-11 10:20:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77529,[],[],
2578094420,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:39:25+00:00,[],2024-10-11 11:43:31+00:00,,https://github.com/tensorflow/tensorflow/pull/77528,[],[],
2578094384,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:39:24+00:00,[],2024-10-11 09:33:46+00:00,,https://github.com/tensorflow/tensorflow/pull/77527,[],[],
2578093782,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:39:06+00:00,[],2024-10-12 08:03:02+00:00,2024-10-12 08:03:01+00:00,https://github.com/tensorflow/tensorflow/pull/77526,[],[],
2578093215,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:38:49+00:00,[],2024-10-11 08:31:52+00:00,,https://github.com/tensorflow/tensorflow/pull/77525,[],[],
2578092394,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:38:35+00:00,[],2024-10-12 07:11:59+00:00,,https://github.com/tensorflow/tensorflow/pull/77524,[],[],
2578091307,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:38:04+00:00,[],2024-10-11 03:53:50+00:00,,https://github.com/tensorflow/tensorflow/pull/77523,[],[],
2578091145,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:38:00+00:00,[],2024-10-11 10:15:07+00:00,2024-10-11 10:15:06+00:00,https://github.com/tensorflow/tensorflow/pull/77522,[],[],
2578089598,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:37:26+00:00,[],2024-10-11 06:48:57+00:00,,https://github.com/tensorflow/tensorflow/pull/77521,[],[],
2578087700,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:36:54+00:00,[],2024-10-10 08:36:54+00:00,,https://github.com/tensorflow/tensorflow/pull/77520,[],[],
2578087045,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:36:39+00:00,[],2024-10-11 04:59:44+00:00,,https://github.com/tensorflow/tensorflow/pull/77519,[],[],
2578086921,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:36:36+00:00,[],2024-10-11 08:48:53+00:00,,https://github.com/tensorflow/tensorflow/pull/77518,[],[],
2578086628,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:36:27+00:00,[],2024-10-12 06:54:45+00:00,2024-10-12 06:54:44+00:00,https://github.com/tensorflow/tensorflow/pull/77517,[],[],
2578086400,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:36:21+00:00,[],2024-10-11 07:14:31+00:00,,https://github.com/tensorflow/tensorflow/pull/77516,[],[],
2578085632,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:36:02+00:00,[],2024-10-11 08:59:49+00:00,,https://github.com/tensorflow/tensorflow/pull/77515,[],[],
2578085388,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:35:55+00:00,[],2024-10-11 06:50:17+00:00,,https://github.com/tensorflow/tensorflow/pull/77514,[],[],
2578084508,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:35:29+00:00,[],2024-10-11 09:26:19+00:00,,https://github.com/tensorflow/tensorflow/pull/77513,[],[],
2578082896,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:34:41+00:00,[],2024-10-12 10:23:05+00:00,2024-10-12 10:23:05+00:00,https://github.com/tensorflow/tensorflow/pull/77512,[],[],
2578078030,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:32:33+00:00,[],2024-10-11 08:23:21+00:00,,https://github.com/tensorflow/tensorflow/pull/77511,[],[],
2578077782,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:32:27+00:00,[],2024-10-11 04:14:43+00:00,,https://github.com/tensorflow/tensorflow/pull/77510,[],[],
2578077643,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:32:23+00:00,[],2024-10-11 09:13:37+00:00,,https://github.com/tensorflow/tensorflow/pull/77509,[],[],
2578076629,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:32:00+00:00,[],2024-10-10 11:24:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77508,[],[],
2578076412,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:31:54+00:00,[],2024-10-11 13:33:06+00:00,2024-10-11 13:33:06+00:00,https://github.com/tensorflow/tensorflow/pull/77507,[],[],
2578075544,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:31:29+00:00,[],2024-10-11 04:47:50+00:00,,https://github.com/tensorflow/tensorflow/pull/77506,[],[],
2578075290,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:31:23+00:00,[],2024-10-12 12:11:20+00:00,2024-10-12 12:11:19+00:00,https://github.com/tensorflow/tensorflow/pull/77505,[],[],
2578074572,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:31:10+00:00,[],2024-10-11 13:22:13+00:00,2024-10-11 13:22:12+00:00,https://github.com/tensorflow/tensorflow/pull/77504,[],[],
2578074507,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:31:08+00:00,[],2024-10-11 04:24:10+00:00,,https://github.com/tensorflow/tensorflow/pull/77503,[],[],
2578073502,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:30:39+00:00,[],2024-10-10 08:30:39+00:00,,https://github.com/tensorflow/tensorflow/pull/77502,[],[],
2578072933,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:30:24+00:00,[],2024-10-11 07:26:38+00:00,,https://github.com/tensorflow/tensorflow/pull/77501,[],[],
2578071052,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:29:30+00:00,[],2024-10-10 08:29:30+00:00,,https://github.com/tensorflow/tensorflow/pull/77500,[],[],
2578070185,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:29:07+00:00,[],2024-10-12 13:52:46+00:00,2024-10-12 13:52:45+00:00,https://github.com/tensorflow/tensorflow/pull/77499,[],[],
2578070168,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:29:06+00:00,[],2024-10-11 10:49:20+00:00,,https://github.com/tensorflow/tensorflow/pull/77498,[],[],
2578069723,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:28:54+00:00,[],2024-10-11 04:44:56+00:00,,https://github.com/tensorflow/tensorflow/pull/77497,[],[],
2578069159,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:28:38+00:00,[],2024-10-11 04:14:02+00:00,,https://github.com/tensorflow/tensorflow/pull/77496,[],[],
2578068226,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:28:12+00:00,[],2024-10-11 05:13:04+00:00,,https://github.com/tensorflow/tensorflow/pull/77495,[],[],
2578067870,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:28:02+00:00,[],2024-10-11 07:04:52+00:00,,https://github.com/tensorflow/tensorflow/pull/77494,[],[],
2578032635,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:14:46+00:00,[],2024-10-11 06:41:56+00:00,,https://github.com/tensorflow/tensorflow/pull/77493,[],[],
2578031146,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:14:02+00:00,[],2024-10-11 11:57:26+00:00,2024-10-11 11:57:25+00:00,https://github.com/tensorflow/tensorflow/pull/77492,[],[],
2578030725,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:13:51+00:00,[],2024-10-11 06:29:01+00:00,,https://github.com/tensorflow/tensorflow/pull/77491,[],[],
2578027034,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:12:21+00:00,[],2024-10-10 10:13:20+00:00,,https://github.com/tensorflow/tensorflow/pull/77490,[],[],
2578025671,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:11:54+00:00,[],2024-10-11 06:59:38+00:00,,https://github.com/tensorflow/tensorflow/pull/77489,[],[],
2578023887,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:11:23+00:00,[],2024-10-11 06:58:56+00:00,2024-10-11 06:58:55+00:00,https://github.com/tensorflow/tensorflow/pull/77488,[],[],
2578022944,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:10:56+00:00,[],2024-10-12 10:36:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77487,[],[],
2578022864,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:10:54+00:00,[],2024-10-11 07:02:13+00:00,,https://github.com/tensorflow/tensorflow/pull/77486,[],[],
2578021202,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:10:04+00:00,[],2024-10-11 04:07:01+00:00,,https://github.com/tensorflow/tensorflow/pull/77485,[],[],
2578020626,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:09:48+00:00,[],2024-10-12 07:05:10+00:00,2024-10-12 07:05:09+00:00,https://github.com/tensorflow/tensorflow/pull/77484,[],[],
2578020130,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:09:33+00:00,[],2024-10-10 11:15:20+00:00,,https://github.com/tensorflow/tensorflow/pull/77483,[],[],
2578019625,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:09:17+00:00,[],2024-10-12 10:19:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77482,[],[],
2578019103,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:09:01+00:00,[],2024-10-11 11:08:51+00:00,2024-10-11 11:08:51+00:00,https://github.com/tensorflow/tensorflow/pull/77481,[],[],
2578018163,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:08:34+00:00,[],2024-10-12 04:15:16+00:00,2024-10-12 04:15:15+00:00,https://github.com/tensorflow/tensorflow/pull/77480,[],[],
2578017991,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:08:28+00:00,[],2024-10-11 03:55:32+00:00,,https://github.com/tensorflow/tensorflow/pull/77479,[],[],
2578017696,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:08:20+00:00,[],2024-10-11 07:08:18+00:00,,https://github.com/tensorflow/tensorflow/pull/77478,[],[],
2578016579,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:07:48+00:00,[],2024-10-11 04:55:39+00:00,,https://github.com/tensorflow/tensorflow/pull/77477,[],[],
2578016447,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:07:44+00:00,[],2024-10-10 08:07:44+00:00,,https://github.com/tensorflow/tensorflow/pull/77476,[],[],
2578016396,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:07:43+00:00,[],2024-10-11 10:13:46+00:00,,https://github.com/tensorflow/tensorflow/pull/77475,[],[],
2578015716,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:07:22+00:00,[],2024-10-11 11:16:14+00:00,,https://github.com/tensorflow/tensorflow/pull/77474,[],[],
2578015656,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:07:20+00:00,[],2024-10-11 04:15:40+00:00,,https://github.com/tensorflow/tensorflow/pull/77473,[],[],
2578015538,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:07:16+00:00,[],2024-10-11 07:21:33+00:00,,https://github.com/tensorflow/tensorflow/pull/77472,[],[],
2578015200,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:07:06+00:00,[],2024-10-11 03:48:08+00:00,,https://github.com/tensorflow/tensorflow/pull/77471,[],[],
2578015123,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:07:04+00:00,[],2024-10-11 03:59:40+00:00,,https://github.com/tensorflow/tensorflow/pull/77470,[],[],
2578014786,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:06:54+00:00,[],2024-10-12 09:25:27+00:00,2024-10-12 09:25:26+00:00,https://github.com/tensorflow/tensorflow/pull/77469,[],[],
2578014714,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:06:52+00:00,[],2024-10-11 05:20:57+00:00,,https://github.com/tensorflow/tensorflow/pull/77468,[],[],
2578014698,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:06:51+00:00,[],2024-10-12 04:52:13+00:00,2024-10-12 04:52:12+00:00,https://github.com/tensorflow/tensorflow/pull/77467,[],[],
2578014383,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:06:41+00:00,[],2024-10-11 04:53:00+00:00,,https://github.com/tensorflow/tensorflow/pull/77466,[],[],
2578014195,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:06:36+00:00,[],2024-10-11 04:26:20+00:00,,https://github.com/tensorflow/tensorflow/pull/77465,[],[],
2578013829,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:06:25+00:00,[],2024-10-12 07:09:54+00:00,,https://github.com/tensorflow/tensorflow/pull/77464,[],[],
2578013037,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:06:01+00:00,[],2024-10-11 11:40:45+00:00,,https://github.com/tensorflow/tensorflow/pull/77463,[],[],
2578012210,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:05:35+00:00,[],2024-10-11 05:33:18+00:00,,https://github.com/tensorflow/tensorflow/pull/77462,[],[],
2578011985,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:05:28+00:00,[],2024-10-12 05:14:12+00:00,2024-10-12 05:14:11+00:00,https://github.com/tensorflow/tensorflow/pull/77461,[],[],
2578011848,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:05:24+00:00,[],2024-10-12 07:42:55+00:00,,https://github.com/tensorflow/tensorflow/pull/77460,[],[],
2578011822,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:05:24+00:00,[],2024-10-12 06:29:04+00:00,2024-10-12 06:29:03+00:00,https://github.com/tensorflow/tensorflow/pull/77459,[],[],
2578011448,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 08:05:12+00:00,[],2024-10-10 09:39:55+00:00,,https://github.com/tensorflow/tensorflow/pull/77458,[],[],
2577973036,pull_request,closed,,PR #18065: Pass Ordering Test for GPU Compiler,"PR #18065: Pass Ordering Test for GPU Compiler

Imported from GitHub PR https://github.com/openxla/xla/pull/18065

Adds a class for testing the order of passes in the GPU compiler. The names of the passes expected to run first and last can be described by regular expressions.

Also adds a test for verifying the order of the collective quantizer and collective pipeliner passes.
Copybara import of the project:

--
2e3624d50ba100b9402a48aab4f3dca2e19208e4 by Philipp Hack <phack@nvidia.com>:

Adds a class for testing the order of passes in the GPU compiler.

--
3243bf2834052f9ec20b9b4ea0a8b078202a7c2e by Philipp Hack <phack@nvidia.com>:

Adds a class for testing the order of passes in the GPU compiler.

--
1b13ef048168072d771185f5e6b81b124c31ea2b by Philipp Hack <phack@nvidia.com>:

Adds a class for testing the order of passes in the GPU compiler.

Merging this change closes #18065

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18065 from philipphack:u_ordering_test_xla 1b13ef048168072d771185f5e6b81b124c31ea2b
",copybara-service[bot],2024-10-10 07:52:01+00:00,[],2024-10-10 16:34:51+00:00,2024-10-10 16:34:50+00:00,https://github.com/tensorflow/tensorflow/pull/77457,[],[],
2577961554,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 07:47:41+00:00,[],2024-10-16 09:07:23+00:00,2024-10-16 09:07:22+00:00,https://github.com/tensorflow/tensorflow/pull/77456,[],[],
2577915241,pull_request,closed,,Consolidate all qnn code into vendors. Misc cleanup/re-styling.,"Consolidate all qnn code into vendors. Misc cleanup/re-styling.

* Always PascalCase for c++ functions/methods
* Use safer global singleton in dispatch api
* Break some targets in to smaller pieces
* Pull more init logic into QnnManager
* Surface element type mapping for other qnn code
* Fix logging
* Use alloca where useful
* Conditionally compile dlopen wrapper (android doesn't have RTLD_DEEPBIND)
* Make shared lib file names camelCase
* Fix bad types in testing/common
* use lrt::qnn namespace

Regarding qnn handle lifetimes:

The sdk will free when the lib unloads; its not a memory leak to not free qnn handles so its not ""required"". Eventually I will pull all create/free/handle into the QnnManager. I think it would be better to control these from a single point (e.g. only in dispatch_api) and to call them explicitly rather than putting in cstor/dstor. Otherwise its too hard to track whats happening.
",copybara-service[bot],2024-10-10 07:31:18+00:00,['LukeBoyer'],2024-10-11 10:32:11+00:00,2024-10-11 10:32:10+00:00,https://github.com/tensorflow/tensorflow/pull/77455,[],[],
2577913792,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 07:30:48+00:00,[],2024-10-11 09:48:29+00:00,2024-10-11 09:48:27+00:00,https://github.com/tensorflow/tensorflow/pull/77454,[],[],
2577913680,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 07:30:44+00:00,[],2024-10-11 07:16:11+00:00,,https://github.com/tensorflow/tensorflow/pull/77453,[],[],
2577817378,pull_request,closed,,Add OP mappings.,"Add OP mappings.
Add parameterized tests for example OPs.
Fix a typo in op_code.
Add I32, Bool to supported types.
Fix transpose OP file name.
Move none from variable to arguments in fully_connected OP.
",copybara-service[bot],2024-10-10 06:52:06+00:00,[],2024-10-11 22:06:37+00:00,2024-10-11 22:06:36+00:00,https://github.com/tensorflow/tensorflow/pull/77452,[],[],
2577789120,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 06:41:30+00:00,[],2024-10-11 05:02:40+00:00,,https://github.com/tensorflow/tensorflow/pull/77451,[],[],
2577778912,pull_request,open,,[XLA:GPU] Use MaterializeOp for side outputs in transpose fusion,"[XLA:GPU] Use MaterializeOp for side outputs in transpose fusion
",copybara-service[bot],2024-10-10 06:36:00+00:00,[],2024-10-10 07:43:32+00:00,,https://github.com/tensorflow/tensorflow/pull/77450,[],[],
2577755646,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 06:25:02+00:00,[],2024-10-11 09:55:53+00:00,,https://github.com/tensorflow/tensorflow/pull/77449,[],[],
2577746006,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 06:21:17+00:00,[],2024-10-11 10:23:57+00:00,,https://github.com/tensorflow/tensorflow/pull/77448,[],[],
2577676582,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 05:43:13+00:00,[],2024-10-10 08:22:25+00:00,,https://github.com/tensorflow/tensorflow/pull/77447,[],[],
2577648635,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 05:28:15+00:00,[],2024-10-10 09:38:17+00:00,,https://github.com/tensorflow/tensorflow/pull/77446,[],[],
2577621252,pull_request,closed,,Internal change only,"Internal change only
",copybara-service[bot],2024-10-10 05:10:03+00:00,[],2024-10-14 18:34:45+00:00,2024-10-14 18:34:45+00:00,https://github.com/tensorflow/tensorflow/pull/77445,[],[],
2577608803,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 05:02:18+00:00,[],2024-10-10 09:51:24+00:00,,https://github.com/tensorflow/tensorflow/pull/77444,[],[],
2577590226,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 04:52:57+00:00,[],2024-10-10 09:36:40+00:00,,https://github.com/tensorflow/tensorflow/pull/77443,[],[],
2577537074,pull_request,closed,,[tflite-gpu] add kTfLiteBuiltinLogicalNot and kTfLiteBuiltinLogicalOr cases to CheckGpuDelegateCompatibility,"[tflite-gpu] add kTfLiteBuiltinLogicalNot and kTfLiteBuiltinLogicalOr cases to CheckGpuDelegateCompatibility
",copybara-service[bot],2024-10-10 04:29:46+00:00,[],2024-10-10 17:06:02+00:00,2024-10-10 17:06:01+00:00,https://github.com/tensorflow/tensorflow/pull/77441,[],[],
2577524544,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 04:24:15+00:00,[],2024-10-11 12:10:35+00:00,2024-10-11 12:10:34+00:00,https://github.com/tensorflow/tensorflow/pull/77440,[],[],
2577485299,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 04:00:52+00:00,[],2024-10-10 04:00:52+00:00,,https://github.com/tensorflow/tensorflow/pull/77439,[],[],
2577478052,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:56:50+00:00,[],2024-10-10 08:34:56+00:00,,https://github.com/tensorflow/tensorflow/pull/77438,[],[],
2577459263,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:45:00+00:00,[],2024-10-11 05:08:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77437,[],[],
2577455691,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:41:24+00:00,[],2024-10-10 05:17:42+00:00,2024-10-10 05:17:41+00:00,https://github.com/tensorflow/tensorflow/pull/77436,[],[],
2577450384,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:39:30+00:00,[],2024-10-11 07:19:31+00:00,2024-10-11 07:19:30+00:00,https://github.com/tensorflow/tensorflow/pull/77435,[],[],
2577448745,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:38:58+00:00,[],2024-10-10 03:38:58+00:00,,https://github.com/tensorflow/tensorflow/pull/77434,[],[],
2577448547,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:38:52+00:00,[],2024-10-10 08:29:35+00:00,,https://github.com/tensorflow/tensorflow/pull/77433,[],[],
2577443443,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:34:26+00:00,[],2024-10-10 03:34:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77432,[],[],
2577442927,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:33:46+00:00,[],2024-10-10 08:16:09+00:00,,https://github.com/tensorflow/tensorflow/pull/77431,[],[],
2577440936,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:31:32+00:00,[],2024-10-10 08:21:33+00:00,,https://github.com/tensorflow/tensorflow/pull/77430,[],[],
2577440777,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:31:19+00:00,[],2024-10-10 03:31:19+00:00,,https://github.com/tensorflow/tensorflow/pull/77429,[],[],
2577436756,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:26:50+00:00,[],2024-10-10 03:26:50+00:00,,https://github.com/tensorflow/tensorflow/pull/77428,[],[],
2577435470,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:25:40+00:00,[],2024-10-10 03:25:40+00:00,,https://github.com/tensorflow/tensorflow/pull/77427,[],[],
2577431884,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:22:04+00:00,[],2024-10-10 03:22:04+00:00,,https://github.com/tensorflow/tensorflow/pull/77426,[],[],
2577431865,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:22:03+00:00,[],2024-10-10 03:22:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77425,[],[],
2577428326,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-10 03:17:56+00:00,[],2024-10-10 09:05:59+00:00,,https://github.com/tensorflow/tensorflow/pull/77424,[],[],
2577368531,pull_request,closed,,PR #17950: Remove Post Layout Assignment Collective Pipeliner,"PR #17950: Remove Post Layout Assignment Collective Pipeliner

Imported from GitHub PR https://github.com/openxla/xla/pull/17950

Removes the functionality to optionally run the collective pipeliner pass post layout assignment. This option was introduced in #12866 to preserve FP8 quantization and dequantization patterns and was obsoleted by the reordering of the collective optimization passes in #17453.
Copybara import of the project:

--
e9e9c1af754b0391d72277de27681bed6c5fa37a by Philipp Hack <phack@nvidia.com>:

Removes the option to run the collective pipeliner post layout assignment.

--
c5489ac962af27ac3b13e3ebc96bc6b7a68cc63e by Philipp Hack <phack@nvidia.com>:

Removes the option to run the collective pipeliner post layout assignment.

Merging this change closes #17950

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17950 from philipphack:u_collective_flag_xla c5489ac962af27ac3b13e3ebc96bc6b7a68cc63e
",copybara-service[bot],2024-10-10 02:33:09+00:00,[],2024-10-10 23:44:11+00:00,2024-10-10 23:44:10+00:00,https://github.com/tensorflow/tensorflow/pull/77423,[],[],
