id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2755060757,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 02:17:15+00:00,[],2024-12-23 02:17:15+00:00,,https://github.com/tensorflow/tensorflow/pull/83552,[],[],
2755060129,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 02:16:27+00:00,[],2024-12-23 02:16:27+00:00,,https://github.com/tensorflow/tensorflow/pull/83551,[],[],
2755058361,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 02:14:21+00:00,[],2024-12-23 02:14:21+00:00,,https://github.com/tensorflow/tensorflow/pull/83550,[],[],
2755058194,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 02:14:08+00:00,[],2024-12-23 02:14:08+00:00,,https://github.com/tensorflow/tensorflow/pull/83549,[],[],
2755056037,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 02:11:35+00:00,[],2024-12-23 02:11:35+00:00,,https://github.com/tensorflow/tensorflow/pull/83548,[],[],
2755023291,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:34:36+00:00,[],2024-12-23 01:34:36+00:00,,https://github.com/tensorflow/tensorflow/pull/83547,[],[],
2755022037,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:33:11+00:00,[],2024-12-23 01:33:11+00:00,,https://github.com/tensorflow/tensorflow/pull/83546,[],[],
2755019440,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:30:09+00:00,[],2024-12-23 01:30:09+00:00,,https://github.com/tensorflow/tensorflow/pull/83545,[],[],
2755017392,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:27:38+00:00,[],2024-12-23 01:27:38+00:00,,https://github.com/tensorflow/tensorflow/pull/83544,[],[],
2755016834,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:26:56+00:00,[],2024-12-23 01:26:56+00:00,,https://github.com/tensorflow/tensorflow/pull/83543,[],[],
2755014255,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:23:39+00:00,[],2024-12-23 01:23:39+00:00,,https://github.com/tensorflow/tensorflow/pull/83542,[],[],
2755011754,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:21:51+00:00,[],2024-12-23 01:21:51+00:00,,https://github.com/tensorflow/tensorflow/pull/83541,[],[],
2755005518,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:14:50+00:00,[],2024-12-23 01:14:50+00:00,,https://github.com/tensorflow/tensorflow/pull/83540,[],[],
2755003093,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:11:44+00:00,[],2024-12-23 01:11:44+00:00,,https://github.com/tensorflow/tensorflow/pull/83539,[],[],
2755000528,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:08:17+00:00,[],2024-12-23 01:08:17+00:00,,https://github.com/tensorflow/tensorflow/pull/83538,[],[],
2754998433,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 01:05:20+00:00,[],2024-12-23 01:05:20+00:00,,https://github.com/tensorflow/tensorflow/pull/83537,[],[],
2754992941,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-23 00:57:49+00:00,[],2024-12-23 00:57:49+00:00,,https://github.com/tensorflow/tensorflow/pull/83536,[],[],
2754648880,pull_request,closed,,[XLA:GPU] Enable sorted scatters.,"[XLA:GPU] Enable sorted scatters.
",copybara-service[bot],2024-12-22 13:01:29+00:00,['pifon2a'],2024-12-24 22:08:57+00:00,2024-12-24 22:08:57+00:00,https://github.com/tensorflow/tensorflow/pull/83535,[],[],
2754498650,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-22 05:36:03+00:00,[],2024-12-22 05:36:03+00:00,,https://github.com/tensorflow/tensorflow/pull/83534,[],[],
2754498543,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-22 05:35:40+00:00,[],2024-12-22 05:35:40+00:00,,https://github.com/tensorflow/tensorflow/pull/83533,[],[],
2754497213,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-22 05:30:23+00:00,[],2024-12-22 05:30:23+00:00,,https://github.com/tensorflow/tensorflow/pull/83532,[],[],
2754457026,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-22 02:57:31+00:00,[],2024-12-22 02:57:31+00:00,,https://github.com/tensorflow/tensorflow/pull/83531,[],[],
2754455180,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-22 02:50:13+00:00,[],2024-12-22 02:50:13+00:00,,https://github.com/tensorflow/tensorflow/pull/83530,[],[],
2754454470,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-22 02:46:53+00:00,[],2024-12-22 02:46:53+00:00,,https://github.com/tensorflow/tensorflow/pull/83529,[],[],
2754452229,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-22 02:36:15+00:00,[],2024-12-22 02:36:15+00:00,,https://github.com/tensorflow/tensorflow/pull/83528,[],[],
2754416628,pull_request,closed,,Make pywrap rules replicate final artifacts structure to ensure backward compatibility with users who directly use TensorFlow's shared object files.,"Make pywrap rules replicate final artifacts structure to ensure backward compatibility with users who directly use TensorFlow's shared object files.
",copybara-service[bot],2024-12-22 00:22:03+00:00,['vam-google'],2024-12-30 08:38:55+00:00,2024-12-30 08:38:54+00:00,https://github.com/tensorflow/tensorflow/pull/83527,[],[],
2754288145,pull_request,closed,,Fix application of JIT compiler plugins,"Fix application of JIT compiler plugins

1) Restore some key logic lost when landing cl/707770943, in compiled_model.cpp:122
2) Don't abort CompiledModel creation if the runtime fails to apply compiler plugins, rather issue warnings
3) Log the list of compiler plugins that were successfully applied
",copybara-service[bot],2024-12-21 17:41:34+00:00,[],2025-01-08 22:51:53+00:00,2025-01-08 22:51:52+00:00,https://github.com/tensorflow/tensorflow/pull/83526,[],[],
2754044966,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 13:43:58+00:00,[],2024-12-30 05:04:39+00:00,2024-12-30 05:04:39+00:00,https://github.com/tensorflow/tensorflow/pull/83525,[],[],
2753882120,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:31:58+00:00,[],2024-12-21 10:31:58+00:00,,https://github.com/tensorflow/tensorflow/pull/83524,[],[],
2753880469,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:26:43+00:00,[],2024-12-21 10:26:43+00:00,,https://github.com/tensorflow/tensorflow/pull/83523,[],[],
2753880025,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:25:22+00:00,[],2024-12-21 10:25:22+00:00,,https://github.com/tensorflow/tensorflow/pull/83522,[],[],
2753879868,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:24:55+00:00,[],2024-12-21 10:24:55+00:00,,https://github.com/tensorflow/tensorflow/pull/83521,[],[],
2753879269,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:23:03+00:00,[],2024-12-21 10:23:03+00:00,,https://github.com/tensorflow/tensorflow/pull/83520,[],[],
2753879204,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:22:54+00:00,[],2024-12-21 10:22:54+00:00,,https://github.com/tensorflow/tensorflow/pull/83519,[],[],
2753878111,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:19:22+00:00,[],2024-12-21 10:19:22+00:00,,https://github.com/tensorflow/tensorflow/pull/83518,[],[],
2753877214,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:16:34+00:00,[],2024-12-21 10:16:34+00:00,,https://github.com/tensorflow/tensorflow/pull/83517,[],[],
2753877176,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:16:27+00:00,[],2024-12-21 10:16:27+00:00,,https://github.com/tensorflow/tensorflow/pull/83516,[],[],
2753875915,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:12:35+00:00,[],2024-12-21 10:12:35+00:00,,https://github.com/tensorflow/tensorflow/pull/83515,[],[],
2753875701,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:11:58+00:00,[],2024-12-21 10:11:58+00:00,,https://github.com/tensorflow/tensorflow/pull/83514,[],[],
2753873766,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 10:06:13+00:00,[],2024-12-21 10:06:13+00:00,,https://github.com/tensorflow/tensorflow/pull/83513,[],[],
2753862257,pull_request,closed,,#sdy use `applyPatternsGreedily` with `config.fold=false` and `config.cseConstants=false` to avoid constant folding and CSE which is expensive.,"#sdy use `applyPatternsGreedily` with `config.fold=false` and `config.cseConstants=false` to avoid constant folding and CSE which is expensive.
",copybara-service[bot],2024-12-21 09:30:00+00:00,[],2025-01-08 15:27:55+00:00,2025-01-08 15:27:54+00:00,https://github.com/tensorflow/tensorflow/pull/83512,[],[],
2753825584,pull_request,open,,Add container type that can support per-op byte codes as well as unblock the multiple plugin application flow.,"Add container type that can support per-op byte codes as well as unblock the multiple plugin application flow.
",copybara-service[bot],2024-12-21 07:36:55+00:00,['LukeBoyer'],2024-12-21 10:30:03+00:00,,https://github.com/tensorflow/tensorflow/pull/83511,[],[],
2753822937,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 07:28:57+00:00,[],2024-12-21 07:28:57+00:00,,https://github.com/tensorflow/tensorflow/pull/83510,[],[],
2753798355,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-21 06:22:25+00:00,[],2024-12-21 07:09:21+00:00,,https://github.com/tensorflow/tensorflow/pull/83509,[],[],
2753767141,pull_request,closed,,[tsl] Make sure that EigenEnvironment::Task is move-only,"[tsl] Make sure that EigenEnvironment::Task is move-only

Accidental copies of tasks might lead to undefined behavior, e.g. we can accidentally execute `delete` multiple times. Make sure that this can't happen by making task move-only.
",copybara-service[bot],2024-12-21 05:12:34+00:00,['ezhulenev'],2024-12-21 06:14:56+00:00,2024-12-21 06:14:55+00:00,https://github.com/tensorflow/tensorflow/pull/83507,[],[],
2753722088,pull_request,closed,,Update packaging and pip versions in rules_python to enable freethreading support.,"Update packaging and pip versions in rules_python to enable freethreading support.

The same change has been sent upstream as https://github.com/bazelbuild/rules_python/pull/2514

Forked from https://github.com/openxla/xla/pull/20723 for merging.
",copybara-service[bot],2024-12-21 03:08:48+00:00,[],2025-01-06 16:36:34+00:00,2025-01-06 16:36:33+00:00,https://github.com/tensorflow/tensorflow/pull/83506,[],[],
2753710704,pull_request,closed,,[HLO Componentization] Populate hlo/testlib sub-component (Phase I).,"[HLO Componentization] Populate hlo/testlib sub-component (Phase I).

This CL takes care of

1. Migrating the targets
```
tensorflow/compiler/xla:test
tensorflow/compiler/xla:test_helpers
tensorflow/compiler/xla/service:pattern_matcher_gmock
```

to tensorflow/compiler/xla/hlo/testlib

2. Setting up build aliases in xla or xla/service/ ensuring external
dependencies are still satisfied.

Phase II will take care of migration of external projects dependencies
",copybara-service[bot],2024-12-21 02:30:28+00:00,['sdasgup3'],2025-01-08 21:46:41+00:00,2025-01-08 21:46:41+00:00,https://github.com/tensorflow/tensorflow/pull/83505,[],[],
2753688967,pull_request,closed,,Add CoreId-to-CoreDetails map to OpStats.,"Add CoreId-to-CoreDetails map to OpStats.
",copybara-service[bot],2024-12-21 01:29:18+00:00,[],2025-01-04 02:31:31+00:00,2025-01-04 02:31:30+00:00,https://github.com/tensorflow/tensorflow/pull/83504,[],[],
2753688821,pull_request,open,,Track the rate at which work is received for a model,"Track the rate at which work is received for a model
",copybara-service[bot],2024-12-21 01:28:54+00:00,[],2024-12-21 01:28:54+00:00,,https://github.com/tensorflow/tensorflow/pull/83503,[],[],
2753645677,pull_request,closed,,[xla:cpu] Add support for pthreadpool_parallelize_1d,"[xla:cpu] Add support for pthreadpool_parallelize_1d
",copybara-service[bot],2024-12-20 23:57:32+00:00,['ezhulenev'],2024-12-21 01:00:38+00:00,2024-12-21 01:00:38+00:00,https://github.com/tensorflow/tensorflow/pull/83502,[],[],
2753620498,pull_request,closed,,Remove redundant test and add channel id test.,"Remove redundant test and add channel id test.
",copybara-service[bot],2024-12-20 23:18:10+00:00,[],2025-01-06 20:31:00+00:00,2025-01-06 20:30:59+00:00,https://github.com/tensorflow/tensorflow/pull/83501,[],[],
2753576678,pull_request,open,,Don't apply compiler plugins for CPU accelerator,"Don't apply compiler plugins for CPU accelerator

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17809 from vfdev-5:free-threading/updated-wrlrucache 5bd17e2f30626853835526aa910aaea3d2738726
",copybara-service[bot],2024-12-20 22:27:43+00:00,['terryheo'],2024-12-20 22:27:44+00:00,,https://github.com/tensorflow/tensorflow/pull/83500,[],[],
2753558509,pull_request,closed,,[XLA:Python] Add locking to the JIT cache.,"[XLA:Python] Add locking to the JIT cache.

We use the object lock on PJitFunctionCache to protect the cache data structures. This is a PyCriticalSection-style lock, and it plays almost exactly the same role the GIL plays under GIL mode, with almost identical semantics.
",copybara-service[bot],2024-12-20 22:15:37+00:00,[],2024-12-21 00:27:36+00:00,2024-12-21 00:27:35+00:00,https://github.com/tensorflow/tensorflow/pull/83499,[],[],
2753542294,pull_request,closed,,[XLA:Python] Add locking to PjitFunctionStore.,"[XLA:Python] Add locking to PjitFunctionStore.
",copybara-service[bot],2024-12-20 22:06:06+00:00,[],2024-12-20 22:48:53+00:00,2024-12-20 22:48:51+00:00,https://github.com/tensorflow/tensorflow/pull/83498,[],[],
2753531064,pull_request,closed,,Fix to enable derived timeline computation via tensorboard to populate GPU step time.,"Fix to enable derived timeline computation via tensorboard to populate GPU step time.
",copybara-service[bot],2024-12-20 21:53:54+00:00,[],2025-01-02 18:23:27+00:00,2025-01-02 18:23:26+00:00,https://github.com/tensorflow/tensorflow/pull/83497,[],[],
2753530272,pull_request,closed,,Move constants to OSS.,"Move constants to OSS.
",copybara-service[bot],2024-12-20 21:53:00+00:00,[],2025-01-03 21:40:41+00:00,2025-01-03 21:40:40+00:00,https://github.com/tensorflow/tensorflow/pull/83496,[],[],
2753521212,pull_request,closed,,[Cleanup] Cleanup whitespace,"[Cleanup] Cleanup whitespace
",copybara-service[bot],2024-12-20 21:43:16+00:00,['frgossen'],2024-12-23 22:00:11+00:00,2024-12-23 22:00:10+00:00,https://github.com/tensorflow/tensorflow/pull/83494,[],[],
2753480820,pull_request,closed,,"Change HostOffloader to mark every DynamicUpdateSlice which operates on host memory as host compute. This, of course, excludes DynamicUpdateSlices which are used for host offloading DMAs.","Change HostOffloader to mark every DynamicUpdateSlice which operates on host memory as host compute. This, of course, excludes DynamicUpdateSlices which are used for host offloading DMAs.
",copybara-service[bot],2024-12-20 21:04:16+00:00,['SandSnip3r'],2025-01-18 00:57:03+00:00,2025-01-18 00:57:02+00:00,https://github.com/tensorflow/tensorflow/pull/83493,[],[],
2753478045,pull_request,closed,,PR #17809: Added free-threading support to WeakrefLRUCache,"PR #17809: Added free-threading support to WeakrefLRUCache

Imported from GitHub PR https://github.com/openxla/xla/pull/17809

Decsription:
- Added free-threading support to WeakrefLRUCache
- Added another multithreaded test

Copybara import of the project:

--
5bd17e2f30626853835526aa910aaea3d2738726 by vfdev-5 <vfdev.5@gmail.com>:

Added free-threading support to WeakrefLRUCache
+ another multi-threaded test

Merging this change closes #17809

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17809 from vfdev-5:free-threading/updated-wrlrucache 5bd17e2f30626853835526aa910aaea3d2738726
",copybara-service[bot],2024-12-20 21:01:41+00:00,[],2024-12-20 22:34:46+00:00,2024-12-20 22:34:45+00:00,https://github.com/tensorflow/tensorflow/pull/83492,[],[],
2753476241,pull_request,closed,,[xla:cpu] Add a build flag to force ThunkExecutor to run in sequential model with blocking,"[xla:cpu] Add a build flag to force ThunkExecutor to run in sequential model with blocking
",copybara-service[bot],2024-12-20 20:59:56+00:00,['ezhulenev'],2024-12-20 21:55:53+00:00,2024-12-20 21:55:52+00:00,https://github.com/tensorflow/tensorflow/pull/83491,[],[],
2753474242,pull_request,open,,"Change HostOffloader by disabling an unsafe assumption that replacing broadcast(0) with ""AllocateBuffer"" is always safe.","Change HostOffloader by disabling an unsafe assumption that replacing broadcast(0) with ""AllocateBuffer"" is always safe.
",copybara-service[bot],2024-12-20 20:58:01+00:00,['SandSnip3r'],2024-12-20 20:58:02+00:00,,https://github.com/tensorflow/tensorflow/pull/83490,[],[],
2753430424,pull_request,closed,,[XLA] Fix ShapeError crashes when element_type is not in the enum,"[XLA] Fix ShapeError crashes when element_type is not in the enum

We tried to pretty-print the name of the type but this is not possible if the element_type is not in the enum. Print the underlying integer instead.
",copybara-service[bot],2024-12-20 20:18:58+00:00,['majnemer'],2024-12-31 09:41:30+00:00,2024-12-31 09:41:29+00:00,https://github.com/tensorflow/tensorflow/pull/83489,[],[],
2753412604,pull_request,closed,,[XLA:Python] Add locking around lazily-initialized fields in PyDeviceList.,"[XLA:Python] Add locking around lazily-initialized fields in PyDeviceList.

* We protect is_fully_addressable_, addressable_device_list_, memory_kind_info_ and hash_ with the PyDeviceList object's associated lock.
* DefaultMemoryKind and MemoryKinds are update to be static methods that take a Python object reference, so we have easy access to that lock.
* We change a number of other methods to be private.
* We move the module registration function into a static method so it can access private methods more easily.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19096 from openxla:skozub/e2m1 d4de0a369d9dc853f34f3cf3bf7dcc5a47502106
",copybara-service[bot],2024-12-20 20:03:26+00:00,[],2024-12-20 21:31:56+00:00,2024-12-20 21:31:55+00:00,https://github.com/tensorflow/tensorflow/pull/83488,[],[],
2753402886,pull_request,closed,,[XLA:Python] Add locking to prevent races on TileAssignment::array_ inside the HloSharding bindings.,"[XLA:Python] Add locking to prevent races on TileAssignment::array_ inside the HloSharding bindings.

array_ is a cached field and is not safe to populate concurrently.
",copybara-service[bot],2024-12-20 19:55:09+00:00,[],2024-12-20 21:10:18+00:00,2024-12-20 21:10:17+00:00,https://github.com/tensorflow/tensorflow/pull/83487,[],[],
2753383474,pull_request,closed,,[Cleanup] Cleanup whitespace,"[Cleanup] Cleanup whitespace
",copybara-service[bot],2024-12-20 19:38:24+00:00,['frgossen'],2024-12-23 21:00:57+00:00,2024-12-23 21:00:57+00:00,https://github.com/tensorflow/tensorflow/pull/83486,[],[],
2753381793,pull_request,closed,,[Cleanup] Cleanup whitespace,"[Cleanup] Cleanup whitespace
",copybara-service[bot],2024-12-20 19:37:05+00:00,['frgossen'],2024-12-24 00:54:14+00:00,2024-12-24 00:54:13+00:00,https://github.com/tensorflow/tensorflow/pull/83485,[],[],
2753381146,pull_request,closed,,[Cleanup] Cleanup whitespace,"[Cleanup] Cleanup whitespace
",copybara-service[bot],2024-12-20 19:36:30+00:00,['frgossen'],2024-12-24 00:30:04+00:00,2024-12-24 00:30:03+00:00,https://github.com/tensorflow/tensorflow/pull/83484,[],[],
2753380409,pull_request,closed,,Integrate LLVM at llvm/llvm-project@773938064371,"Integrate LLVM at llvm/llvm-project@773938064371

Updates LLVM usage to match
[773938064371](https://github.com/llvm/llvm-project/commit/773938064371)
",copybara-service[bot],2024-12-20 19:35:55+00:00,[],2024-12-21 00:44:41+00:00,2024-12-21 00:44:40+00:00,https://github.com/tensorflow/tensorflow/pull/83483,[],[],
2753379212,pull_request,closed,,[Cleanup] Cleanup whitespace,"[Cleanup] Cleanup whitespace
",copybara-service[bot],2024-12-20 19:35:20+00:00,['frgossen'],2024-12-20 22:23:19+00:00,2024-12-20 22:23:18+00:00,https://github.com/tensorflow/tensorflow/pull/83482,[],[],
2753377839,pull_request,open,,[Cleanup] Use std::make_unique instead of new (go/totw/126),"[Cleanup] Use std::make_unique instead of new (go/totw/126)
",copybara-service[bot],2024-12-20 19:34:10+00:00,['frgossen'],2024-12-20 19:34:11+00:00,,https://github.com/tensorflow/tensorflow/pull/83481,[],[],
2753377401,pull_request,closed,,[Cleanup] Cleanup whitespace,"[Cleanup] Cleanup whitespace
",copybara-service[bot],2024-12-20 19:33:49+00:00,['frgossen'],2024-12-23 22:25:14+00:00,2024-12-23 22:25:14+00:00,https://github.com/tensorflow/tensorflow/pull/83480,[],[],
2753366626,pull_request,closed,,Reverts b384752134fc90cf65a639370444b692d3ebe136,"Reverts b384752134fc90cf65a639370444b692d3ebe136
",copybara-service[bot],2024-12-20 19:27:22+00:00,['ecalubaquib'],2024-12-20 20:10:39+00:00,2024-12-20 20:10:38+00:00,https://github.com/tensorflow/tensorflow/pull/83479,[],[],
2753351217,pull_request,closed,,Cascade error messages in CompiledModel,"Cascade error messages in CompiledModel

This makes error message more verbose.
",copybara-service[bot],2024-12-20 19:19:46+00:00,['terryheo'],2024-12-20 22:43:43+00:00,2024-12-20 22:43:42+00:00,https://github.com/tensorflow/tensorflow/pull/83478,[],[],
2753338482,pull_request,closed,,Internal visibility change.,"Internal visibility change.
",copybara-service[bot],2024-12-20 19:12:58+00:00,['hheydary'],2024-12-20 20:23:07+00:00,2024-12-20 20:23:06+00:00,https://github.com/tensorflow/tensorflow/pull/83477,[],[],
2753303830,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 18:57:16+00:00,[],2024-12-31 01:47:58+00:00,2024-12-31 01:47:57+00:00,https://github.com/tensorflow/tensorflow/pull/83476,[],[],
2753264319,pull_request,closed,,Add a counter to track sum of task sizes in a batch.,"Add a counter to track sum of task sizes in a batch.
",copybara-service[bot],2024-12-20 18:33:57+00:00,[],2024-12-21 00:13:54+00:00,2024-12-21 00:13:53+00:00,https://github.com/tensorflow/tensorflow/pull/83475,[],[],
2753200972,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@38bb2f9b,"Integrate StableHLO at openxla/stablehlo@38bb2f9b
",copybara-service[bot],2024-12-20 17:49:56+00:00,['sdasgup3'],2024-12-20 20:32:59+00:00,2024-12-20 20:32:56+00:00,https://github.com/tensorflow/tensorflow/pull/83474,[],[],
2753130983,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 17:08:27+00:00,[],2025-01-03 18:33:59+00:00,2025-01-03 18:33:59+00:00,https://github.com/tensorflow/tensorflow/pull/83473,[],[],
2753081423,pull_request,closed,,[XLA:CPU] Populate `buffer_uses` ElementalKernelEmitter::EmitKernelSpec,"[XLA:CPU] Populate `buffer_uses` ElementalKernelEmitter::EmitKernelSpec
",copybara-service[bot],2024-12-20 16:37:54+00:00,[],2024-12-30 13:40:46+00:00,2024-12-30 13:40:46+00:00,https://github.com/tensorflow/tensorflow/pull/83472,[],[],
2753076555,pull_request,closed,,[XLA:CPU] Use IrEmitter in ElementalKernelEmitter to enable nested function calls.,"[XLA:CPU] Use IrEmitter in ElementalKernelEmitter to enable nested function calls.
",copybara-service[bot],2024-12-20 16:34:51+00:00,[],2024-12-30 13:55:11+00:00,2024-12-30 13:55:10+00:00,https://github.com/tensorflow/tensorflow/pull/83471,[],[],
2753069906,pull_request,closed,,[tsl] Cleanup and optimize threadpool EigenEnvironment,"[tsl] Cleanup and optimize threadpool EigenEnvironment

Avoid heap allocations on a hot path and keep task implementation in std::optional
",copybara-service[bot],2024-12-20 16:32:02+00:00,['ezhulenev'],2024-12-20 18:56:11+00:00,2024-12-20 18:56:11+00:00,https://github.com/tensorflow/tensorflow/pull/83470,[],[],
2753051285,pull_request,closed,,Update scripts/configs for Windows nightly/release builds.,"Update scripts/configs for Windows nightly/release builds.

`set -u` (does not allow unbound variables) has been removed from all scripts.
This is due to Docker on Windows treating variables in an env file,
set to an empty value (`MY_VAR=`), as unbound variables. Consequently,
these variables, even though they are ""set"", do not make it into the Docker
container at all, and various checks for those variables fail outright.
",copybara-service[bot],2024-12-20 16:21:50+00:00,['belitskiy'],2025-01-09 18:37:36+00:00,2025-01-09 18:37:35+00:00,https://github.com/tensorflow/tensorflow/pull/83469,[],[],
2753050012,pull_request,open,,[XLA:CPU] Improve performance and reduce memory usage of transposed convolution algorithm,"[XLA:CPU] Improve performance and reduce memory usage of transposed convolution algorithm


Improve memory usage by splitting convolution into smaller chunks. Instead of allocating memory for the whole convolution matrix, every worker thread works on a chunk of data at a time (contracts and packs patches to the output tensor), using only as much extra memory as needed to process this one chunk.

Improve performance by parallel packing patches. Performance results:

name                                                        old cpu/op   new cpu/op   delta
BM_Conv1DTransposedStrided/process_time                     31.9ms ± 5%  32.8ms ± 3%     ~     (p=0.310 n=5+5)
BM_Conv1DTransposedStridedNonDefaultLayout/process_time     31.1ms ± 5%  32.1ms ± 2%     ~     (p=0.095 n=5+5)
BM_Conv2DTransposedStrided/process_time                     33.4ms ± 2%  34.0ms ± 2%     ~     (p=0.056 n=5+5)
BM_GroupedConv2DTransposedStrided/128/128/128/process_time  85.0ms ± 2%  69.8ms ± 3%  -17.83%  (p=0.008 n=5+5)
BM_GroupedConv2DTransposedStrided/128/128/16/process_time   51.7ms ± 4%  53.4ms ± 5%     ~     (p=0.056 n=5+5)

name                                                        old time/op  new time/op  delta
BM_Conv1DTransposedStrided/process_time                     8.76ms ± 4%  4.61ms ± 1%  -47.43%  (p=0.008 n=5+5)
BM_Conv1DTransposedStridedNonDefaultLayout/process_time     8.36ms ± 6%  3.77ms ± 4%  -54.94%  (p=0.008 n=5+5)
BM_Conv2DTransposedStrided/process_time                     9.18ms ± 6%  4.67ms ± 3%  -49.16%  (p=0.008 n=5+5)
BM_GroupedConv2DTransposedStrided/128/128/128/process_time  10.2ms ± 3%   7.0ms ± 3%  -32.12%  (p=0.008 n=5+5)
BM_GroupedConv2DTransposedStrided/128/128/16/process_time   8.89ms ± 1%  7.67ms ± 5%  -13.82%  (p=0.008 n=5+5)
",copybara-service[bot],2024-12-20 16:21:02+00:00,[],2024-12-31 14:32:19+00:00,,https://github.com/tensorflow/tensorflow/pull/83468,[],"[{'comment_id': 2557310435, 'issue_id': 2753050012, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/83468/checks?check_run_id=34719353432) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 20, 16, 21, 7, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-20 16:21:07 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/83468/checks?check_run_id=34719353432) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2753047154,pull_request,open,,[XLA:CPU] Improve the performance of grouped transposed convolution,"[XLA:CPU] Improve the performance of grouped transposed convolution


Extend the custom algorithm for transposed convolutions by supporting the grouped convolution case.

This commit duplicates some code from EigenGenericConv2D, it is intentionally not unified yet because of the planned changes for custom algorithm (mainly split convolution to smaller chunks), which will significantly change the code structure.

Performance results:

name                                                         old cpu/op   new cpu/op   delta
BM_GroupedConv2DStrided/128/128/128/process_time             76.2ms ± 8%  77.1ms ± 8%     ~     (p=0.841 n=5+5)
BM_GroupedConv2DTransposedStrided/128/128/128/process_time    6.31s ± 6%   0.10s ± 2%  -98.40%  (p=0.008 n=5+5)
BM_GroupedConv2DStrided/128/128/16/process_time              41.8ms ± 5%  41.4ms ± 6%     ~     (p=0.690 n=5+5)
BM_GroupedConv2DTransposedStrided/128/128/16/process_time     1.21s ±11%   0.06s ± 2%  -94.94%  (p=0.008 n=5+5)

name                                                         old time/op  new time/op  delta
BM_GroupedConv2DStrided/128/128/128/process_time             6.23ms ± 7%  6.44ms ± 9%     ~     (p=0.548 n=5+5)
BM_GroupedConv2DTransposedStrided/128/128/128/process_time    281ms ± 5%    13ms ± 3%  -95.44%  (p=0.008 n=5+5)
BM_GroupedConv2DStrided/128/128/16/process_time              3.72ms ± 8%  3.58ms ± 8%     ~     (p=0.421 n=5+5)
BM_GroupedConv2DTransposedStrided/128/128/16/process_time    55.5ms ±11%  11.0ms ± 3%  -80.21%  (p=0.008 n=5+5)
",copybara-service[bot],2024-12-20 16:19:19+00:00,[],2024-12-30 09:57:46+00:00,,https://github.com/tensorflow/tensorflow/pull/83467,[],"[{'comment_id': 2557307600, 'issue_id': 2753047154, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/83467/checks?check_run_id=34719276397) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 20, 16, 19, 25, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-20 16:19:25 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/83467/checks?check_run_id=34719276397) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2753027436,pull_request,closed,,[XLA:GPU] Cleanup dead `ExecTimeOptimizationEffort`.,"[XLA:GPU] Cleanup dead `ExecTimeOptimizationEffort`.
",copybara-service[bot],2024-12-20 16:07:44+00:00,[],2024-12-20 17:06:20+00:00,2024-12-20 17:06:19+00:00,https://github.com/tensorflow/tensorflow/pull/83466,[],[],
2752922225,pull_request,closed,,Fix ASAN for `//tensorflow/python/eager:tensor_test_cpu` by using a more carefully chosen enum value,"Fix ASAN for `//tensorflow/python/eager:tensor_test_cpu` by using a more carefully chosen enum value
",copybara-service[bot],2024-12-20 15:07:41+00:00,['ddunl'],2024-12-20 18:33:39+00:00,2024-12-20 18:33:38+00:00,https://github.com/tensorflow/tensorflow/pull/83465,[],[],
2752918158,pull_request,closed,,Integrate LLVM at llvm/llvm-project@93743ee56669,"Integrate LLVM at llvm/llvm-project@93743ee56669

Updates LLVM usage to match
[93743ee56669](https://github.com/llvm/llvm-project/commit/93743ee56669)
",copybara-service[bot],2024-12-20 15:05:20+00:00,['metaflow'],2024-12-20 16:33:07+00:00,2024-12-20 16:33:06+00:00,https://github.com/tensorflow/tensorflow/pull/83464,[],[],
2752860876,pull_request,closed,,[XLA:GPU] Measure collective predictions for SoL model.,"[XLA:GPU] Measure collective predictions for SoL model.
",copybara-service[bot],2024-12-20 14:33:02+00:00,[],2025-01-06 09:43:36+00:00,2025-01-06 09:43:35+00:00,https://github.com/tensorflow/tensorflow/pull/83463,[],[],
2752838928,pull_request,closed,,[XLA] Remove unused local_device_count_ field from ServiceExecutableRunOptions.,"[XLA] Remove unused local_device_count_ field from ServiceExecutableRunOptions.
",copybara-service[bot],2024-12-20 14:20:51+00:00,[],2024-12-20 19:29:44+00:00,2024-12-20 19:29:43+00:00,https://github.com/tensorflow/tensorflow/pull/83462,[],[],
2752826825,pull_request,closed,,Integrate Triton up to [88c704e](https://github.com/openai/triton/commits/88c704e5e57542e8c34558d9a1bd2dff328f02af),"Integrate Triton up to [88c704e](https://github.com/openai/triton/commits/88c704e5e57542e8c34558d9a1bd2dff328f02af)
",copybara-service[bot],2024-12-20 14:14:06+00:00,[],2024-12-23 13:03:04+00:00,2024-12-23 13:03:00+00:00,https://github.com/tensorflow/tensorflow/pull/83461,[],[],
2752708988,pull_request,closed,,Add LiteRtEvent to LiteRtTensorBuffer,"Add LiteRtEvent to LiteRtTensorBuffer

When running a synchronous inference with LiteRtRunCompiledModel(), the runtime will wait for any event attached to the input tensor buffers. Because LiteRtRunCompiledModel() is for synchronous inference, it returns only when the inference is complete and it will not attach event to the output buffers.
",copybara-service[bot],2024-12-20 13:08:03+00:00,[],2024-12-20 20:55:26+00:00,2024-12-20 20:55:26+00:00,https://github.com/tensorflow/tensorflow/pull/83458,[],[],
2752675682,pull_request,closed,,[XLA:GPU] Move ambiguous `GetConfig` into a class.,"[XLA:GPU] Move ambiguous `GetConfig` into a class.
",copybara-service[bot],2024-12-20 12:47:50+00:00,[],2024-12-20 14:04:08+00:00,2024-12-20 14:04:06+00:00,https://github.com/tensorflow/tensorflow/pull/83457,[],[],
2752564020,pull_request,closed,,[XLA:CPU] Use EmitKernelPrototype ElementalKernelEmitter,"[XLA:CPU] Use EmitKernelPrototype ElementalKernelEmitter
",copybara-service[bot],2024-12-20 11:42:29+00:00,[],2024-12-30 11:33:36+00:00,2024-12-30 11:33:35+00:00,https://github.com/tensorflow/tensorflow/pull/83444,[],[],
2752549908,pull_request,closed,,[XLA:CPU] Enable passing a HloInstruction & BufferAssignment to EmitKernelPrototype,"[XLA:CPU] Enable passing a HloInstruction & BufferAssignment to EmitKernelPrototype
",copybara-service[bot],2024-12-20 11:33:59+00:00,[],2024-12-30 11:17:41+00:00,2024-12-30 11:17:40+00:00,https://github.com/tensorflow/tensorflow/pull/83443,[],[],
2752547251,pull_request,closed,,[XLA:CPU] Move kernel prototype emission into the KernelApiIrBuilder,"[XLA:CPU] Move kernel prototype emission into the KernelApiIrBuilder
",copybara-service[bot],2024-12-20 11:32:16+00:00,[],2024-12-30 10:23:06+00:00,2024-12-30 10:23:04+00:00,https://github.com/tensorflow/tensorflow/pull/83442,[],[],
2752545955,pull_request,closed,,[XLA:CPU] Pass ThreadLocalCall callback to CpuElementalIrEmitter,"[XLA:CPU] Pass ThreadLocalCall callback to CpuElementalIrEmitter
",copybara-service[bot],2024-12-20 11:31:26+00:00,[],2024-12-30 10:08:26+00:00,2024-12-30 10:08:26+00:00,https://github.com/tensorflow/tensorflow/pull/83441,[],[],
2752368332,pull_request,closed,,Add initial version of a MediaTek compiler plugin,"Add initial version of a MediaTek compiler plugin

For now it supports only the ADD op.
",copybara-service[bot],2024-12-20 09:55:16+00:00,[],2024-12-21 08:56:22+00:00,2024-12-21 08:56:22+00:00,https://github.com/tensorflow/tensorflow/pull/83411,[],[],
2752367286,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 09:54:51+00:00,[],2024-12-21 09:36:25+00:00,2024-12-21 09:36:24+00:00,https://github.com/tensorflow/tensorflow/pull/83410,[],[],
2752328820,pull_request,closed,,Fix Dispatch API test cases,"Fix Dispatch API test cases

The NPU binary files were not being loaded from the right path
",copybara-service[bot],2024-12-20 09:37:50+00:00,[],2024-12-20 10:56:29+00:00,2024-12-20 10:56:29+00:00,https://github.com/tensorflow/tensorflow/pull/83409,[],[],
2752308405,pull_request,open,,Update GraphDef version to 2082.,"Update GraphDef version to 2082.
",copybara-service[bot],2024-12-20 09:26:22+00:00,[],2024-12-20 09:26:22+00:00,,https://github.com/tensorflow/tensorflow/pull/83408,[],[],
2752293742,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 09:18:01+00:00,[],2024-12-20 10:45:00+00:00,2024-12-20 10:44:59+00:00,https://github.com/tensorflow/tensorflow/pull/83401,[],[],
2752292064,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 09:17:03+00:00,[],2024-12-20 12:22:15+00:00,,https://github.com/tensorflow/tensorflow/pull/83400,[],[],
2752260905,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 08:58:49+00:00,[],2024-12-21 05:38:17+00:00,,https://github.com/tensorflow/tensorflow/pull/83397,[],[],
2752238519,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 08:45:07+00:00,[],2024-12-20 09:05:59+00:00,,https://github.com/tensorflow/tensorflow/pull/83396,[],[],
2752230104,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 08:40:03+00:00,[],2024-12-20 08:40:03+00:00,,https://github.com/tensorflow/tensorflow/pull/83395,[],[],
2752223926,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 08:36:27+00:00,[],2024-12-21 09:49:15+00:00,2024-12-21 09:49:14+00:00,https://github.com/tensorflow/tensorflow/pull/83394,[],[],
2752196747,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 08:19:18+00:00,[],2024-12-21 09:43:04+00:00,2024-12-21 09:43:04+00:00,https://github.com/tensorflow/tensorflow/pull/83393,[],[],
2752161940,pull_request,closed,,Link HloSharding ser-deser support to  common_serdes,"Link HloSharding ser-deser support to  common_serdes
",copybara-service[bot],2024-12-20 07:55:31+00:00,[],2024-12-20 19:07:08+00:00,2024-12-20 19:07:07+00:00,https://github.com/tensorflow/tensorflow/pull/83392,[],[],
2752140988,pull_request,closed,,fix rand and randn lowering,"fix rand and randn lowering
",copybara-service[bot],2024-12-20 07:42:07+00:00,['chunnienc'],2024-12-20 18:46:49+00:00,2024-12-20 18:46:49+00:00,https://github.com/tensorflow/tensorflow/pull/83391,[],[],
2752130528,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 07:34:33+00:00,[],2024-12-21 07:05:07+00:00,2024-12-21 07:05:05+00:00,https://github.com/tensorflow/tensorflow/pull/83390,[],[],
2752128428,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 07:33:03+00:00,[],2024-12-20 07:33:03+00:00,,https://github.com/tensorflow/tensorflow/pull/83389,[],[],
2752121629,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 07:29:18+00:00,[],2024-12-27 08:40:39+00:00,,https://github.com/tensorflow/tensorflow/pull/83388,[],[],
2752114893,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 07:25:04+00:00,[],2024-12-21 07:13:23+00:00,2024-12-21 07:13:23+00:00,https://github.com/tensorflow/tensorflow/pull/83387,[],[],
2752112714,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 07:23:32+00:00,[],2024-12-20 07:23:32+00:00,,https://github.com/tensorflow/tensorflow/pull/83386,[],[],
2752111785,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 07:22:53+00:00,[],2024-12-20 07:22:53+00:00,,https://github.com/tensorflow/tensorflow/pull/83385,[],[],
2752111643,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 07:22:47+00:00,[],2024-12-20 07:22:47+00:00,,https://github.com/tensorflow/tensorflow/pull/83384,[],[],
2752102735,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/83283 from noexecstack:inspect-checkpoint-improvements 1bb7e5cea1bc8a3ba0e9a13b4142993eb48db1a1
",copybara-service[bot],2024-12-20 07:16:28+00:00,[],2024-12-20 07:16:28+00:00,,https://github.com/tensorflow/tensorflow/pull/83383,[],[],
2752101711,pull_request,open,,PR #17809: Added free-threading support to WeakrefLRUCache,"PR #17809: Added free-threading support to WeakrefLRUCache

Imported from GitHub PR https://github.com/openxla/xla/pull/17809

Decsription:
- Added free-threading support to WeakrefLRUCache
- Added another multithreaded test

Copybara import of the project:

--
5bd17e2f30626853835526aa910aaea3d2738726 by vfdev-5 <vfdev.5@gmail.com>:

Added free-threading support to WeakrefLRUCache
+ another multi-threaded test

Merging this change closes #17809

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17809 from vfdev-5:free-threading/updated-wrlrucache 5bd17e2f30626853835526aa910aaea3d2738726
",copybara-service[bot],2024-12-20 07:15:45+00:00,[],2024-12-20 07:15:45+00:00,,https://github.com/tensorflow/tensorflow/pull/83382,[],[],
2752091837,pull_request,closed,,"Fix visibility for targets in LiteRT repo for :gfile, :dispatch, :lazy_loader, :test_lib, :client_testlib","Fix visibility for targets in LiteRT repo for :gfile, :dispatch, :lazy_loader, :test_lib, :client_testlib
",copybara-service[bot],2024-12-20 07:08:51+00:00,['ecalubaquib'],2024-12-20 07:52:08+00:00,2024-12-20 07:52:08+00:00,https://github.com/tensorflow/tensorflow/pull/83381,[],[],
2752078492,pull_request,closed,,Fix visibility for targets in LiteRT repo,"Fix visibility for targets in LiteRT repo
",copybara-service[bot],2024-12-20 06:58:45+00:00,['ecalubaquib'],2024-12-20 18:05:52+00:00,2024-12-20 18:05:51+00:00,https://github.com/tensorflow/tensorflow/pull/83380,[],[],
2752076410,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-20 06:57:10+00:00,[],2024-12-20 06:57:10+00:00,,https://github.com/tensorflow/tensorflow/pull/83378,[],[],
2752051203,pull_request,open,,"[MHLO Deprecation] Replace createLegalizeToArithmeticPass MHLO based pass with createStablehloLegalizeToLinalgPass, a StableHLO based pass.","[MHLO Deprecation] Replace createLegalizeToArithmeticPass MHLO based pass with createStablehloLegalizeToLinalgPass, a StableHLO based pass.
",copybara-service[bot],2024-12-20 06:37:22+00:00,[],2024-12-20 06:37:22+00:00,,https://github.com/tensorflow/tensorflow/pull/83377,[],[],
2752020681,pull_request,closed,,[XLA:SchedulingAnnotations] Add a configuration to filter the ops so that we can keep/drop the annotations in/from certain synchronous ops.,"[XLA:SchedulingAnnotations] Add a configuration to filter the ops so that we can keep/drop the annotations in/from certain synchronous ops.

If an annotation gap is discovered, print the respective path between the annotated ops. This is particularly useful to detect when data-dependent sync & async ops were mistakenly annotated with the same scheduling group.
",copybara-service[bot],2024-12-20 06:11:40+00:00,['seherellis'],2024-12-20 19:41:50+00:00,2024-12-20 19:41:49+00:00,https://github.com/tensorflow/tensorflow/pull/83376,[],[],
2751980426,pull_request,closed,,[xla:cpu] Optimize parallel loop runner,"[xla:cpu] Optimize parallel loop runner

Make sure that all scheduled tasks capture <24 bytes to be able to create std::function without extra heap allocation.

BEFORE

------------------------------------------------------------------------
Benchmark                              Time             CPU   Iterations
------------------------------------------------------------------------
BM_HloModule/dot/process_time     560396 ns      6503078 ns          415

AFTER

------------------------------------------------------------------------
Benchmark                              Time             CPU   Iterations
------------------------------------------------------------------------
BM_HloModule/dot/process_time     320843 ns      3224568 ns          858
",copybara-service[bot],2024-12-20 05:37:11+00:00,['ezhulenev'],2024-12-20 17:19:56+00:00,2024-12-20 17:19:55+00:00,https://github.com/tensorflow/tensorflow/pull/83375,[],[],
2751970361,pull_request,closed,,Modernize and make tighter CollectivePermuteDecomposerTest,"Modernize and make tighter CollectivePermuteDecomposerTest
",copybara-service[bot],2024-12-20 05:27:34+00:00,[],2024-12-21 01:15:17+00:00,2024-12-21 01:15:16+00:00,https://github.com/tensorflow/tensorflow/pull/83374,[],[],
2751935729,pull_request,closed,,Try to handle multiple source target pairs when generating a single all-to-all operation.,"Try to handle multiple source target pairs when generating a single all-to-all operation.

The following example shows the detailed method.
```
base_shape: (32,32,32,32)
mesh: a=2, b=4
old sharding: P('a', 'b', None, None), local shape (16,8,32,32)
new sharding: P(None, None, 'a', 'b'), local shape (32,32,16,8)

// Step 1. Merge sharding axes to a single dimension
reshape (16,8,32,32) -> (16,8,2,16,4,8)
transpose (16,8,2,16,4,8) -> (2,4,16,8,16,8) with permutation (2,4,0,1,3,5)
reshape (2,4,16,8,16,8) -> (8,16,8,16,8)

// Step 2. Apply the all-to-all
all-to-all on (8,16,8,16,8) with split_dimension = 0

// Step 3. Split sharding axes to multiple dimensions
reshape (8,16,8,16,8) -> (2,4,16,8,16,8)
transpose (2,4,16,8,16,8) -> (2,16,4,8,16,8) with permutation (0,2,1,3,4,5)
reshape (2,16,4,8,16,8) -> (32,32,16,8)
```
",copybara-service[bot],2024-12-20 04:53:52+00:00,[],2025-01-08 19:51:13+00:00,2025-01-08 19:51:12+00:00,https://github.com/tensorflow/tensorflow/pull/83373,[],[],
2751800723,pull_request,open,,Fix crash of transpose,This PR tries to address the issue raised in https://github.com/tensorflow/tensorflow/issues/76036 where `transpose` will crash when `perm` is assigned negative value. Based on a closed PR https://github.com/tensorflow/tensorflow/pull/63064,cybersupersoap,2024-12-20 02:42:29+00:00,['gbaned'],2025-02-05 17:40:49+00:00,,https://github.com/tensorflow/tensorflow/pull/83372,"[('stat:awaiting response', 'Status  - Awaiting response from author'), ('size:S', 'CL Change Size: Small'), ('prtype:bugfix', 'PR to fix a bug'), ('comp:core', 'issues related to core part of tensorflow')]","[{'comment_id': 2561888206, 'issue_id': 2751800723, 'author': 'cybersupersoap', 'body': 'Hi @rdzhabarov,  Could you please review my PR? Thank you!', 'created_at': datetime.datetime(2024, 12, 25, 13, 17, 19, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562080966, 'issue_id': 2751800723, 'author': 'cybersupersoap', 'body': 'Hi @keerthanakadiri , Could you please review my PR? Thank you!', 'created_at': datetime.datetime(2024, 12, 26, 2, 15, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585030511, 'issue_id': 2751800723, 'author': 'cybersupersoap', 'body': 'Hi @sagunb, Could you please review my PR? Thank you!', 'created_at': datetime.datetime(2025, 1, 11, 2, 44, 17, tzinfo=datetime.timezone.utc)}]","cybersupersoap (Issue Creator) on (2024-12-25 13:17:19 UTC): Hi @rdzhabarov,  Could you please review my PR? Thank you!

cybersupersoap (Issue Creator) on (2024-12-26 02:15:38 UTC): Hi @keerthanakadiri , Could you please review my PR? Thank you!

cybersupersoap (Issue Creator) on (2025-01-11 02:44:17 UTC): Hi @sagunb, Could you please review my PR? Thank you!

"
2751608279,pull_request,closed,,Fix segfault.,"Fix segfault.
Make xla::MemorySpaceDescription back its own pointers. Also, add missing
reserve() so memory_description_pointers don't go uninitialized.
",copybara-service[bot],2024-12-19 23:29:38+00:00,[],2024-12-20 03:59:08+00:00,2024-12-20 03:59:07+00:00,https://github.com/tensorflow/tensorflow/pull/83370,[],[],
2751544924,pull_request,closed,,Fix AllToAll operation semantics in operation_semantics.md.,"Fix AllToAll operation semantics in operation_semantics.md.
",copybara-service[bot],2024-12-19 22:30:34+00:00,[],2024-12-19 23:52:15+00:00,2024-12-19 23:52:13+00:00,https://github.com/tensorflow/tensorflow/pull/83368,[],[],
2751537374,pull_request,closed,,Move ProfileTimeBreakdown to open source.,"Move ProfileTimeBreakdown to open source.
",copybara-service[bot],2024-12-19 22:24:36+00:00,[],2024-12-20 21:22:34+00:00,2024-12-20 21:22:33+00:00,https://github.com/tensorflow/tensorflow/pull/83367,[],[],
2751524966,pull_request,closed,,Integrate LLVM at llvm/llvm-project@b5d02786be31,"Integrate LLVM at llvm/llvm-project@b5d02786be31

Updates LLVM usage to match
[b5d02786be31](https://github.com/llvm/llvm-project/commit/b5d02786be31)
",copybara-service[bot],2024-12-19 22:13:57+00:00,[],2024-12-20 01:36:38+00:00,2024-12-20 01:36:37+00:00,https://github.com/tensorflow/tensorflow/pull/83366,[],[],
2751499302,pull_request,closed,,Factor out GetMemorySpaceDescriptions().,"Factor out GetMemorySpaceDescriptions().
",copybara-service[bot],2024-12-19 21:53:00+00:00,[],2024-12-20 02:08:12+00:00,2024-12-20 02:08:12+00:00,https://github.com/tensorflow/tensorflow/pull/83365,[],[],
2751473340,pull_request,closed,,[Distributed runtime] Improve error message when exceeding the 2GB protobuf limit in RecvTensor.,"[Distributed runtime] Improve error message when exceeding the 2GB protobuf limit in RecvTensor.

Previously we would LOG(FATAL) with the tensor size; now we attempt a clean shutdown via returning an error status, and add information about the rendezvous key to aid debugging.
",copybara-service[bot],2024-12-19 21:33:01+00:00,[],2024-12-20 08:54:06+00:00,2024-12-20 08:54:05+00:00,https://github.com/tensorflow/tensorflow/pull/83364,[],[],
2751471434,pull_request,open,,PR #20744: [NVIDIA GPU] Add a flag to control a2a collective matmul rewrite,"PR #20744: [NVIDIA GPU] Add a flag to control a2a collective matmul rewrite

Imported from GitHub PR https://github.com/openxla/xla/pull/20744

This is address the revert in https://github.com/openxla/xla/pull/19451 where customers see MFU when enabling collective matmul by default. The a2a collective matmul kicks in by default on some small gemms and lead to inefficient transformation.
Adding a flag to disable it by default since it's experimental.
Copybara import of the project:

--
f3d320881ba0de6cd07429dc00176231fd2a1d9a by TJ Xu <tjx@nvidia.com>:

Add a flag to control a2a collective matmul rewrite

--
0068abc2dba6865debcd71b80b235b268f048e6c by TJ Xu <tjx@nvidia.com>:

added more comment for the new flag

Merging this change closes #20744

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20744 from Tixxx:tixxx/add_flag_a2a_gemm 0068abc2dba6865debcd71b80b235b268f048e6c
",copybara-service[bot],2024-12-19 21:31:29+00:00,[],2024-12-20 22:18:19+00:00,,https://github.com/tensorflow/tensorflow/pull/83363,[],[],
2751407499,pull_request,closed,,Factor out lamda function in collective-select-folder,"Factor out lamda function in collective-select-folder
",copybara-service[bot],2024-12-19 20:58:01+00:00,['frgossen'],2025-01-02 19:06:00+00:00,2025-01-02 19:06:00+00:00,https://github.com/tensorflow/tensorflow/pull/83362,[],[],
2751344100,pull_request,open,,implement hlo co-lowering for window prefetch,"implement hlo co-lowering for window prefetch
",copybara-service[bot],2024-12-19 20:22:33+00:00,[],2025-01-02 20:46:42+00:00,,https://github.com/tensorflow/tensorflow/pull/83361,[],[],
2751327651,pull_request,closed,,"Converts WindowPrefetch as a single operation, instead of wrapping it in an AsyncOp pair. Also add a sync flag in its output.","Converts WindowPrefetch as a single operation, instead of wrapping it in an AsyncOp pair. Also add a sync flag in its output.
",copybara-service[bot],2024-12-19 20:14:42+00:00,[],2025-01-02 21:40:12+00:00,2025-01-02 21:40:11+00:00,https://github.com/tensorflow/tensorflow/pull/83360,[],[],
2751195047,pull_request,closed,,[XLA:TPU] Rollback Disable some optimization passes based on effort flag,"[XLA:TPU] Rollback Disable some optimization passes based on effort flag

Reverts 16b5c0451fb851b68f90f398ee0fe11421793f75
",copybara-service[bot],2024-12-19 18:53:56+00:00,[],2024-12-20 15:55:45+00:00,2024-12-20 15:55:44+00:00,https://github.com/tensorflow/tensorflow/pull/83359,[],[],
2751063474,pull_request,closed,,"Deprecate EVENT_TYPE_FLOW in TraceViewer. We only use Flow V2 now, so flow data","Deprecate EVENT_TYPE_FLOW in TraceViewer. We only use Flow V2 now, so flow data
is embedded in COMPLETE events.

Flow V2: https://codereview.chromium.org/1276223005/diff/60001/tracing/tracing/extras/importer/trace_event_importer.html
",copybara-service[bot],2024-12-19 17:45:18+00:00,[],2025-01-15 00:34:04+00:00,2025-01-15 00:34:03+00:00,https://github.com/tensorflow/tensorflow/pull/83358,[],[],
2751032323,pull_request,closed,,Introduce view variants of `BasicDeviceList::Create()`,"Introduce view variants of `BasicDeviceList::Create()`

Several IFRT APIs return `absl::Span<Device* const>` and it's a bit cumbersome to create a basic device list from a span because one needs to manually create `BasicDeviceList::Devices`. These new factory methods allow for more concise construction patterns.

```
// Before
xla::ifrt::BasicDeviceList::Create(xla::ifrt::BasicDeviceList::Devices(devices.begin(), devices.end()));

// After
xla::ifrt::BasicDeviceList::Create(devices);
```
",copybara-service[bot],2024-12-19 17:32:33+00:00,[],2024-12-19 22:12:15+00:00,2024-12-19 22:12:15+00:00,https://github.com/tensorflow/tensorflow/pull/83357,[],[],
2750992901,pull_request,open,,[XLA:CPU] Add direct F64->F8 conversion for better accuracy,"[XLA:CPU] Add direct F64->F8 conversion for better accuracy

Related to https://github.com/openxla/xla/issues/17324
",copybara-service[bot],2024-12-19 17:17:11+00:00,[],2024-12-19 20:15:49+00:00,,https://github.com/tensorflow/tensorflow/pull/83356,[],"[{'comment_id': 2555209790, 'issue_id': 2750992901, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/83356/checks?check_run_id=34668781376) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 19, 17, 17, 18, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-19 17:17:18 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/83356/checks?check_run_id=34668781376) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2750783735,pull_request,closed,,[XLA:CPU] Make convolution HLO tests robust to proto format changes,"[XLA:CPU] Make convolution HLO tests robust to proto format changes


Instead of reimplementing window and shape stringification logic in HLO tests, reuse it from XLA utils. This makes the tests robust to changes in XLA proto file and HLO text format.

Additionally simplify these tests by omitting the output shape calculations.
",copybara-service[bot],2024-12-19 15:59:21+00:00,[],2024-12-20 18:20:22+00:00,2024-12-20 18:20:21+00:00,https://github.com/tensorflow/tensorflow/pull/83355,[],"[{'comment_id': 2554790165, 'issue_id': 2750783735, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/83355/checks?check_run_id=34664482825) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 19, 15, 59, 26, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-19 15:59:26 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/83355/checks?check_run_id=34664482825) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2750772552,pull_request,closed,,Rollback of changelist 698372450.,"Rollback of changelist 698372450.

Reverts 3d74da5df5ddbce788c7411b429df87cc9066c4e
",copybara-service[bot],2024-12-19 15:55:41+00:00,[],2025-01-06 10:04:46+00:00,2025-01-06 10:04:45+00:00,https://github.com/tensorflow/tensorflow/pull/83354,[],[],
2750686109,pull_request,closed,,[XLA] Consider the end-of-program as a valid end-of-program-prefetch start time.,"[XLA] Consider the end-of-program as a valid end-of-program-prefetch start time.

Otherwise, we may get unlucky and an earlier while loop may prevent the EOPP
optimization.
",copybara-service[bot],2024-12-19 15:26:13+00:00,[],2024-12-19 21:24:37+00:00,2024-12-19 21:24:36+00:00,https://github.com/tensorflow/tensorflow/pull/83353,[],[],
2750619751,pull_request,closed,,[XLA:GPU] move int4 related tests to a separate file.,"[XLA:GPU] move int4 related tests to a separate file.
",copybara-service[bot],2024-12-19 15:03:21+00:00,[],2024-12-19 16:03:45+00:00,2024-12-19 16:03:43+00:00,https://github.com/tensorflow/tensorflow/pull/83352,[],[],
2750584390,pull_request,closed,,[xla:cpu] Add support for running with default pthreadpool,"[xla:cpu] Add support for running with default pthreadpool
",copybara-service[bot],2024-12-19 14:51:30+00:00,['ezhulenev'],2024-12-20 05:23:44+00:00,2024-12-20 05:23:44+00:00,https://github.com/tensorflow/tensorflow/pull/83351,[],[],
2750550642,pull_request,closed,,Add `xla/tsl/platform` to `default_visibility` in `xla/tsl/platform/windows`,"Add `xla/tsl/platform` to `default_visibility` in `xla/tsl/platform/windows`
",copybara-service[bot],2024-12-19 14:40:05+00:00,['ddunl'],2024-12-19 21:10:35+00:00,2024-12-19 21:10:34+00:00,https://github.com/tensorflow/tensorflow/pull/83350,[],[],
2750521575,pull_request,closed,,[xla:python] Fix type annotation for new register_custom_type_id function.,"[xla:python] Fix type annotation for new register_custom_type_id function.
",copybara-service[bot],2024-12-19 14:29:57+00:00,[],2024-12-19 15:13:06+00:00,2024-12-19 15:13:04+00:00,https://github.com/tensorflow/tensorflow/pull/83349,[],[],
2750416760,pull_request,closed,,[XLA:GPU] Deprecate diamond chains in `SoftmaxRewriterTriton` (roll forward).,"[XLA:GPU] Deprecate diamond chains in `SoftmaxRewriterTriton` (roll forward).

Now that priority fusion is able to fuse into normalization diamonds, it shouldn't be necessary to match long strings of ops around normalizations.

This is part of a series of simplifications which should minimize the normalization rewriter.

Also re-relaxes the restrictions on bitcasts in the rewriter.

Reverts 24fcd16bc4c138c9fcbff91cfcd7fc7a67c087e0
",copybara-service[bot],2024-12-19 13:56:33+00:00,[],2024-12-19 15:27:31+00:00,2024-12-19 15:27:31+00:00,https://github.com/tensorflow/tensorflow/pull/83348,[],[],
2750404661,pull_request,open,,[xla:gpu] Removed unused `GetLibdevicePath`,"[xla:gpu] Removed unused `GetLibdevicePath`
",copybara-service[bot],2024-12-19 13:52:20+00:00,['superbobry'],2024-12-19 13:52:22+00:00,,https://github.com/tensorflow/tensorflow/pull/83347,[],[],
2750327042,pull_request,closed,,[AutoPGLE] Explicitly disable command buffers when profiler is used.,"[AutoPGLE] Explicitly disable command buffers when profiler is used.
",copybara-service[bot],2024-12-19 13:25:03+00:00,[],2024-12-25 05:36:28+00:00,2024-12-25 05:36:27+00:00,https://github.com/tensorflow/tensorflow/pull/83346,[],[],
2750257114,pull_request,closed,,Add the index of the delegated graph in the partitioning info log.,"Add the index of the delegated graph in the partitioning info log.
",copybara-service[bot],2024-12-19 12:59:26+00:00,['qukhan'],2024-12-19 22:35:42+00:00,2024-12-19 22:35:42+00:00,https://github.com/tensorflow/tensorflow/pull/83345,[],[],
2750079203,pull_request,closed,,Fix MapUnstage crash when key is not a scaler,This PR tries to address the issue raised in https://github.com/tensorflow/tensorflow/issues/72295 where `MapUnstage` will crash when `key` is not a scaler. ,cybersupersoap,2024-12-19 11:55:42+00:00,['gbaned'],2025-01-29 02:52:02+00:00,2025-01-29 02:52:02+00:00,https://github.com/tensorflow/tensorflow/pull/83343,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small'), ('prtype:bugfix', 'PR to fix a bug'), ('comp:core', 'issues related to core part of tensorflow')]","[{'comment_id': 2561888331, 'issue_id': 2750079203, 'author': 'cybersupersoap', 'body': 'Hi @rdzhabarov, Could you please review my PR? Thank you!', 'created_at': datetime.datetime(2024, 12, 25, 13, 17, 41, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562081062, 'issue_id': 2750079203, 'author': 'cybersupersoap', 'body': 'Hi @keerthanakadiri , Could you please review my PR? Thank you!', 'created_at': datetime.datetime(2024, 12, 26, 2, 15, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2585030714, 'issue_id': 2750079203, 'author': 'cybersupersoap', 'body': 'Hi @sagunb, Could you please review my PR? Thank you!', 'created_at': datetime.datetime(2025, 1, 11, 2, 44, 56, tzinfo=datetime.timezone.utc)}]","cybersupersoap (Issue Creator) on (2024-12-25 13:17:41 UTC): Hi @rdzhabarov, Could you please review my PR? Thank you!

cybersupersoap (Issue Creator) on (2024-12-26 02:15:51 UTC): Hi @keerthanakadiri , Could you please review my PR? Thank you!

cybersupersoap (Issue Creator) on (2025-01-11 02:44:56 UTC): Hi @sagunb, Could you please review my PR? Thank you!

"
2750033252,pull_request,closed,,[XLA:GPU] Remove the call to `FloatNormalization` preceding the normalization rewriter.,"[XLA:GPU] Remove the call to `FloatNormalization` preceding the normalization rewriter.

It should no longer be necessary. This is part of a series of changes aimed
at decreasing the slight added complexity introduced by the normalization
rewriter.
",copybara-service[bot],2024-12-19 11:36:21+00:00,[],2024-12-19 13:20:20+00:00,2024-12-19 13:20:20+00:00,https://github.com/tensorflow/tensorflow/pull/83342,[],[],
2750007418,pull_request,closed,,Rollback breaking C API changes (TryGetKeyValue()).,"Rollback breaking C API changes (TryGetKeyValue()).

Reverts bccc45d56d727354d7a634b192ae7552c2c36932
",copybara-service[bot],2024-12-19 11:24:09+00:00,[],2024-12-19 14:15:21+00:00,2024-12-19 14:15:20+00:00,https://github.com/tensorflow/tensorflow/pull/83341,[],[],
2749928287,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 10:49:59+00:00,[],2024-12-19 10:49:59+00:00,,https://github.com/tensorflow/tensorflow/pull/83340,[],[],
2749921231,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 10:47:44+00:00,[],2024-12-19 10:47:44+00:00,,https://github.com/tensorflow/tensorflow/pull/83339,[],[],
2749836656,pull_request,closed,,Fix typos in documentation strings,"Hi, Team
I observed few typos in the documentation strings and I have fixed those typos so please do the needful. Thank you.",Venkat6871,2024-12-19 10:14:13+00:00,['gbaned'],2024-12-19 16:22:41+00:00,2024-12-19 16:22:40+00:00,https://github.com/tensorflow/tensorflow/pull/83338,"[('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small'), ('comp:core', 'issues related to core part of tensorflow')]",[],
2749824122,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 10:08:39+00:00,[],2024-12-19 10:08:39+00:00,,https://github.com/tensorflow/tensorflow/pull/83337,[],[],
2749821377,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 10:07:21+00:00,[],2024-12-25 07:21:54+00:00,2024-12-25 07:21:52+00:00,https://github.com/tensorflow/tensorflow/pull/83336,[],[],
2749806701,pull_request,open,,[XLA:CPU] Emit nested computations prior to calling ElementalIrEmitter,"[XLA:CPU] Emit nested computations prior to calling ElementalIrEmitter
",copybara-service[bot],2024-12-19 10:00:31+00:00,[],2024-12-19 10:00:31+00:00,,https://github.com/tensorflow/tensorflow/pull/83335,[],[],
2749730619,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:28:58+00:00,[],2024-12-20 08:39:31+00:00,2024-12-20 08:39:30+00:00,https://github.com/tensorflow/tensorflow/pull/83334,[],[],
2749721054,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:24:21+00:00,[],2024-12-20 09:03:07+00:00,,https://github.com/tensorflow/tensorflow/pull/83333,[],[],
2749717060,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:22:34+00:00,[],2024-12-20 08:35:48+00:00,,https://github.com/tensorflow/tensorflow/pull/83332,[],[],
2749708815,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:18:34+00:00,[],2024-12-20 07:52:04+00:00,,https://github.com/tensorflow/tensorflow/pull/83330,[],[],
2749708026,pull_request,closed,,PR #20635: Remove workspace size for SDPA FP8 custom-call tests,"PR #20635: Remove workspace size for SDPA FP8 custom-call tests

Imported from GitHub PR https://github.com/openxla/xla/pull/20635

Related to #20564 where only one of the commits is merged. @hawkinsp

The 2 tests affected by the workspace size on blackwell are
FlashAttentionBMMScaleSoftmaxBMMF8.Flash_Attention_Inference_BMM1_NoMask_Softmax_BMM2_BNTH_F8 and
FlashAttentionBMMScaleSoftmaxBMMF8.Flash_Attention_Inference_BMM1_NoMask_Softmax_BMM2_BNTH_F8.

On Blackwell, the required workspace size is 0 as oppose to 16 on Hopper. Removing hardcoded workspace size to have cuDNN compiler handle it automatically.
Copybara import of the project:

--
83153e7cd138f9ef3619ba38b5760e644c62037b by “wenscarl” <shuw@nvidia.com>:

Remove hard-coded workspace size for FP8 SPDA tests

Merging this change closes #20635

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20635 from wenscarl:spda_fp8_custom_call_workspace 83153e7cd138f9ef3619ba38b5760e644c62037b
",copybara-service[bot],2024-12-19 09:18:11+00:00,[],2024-12-19 10:28:46+00:00,2024-12-19 10:28:46+00:00,https://github.com/tensorflow/tensorflow/pull/83329,[],[],
2749705297,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:16:50+00:00,[],2024-12-19 09:16:50+00:00,,https://github.com/tensorflow/tensorflow/pull/83328,[],[],
2749696380,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:12:30+00:00,[],2024-12-20 09:05:53+00:00,,https://github.com/tensorflow/tensorflow/pull/83327,[],[],
2749696170,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:12:24+00:00,[],2024-12-19 11:15:28+00:00,,https://github.com/tensorflow/tensorflow/pull/83326,[],[],
2749692692,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:10:41+00:00,[],2024-12-19 11:07:43+00:00,,https://github.com/tensorflow/tensorflow/pull/83325,[],[],
2749686671,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:07:46+00:00,[],2024-12-19 10:17:39+00:00,,https://github.com/tensorflow/tensorflow/pull/83324,[],[],
2749678903,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:04:57+00:00,[],2024-12-19 10:22:33+00:00,,https://github.com/tensorflow/tensorflow/pull/83323,[],[],
2749673895,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 09:02:59+00:00,[],2024-12-19 09:02:59+00:00,,https://github.com/tensorflow/tensorflow/pull/83322,[],[],
2749655786,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 08:53:55+00:00,[],2024-12-19 10:11:49+00:00,,https://github.com/tensorflow/tensorflow/pull/83321,[],[],
2749630051,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 08:42:00+00:00,[],2024-12-19 09:31:41+00:00,,https://github.com/tensorflow/tensorflow/pull/83320,[],[],
2749440782,pull_request,closed,,Add tf_keras installation and import statements to tf.autodiff.ForwardAccumulator example,"Hi, Team
I have added necessary installation and import statements to the example section [here](https://www.tensorflow.org/api_docs/python/tf/autodiff/ForwardAccumulator) to ensure the code runs correctly starting with TensorFlow 2.16, doing `pip install tensorflow` will install Keras 3 , then by default `from tensorflow import keras` ([tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras)) will be Keras 3.When you have TensorFlow >= 2.16 and [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) to stay on Keras 2 after upgrading to TensorFlow 2.16+, we can configure your TensorFlow installation so that [tf.keras](https://www.tensorflow.org/api_docs/python/tf/keras) points to tf_keras. To achieve this:

- Make sure to install tf_keras. Note that TensorFlow does not install it by default.
- Export the environment variable TF_USE_LEGACY_KERAS=1.

 The following changes have been made as per [TensorFlow + Keras 2 backwards compatibility](https://keras.io/getting_started/):

- Added `pip install tf_keras` command to install the required package.
- Added import statements for `os`, `numpy`, and `tensorflow`
- Set the environment variable `TF_USE_LEGACY_KERAS to ""1""` to ensure compatibility with legacy Keras.

These changes are reflected in the example section to provide a complete and functional code snippet for users please refer this [gist-file](https://colab.research.google.com/gist/gaikwadrahul8/71722791ba518fd8b60f18f702d33924/tf-core-issue-79523.ipynb). if you've any feedback or suggestions for these changes please feel free to let me know. Thank you.

It will fix this issue https://github.com/tensorflow/tensorflow/issues/79523

Changes looks like below now :
```
>>> pip install tf_keras
>>> import os
>>> import numpy as np
>>> import tensorflow as tf
>>> os.environ[""TF_USE_LEGACY_KERAS""] = ""1""

>>> x = tf.constant([[2.0, 3.0], [1.0, 4.0]])
>>> targets = tf.constant([[1.], [-1.]])
>>> dense = tf.keras.layers.Dense(1)
>>> dense.build([None, 2])
>>> with tf.autodiff.ForwardAccumulator(
...    primals=dense.kernel,
...    tangents=tf.constant([[1.], [0.]])) as acc:
...   loss = tf.reduce_sum((dense(x) - targets) ** 2.)
>>> acc.jvp(loss)
<tf.Tensor: shape=(), dtype=float32, numpy=...>
```",gaikwadrahul8,2024-12-19 07:06:33+00:00,['gbaned'],2025-01-29 21:27:13+00:00,2024-12-19 13:24:27+00:00,https://github.com/tensorflow/tensorflow/pull/83318,"[('size:XS', 'CL Change Size: Extra Small')]",[],
2749298098,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-19 05:28:47+00:00,[],2024-12-19 05:28:47+00:00,,https://github.com/tensorflow/tensorflow/pull/83317,[],[],
2749132627,pull_request,closed,,Improve S1/U1 support,"Improve S1/U1 support
",copybara-service[bot],2024-12-19 02:57:03+00:00,[],2024-12-20 23:58:05+00:00,2024-12-20 23:58:04+00:00,https://github.com/tensorflow/tensorflow/pull/83316,[],[],
2749076833,pull_request,closed,,PR #19096: Add F4E2M1FN and F8E8M0FNU types,"PR #19096: Add F4E2M1FN and F8E8M0FNU types

Imported from GitHub PR https://github.com/openxla/xla/pull/19096

This PR adds F4E2M1FN primitive type (4-bit float with 2 bits exponent and 1 bit mantissa), F8E8M0FNU primitive type (8-bit float with 8 bits exponent, no mantissa and no sign) and enables loads/stores in the same way S4/U4 type is implemented.

This will enable using microscaling (MX) formats ([RFC](https://github.com/openxla/xla/discussions/18085)), such as MXFP4.

```c
F4E2M1FN
- Exponent bias: 1
- Maximum stored exponent value: 3 (binary 11)
- Maximum unbiased exponent value: 3 - 1 = 2
- Minimum stored exponent value: 1 (binary 01)
- Minimum unbiased exponent value: 1 − 1 = 0
- Has Positive and Negative zero
- Doesn't have infinity
- Doesn't have NaNs

Additional details:
- Zeros (+/-): S.00.0
- Max normal number: S.11.1 = ±2^(2) x (1 + 0.5) = ±6.0
- Min normal number: S.01.0 = ±2^(0) = ±1.0
- Min subnormal number: S.00.1 = ±2^(0) x 0.5 = ±0.5

F8E8M0FNU
- Exponent bias: 127
- Maximum stored exponent value: 254 (binary 1111'1110)
- Maximum unbiased exponent value: 254 - 127 = 127
- Minimum stored exponent value: 0 (binary 0000'0000)
- Minimum unbiased exponent value: 0 − 127 = -127
- Doesn't have zero
- Doesn't have infinity
- NaN is encoded as binary 1111'1111

Additional details:
- Zeros cannot be represented
- Negative values cannot be represented
- Mantissa is always 1
```

Related PRs:
- https://github.com/openxla/stablehlo/pull/2582
- https://github.com/jax-ml/ml_dtypes/pull/181
- https://github.com/llvm/llvm-project/pull/95392
- https://github.com/llvm/llvm-project/pull/108877
- https://github.com/jax-ml/ml_dtypes/pull/166
- https://github.com/llvm/llvm-project/pull/107127
- https://github.com/llvm/llvm-project/pull/111028

The PR is split into multiple commits just to make the review easier, it is possible that some tests could fail if only some (i.e. not all) of these commits are applied.
Copybara import of the project:

--
f493e4803eaa5ff3da3ceb130e9348c014b4a2e8 by Sergey Kozub <skozub@nvidia.com>:

Add F4E2M1FN type: import mxfloat.h

--
87d005630b310a355d7c30b22828c35237373f17 by Sergey Kozub <skozub@nvidia.com>:

Add F4E2M1FN type: primitive type

--
70ca82093faeec98f2dc5e8b82f617d99ca96849 by Sergey Kozub <skozub@nvidia.com>:

Add F4E2M1FN type: literal support

--
c479f0940da490e9668e2f48e14a7466f0c4a97f by Sergey Kozub <skozub@nvidia.com>:

Add F4E2M1FN type: conversion codegen

--
daaa3af3ce3af456f2ef44dbc291ebeb09e86d9b by Sergey Kozub <skozub@nvidia.com>:

Add F4E2M1FN type: python interface

--
1f0e19ff14733eff790726936b68ef0cf607a766 by Sergey Kozub <skozub@nvidia.com>:

Add F4E2M1FN type: FFI

--
999bf96092e57c7b3039811f2887281f347ff17a by Sergey Kozub <skozub@nvidia.com>:

Add F4E2M1FN type: HLO evaluator

--
d7d5af74c5f8a94522779a121c0a4a962156fb64 by Sergey Kozub <skozub@nvidia.com>:

Add F4E2M1FN type: add tests

--
9e8c7bc02849f241d0f05941221d99f1d08d9e67 by Sergey Kozub <skozub@nvidia.com>:

Add F8E8M0FNU type

--
1e344174b931cea4978770ab740dfed67186c2f4 by Sergey Kozub <skozub@nvidia.com>:

Addressing PR#19096 review comments

--
d4de0a369d9dc853f34f3cf3bf7dcc5a47502106 by Sergey Kozub <skozub@nvidia.com>:

Addressing PR#19096 review comments (round 2)

Merging this change closes #19096

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19096 from openxla:skozub/e2m1 d4de0a369d9dc853f34f3cf3bf7dcc5a47502106
",copybara-service[bot],2024-12-19 01:58:42+00:00,[],2024-12-20 20:45:50+00:00,2024-12-20 20:45:50+00:00,https://github.com/tensorflow/tensorflow/pull/83315,[],[],
2749071131,pull_request,closed,,[xla:cpu] Add support for running xnnpack dot on an intra-op threadpool,"[xla:cpu] Add support for running xnnpack dot on an intra-op threadpool
",copybara-service[bot],2024-12-19 01:52:02+00:00,['ezhulenev'],2024-12-20 04:33:35+00:00,2024-12-20 04:33:34+00:00,https://github.com/tensorflow/tensorflow/pull/83314,[],[],
2749022667,pull_request,closed,,Enable support for DenseResourceElementsAttr in the convert_tensor utility.,"Enable support for DenseResourceElementsAttr in the convert_tensor utility.

DenseResourceElementsAttr are used to store and reuse pointer resources when accessing large constants. This is garbage collected unlike DenseElementsAttr which lives through the life of the module, even after being explicitly deleted.

This CL itself doesn't prevent data copy. But the option to import tensorflow::Tensor objects as DenseResourceElementsAttr in MLIR is going to be useful to reduce data copies in downstream compilers/converters like TFLite Converter.
",copybara-service[bot],2024-12-19 00:56:11+00:00,['vamsimanchala'],2025-01-07 03:02:21+00:00,2025-01-07 03:02:20+00:00,https://github.com/tensorflow/tensorflow/pull/83313,[],[],
2749018897,pull_request,closed,,Add output streaming for CostValue.,"Add output streaming for CostValue.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19096 from openxla:skozub/e2m1 d4de0a369d9dc853f34f3cf3bf7dcc5a47502106
",copybara-service[bot],2024-12-19 00:51:34+00:00,['sparc1998'],2024-12-20 21:37:57+00:00,2024-12-20 21:37:57+00:00,https://github.com/tensorflow/tensorflow/pull/83312,[],[],
2749010859,pull_request,open,,Support sharding int4 arrays by upcasting collectives.,"Support sharding int4 arrays by upcasting collectives.

This adds support for int4 collectives by converting them to int8 collectives, which allows int4 arrays to be sharded. Ideally we would directly communicate int4 arrays across devices instead of converting them to int8, as this would mean half the bytes are transferred, but this is more difficult since NCCL doesn't support 4-bit types.
",copybara-service[bot],2024-12-19 00:41:43+00:00,['reedwm'],2024-12-19 00:41:44+00:00,,https://github.com/tensorflow/tensorflow/pull/83311,[],[],
2748991952,pull_request,closed,,Add `test.h` to `xla/tsl/platform:android_test_srcs`,"Add `test.h` to `xla/tsl/platform:android_test_srcs`
",copybara-service[bot],2024-12-19 00:20:11+00:00,['ddunl'],2024-12-19 01:37:34+00:00,2024-12-19 01:37:33+00:00,https://github.com/tensorflow/tensorflow/pull/83310,[],[],
2748963779,pull_request,closed,,[xla:cpu] Add an object pool for xnnpack runtimes,"[xla:cpu] Add an object pool for xnnpack runtimes
",copybara-service[bot],2024-12-18 23:53:45+00:00,['ezhulenev'],2024-12-20 03:33:05+00:00,2024-12-20 03:33:05+00:00,https://github.com/tensorflow/tensorflow/pull/83309,[],[],
2748936691,pull_request,closed,,Implement `HloRunnerPjRt::ExecuteReplicated` w/ `executable_provider` overload.,"Implement `HloRunnerPjRt::ExecuteReplicated` w/ `executable_provider` overload.

This is mostly modeled after the implementation that I found in the `HloRunner`
class, with a few modifications.
",copybara-service[bot],2024-12-18 23:33:36+00:00,[],2024-12-24 01:07:10+00:00,2024-12-24 01:07:10+00:00,https://github.com/tensorflow/tensorflow/pull/83308,[],[],
2748932830,pull_request,closed,,Create a PjRt interpreter client.,"Create a PjRt interpreter client.

The existing stream executor interpreter platform is used throughout our testing
frameworks as a reference platform. It is implemented as a wrapper around
`HloEvaluator`.

This change adds a new PjRt client to act as an alternative to the stream
executor interpreter platform. It wraps `HloEvaluator`, like the stream executor
based implementation. This is a first implementation that leaves many interfaces
stubbed instead of implemented. It has been validated against all tests that
have been migrated to `HloPjRtTestBase`.
",copybara-service[bot],2024-12-18 23:29:31+00:00,[],2024-12-19 21:47:30+00:00,2024-12-19 21:47:29+00:00,https://github.com/tensorflow/tensorflow/pull/83307,[],[],
2748931455,pull_request,closed,,Use the new PjRt InterpreterClient in test base and PjRt test client registry.,"Use the new PjRt InterpreterClient in test base and PjRt test client registry.
",copybara-service[bot],2024-12-18 23:28:03+00:00,[],2024-12-20 01:03:32+00:00,2024-12-20 01:03:31+00:00,https://github.com/tensorflow/tensorflow/pull/83306,[],[],
2748916780,pull_request,closed,,[HLO Componentization] Remove spurious fan-out deps from hlo component to xla_proto_cc,"[HLO Componentization] Remove spurious fan-out deps from hlo component to xla_proto_cc
",copybara-service[bot],2024-12-18 23:12:29+00:00,['sdasgup3'],2024-12-19 01:13:40+00:00,2024-12-19 01:13:39+00:00,https://github.com/tensorflow/tensorflow/pull/83305,[],[],
2748906501,pull_request,closed,,Remove the use of ifdefs in topk_custom_kernel.cc.,"Remove the use of ifdefs in topk_custom_kernel.cc.
",copybara-service[bot],2024-12-18 23:02:56+00:00,[],2025-01-07 18:19:00+00:00,2025-01-07 18:18:59+00:00,https://github.com/tensorflow/tensorflow/pull/83304,[],[],
2748900791,pull_request,open,,PR #19451: Setting xla_gpu_multi_streamed_windowed_einsum to true by default,"PR #19451: Setting xla_gpu_multi_streamed_windowed_einsum to true by default

Imported from GitHub PR https://github.com/openxla/xla/pull/19451

We are trying to deprecate xla_gpu_multi_streamed_windowed_einsum  since we always have better perf with it enabled. This is the first pr to enable it by default to test for stability.
Copybara import of the project:

--
808a9cc0af8901d36a3c219bdf19f38323d01bf3 by Tj Xu <tjx@nvidia.com>:

Turn xla_gpu_multi_streamed_windowed_einsum on by default

--
8221fc4481773f457f5e0235625be22f255fe75b by TJ Xu <tjx@nvidia.com>:

Add an option to StreamAttributeAnnotator to skip annotating copy-start
and async DUS
Don't annotate copy-start and async DUS when the pass is run before
remat

--
352c1c593b9dcd895f123dea4f7c38e44a787ae6 by TJ Xu <tjx@nvidia.com>:

Remove the option to skip annotating copy start and inpect if the module
has schedule

--
257ff6768b59fc7c47c04fa5faa524399f74c80e by TJ Xu <tjx@nvidia.com>:

Address roll-back by disabling a2a rewrite by default

--
d3bafebdc0961d61384a49616c29cb9bb6c59db9 by TJ Xu <tjx@nvidia.com>:

reverted new flag changes

Merging this change closes #19451

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19451 from Tixxx:tixxx/remove_multi_stream_flag d3bafebdc0961d61384a49616c29cb9bb6c59db9
",copybara-service[bot],2024-12-18 22:57:47+00:00,[],2024-12-20 09:46:16+00:00,,https://github.com/tensorflow/tensorflow/pull/83303,[],[],
2748870082,pull_request,closed,,[XLA:CPU] Consistently initialize the LLVM native target.,"[XLA:CPU] Consistently initialize the LLVM native target.

Fixes the following TSAN race:

```
WARNING: ThreadSanitizer: data race (pid=899472)
  Write of size 8 at 0x7f979e0f1cd8 by thread T69:
    #0 llvm::TargetRegistry::RegisterTargetMachine(llvm::Target&, llvm::TargetMachine* (*)(llvm::Target const&, llvm::Triple const&, llvm::StringRef, llvm::StringRef, llvm::TargetOptions const&, std::optional<llvm::Reloc::Model>, std::optional<llvm::CodeModel::Model>, llvm::CodeGenOptLevel, bool)) /proc/self/cwd/external/llvm-project/llvm/include/llvm/MC/TargetRegistry.h:827:27 (xla_extension.so+0x9803668) (BuildId: 6fa88e3910a5eb04)
    #1 llvm::RegisterTargetMachine<llvm::X86TargetMachine>::RegisterTargetMachine(llvm::Target&) /proc/self/cwd/external/llvm-project/llvm/include/llvm/MC/TargetRegistry.h:1250:5 (xla_extension.so+0x9803668)
    #2 LLVMInitializeX86Target /proc/self/cwd/external/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:69:43 (xla_extension.so+0x9803668)
    #3 llvm::InitializeNativeTarget() /proc/self/cwd/external/llvm-project/llvm/include/llvm/Support/TargetSelect.h:123:5 (xla_extension.so+0x48d2358) (BuildId: 6fa88e3910a5eb04)
    #4 xla::cpu::JitCompiler::Create(llvm::TargetOptions, xla::cpu::JitCompiler::Options, absl::lts_20230802::AnyInvocable<void (std::function<void ()>)>)::$_0::operator()() const /proc/self/cwd/external/xla/xla/backends/cpu/codegen/jit_compiler.cc:113:5 (xla_extension.so+0x48d2358)
    #5 xla::cpu::JitCompiler::Create(llvm::TargetOptions, xla::cpu::JitCompiler::Options, absl::lts_20230802::AnyInvocable<void (std::function<void ()>)>) /proc/self/cwd/external/xla/xla/backends/cpu/codegen/jit_compiler.cc:112:34 (xla_extension.so+0x48d209b) (BuildId: 6fa88e3910a5eb04)
    #6 xla::cpu::CpuCompiler::CompileLegacyCpuExecutable(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule>>) /proc/self/cwd/external/xla/xla/service/cpu/cpu_compiler.cc:1416:3 (xla_extension.so+0x2f716a0) (BuildId: 6fa88e3910a5eb04)
    #7 xla::cpu::CpuCompiler::RunBackend(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule>>, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&) /proc/self/cwd/external/xla/xla/service/cpu/cpu_compiler.cc:1730:3 (xla_extension.so+0x2f7ae18) (BuildId: 6fa88e3910a5eb04)
    #8 xla::JitCompile(xla::XlaComputation const&, absl::lts_20230802::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&, xla::ExecutionOptions const&, xla::Compiler::CompileOptions const&, int, std::function<void (xla::HloModuleConfig&)>) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:759:19 (xla_extension.so+0x2f12915) (BuildId: 6fa88e3910a5eb04)
    #9 xla::TfrtCpuClient::Compile(xla::XlaComputation const&, xla::CompileOptions) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:847:3 (xla_extension.so+0x2f12915)

  Previous read of size 8 at 0x7f979e0f1cd8 by thread T66:
    #0 llvm::Target::createTargetMachine(llvm::StringRef, llvm::StringRef, llvm::StringRef, llvm::TargetOptions const&, std::optional<llvm::Reloc::Model>, std::optional<llvm::CodeModel::Model>, llvm::CodeGenOptLevel, bool) const /proc/self/cwd/external/llvm-project/llvm/include/llvm/MC/TargetRegistry.h:460:10 (xla_extension.so+0x94ba6db) (BuildId: 6fa88e3910a5eb04)
    #1 llvm::EngineBuilder::selectTarget(llvm::Triple const&, llvm::StringRef, llvm::StringRef, llvm::SmallVectorImpl<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>> const&) /proc/self/cwd/external/llvm-project/llvm/lib/ExecutionEngine/TargetSelect.cpp:88:18 (xla_extension.so+0x94ba6db)
    #2 xla::cpu::JitCompiler::InferTargetMachine(llvm::TargetOptions const&, llvm::CodeGenOptLevel, std::optional<tsl::port::CPUFeature>) /proc/self/cwd/external/xla/xla/backends/cpu/codegen/jit_compiler.cc:88:12 (xla_extension.so+0x48d096f) (BuildId: 6fa88e3910a5eb04)
    #3 xla::cpu::CpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule>>, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&) /proc/self/cwd/external/xla/xla/service/cpu/cpu_compiler.cc:1017:3 (xla_extension.so+0x2f70857) (BuildId: 6fa88e3910a5eb04)
    #4 xla::JitCompile(xla::XlaComputation const&, absl::lts_20230802::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&, xla::ExecutionOptions const&, xla::Compiler::CompileOptions const&, int, std::function<void (xla::HloModuleConfig&)>) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:754:3 (xla_extension.so+0x2f12874) (BuildId: 6fa88e3910a5eb04)
    #5 xla::TfrtCpuClient::Compile(xla::XlaComputation const&, xla::CompileOptions) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:847:3 (xla_extension.so+0x2f12874)
    #6 xla::TfrtCpuClient::Compile(mlir::ModuleOp, xla::CompileOptions) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:893:10 (xla_extension.so+0x2f13ef2) (BuildId: 6fa88e3910a5eb04)
```
",copybara-service[bot],2024-12-18 22:31:21+00:00,[],2024-12-19 00:29:16+00:00,2024-12-19 00:29:15+00:00,https://github.com/tensorflow/tensorflow/pull/83302,[],[],
2748868588,pull_request,closed,,[XLA:CPU] Acquire the LLVM options lock before calling RunHloPasses or RunBackend.,"[XLA:CPU] Acquire the LLVM options lock before calling RunHloPasses or RunBackend.

Both of these call into LLVM code that reads the compiler options.

Fixes the following race:

```
WARNING: ThreadSanitizer: data race (pid=869815)
  Read of size 1 at 0x7f8b24effc08 by thread T65:
    #0 llvm::cl::opt_storage<bool, false, false>::getValue() const /proc/self/cwd/external/llvm-project/llvm/include/llvm/Support/CommandLine.h:1406:38 (xla_extension.so+0xa281417) (BuildId: 7f5d2098f168c4db)
    #1 llvm::cl::opt_storage<bool, false, false>::operator bool() const /proc/self/cwd/external/llvm-project/llvm/include/llvm/Support/CommandLine.h:1410:38 (xla_extension.so+0xa281417)
    #2 llvm::CodeGenTargetMachineImpl::CodeGenTargetMachineImpl(llvm::Target const&, llvm::StringRef, llvm::Triple const&, llvm::StringRef, llvm::StringRef, llvm::TargetOptions const&, llvm::Reloc::Model, llvm::CodeModel::Model, llvm::CodeGenOptLevel) /proc/self/cwd/external/llvm-project/llvm/lib/CodeGen/CodeGenTargetMachineImpl.cpp:97:7 (xla_extension.so+0xa281417)
    #3 llvm::X86TargetMachine::X86TargetMachine(llvm::Target const&, llvm::Triple const&, llvm::StringRef, llvm::StringRef, llvm::TargetOptions const&, std::optional<llvm::Reloc::Model>, std::optional<llvm::CodeModel::Model>, llvm::CodeGenOptLevel, bool) /proc/self/cwd/external/llvm-project/llvm/lib/Target/X86/X86TargetMachine.cpp:236:7 (xla_extension.so+0x9803b80) (BuildId: 7f5d2098f168c4db)
    #4 llvm::RegisterTargetMachine<llvm::X86TargetMachine>::Allocator(llvm::Target const&, llvm::Triple const&, llvm::StringRef, llvm::StringRef, llvm::TargetOptions const&, std::optional<llvm::Reloc::Model>, std::optional<llvm::CodeModel::Model>, llvm::CodeGenOptLevel, bool) /proc/self/cwd/external/llvm-project/llvm/include/llvm/MC/TargetRegistry.h:1258:16 (xla_extension.so+0x980757a) (BuildId: 7f5d2098f168c4db)
    #5 llvm::Target::createTargetMachine(llvm::StringRef, llvm::StringRef, llvm::StringRef, llvm::TargetOptions const&, std::optional<llvm::Reloc::Model>, std::optional<llvm::CodeModel::Model>, llvm::CodeGenOptLevel, bool) const /proc/self/cwd/external/llvm-project/llvm/include/llvm/MC/TargetRegistry.h:462:12 (xla_extension.so+0x94ba529) (BuildId: 7f5d2098f168c4db)
    #6 llvm::EngineBuilder::selectTarget(llvm::Triple const&, llvm::StringRef, llvm::StringRef, llvm::SmallVectorImpl<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>> const&) /proc/self/cwd/external/llvm-project/llvm/lib/ExecutionEngine/TargetSelect.cpp:88:18 (xla_extension.so+0x94ba529)
    #7 xla::cpu::JitCompiler::InferTargetMachine(llvm::TargetOptions const&, llvm::CodeGenOptLevel, std::optional<tsl::port::CPUFeature>) /proc/self/cwd/external/xla/xla/backends/cpu/codegen/jit_compiler.cc:88:12 (xla_extension.so+0x48d070f) (BuildId: 7f5d2098f168c4db)
    #8 xla::cpu::CpuCompiler::RunHloPasses(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule>>, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&) /proc/self/cwd/external/xla/xla/service/cpu/cpu_compiler.cc:1017:3 (xla_extension.so+0x2f6dc47) (BuildId: 7f5d2098f168c4db)
    #9 xla::JitCompile(xla::XlaComputation const&, absl::lts_20230802::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&, xla::ExecutionOptions const&, xla::Compiler::CompileOptions const&, int, std::function<void (xla::HloModuleConfig&)>) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:749:3 (xla_extension.so+0x2f127e2) (BuildId: 7f5d2098f168c4db)
    #10 xla::TfrtCpuClient::Compile(xla::XlaComputation const&, xla::CompileOptions) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:842:3 (xla_extension.so+0x2f127e2)
    #11 xla::TfrtCpuClient::Compile(mlir::ModuleOp, xla::CompileOptions) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:888:10 (xla_extension.so+0x2f13da2) (BuildId: 7f5d2098f168c4db)
    #12 xla::ifrt::PjRtLoadedExecutable::Create(xla::ifrt::PjRtCompatibleClient*, mlir::ModuleOp, xla::CompileOptions, std::vector<tsl::RCReference<xla::ifrt::LoadedHostCallback>, std::allocator<tsl::RCReference<xla::ifrt::LoadedHostCallback>>>) /proc/self/cwd/external/xla/xla/python/pjrt_ifrt/pjrt_executable.cc:258:3 (xla_extension.so+0xdd04d77) (BuildId: 7f5d2098f168c4db)
    #13 xla::ifrt::PjRtCompiler::Compile(std::unique_ptr<xla::ifrt::Program, std::default_delete<xla::ifrt::Program>>, std::unique_ptr<xla::ifrt::CompileOptions, std::default_delete<xla::ifrt::CompileOptions>>) /proc/self/cwd/external/xla/xla/python/pjrt_ifrt/pjrt_compiler.cc:97:10 (xla_extension.so+0xdcfd29b) (BuildId: 7f5d2098f168c4db)
    #14 xla::PyClient::CompileIfrtProgram(xla::nb_class_ptr<xla::PyClient>, std::unique_ptr<xla::ifrt::Program, std::default_delete<xla::ifrt::Program>>, std::unique_ptr<xla::ifrt::CompileOptions, std::default_delete<xla::ifrt::CompileOptions>>) /proc/self/cwd/external/xla/xla/python/py_client.cc:443:5 (xla_extension.so+0xc62a228) (BuildId: 7f5d2098f168c4db)
    #15 xla::PyClient::Compile(xla::nb_class_ptr<xla::PyClient>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>, xla::CompileOptions, std::vector<nanobind::capsule, std::allocator<nanobind::capsule>>) /proc/self/cwd/external/xla/xla/python/py_client.cc:466:10 (xla_extension.so+0xc62b514) (BuildId: 7f5d2098f168c4db)

  Previous write of size 1 at 0x7f8b24effc08 by thread T66 (mutexes: write M0):
    #0 void llvm::cl::opt_storage<bool, false, false>::setValue<bool>(bool const&, bool) /proc/self/cwd/external/llvm-project/llvm/include/llvm/Support/CommandLine.h:1401:11 (xla_extension.so+0x100bace9) (BuildId: 7f5d2098f168c4db)
    #1 void llvm::cl::opt<bool, false, llvm::cl::parser<bool>>::setDefaultImpl<bool, void>() /proc/self/cwd/external/llvm-project/llvm/include/llvm/Support/CommandLine.h (xla_extension.so+0x100bace9)
    #2 llvm::cl::opt<bool, false, llvm::cl::parser<bool>>::setDefault() /proc/self/cwd/external/llvm-project/llvm/include/llvm/Support/CommandLine.h:1474:32 (xla_extension.so+0x100bace9)
    #3 llvm::cl::Option::reset() /proc/self/cwd/external/llvm-project/llvm/lib/Support/CommandLine.cpp:460:3 (xla_extension.so+0x100cac0e) (BuildId: 7f5d2098f168c4db)
    #4 (anonymous namespace)::CommandLineParser::ResetAllOptionOccurrences() /proc/self/cwd/external/llvm-project/llvm/lib/Support/CommandLine.cpp:1478:17 (xla_extension.so+0x100cac0e)
    #5 llvm::cl::ResetAllOptionOccurrences() /proc/self/cwd/external/llvm-project/llvm/lib/Support/CommandLine.cpp:2831:17 (xla_extension.so+0x100caa72) (BuildId: 7f5d2098f168c4db)
    #6 xla::llvm_ir::LLVMCommandLineOptionsLock::LLVMCommandLineOptionsLock(std::vector<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>, std::allocator<std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>>> const&) /proc/self/cwd/external/xla/xla/service/llvm_ir/llvm_command_line_options.cc:70:5 (xla_extension.so+0x91d69f4) (BuildId: 7f5d2098f168c4db)
    #7 xla::cpu::CpuCompiler::RunBackend(std::unique_ptr<xla::HloModule, std::default_delete<xla::HloModule>>, stream_executor::StreamExecutor*, xla::Compiler::CompileOptions const&) /proc/self/cwd/external/xla/xla/service/cpu/cpu_compiler.cc:1727:39 (xla_extension.so+0x2f781c8) (BuildId: 7f5d2098f168c4db)
    #8 xla::JitCompile(xla::XlaComputation const&, absl::lts_20230802::Span<xla::Shape const* const>, xla::ExecutableBuildOptions const&, xla::ExecutionOptions const&, xla::Compiler::CompileOptions const&, int, std::function<void (xla::HloModuleConfig&)>) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:754:19 (xla_extension.so+0x2f12883) (BuildId: 7f5d2098f168c4db)
    #9 xla::TfrtCpuClient::Compile(xla::XlaComputation const&, xla::CompileOptions) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:842:3 (xla_extension.so+0x2f12883)
    #10 xla::TfrtCpuClient::Compile(mlir::ModuleOp, xla::CompileOptions) /proc/self/cwd/external/xla/xla/pjrt/cpu/cpu_client.cc:888:10 (xla_extension.so+0x2f13da2) (BuildId: 7f5d2098f168c4db)
    #11 xla::ifrt::PjRtLoadedExecutable::Create(xla::ifrt::PjRtCompatibleClient*, mlir::ModuleOp, xla::CompileOptions, std::vector<tsl::RCReference<xla::ifrt::LoadedHostCallback>, std::allocator<tsl::RCReference<xla::ifrt::LoadedHostCallback>>>) /proc/self/cwd/external/xla/xla/python/pjrt_ifrt/pjrt_executable.cc:258:3 (xla_extension.so+0xdd04d77) (BuildId: 7f5d2098f168c4db)
    #12 xla::ifrt::PjRtCompiler::Compile(std::unique_ptr<xla::ifrt::Program, std::default_delete<xla::ifrt::Program>>, std::unique_ptr<xla::ifrt::CompileOptions, std::default_delete<xla::ifrt::CompileOptions>>) /proc/self/cwd/external/xla/xla/python/pjrt_ifrt/pjrt_compiler.cc:97:10 (xla_extension.so+0xdcfd29b) (BuildId: 7f5d2098f168c4db)
    #13 xla::PyClient::CompileIfrtProgram(xla::nb_class_ptr<xla::PyClient>, std::unique_ptr<xla::ifrt::Program, std::default_delete<xla::ifrt::Program>>, std::unique_ptr<xla::ifrt::CompileOptions, std::default_delete<xla::ifrt::CompileOptions>>) /proc/self/cwd/external/xla/xla/python/py_client.cc:443:5 (xla_extension.so+0xc62a228) (BuildId: 7f5d2098f168c4db)
    #14 xla::PyClient::Compile(xla::nb_class_ptr<xla::PyClient>, std::__cxx11::basic_string<char, std::char_traits<char>, std::allocator<char>>, xla::CompileOptions, std::vector<nanobind::capsule, std::allocator<nanobind::capsule>>) /proc/self/cwd/external/xla/xla/python/py_client.cc:466:10 (xla_extension.so+0xc62b514) (BuildId: 7f5d2098f168c4db)
```
",copybara-service[bot],2024-12-18 22:29:59+00:00,[],2024-12-19 02:07:12+00:00,2024-12-19 02:07:11+00:00,https://github.com/tensorflow/tensorflow/pull/83301,[],[],
2748812054,pull_request,open,,Disable Litert's TFLite experimental targets and :modify_model_interface_main failing target,"Disable Litert's TFLite experimental targets and :modify_model_interface_main failing target
",copybara-service[bot],2024-12-18 21:50:45+00:00,['ecalubaquib'],2024-12-19 20:51:44+00:00,,https://github.com/tensorflow/tensorflow/pull/83300,[],[],
2748800337,pull_request,closed,,Update visibility of LiteRT C / C++ APIs,"Update visibility of LiteRT C / C++ APIs
",copybara-service[bot],2024-12-18 21:41:44+00:00,['terryheo'],2024-12-19 18:22:48+00:00,2024-12-19 18:22:47+00:00,https://github.com/tensorflow/tensorflow/pull/83299,[],[],
2748793253,pull_request,closed,,Update XNNPACK version to fix error with gem-config.c,"Update XNNPACK version to fix error with gem-config.c
",copybara-service[bot],2024-12-18 21:36:16+00:00,['ecalubaquib'],2024-12-19 22:02:38+00:00,2024-12-19 22:02:38+00:00,https://github.com/tensorflow/tensorflow/pull/83298,[],[],
2748769238,pull_request,closed,,Make PjRtClient query the C API for memory (space) descriptions.,"Make PjRtClient query the C API for memory (space) descriptions.
",copybara-service[bot],2024-12-18 21:19:11+00:00,[],2024-12-19 21:36:23+00:00,2024-12-19 21:36:23+00:00,https://github.com/tensorflow/tensorflow/pull/83297,[],[],
2748740575,pull_request,closed,,Changes for OSS LiteRT Android build fix,"Changes for OSS LiteRT Android build fix
",copybara-service[bot],2024-12-18 20:59:36+00:00,['terryheo'],2024-12-19 00:14:44+00:00,2024-12-19 00:14:43+00:00,https://github.com/tensorflow/tensorflow/pull/83296,[],[],
2748699572,pull_request,closed,,Add constants for gpu cost,"Add constants for gpu cost
",copybara-service[bot],2024-12-18 20:32:15+00:00,[],2024-12-18 23:19:58+00:00,2024-12-18 23:19:58+00:00,https://github.com/tensorflow/tensorflow/pull/83295,[],[],
2748678248,pull_request,closed,,Remove #ifdef TENSORFLOW_USE_ROCM usage from cublass_gemm_rewriter_test.cc.,"Remove #ifdef TENSORFLOW_USE_ROCM usage from cublass_gemm_rewriter_test.cc.
",copybara-service[bot],2024-12-18 20:18:43+00:00,[],2025-01-06 18:56:20+00:00,2025-01-06 18:56:19+00:00,https://github.com/tensorflow/tensorflow/pull/83294,[],[],
2748678014,pull_request,open,,Integrate LLVM at llvm/llvm-project@59890c13343a,"Integrate LLVM at llvm/llvm-project@59890c13343a

Updates LLVM usage to match
[59890c13343a](https://github.com/llvm/llvm-project/commit/59890c13343a)
",copybara-service[bot],2024-12-18 20:18:33+00:00,[],2024-12-18 23:39:17+00:00,,https://github.com/tensorflow/tensorflow/pull/83293,[],[],
2748674216,pull_request,open,,Remove unused code in gpu_compiler.cc,"Remove unused code in gpu_compiler.cc
",copybara-service[bot],2024-12-18 20:16:09+00:00,[],2024-12-20 02:44:22+00:00,,https://github.com/tensorflow/tensorflow/pull/83292,[],[],
2748671859,pull_request,open,,Internal dependency change,"Internal dependency change
",copybara-service[bot],2024-12-18 20:14:34+00:00,[],2024-12-18 20:14:34+00:00,,https://github.com/tensorflow/tensorflow/pull/83291,[],[],
2748640434,pull_request,closed,,[pjrt:cpu] Refactoring of TfrtCpuDevice and TfrtCpuTopologyDescription,"[pjrt:cpu] Refactoring of TfrtCpuDevice and TfrtCpuTopologyDescription

This change moves `TfrtCpuDevice` and `TfrtCpuTopologyDescription` from
`cpu_client.*` to new files.

`TfrtCpuTopologyDescription` and `TfrtCpuDeviceDescription`, as well as
`CpuTopology` and its proto are moved to `pjrt_cpu` as portable data types
(with `Tfrt` prefix removed).
",copybara-service[bot],2024-12-18 19:54:00+00:00,[],2024-12-19 22:23:36+00:00,2024-12-19 22:23:36+00:00,https://github.com/tensorflow/tensorflow/pull/83290,[],[],
2748619343,pull_request,closed,,FC per-channel quantization issue fix for 3D input,"FC per-channel quantization issue fix for 3D input
",copybara-service[bot],2024-12-18 19:41:33+00:00,[],2025-01-06 05:09:42+00:00,2025-01-06 05:09:41+00:00,https://github.com/tensorflow/tensorflow/pull/83289,[],[],
2748594872,pull_request,open,,#sdy enable pure callbacks and debug prints in JAX.,"#sdy enable pure callbacks and debug prints in JAX.

Everything passes other than an io callback test due to the lowered `sdy.manual_computation` returning a token. Will be fixed in a follow-up.
",copybara-service[bot],2024-12-18 19:26:30+00:00,[],2024-12-18 19:26:30+00:00,,https://github.com/tensorflow/tensorflow/pull/83288,[],[],
2748521938,pull_request,closed,,Fix use-after free reported by tsan in PJRT_Client_CreateBuffersForAsyncHostToDevice.,"Fix use-after free reported by tsan in PJRT_Client_CreateBuffersForAsyncHostToDevice.
",copybara-service[bot],2024-12-18 18:48:44+00:00,['pschuh'],2024-12-18 19:44:39+00:00,2024-12-18 19:44:38+00:00,https://github.com/tensorflow/tensorflow/pull/83287,[],[],
2748469345,pull_request,open,,Make `XFlow::GetUniqueId()` generate flow ids that are likely to be globally unique,"Make `XFlow::GetUniqueId()` generate flow ids that are likely to be globally unique

Even if the flow is internal to a host, having different hosts share the same flow id confuses the UI when looking at traces from different hosts in one view.
",copybara-service[bot],2024-12-18 18:21:42+00:00,[],2024-12-18 18:21:42+00:00,,https://github.com/tensorflow/tensorflow/pull/83286,[],[],
2748467258,pull_request,open,,#sdy support JAX export tests when Shardy is enabled.,"#sdy support JAX export tests when Shardy is enabled.
",copybara-service[bot],2024-12-18 18:20:26+00:00,[],2024-12-18 18:20:26+00:00,,https://github.com/tensorflow/tensorflow/pull/83285,[],[],
2748447738,pull_request,open,,#sdy Make XLA changes to support JAX export.,"#sdy Make XLA changes to support JAX export.

- Shardy isn't serializable yet with StableHLO, so we need to expose the `SdyRoundTripExportPipeline` to JAX to remove the dialect before serializing.
- Pass an option to `refine_polymoprhic_shapes` if shardy is enabled as we need to undo `SdyRoundTripExportPipeline` through importing again with `SdyRoundTripImportPipeline`
",copybara-service[bot],2024-12-18 18:08:24+00:00,[],2024-12-18 18:08:24+00:00,,https://github.com/tensorflow/tensorflow/pull/83284,[],[],
2748421992,pull_request,closed,,Adding missing count_exclude_pattern usage message and fixed typos,"I am running tensorflow.python.tools.inspect_checkpoint as a library module and realized that the current usage does not list the count_exclude_pattern as an argument. Whilst reading the source code I also discovered two typos. This is the current usage message:

```python
python -m tensorflow.python.tools.inspect_checkpoint 
Usage: inspect_checkpoint --file_name=checkpoint_file_name [--tensor_name=tensor_to_print] [--all_tensors] [--all_tensor_names] [--printoptions]
```
The argument is already accepted and can be used successfully as follows:

```python
python -m tensorflow.python.tools.inspect_checkpoint --file_name="".checkpoint"" --all_tensors --count_exclude_pattern=""bias""
```

I hope this will improve the usability.
",noexecstack,2024-12-18 17:53:14+00:00,['gbaned'],2024-12-20 07:06:39+00:00,2024-12-20 07:06:39+00:00,https://github.com/tensorflow/tensorflow/pull/83283,"[('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2748395747,pull_request,closed,,Integrate LLVM at llvm/llvm-project@59890c13343a,"Integrate LLVM at llvm/llvm-project@59890c13343a

Updates LLVM usage to match
[59890c13343a](https://github.com/llvm/llvm-project/commit/59890c13343a)
",copybara-service[bot],2024-12-18 17:37:22+00:00,['metaflow'],2024-12-19 18:32:43+00:00,2024-12-19 18:32:42+00:00,https://github.com/tensorflow/tensorflow/pull/83282,[],[],
2748258395,pull_request,closed,,[XLA:GPU][Emitters] Add codegen for sorted scatters.,"[XLA:GPU][Emitters] Add codegen for sorted scatters.
 Do not enable it for now. There are some numerical issues.
",copybara-service[bot],2024-12-18 16:26:56+00:00,['pifon2a'],2024-12-20 23:47:07+00:00,2024-12-20 23:47:05+00:00,https://github.com/tensorflow/tensorflow/pull/83281,[],[],
2748254199,pull_request,closed,,[XLA:Python] Add locking around data structures in free-threading mode.,"[XLA:Python] Add locking around data structures in free-threading mode.

* add a global lock for the list of live executables.
* add a global lock around a cache for ShapedArray objects.
* add a sharded lock keyed by the thread ID of the creator for the list of live arrays.
* change some code that iterates over the list of live arrays to instead use LiveArrays().
",copybara-service[bot],2024-12-18 16:24:52+00:00,[],2024-12-18 19:31:09+00:00,2024-12-18 19:31:07+00:00,https://github.com/tensorflow/tensorflow/pull/83280,[],[],
2748182822,pull_request,closed,,[XLA:GPU] Fix output_offsets usage in RaggedAllToAll implementation.,"[XLA:GPU] Fix output_offsets usage in RaggedAllToAll implementation.

The expected behaviour of `output_offsets` was not fully documented and the initial implementation and tests assumed that offsets are relative to the local output buffer. In reality the offsets are ""transposed"" and refer to the buffer on the target peer's memory. To use NCCL send and recv, we need to performance an additional all-to-all and the `output_offsets` buffer to get the needed offset values.
",copybara-service[bot],2024-12-18 15:52:27+00:00,[],2024-12-20 14:19:54+00:00,2024-12-20 14:19:53+00:00,https://github.com/tensorflow/tensorflow/pull/83278,[],[],
2748160281,pull_request,closed,,disable compilation warning for core/kernels/stateful_random_ops,"disable compilation warning for core/kernels/stateful_random_ops
",copybara-service[bot],2024-12-18 15:44:50+00:00,['metaflow'],2024-12-18 16:33:52+00:00,2024-12-18 16:33:52+00:00,https://github.com/tensorflow/tensorflow/pull/83277,[],[],
2748141137,pull_request,closed,,[XLA:TPU] Disable some optimization passes based on effort flag,"[XLA:TPU] Disable some optimization passes based on effort flag
",copybara-service[bot],2024-12-18 15:37:04+00:00,[],2024-12-18 19:19:24+00:00,2024-12-18 19:19:22+00:00,https://github.com/tensorflow/tensorflow/pull/83276,[],[],
2747924011,pull_request,closed,,[XLA:GPU] Give descriptive name to modules created with `ExtractComputationIntoNewModule`.,"[XLA:GPU] Give descriptive name to modules created with `ExtractComputationIntoNewModule`.

This helps debug where the new module originates from and align with the `ExtractInstructionIntoNewModule` behavior.
",copybara-service[bot],2024-12-18 14:07:52+00:00,[],2024-12-20 09:32:27+00:00,2024-12-20 09:32:26+00:00,https://github.com/tensorflow/tensorflow/pull/83273,[],[],
2747843693,pull_request,closed,,[XLA:GPU] Introduce EmitterLocOpBuilder that could annotate the mlir with the file:line annotations that are visible in the triton dump,"[XLA:GPU] Introduce EmitterLocOpBuilder that could annotate the mlir with the file:line annotations that are visible in the triton dump

During the troubleshooting sessions it sometimes hard to find the emitter code that emitted the particular instruction. It make sense to instrument the emitter code and annotate the generated code with file:line info. The annotations emitting and dumping code is guarded with the --xla_dump_emitter_loc flag.
",copybara-service[bot],2024-12-18 13:36:35+00:00,[],2024-12-18 17:13:01+00:00,2024-12-18 17:13:00+00:00,https://github.com/tensorflow/tensorflow/pull/83271,[],[],
2747781294,pull_request,closed,,Clarify documentation for output_offsets operand of ragged_all_to_all.,"Clarify documentation for output_offsets operand of ragged_all_to_all.
",copybara-service[bot],2024-12-18 13:11:35+00:00,[],2024-12-20 16:08:26+00:00,2024-12-20 16:08:25+00:00,https://github.com/tensorflow/tensorflow/pull/83270,[],[],
2747780073,pull_request,closed,,[xla:cpu] replace test_xla_cpu_thunks build tags with test_xla_cpu_no_thunks,"[xla:cpu] replace test_xla_cpu_thunks build tags with test_xla_cpu_no_thunks

Thunks are the default for XLA:CPU, so the test_xla_cpu_thunks tags are redundant. Flip them to test XLA:CPU without thunks instead.
",copybara-service[bot],2024-12-18 13:11:03+00:00,[],2025-01-07 14:41:34+00:00,2025-01-07 14:41:34+00:00,https://github.com/tensorflow/tensorflow/pull/83269,[],[],
2747643331,pull_request,closed,,"[XLA:CPU] Create ""test_xla_cpu_no_thunks"" test tag","[XLA:CPU] Create ""test_xla_cpu_no_thunks"" test tag

This allows tests to be tagged ""test_xla_cpu_no_thunks"" to run the test with XLA:CPU's non-thunks runtime enabled.
",copybara-service[bot],2024-12-18 12:09:34+00:00,[],2024-12-18 12:44:13+00:00,2024-12-18 12:44:12+00:00,https://github.com/tensorflow/tensorflow/pull/83268,[],[],
2747569345,pull_request,closed,,[XLA:CPU] Emit nested computations prior to calling ElementalIrEmitter,"[XLA:CPU] Emit nested computations prior to calling ElementalIrEmitter
",copybara-service[bot],2024-12-18 11:35:16+00:00,[],2024-12-19 10:02:35+00:00,2024-12-19 10:02:33+00:00,https://github.com/tensorflow/tensorflow/pull/83266,[],[],
2747562261,pull_request,closed,,[XLA:CPU] Fix extension typos,"[XLA:CPU] Fix extension typos
",copybara-service[bot],2024-12-18 11:31:44+00:00,[],2024-12-18 12:12:20+00:00,2024-12-18 12:12:19+00:00,https://github.com/tensorflow/tensorflow/pull/83265,[],[],
2747521323,pull_request,open,,Restrict autotuner to use block_sizes <= 256 when tma is enabled,"Restrict autotuner to use block_sizes <= 256 when tma is enabled
",copybara-service[bot],2024-12-18 11:12:39+00:00,[],2024-12-18 11:12:39+00:00,,https://github.com/tensorflow/tensorflow/pull/83264,[],[],
2747513477,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 11:09:02+00:00,[],2024-12-18 11:09:02+00:00,,https://github.com/tensorflow/tensorflow/pull/83263,[],[],
2747479780,pull_request,closed,,[XLA:GPU] Simplify logic with higher level HloComputation APIs.,"[XLA:GPU] Simplify logic with higher level HloComputation APIs.
",copybara-service[bot],2024-12-18 10:53:53+00:00,[],2025-01-07 16:04:07+00:00,2025-01-07 16:04:06+00:00,https://github.com/tensorflow/tensorflow/pull/83262,[],[],
2747461603,pull_request,closed,,[XLA:GPU] Create cuda-specific api for the runtime to populate the tensor map parameter. See child cl for how this is called.,"[XLA:GPU] Create cuda-specific api for the runtime to populate the tensor map parameter. See child cl for how this is called.
",copybara-service[bot],2024-12-18 10:46:27+00:00,[],2025-01-14 16:07:10+00:00,2025-01-14 16:07:09+00:00,https://github.com/tensorflow/tensorflow/pull/83261,[],[],
2747416971,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:26:40+00:00,[],2024-12-18 10:26:40+00:00,,https://github.com/tensorflow/tensorflow/pull/83260,[],[],
2747405898,pull_request,closed,,[xla:cpu][roll forward] Improve compilation time by not fusing large constants into LLVM modules,"[xla:cpu][roll forward] Improve compilation time by not fusing large constants into LLVM modules

Fix for the breaking of a large model without thunks.
Add tests to make sure this doesn't happen again.

Reverts 067cc0b14bf9a530de508aa636ea4240d101154f
",copybara-service[bot],2024-12-18 10:21:49+00:00,[],2024-12-18 14:16:20+00:00,2024-12-18 14:16:19+00:00,https://github.com/tensorflow/tensorflow/pull/83259,[],[],
2747405746,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:21:45+00:00,[],2024-12-24 07:06:18+00:00,2024-12-24 07:06:17+00:00,https://github.com/tensorflow/tensorflow/pull/83258,[],[],
2747403764,pull_request,closed,,Create TmaDescriptor class.  This will be used to pass information about TMA between the compiler and runtime. The compiler will populate it and the runtime will create a cuda tensor map to pass it to the kernel at runtime (further along this chain of cls).,"Create TmaDescriptor class.  This will be used to pass information about TMA between the compiler and runtime. The compiler will populate it and the runtime will create a cuda tensor map to pass it to the kernel at runtime (further along this chain of cls).
",copybara-service[bot],2024-12-18 10:20:53+00:00,[],2025-01-14 11:36:34+00:00,2025-01-14 11:36:33+00:00,https://github.com/tensorflow/tensorflow/pull/83257,[],[],
2747395540,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:18:04+00:00,[],2024-12-18 10:18:04+00:00,,https://github.com/tensorflow/tensorflow/pull/83256,[],[],
2747386287,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:14:19+00:00,[],2024-12-18 10:14:19+00:00,,https://github.com/tensorflow/tensorflow/pull/83255,[],[],
2747386094,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:14:13+00:00,[],2024-12-18 11:41:13+00:00,,https://github.com/tensorflow/tensorflow/pull/83254,[],[],
2747384271,pull_request,open,,PR #20429: [PJRT] Expose `ExecutionContext` when executing a `LoadedExecutable`,"PR #20429: [PJRT] Expose `ExecutionContext` when executing a `LoadedExecutable`

Imported from GitHub PR https://github.com/openxla/xla/pull/20429

Currently, there is no way to provide an `ExecutionContext` when launching an executable. This prevents using it in custom calls through FFI.

I exposed the field in the `PJRT_ExecuteOptions` struct and wired it in `xla::ExecuteOptions`
Copybara import of the project:

--
d22969c1ed76cc52dd2b99882cd6dc8d0acc7dbc by Corentin Godeau <corentin.godeau@zml.ai>:

[PJRT] Expose ExecutionContext when executing a LoadedExecutable

--
67d8c2146239558ecae141d90aaf707823f89a7d by Corentin Godeau <corentin.godeau37@gmail.com>:

Update xla/pjrt/c/pjrt_c_api.h

Co-authored-by: Steeve Morin <steeve.morin@gmail.com>
--
5017a0ed720492ecf8d47cafd8d2b09d7222cbf8 by Corentin Godeau <corentin.godeau@zml.ai>:

Added changes to the changelog

--
7128d161701c2bf872b99d94b29ecc43a3d779d3 by Corentin Godeau <corentin.godeau@zml.ai>:

Check that `context` is non-null before dereferencing it

Merging this change closes #20429

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20429 from Corendos:corendos/pjrt-execution-context 034e6cc03e36f216392103fdb196111e3608e9f5
",copybara-service[bot],2024-12-18 10:13:22+00:00,[],2024-12-20 19:33:30+00:00,,https://github.com/tensorflow/tensorflow/pull/83253,[],[],
2747380867,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:11:46+00:00,[],2024-12-19 09:39:11+00:00,2024-12-19 09:39:10+00:00,https://github.com/tensorflow/tensorflow/pull/83252,[],[],
2747363231,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:04:04+00:00,[],2024-12-19 08:40:40+00:00,2024-12-19 08:40:40+00:00,https://github.com/tensorflow/tensorflow/pull/83251,[],[],
2747357358,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:01:29+00:00,[],2024-12-19 08:29:22+00:00,2024-12-19 08:29:21+00:00,https://github.com/tensorflow/tensorflow/pull/83250,[],[],
2747357171,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:01:25+00:00,[],2024-12-19 17:58:30+00:00,,https://github.com/tensorflow/tensorflow/pull/83249,[],[],
2747355489,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 10:00:45+00:00,[],2024-12-18 10:00:45+00:00,,https://github.com/tensorflow/tensorflow/pull/83248,[],[],
2747351946,pull_request,closed,,PR #20428: [XLA:FFI] Fix C API,"PR #20428: [XLA:FFI] Fix C API

Imported from GitHub PR https://github.com/openxla/xla/pull/20428

Some of the definition in `xla/ffi/api/c_api.h` were not valid C. I fixed them so that it's possible to import the header in a C project.
Copybara import of the project:

--
0ff4b821e3dc1511e516f5d5d9556515addbd83f by Corentin Godeau <corentin.godeau@zml.ai>:

[XLA:FFI] Fix type definitions to make it a valid C API

Merging this change closes #20428

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20428 from Corendos:corendos/fix-ffi-c-api 1eec519ab4fdc8909f2b9613ad4101d75f8d800c
",copybara-service[bot],2024-12-18 09:59:21+00:00,[],2024-12-18 11:11:42+00:00,2024-12-18 11:11:41+00:00,https://github.com/tensorflow/tensorflow/pull/83247,[],[],
2747338040,pull_request,closed,,"[XLA:GPU] Use Cub RaddixSort for f16, f32, and f64 sorts in Numpy order (NaNs go last).","[XLA:GPU] Use Cub RaddixSort for f16, f32, and f64 sorts in Numpy order (NaNs go last).
",copybara-service[bot],2024-12-18 09:53:20+00:00,['thomasjoerg'],2025-01-15 17:23:14+00:00,2025-01-15 17:23:13+00:00,https://github.com/tensorflow/tensorflow/pull/83246,[],[],
2747335480,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:52:32+00:00,[],2024-12-18 09:52:32+00:00,,https://github.com/tensorflow/tensorflow/pull/83245,[],[],
2747297022,pull_request,open,,Fix cpu non thunk execution failure.,"Fix cpu non thunk execution failure.
Add tests to ensure this doesn't fail again.

Reverts 067cc0b14bf9a530de508aa636ea4240d101154f
",copybara-service[bot],2024-12-18 09:37:25+00:00,[],2024-12-18 10:10:33+00:00,,https://github.com/tensorflow/tensorflow/pull/83244,[],[],
2747289475,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:34:08+00:00,[],2024-12-18 09:34:08+00:00,,https://github.com/tensorflow/tensorflow/pull/83243,[],[],
2747280054,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:29:49+00:00,[],2024-12-18 12:50:40+00:00,,https://github.com/tensorflow/tensorflow/pull/83242,[],[],
2747274643,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:27:41+00:00,[],2024-12-18 09:27:41+00:00,,https://github.com/tensorflow/tensorflow/pull/83241,[],[],
2747274144,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:27:30+00:00,[],2024-12-18 09:27:30+00:00,,https://github.com/tensorflow/tensorflow/pull/83240,[],[],
2747270116,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:25:46+00:00,[],2024-12-18 09:25:46+00:00,,https://github.com/tensorflow/tensorflow/pull/83239,[],[],
2747269641,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:25:34+00:00,[],2024-12-18 09:25:34+00:00,,https://github.com/tensorflow/tensorflow/pull/83238,[],[],
2747267432,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:24:35+00:00,[],2024-12-20 13:03:03+00:00,2024-12-20 13:03:02+00:00,https://github.com/tensorflow/tensorflow/pull/83237,[],[],
2747267386,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:24:34+00:00,[],2024-12-18 09:24:34+00:00,,https://github.com/tensorflow/tensorflow/pull/83236,[],[],
2747267231,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:24:30+00:00,[],2024-12-18 09:24:30+00:00,,https://github.com/tensorflow/tensorflow/pull/83235,[],[],
2747266483,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:24:11+00:00,[],2024-12-19 08:38:02+00:00,,https://github.com/tensorflow/tensorflow/pull/83234,[],[],
2747265436,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:23:41+00:00,[],2024-12-19 09:53:30+00:00,2024-12-19 09:53:29+00:00,https://github.com/tensorflow/tensorflow/pull/83233,[],[],
2747265164,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:23:33+00:00,[],2024-12-18 14:01:01+00:00,,https://github.com/tensorflow/tensorflow/pull/83232,[],[],
2747264515,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:23:16+00:00,[],2024-12-18 11:51:24+00:00,,https://github.com/tensorflow/tensorflow/pull/83231,[],[],
2747264047,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20428 from Corendos:corendos/fix-ffi-c-api 1eec519ab4fdc8909f2b9613ad4101d75f8d800c
",copybara-service[bot],2024-12-18 09:23:03+00:00,[],2024-12-18 11:20:29+00:00,,https://github.com/tensorflow/tensorflow/pull/83230,[],[],
2747263449,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:22:49+00:00,[],2024-12-18 12:44:33+00:00,,https://github.com/tensorflow/tensorflow/pull/83229,[],[],
2747262228,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:22:13+00:00,[],2024-12-18 12:13:56+00:00,,https://github.com/tensorflow/tensorflow/pull/83228,[],[],
2747261031,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:21:39+00:00,[],2024-12-20 08:27:48+00:00,2024-12-20 08:27:48+00:00,https://github.com/tensorflow/tensorflow/pull/83227,[],[],
2747254298,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:18:35+00:00,[],2024-12-18 09:18:35+00:00,,https://github.com/tensorflow/tensorflow/pull/83226,[],[],
2747249464,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:16:58+00:00,[],2024-12-18 09:16:58+00:00,,https://github.com/tensorflow/tensorflow/pull/83225,[],[],
2747249080,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:16:46+00:00,[],2024-12-18 09:16:46+00:00,,https://github.com/tensorflow/tensorflow/pull/83224,[],[],
2747248346,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:16:32+00:00,[],2024-12-24 06:12:49+00:00,2024-12-24 06:12:48+00:00,https://github.com/tensorflow/tensorflow/pull/83223,[],[],
2747248329,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:16:32+00:00,[],2024-12-18 09:16:32+00:00,,https://github.com/tensorflow/tensorflow/pull/83222,[],[],
2747244604,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:15:16+00:00,[],2024-12-18 09:15:16+00:00,,https://github.com/tensorflow/tensorflow/pull/83221,[],[],
2747241020,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:14:15+00:00,[],2024-12-18 09:14:15+00:00,,https://github.com/tensorflow/tensorflow/pull/83220,[],[],
2747239975,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 09:13:56+00:00,[],2024-12-18 09:13:56+00:00,,https://github.com/tensorflow/tensorflow/pull/83219,[],[],
2747180755,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 08:47:34+00:00,[],2024-12-18 08:47:34+00:00,,https://github.com/tensorflow/tensorflow/pull/83218,[],[],
2747074756,pull_request,closed,,Add generic graph convert function that can share legalization impls with the partition step.,"Add generic graph convert function that can share legalization impls with the partition step.
",copybara-service[bot],2024-12-18 07:57:02+00:00,['LukeBoyer'],2024-12-21 01:43:10+00:00,2024-12-21 01:43:10+00:00,https://github.com/tensorflow/tensorflow/pull/83217,[],[],
2747036593,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-18 07:36:41+00:00,[],2024-12-18 07:36:41+00:00,,https://github.com/tensorflow/tensorflow/pull/83216,[],[],
2746949011,pull_request,closed,,Add string names to example IR to make testing easier,"Add string names to example IR to make testing easier
",copybara-service[bot],2024-12-18 06:53:34+00:00,['LukeBoyer'],2024-12-21 00:05:53+00:00,2024-12-21 00:05:52+00:00,https://github.com/tensorflow/tensorflow/pull/83215,[],[],
2746831546,pull_request,closed,,Add a type name struct to avoid needing specify  template instantiations in function params.,"Add a type name struct to avoid needing specify  template instantiations in function params.
",copybara-service[bot],2024-12-18 05:41:22+00:00,['LukeBoyer'],2024-12-20 23:38:26+00:00,2024-12-20 23:38:25+00:00,https://github.com/tensorflow/tensorflow/pull/83214,[],[],
2746823982,pull_request,closed,,Refactor `PartitionedHlo::ReshardWithAllToAll` without behavior change.,"Refactor `PartitionedHlo::ReshardWithAllToAll` without behavior change.
",copybara-service[bot],2024-12-18 05:36:27+00:00,[],2024-12-18 14:27:43+00:00,2024-12-18 14:27:42+00:00,https://github.com/tensorflow/tensorflow/pull/83213,[],[],
2746705451,pull_request,closed,,Bug fix for FC per channel quantization for 3d input,,rameshkunasi,2024-12-18 04:03:26+00:00,['gbaned'],2024-12-24 09:24:03+00:00,2024-12-24 09:24:00+00:00,https://github.com/tensorflow/tensorflow/pull/83212,"[('comp:lite', 'TF Lite related issues'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2746601652,pull_request,closed,,"Public interface for legalizations and supporting types. Generic function for ""partitioning"" graph via a set of legalizations and backend hook (similar to executorch flow).","Public interface for legalizations and supporting types. Generic function for ""partitioning"" graph via a set of legalizations and backend hook (similar to executorch flow).

Also expand the example plugins to include an implementation of these types and a plugin that leverages them.
",copybara-service[bot],2024-12-18 02:41:40+00:00,['LukeBoyer'],2024-12-20 21:50:20+00:00,2024-12-20 21:50:19+00:00,https://github.com/tensorflow/tensorflow/pull/83211,[],[],
2746521735,pull_request,closed,,Reverts 4b19646e9c8cf586d3a4c400173f7b68f1ade595,"Reverts 4b19646e9c8cf586d3a4c400173f7b68f1ade595
",copybara-service[bot],2024-12-18 01:41:40+00:00,[],2024-12-18 08:17:40+00:00,2024-12-18 08:17:39+00:00,https://github.com/tensorflow/tensorflow/pull/83210,[],[],
2746507363,pull_request,closed,,Adds more logging in `SessionManager`,"Adds more logging in `SessionManager`
",copybara-service[bot],2024-12-18 01:31:01+00:00,['anshumang'],2024-12-18 09:32:12+00:00,2024-12-18 09:32:11+00:00,https://github.com/tensorflow/tensorflow/pull/83209,[],[],
2746497958,pull_request,open,,Fix the breakage caused by deleted enable_memories config,"Fix the breakage caused by deleted enable_memories config
",copybara-service[bot],2024-12-18 01:23:39+00:00,['yashk2810'],2024-12-18 01:43:19+00:00,,https://github.com/tensorflow/tensorflow/pull/83208,[],[],
2746482566,pull_request,closed,,add test for partial-auto ppermute,"add test for partial-auto ppermute
",copybara-service[bot],2024-12-18 01:12:44+00:00,['mattjj'],2024-12-19 20:34:55+00:00,2024-12-19 20:34:54+00:00,https://github.com/tensorflow/tensorflow/pull/83207,[],[],
2746435180,pull_request,closed,,Add an upper bound check on block_size in the DepthToSpace kernel.,"Add an upper bound check on block_size in the DepthToSpace kernel.

When the block size is too large, its square may overflow and cause a division by zero in output computation.
",copybara-service[bot],2024-12-18 00:40:01+00:00,[],2024-12-18 07:13:56+00:00,2024-12-18 07:13:55+00:00,https://github.com/tensorflow/tensorflow/pull/83206,[],[],
2746392459,pull_request,closed,,Make MatchShapeCoveringDynamicIndexInstruction handle non-unit slice sizes.,"Make MatchShapeCoveringDynamicIndexInstruction handle non-unit slice sizes.
",copybara-service[bot],2024-12-18 00:11:24+00:00,[],2025-01-08 19:20:30+00:00,2025-01-08 19:20:29+00:00,https://github.com/tensorflow/tensorflow/pull/83205,[],[],
2746377604,pull_request,closed,,Added DCN topology level to Megascale stats.,"Added DCN topology level to Megascale stats.
",copybara-service[bot],2024-12-18 00:02:21+00:00,[],2024-12-21 01:09:41+00:00,2024-12-21 01:09:40+00:00,https://github.com/tensorflow/tensorflow/pull/83204,[],[],
2746355175,pull_request,closed,,Delete enable_memories code in C++ since that flag is always True and cannot be turned off now.,"Delete enable_memories code in C++ since that flag is always True and cannot be turned off now.
",copybara-service[bot],2024-12-17 23:46:47+00:00,['yashk2810'],2024-12-18 00:51:39+00:00,2024-12-18 00:51:39+00:00,https://github.com/tensorflow/tensorflow/pull/83203,[],[],
2746337906,pull_request,closed,,"Replace the include of `verified_hlo_module.h` from `tensorflow/compiler/xla/tests/` to `tensorflow/compiler/xla/hlo/testlib/`, in `memory_bound_loop_optimizer_test.cc`.","Replace the include of `verified_hlo_module.h` from `tensorflow/compiler/xla/tests/` to `tensorflow/compiler/xla/hlo/testlib/`, in `memory_bound_loop_optimizer_test.cc`.
",copybara-service[bot],2024-12-17 23:33:31+00:00,['sparc1998'],2024-12-18 00:04:58+00:00,2024-12-18 00:04:57+00:00,https://github.com/tensorflow/tensorflow/pull/83202,[],[],
2746274856,pull_request,closed,,Check for null in litert_options.,"Check for null in litert_options.
",copybara-service[bot],2024-12-17 22:52:23+00:00,[],2024-12-21 01:32:51+00:00,2024-12-21 01:32:50+00:00,https://github.com/tensorflow/tensorflow/pull/83201,[],[],
2746266910,pull_request,closed,,Add num_cores to device_op_metrics_db construction.,"Add num_cores to device_op_metrics_db construction.
",copybara-service[bot],2024-12-17 22:46:45+00:00,[],2024-12-19 18:55:59+00:00,2024-12-19 18:55:59+00:00,https://github.com/tensorflow/tensorflow/pull/83200,[],[],
2746225883,pull_request,closed,,[XLA:LatencyHidingScheduler] Do not schedule a ready annotated group if doing so would cause an overlap limit to be crossed. Wait until the respective resources are released.,"[XLA:LatencyHidingScheduler] Do not schedule a ready annotated group if doing so would cause an overlap limit to be crossed. Wait until the respective resources are released.

Move the initialization of `scheduling_instruction_crosses_overlap_limit_` to `DefaultSchedulerCore::Initialize` as we now need to use it with scheduling annotation groups and it should be available before the first entry to `FindAndExtractBestNodeAvailable`.
",copybara-service[bot],2024-12-17 22:24:28+00:00,['seherellis'],2024-12-19 00:50:17+00:00,2024-12-19 00:50:17+00:00,https://github.com/tensorflow/tensorflow/pull/83199,[],[],
2746222683,pull_request,closed,,[mlir python] Migrate mhlo dialect to nanobind instead of pybind11.,"[mlir python] Migrate mhlo dialect to nanobind instead of pybind11.
",copybara-service[bot],2024-12-17 22:22:56+00:00,[],2024-12-18 16:40:53+00:00,2024-12-18 16:40:52+00:00,https://github.com/tensorflow/tensorflow/pull/83198,[],[],
2746180041,pull_request,closed,,Make TF wheel API tests manual.,"Make TF wheel API tests manual.
",copybara-service[bot],2024-12-17 22:03:12+00:00,[],2024-12-18 20:29:44+00:00,2024-12-18 20:29:43+00:00,https://github.com/tensorflow/tensorflow/pull/83197,[],[],
2746178427,pull_request,closed,,[xla:cpu] Add a flag to enable XNNPACK operations in XLA and connect XnnDotThunk to ThunkEmitter,"[xla:cpu] Add a flag to enable XNNPACK operations in XLA and connect XnnDotThunk to ThunkEmitter
",copybara-service[bot],2024-12-17 22:02:27+00:00,['ezhulenev'],2024-12-20 01:48:46+00:00,2024-12-20 01:48:45+00:00,https://github.com/tensorflow/tensorflow/pull/83196,[],[],
2746177421,pull_request,closed,,[xla:cpu:xnn] Add a very basic single-threaded XnnDotThunk,"[xla:cpu:xnn] Add a very basic single-threaded XnnDotThunk

- extract dot_lib library with a code shared between dot thunk implementations
- add xnn_status conversion to xnn_interop
",copybara-service[bot],2024-12-17 22:01:51+00:00,['ezhulenev'],2024-12-18 08:28:46+00:00,2024-12-18 08:28:45+00:00,https://github.com/tensorflow/tensorflow/pull/83195,[],[],
2746177290,pull_request,open,,Add an extra step to tag the tensorflow-sigs build image with `infrastructure-public-image-` prefix followed by its digest.,"Add an extra step to tag the tensorflow-sigs build image with `infrastructure-public-image-` prefix followed by its digest.
",copybara-service[bot],2024-12-17 22:01:45+00:00,['quoctruong'],2024-12-17 22:01:46+00:00,,https://github.com/tensorflow/tensorflow/pull/83194,[],[],
2746143496,pull_request,closed,,CompiledModel::Run() with input / output maps,"CompiledModel::Run() with input / output maps
",copybara-service[bot],2024-12-17 21:40:48+00:00,['terryheo'],2024-12-18 23:08:59+00:00,2024-12-18 23:08:58+00:00,https://github.com/tensorflow/tensorflow/pull/83193,[],[],
2746061732,pull_request,closed,,Open source SparseCoreV0 op categories.,"Open source SparseCoreV0 op categories.
",copybara-service[bot],2024-12-17 21:07:01+00:00,[],2024-12-18 02:05:16+00:00,2024-12-18 02:05:10+00:00,https://github.com/tensorflow/tensorflow/pull/83192,[],[],
2746020668,pull_request,closed,,Remove some #ifdefs and simplify some complex functions in command_buffer_cmd.cc.,"Remove some #ifdefs and simplify some complex functions in command_buffer_cmd.cc.
",copybara-service[bot],2024-12-17 20:45:25+00:00,[],2025-01-07 18:00:33+00:00,2025-01-07 18:00:32+00:00,https://github.com/tensorflow/tensorflow/pull/83191,[],[],
2745770409,pull_request,open,,Remove GitHub Actions for building tensorflow sigs Dockerfile since we have migrated to the new ML build container.,"Remove GitHub Actions for building tensorflow sigs Dockerfile since we have migrated to the new ML build container.
",copybara-service[bot],2024-12-17 18:54:23+00:00,['quoctruong'],2024-12-17 18:54:24+00:00,,https://github.com/tensorflow/tensorflow/pull/83190,[],[],
2745751361,pull_request,closed,,Clean up the reshard API from the IFRT Proxy server,"Clean up the reshard API from the IFRT Proxy server

It has been six months since we switched from `Reshard` to `CopyArrays`. Per compatibility contract, it is now safe to remove the Reshard emulation code on the proxy server.
",copybara-service[bot],2024-12-17 18:45:09+00:00,[],2024-12-17 19:39:31+00:00,2024-12-17 19:39:30+00:00,https://github.com/tensorflow/tensorflow/pull/83189,[],[],
