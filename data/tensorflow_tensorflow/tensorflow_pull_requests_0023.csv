id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2611951466,pull_request,closed,,Promote signature-related Java API methods from experimental to stable.,"Promote signature-related Java API methods from experimental to stable.

This involved also moving the declarations of those methods from the `Interpreter` class,
which is experimental, to the `InterpreterApi` interface that it implements, which is
stable.

These Java API methods were implemented in terms of C++ API methods that have already been promoted to stable, so there seems little reason for them to remain experimental, and leaving them as experimental results in undesirable API
differences between TFLite and TFLite-in-Play-services, because the latter does
not support experimental methods.
",copybara-service[bot],2024-10-24 15:33:25+00:00,[],2024-10-28 11:35:46+00:00,2024-10-28 11:35:45+00:00,https://github.com/tensorflow/tensorflow/pull/78688,[],[],
2611867622,pull_request,closed,,Explicitly tell the GpuCompiler which stream to use from PJRT during the build step.,"Explicitly tell the GpuCompiler which stream to use from PJRT during the build step.

Prior to this CL, the GpuCompiler would go ask the DeviceMemoryAllocator for the stream to use.
",copybara-service[bot],2024-10-24 14:58:03+00:00,[],2024-10-25 16:15:33+00:00,2024-10-25 16:15:27+00:00,https://github.com/tensorflow/tensorflow/pull/78687,[],[],
2611791820,pull_request,closed,,[PJRT:Python] Pass key value store to XLA compilation options.,"[PJRT:Python] Pass key value store to XLA compilation options.
",copybara-service[bot],2024-10-24 14:31:05+00:00,[],2024-10-25 09:04:06+00:00,2024-10-25 09:04:05+00:00,https://github.com/tensorflow/tensorflow/pull/78686,[],[],
2611718638,pull_request,closed,,[XLA] Remove a check that verified channel_ids for host send/recv instructions were unique.,"[XLA] Remove a check that verified channel_ids for host send/recv instructions were unique.

We can't think of why this check is needed in the first place, and it breaks as soon as one has a host send/recv inside an inner computation in the presence of inlining.

For example, consider the pseudo-code:

```
def f(...):
  send(..., channel_id=42)

def main(...):
  f(...)
  f(...)
```

If we inline `f`, then we now violate that invariant. But inlining is something that should always be safe to do.
",copybara-service[bot],2024-10-24 14:05:15+00:00,[],2024-10-24 19:51:21+00:00,2024-10-24 19:51:20+00:00,https://github.com/tensorflow/tensorflow/pull/78685,[],[],
2611681258,pull_request,closed,,[XLA:GPU] Deprecate xla_gpu_enable_priority_fusion flag.,"[XLA:GPU] Deprecate xla_gpu_enable_priority_fusion flag.

This flag has been enabled by default since Feb 2024. All users should have migrated to Priority Fusion by this time.
",copybara-service[bot],2024-10-24 13:51:11+00:00,[],2024-10-25 07:28:50+00:00,2024-10-25 07:28:49+00:00,https://github.com/tensorflow/tensorflow/pull/78684,[],[],
2611671535,pull_request,closed,,[xla:ffi] Add decoding for PlatformStream in internal FFI.,"[xla:ffi] Add decoding for PlatformStream in internal FFI.

The test coverage is limited without a GPU test configuration, but I've added a basic decoding test like the one used for the external API.
",copybara-service[bot],2024-10-24 13:47:18+00:00,[],2024-10-25 17:37:38+00:00,2024-10-25 17:37:37+00:00,https://github.com/tensorflow/tensorflow/pull/78683,[],[],
2611662055,pull_request,closed,,PR #18695: Document --xla_gpu_per_fusion_autotune_cache_dir,"PR #18695: Document --xla_gpu_per_fusion_autotune_cache_dir

Imported from GitHub PR https://github.com/openxla/xla/pull/18695

Many people use this at NVIDIA as their preferred method of caching, so now it makes sense to recommend it in the documentation.
Copybara import of the project:

--
31a7ef0607750f22fb9a857b89df5e4cf47c2089 by Thomas Danyluk <tdanyluk@nvidia.com>:

Document --xla_gpu_per_fusion_autotune_cache_dir

Many people use this at NVIDIA as their preferred method of caching,
so now it makes sense to recommend it in the documentation.

Merging this change closes #18695

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18695 from tdanyluk:tdanyluk_docs 31a7ef0607750f22fb9a857b89df5e4cf47c2089
",copybara-service[bot],2024-10-24 13:43:32+00:00,[],2024-10-24 13:56:33+00:00,2024-10-24 13:56:32+00:00,https://github.com/tensorflow/tensorflow/pull/78682,[],"[{'comment_id': 2435338657, 'issue_id': 2611662055, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78682/checks?check_run_id=32011210646) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 24, 13, 43, 37, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-24 13:43:37 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78682/checks?check_run_id=32011210646) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2611648380,pull_request,closed,,Rename C API functions for Dispatch Delegate,"Rename C API functions for Dispatch Delegate
",copybara-service[bot],2024-10-24 13:38:40+00:00,[],2024-10-24 18:01:09+00:00,2024-10-24 18:01:08+00:00,https://github.com/tensorflow/tensorflow/pull/78681,[],[],
2611633060,pull_request,closed,,Fix image display in profiler module documentation,"While reading the profiler documentation, I noticed that the images weren't showing up correctly. Then I found some `<left>` labels in the docs. These labels aren't standard HTML and were causing the images to not render properly. I checked and saw that these `<left>` labels were only in the profiler section. This pull request removes those invalid labels so the images display correctly.",wokron,2024-10-24 13:32:21+00:00,['gbaned'],2025-01-16 01:59:13+00:00,2025-01-16 01:59:08+00:00,https://github.com/tensorflow/tensorflow/pull/78680,"[('stale', 'This label marks the issue/pr stale - to be closed automatically if no activity'), ('size:S', 'CL Change Size: Small'), ('comp:core', 'issues related to core part of tensorflow')]","[{'comment_id': 2437975983, 'issue_id': 2611633060, 'author': 'mihaimaruseac', 'body': 'They might be relevant internally and would need to be removed via Copybara (same effect as this PR externally, but would need to happen via an internal change)', 'created_at': datetime.datetime(2024, 10, 25, 14, 29, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2566804232, 'issue_id': 2611633060, 'author': 'github-actions[bot]', 'body': 'This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.', 'created_at': datetime.datetime(2025, 1, 1, 2, 6, 22, tzinfo=datetime.timezone.utc)}, {'comment_id': 2594310129, 'issue_id': 2611633060, 'author': 'github-actions[bot]', 'body': ""This PR was closed because it has been inactive for 14 days since being marked as stale. Please reopen if you'd like to work on this further."", 'created_at': datetime.datetime(2025, 1, 16, 1, 59, 8, tzinfo=datetime.timezone.utc)}]","mihaimaruseac on (2024-10-25 14:29:30 UTC): They might be relevant internally and would need to be removed via Copybara (same effect as this PR externally, but would need to happen via an internal change)

github-actions[bot] on (2025-01-01 02:06:22 UTC): This PR is stale because it has been open for 14 days with no activity. It will be closed if no further activity occurs. Thank you.

github-actions[bot] on (2025-01-16 01:59:08 UTC): This PR was closed because it has been inactive for 14 days since being marked as stale. Please reopen if you'd like to work on this further.

"
2611491369,pull_request,closed,,[xla:ffi] Add typed_data() method to AnyBuffer.,"[xla:ffi] Add typed_data() method to AnyBuffer.
",copybara-service[bot],2024-10-24 12:50:46+00:00,[],2024-10-24 14:17:14+00:00,2024-10-24 14:17:13+00:00,https://github.com/tensorflow/tensorflow/pull/78679,[],[],
2611418975,pull_request,closed,,Reverts 69bddaf7237d303202108e0352a269dd5a185604,"Reverts 69bddaf7237d303202108e0352a269dd5a185604
",copybara-service[bot],2024-10-24 12:22:39+00:00,[],2024-10-24 13:15:16+00:00,2024-10-24 13:15:15+00:00,https://github.com/tensorflow/tensorflow/pull/78678,[],[],
2611409552,pull_request,open,,Update tensorflow-io-gcs-filesystem dependency,"Update tensorflow-io-gcs-filesystem dependency
",copybara-service[bot],2024-10-24 12:18:45+00:00,[],2024-10-28 08:22:46+00:00,,https://github.com/tensorflow/tensorflow/pull/78677,[],[],
2611368268,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 12:04:33+00:00,[],2024-10-24 12:04:33+00:00,,https://github.com/tensorflow/tensorflow/pull/78676,[],[],
2611341292,pull_request,closed,,Allow to pass attributes when mapping from Mhlo to Scalar.,"Allow to pass attributes when mapping from Mhlo to Scalar.

This will be used in a future change, for now it is a non-functional change.
",copybara-service[bot],2024-10-24 11:54:37+00:00,['akuegel'],2024-10-24 13:09:33+00:00,2024-10-24 13:09:30+00:00,https://github.com/tensorflow/tensorflow/pull/78675,[],[],
2611099913,pull_request,closed,,"[XLA:GPU] Add support for reshaping [1,1,...] to [] in Triton.","[XLA:GPU] Add support for reshaping [1,1,...] to [] in Triton.
",copybara-service[bot],2024-10-24 10:08:56+00:00,[],2024-10-24 12:43:44+00:00,2024-10-24 12:43:43+00:00,https://github.com/tensorflow/tensorflow/pull/78674,[],[],
2611078320,pull_request,closed,,[XLA:GPU][NFC] Expose grouping key extra args in all_reduce_combiner.,"[XLA:GPU][NFC] Expose grouping key extra args in all_reduce_combiner.

Brings up the functionality on par with {all_gather,reduce_scatter}_combiner.
",copybara-service[bot],2024-10-24 10:01:41+00:00,[],2024-11-01 09:35:55+00:00,2024-11-01 09:35:54+00:00,https://github.com/tensorflow/tensorflow/pull/78673,[],[],
2611057360,pull_request,closed,,[XLA:GPU] Fix includes in all_reduce_combiner.,"[XLA:GPU] Fix includes in all_reduce_combiner.
",copybara-service[bot],2024-10-24 09:54:18+00:00,[],2024-10-24 11:50:46+00:00,2024-10-24 11:50:45+00:00,https://github.com/tensorflow/tensorflow/pull/78672,[],[],
2611025556,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 09:39:52+00:00,[],2024-10-24 09:39:52+00:00,,https://github.com/tensorflow/tensorflow/pull/78671,[],[],
2611016868,pull_request,open,,Integrate LLVM at llvm/llvm-project@33363521ca24,"Integrate LLVM at llvm/llvm-project@33363521ca24

Updates LLVM usage to match
[33363521ca24](https://github.com/llvm/llvm-project/commit/33363521ca24)
",copybara-service[bot],2024-10-24 09:36:02+00:00,[],2024-10-24 14:15:32+00:00,,https://github.com/tensorflow/tensorflow/pull/78670,[],[],
2610998855,pull_request,closed,,[XLA:GPU] Fix includes and typo in hlo_domain_map.,"[XLA:GPU] Fix includes and typo in hlo_domain_map.
",copybara-service[bot],2024-10-24 09:29:11+00:00,[],2024-10-24 12:21:18+00:00,2024-10-24 12:21:17+00:00,https://github.com/tensorflow/tensorflow/pull/78669,[],[],
2610882948,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 08:42:52+00:00,[],2024-10-24 08:42:52+00:00,,https://github.com/tensorflow/tensorflow/pull/78668,[],[],
2610865366,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 08:34:37+00:00,[],2024-10-27 04:19:54+00:00,2024-10-27 04:19:53+00:00,https://github.com/tensorflow/tensorflow/pull/78667,[],[],
2610855832,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 08:30:23+00:00,[],2024-10-24 08:30:23+00:00,,https://github.com/tensorflow/tensorflow/pull/78666,[],[],
2610851468,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 08:28:25+00:00,[],2024-10-24 08:28:25+00:00,,https://github.com/tensorflow/tensorflow/pull/78665,[],[],
2610818840,pull_request,closed,,Reverts 91bb94cdfa6c22dcb6a4ce460717b9450307e561,"Reverts 91bb94cdfa6c22dcb6a4ce460717b9450307e561
",copybara-service[bot],2024-10-24 08:13:43+00:00,[],2024-10-25 03:23:38+00:00,2024-10-25 03:23:36+00:00,https://github.com/tensorflow/tensorflow/pull/78664,"[('ready to pull', 'PR ready for merge process')]",[],
2610762751,pull_request,closed,,[XLA:GPU] Use AtomicRMWOp in RewriteTensorInsert for i4 type.,"[XLA:GPU] Use AtomicRMWOp in RewriteTensorInsert for i4 type.

Due to packing 2 int4 values into one i8 value, we need a read modify write
sequence for writing those values. These need to happen atomically in case that
two different threads access the same memory location.
",copybara-service[bot],2024-10-24 07:47:31+00:00,['akuegel'],2024-10-24 08:32:31+00:00,2024-10-24 08:32:29+00:00,https://github.com/tensorflow/tensorflow/pull/78662,[],[],
2610679677,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 07:05:26+00:00,[],2024-10-24 07:05:26+00:00,,https://github.com/tensorflow/tensorflow/pull/78659,[],[],
2610668500,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 06:59:44+00:00,[],2024-10-24 06:59:44+00:00,,https://github.com/tensorflow/tensorflow/pull/78658,[],[],
2610467798,pull_request,closed,,[HLO] Factor out Literal to DenseElements conversion,"[HLO] Factor out Literal to DenseElements conversion

This is a useful utility for PJRT plugins that want to operate on MLIR datatypes, so better to export the method instead of allowing duplicated logic everywhere.
",copybara-service[bot],2024-10-24 05:01:34+00:00,['GleasonK'],2024-10-24 20:09:27+00:00,2024-10-24 20:09:25+00:00,https://github.com/tensorflow/tensorflow/pull/78657,[],[],
2610385742,pull_request,closed,,[PJRT] Use the least common StableHLO version between the framework and the plugin.,"[PJRT] Use the least common StableHLO version between the framework and the plugin.
",copybara-service[bot],2024-10-24 04:26:25+00:00,['GleasonK'],2024-10-24 16:57:48+00:00,2024-10-24 16:57:47+00:00,https://github.com/tensorflow/tensorflow/pull/78656,[],[],
2610311383,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:32:31+00:00,[],2024-10-24 03:32:31+00:00,,https://github.com/tensorflow/tensorflow/pull/78655,[],[],
2610307696,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:29:40+00:00,[],2024-10-29 05:22:41+00:00,2024-10-29 05:22:40+00:00,https://github.com/tensorflow/tensorflow/pull/78654,[],[],
2610304199,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:27:14+00:00,[],2024-10-24 03:27:14+00:00,,https://github.com/tensorflow/tensorflow/pull/78653,[],[],
2610303557,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:26:45+00:00,[],2024-10-24 03:26:45+00:00,,https://github.com/tensorflow/tensorflow/pull/78652,[],[],
2610302989,pull_request,closed,,Fix Reshape on BMM output pattern.,"Fix Reshape on BMM output pattern.
",copybara-service[bot],2024-10-24 03:26:20+00:00,['vamsimanchala'],2024-10-25 01:23:18+00:00,2024-10-25 01:23:17+00:00,https://github.com/tensorflow/tensorflow/pull/78651,[],[],
2610300973,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:24:50+00:00,[],2024-10-24 05:57:51+00:00,,https://github.com/tensorflow/tensorflow/pull/78650,[],[],
2610300957,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:24:49+00:00,[],2024-10-29 07:19:52+00:00,,https://github.com/tensorflow/tensorflow/pull/78649,[],[],
2610300541,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:24:31+00:00,[],2024-10-24 06:18:02+00:00,,https://github.com/tensorflow/tensorflow/pull/78648,[],[],
2610300514,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:24:30+00:00,[],2024-10-24 06:52:28+00:00,,https://github.com/tensorflow/tensorflow/pull/78647,[],[],
2610299186,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:23:36+00:00,[],2024-10-24 06:41:05+00:00,,https://github.com/tensorflow/tensorflow/pull/78646,[],[],
2610298671,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:23:23+00:00,[],2024-10-24 03:23:23+00:00,,https://github.com/tensorflow/tensorflow/pull/78645,[],[],
2610298233,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:22:56+00:00,[],2024-10-24 03:22:56+00:00,,https://github.com/tensorflow/tensorflow/pull/78644,[],[],
2610298017,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:22:41+00:00,[],2024-10-25 05:59:08+00:00,2024-10-25 05:59:07+00:00,https://github.com/tensorflow/tensorflow/pull/78643,[],[],
2610297479,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:22:05+00:00,[],2024-10-24 03:22:05+00:00,,https://github.com/tensorflow/tensorflow/pull/78642,[],[],
2610297419,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:22:02+00:00,[],2024-10-24 06:10:49+00:00,,https://github.com/tensorflow/tensorflow/pull/78641,[],[],
2610295534,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-24 03:20:02+00:00,[],2024-10-29 06:04:19+00:00,2024-10-29 06:04:18+00:00,https://github.com/tensorflow/tensorflow/pull/78640,[],[],
2610236276,pull_request,open,,Integrate LLVM at llvm/llvm-project@33363521ca24,"Integrate LLVM at llvm/llvm-project@33363521ca24

Updates LLVM usage to match
[33363521ca24](https://github.com/llvm/llvm-project/commit/33363521ca24)
",copybara-service[bot],2024-10-24 02:25:30+00:00,[],2024-10-24 02:25:30+00:00,,https://github.com/tensorflow/tensorflow/pull/78639,[],[],
2610154968,pull_request,open,,Integrate LLVM at llvm/llvm-project@141574bacb2c,"Integrate LLVM at llvm/llvm-project@141574bacb2c

Updates LLVM usage to match
[141574bacb2c](https://github.com/llvm/llvm-project/commit/141574bacb2c)
",copybara-service[bot],2024-10-24 01:23:33+00:00,[],2024-10-24 01:23:33+00:00,,https://github.com/tensorflow/tensorflow/pull/78638,[],[],
2610143280,pull_request,open,,[XLA] Fix case in which conditional_canonicalizer mishandled conditional branch computations shared between multiple conditionals.,"[XLA] Fix case in which conditional_canonicalizer mishandled conditional branch computations shared between multiple conditionals.

Clone computations rather than modifying them in place.
",copybara-service[bot],2024-10-24 01:11:09+00:00,[],2024-10-24 19:46:36+00:00,,https://github.com/tensorflow/tensorflow/pull/78637,[],[],
2610141748,pull_request,closed,,"Allow individual layouts in the `device_layouts` argument of `PjRtClient::CreateBuffersForAsyncHostToDevice` to be `std::nullopt`, meaning that those buffers should use the default device layout.","Allow individual layouts in the `device_layouts` argument of `PjRtClient::CreateBuffersForAsyncHostToDevice` to be `std::nullopt`, meaning that those buffers should use the default device layout.

This change obviates the need for the caller to generate and specify layouts for buffers that should use the default device layout.
",copybara-service[bot],2024-10-24 01:09:16+00:00,[],2024-10-24 19:39:50+00:00,2024-10-24 19:39:50+00:00,https://github.com/tensorflow/tensorflow/pull/78636,[],[],
2610138959,pull_request,closed,,Simplify CopyOnWrite implementation of HloModule::HloModuleConfig by simply using shared_ptr. ,"Simplify CopyOnWrite implementation of HloModule::HloModuleConfig by simply using shared_ptr. 
Removed unsafe reference to stale DebugOptions in CPU Compiler.
",copybara-service[bot],2024-10-24 01:05:53+00:00,[],2024-10-29 23:30:02+00:00,2024-10-29 23:30:01+00:00,https://github.com/tensorflow/tensorflow/pull/78635,[],[],
2610092651,pull_request,closed,,[XLA] Fix a miscompilation during loop constant sinking if the same body computation was shared by multiple while loops.,"[XLA] Fix a miscompilation during loop constant sinking if the same body computation was shared by multiple while loops.

The current code assumes that a while loop's body is not shared with any other while loop. It is incorrect to sink a constant from one while loop into a body shared with multiple loops (or indeed, with other non-while instructions).

It is hard to construct such a while loop with the current XlaBuilder API, which is why we have not noticed this bug until now, but it is certainly possible to do so.

Fix the problem by cloning the body/conditional computations if they need to be modified. To correctly traverse the module in the presence of cloning, also fix a long-standing TODO and traverse the module recursively from the entry computation to the leaves.
",copybara-service[bot],2024-10-24 00:18:43+00:00,[],2024-10-24 14:51:02+00:00,2024-10-24 14:51:01+00:00,https://github.com/tensorflow/tensorflow/pull/78634,[],[],
2610075146,pull_request,open,,Reverts 30b2ecdd24ec276b139d169e3f92c81d51b8a32a,"Reverts 30b2ecdd24ec276b139d169e3f92c81d51b8a32a
",copybara-service[bot],2024-10-24 00:00:50+00:00,[],2024-10-24 00:00:50+00:00,,https://github.com/tensorflow/tensorflow/pull/78633,[],[],
2610053313,pull_request,closed,,[XLA:CollectivePipeliner] Fix a bug when a loop variant appears in the root tuple multiple times. ,"[XLA:CollectivePipeliner] Fix a bug when a loop variant appears in the root tuple multiple times. 

Before this CL, we got a segfault because the first (n-1) tuple entries that have this same instruction had a nullptr in the newly-constructed output tuple, where n denotes the number of times this instruction appeared in the original tuple.
",copybara-service[bot],2024-10-23 23:43:55+00:00,['seherellis'],2024-10-24 17:27:32+00:00,2024-10-24 17:27:31+00:00,https://github.com/tensorflow/tensorflow/pull/78632,[],[],
2610045261,pull_request,open,,Fix the issue that two or more framework op scopes of same prefix/name are merged into one.,"Fix the issue that two or more framework op scopes of same prefix/name are merged into one.
",copybara-service[bot],2024-10-23 23:35:22+00:00,[],2024-10-23 23:35:22+00:00,,https://github.com/tensorflow/tensorflow/pull/78631,[],[],
2610044932,pull_request,closed,,A host-to-host copy should not be moved/removed. We'll solve this case,"A host-to-host copy should not be moved/removed. We'll solve this case
later by rewriting it into a host compute.
",copybara-service[bot],2024-10-23 23:34:57+00:00,[],2024-11-04 22:08:42+00:00,2024-11-04 22:08:41+00:00,https://github.com/tensorflow/tensorflow/pull/78630,[],[],
2610041474,pull_request,closed,,Reverts 30b2ecdd24ec276b139d169e3f92c81d51b8a32a,"Reverts 30b2ecdd24ec276b139d169e3f92c81d51b8a32a
",copybara-service[bot],2024-10-23 23:31:44+00:00,[],2024-10-23 23:59:19+00:00,2024-10-23 23:59:18+00:00,https://github.com/tensorflow/tensorflow/pull/78629,[],[],
2610039992,pull_request,closed,,Add a pattern matcher for ragged dot HLO.,"Add a pattern matcher for ragged dot HLO.
",copybara-service[bot],2024-10-23 23:30:01+00:00,[],2024-11-20 09:30:19+00:00,2024-11-20 09:30:18+00:00,https://github.com/tensorflow/tensorflow/pull/78628,[],[],
2610030849,pull_request,closed,,Disable some test cases for Complex Tan on Arm,"Disable some test cases for Complex Tan on Arm
",copybara-service[bot],2024-10-23 23:23:31+00:00,[],2024-10-24 17:37:31+00:00,2024-10-24 17:37:30+00:00,https://github.com/tensorflow/tensorflow/pull/78627,[],[],
2609999526,pull_request,open,,Integrate LLVM at llvm/llvm-project@6c4267fb1779,"Integrate LLVM at llvm/llvm-project@6c4267fb1779

Updates LLVM usage to match
[6c4267fb1779](https://github.com/llvm/llvm-project/commit/6c4267fb1779)
",copybara-service[bot],2024-10-23 22:59:39+00:00,[],2024-10-23 22:59:39+00:00,,https://github.com/tensorflow/tensorflow/pull/78626,[],[],
2609960673,pull_request,closed,,Move tensorflow/lite/experimental/lrt to tensorflow/lite/experimental/litert,"Move tensorflow/lite/experimental/lrt to tensorflow/lite/experimental/litert
",copybara-service[bot],2024-10-23 22:25:36+00:00,[],2024-10-24 05:44:41+00:00,2024-10-24 05:44:40+00:00,https://github.com/tensorflow/tensorflow/pull/78625,[],[],
2609922104,pull_request,closed,,Move node_order from translate directory to internal tf2xla directory.,"Move node_order from translate directory to internal tf2xla directory.
",copybara-service[bot],2024-10-23 21:55:14+00:00,['rocketas'],2024-10-23 22:05:14+00:00,2024-10-23 22:05:13+00:00,https://github.com/tensorflow/tensorflow/pull/78624,[],[],
2609892076,pull_request,closed,,[XLA] Make our LLVM usage more googley,"[XLA] Make our LLVM usage more googley

With the advent of heterogenuous compute, XLA compilation now encompasses sub-compilation for multiple devices. These all can use LLVM, but with different settings. Today this means it is possible for one XLA client to reinitialize LLVM's global state while another client is in the middle of compilation.

Add a global lock around our LLVM usage. Concurrent compilation is still allowed, as long as both invocations have the same set of options. This means from within the same client multiple compilation invocations should still be non-blocking.
",copybara-service[bot],2024-10-23 21:33:31+00:00,[],2024-11-13 06:09:17+00:00,2024-11-13 06:09:16+00:00,https://github.com/tensorflow/tensorflow/pull/78623,[],[],
2609871772,pull_request,closed,,[xla:GatherExpander:NFC] Move ExpandIndexVectorIntoOperandSpace to,"[xla:GatherExpander:NFC] Move ExpandIndexVectorIntoOperandSpace to
gather_scatter_utils.

So that the function can be used in ScatterExpander.
",copybara-service[bot],2024-10-23 21:18:59+00:00,['bixia1'],2024-10-23 22:18:41+00:00,2024-10-23 22:18:40+00:00,https://github.com/tensorflow/tensorflow/pull/78622,[],[],
2609728535,pull_request,closed,,Integrate LLVM at llvm/llvm-project@6c4267fb1779,"Integrate LLVM at llvm/llvm-project@6c4267fb1779

Updates LLVM usage to match
[6c4267fb1779](https://github.com/llvm/llvm-project/commit/6c4267fb1779)
",copybara-service[bot],2024-10-23 20:07:44+00:00,[],2024-10-23 22:52:51+00:00,2024-10-23 22:52:51+00:00,https://github.com/tensorflow/tensorflow/pull/78620,[],[],
2609664749,pull_request,closed,,PR #18441: [XLA:CPU][oneDNN] Fixing a bug in algebraic simplifier,"PR #18441: [XLA:CPU][oneDNN] Fixing a bug in algebraic simplifier

Imported from GitHub PR https://github.com/openxla/xla/pull/18441

This PR fixes a bug for a corner case where the code that optimizes the pattern copy->bitcast->copy produces output pattern with incorrect memory layout. Existing code blocks the optimization when combining non-contiguous dimensions but ignores the case if dim_size is 1. The change extends that blockage if we have non-contiguous dims with dim_size of 1 in between. Without the fix, this is what was happening:
input module:
`HloModule m, entry_computation_layout={(f32[3,1,2]{2,1,0})->f32[1,6]{0,1}}

ENTRY %test (parameter.1: f32[3,1,2]) -> f32[1,6] {
%parameter.1 = f32[3,1,2]{2,1,0} parameter(0)
%transpose.1 = f32[1,2,3]{1,0,2} transpose(f32[3,1,2]{2,1,0} %parameter.1), dimensions={1,2,0}
%copy.1 = f32[1,2,3]{2,1,0} copy(f32[1,2,3]{1,0,2} %transpose.1)
%bitcast.1 = f32[1,6]{1,0} bitcast(f32[1,2,3]{2,1,0} %copy.1)
ROOT %copy.2 = f32[1,6]{0,1} copy(f32[1,6]{1,0} %bitcast.1)
}`

output module:
`HloModule m, entry_computation_layout={(f32[3,1,2]{2,1,0})->f32[1,6]{0,1}}

ENTRY %test (parameter.1: f32[3,1,2]) -> f32[1,6] {
%parameter.1 = f32[3,1,2]{2,1,0} parameter(0)
%bitcast = f32[1,2,3]{1,0,2} bitcast(f32[3,1,2]{2,1,0} %parameter.1)
%bitcast.2 = f32[1,6]{1,0} bitcast(f32[1,2,3]{1,0,2} %bitcast)
ROOT %copy.2 = f32[1,6]{0,1} copy(f32[1,6]{1,0} %bitcast.2)
}`

%copy.1's functionality cannot be substituted by copy.2 (which is identical to input module), so removing copy.1 leads to incorrect order of elements of final results.
Copybara import of the project:

--
09478fac30810e3a473b83500ac5cb4959341240 by Mahmoud Abuzaina <mahmoud.abuzaina@intel.com>:

Fixing a bug in algebraic simplifier

Merging this change closes #18441

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18441 from Intel-tensorflow:mabuzain/fixing-bug-in-algsimp f5f617ded891733e5cbe8fe2483b3d3dc05bcb62
",copybara-service[bot],2024-10-23 19:31:31+00:00,[],2024-10-24 08:57:06+00:00,2024-10-24 08:57:05+00:00,https://github.com/tensorflow/tensorflow/pull/78619,[],[],
2609655822,pull_request,closed,,Remove use_bfloat16 from reduce_window_test.cc,"Remove use_bfloat16 from reduce_window_test.cc

This CL removes the use_bfloat16 flag from reduce_window_test.cc and replaces it with the test_type flag. This allows the test to be run with any of the supported float types, not just BF16.
",copybara-service[bot],2024-10-23 19:26:41+00:00,[],2024-10-24 17:10:59+00:00,2024-10-24 17:10:58+00:00,https://github.com/tensorflow/tensorflow/pull/78618,[],[],
2609641337,pull_request,closed,,[SPMD] Always colocate the `XlaSharding` metadata op with the `ReadVariableOp`.,"[SPMD] Always colocate the `XlaSharding` metadata op with the `ReadVariableOp`.

Without this annotation, the `XlaSharding` op can be placed arbitrarily, triggering a copy of the entire variable content to an arbitrary task.
",copybara-service[bot],2024-10-23 19:19:02+00:00,[],2024-10-25 05:31:22+00:00,2024-10-25 05:31:21+00:00,https://github.com/tensorflow/tensorflow/pull/78617,[],[],
2609586113,pull_request,open,,Moving some code around,"Moving some code around
",copybara-service[bot],2024-10-23 18:57:45+00:00,[],2024-10-23 18:57:45+00:00,,https://github.com/tensorflow/tensorflow/pull/78616,[],[],
2609564725,pull_request,closed,,Remove unused mlir registry from CompileOptions.,"Remove unused mlir registry from CompileOptions.
",copybara-service[bot],2024-10-23 18:50:40+00:00,[],2024-10-23 21:12:32+00:00,2024-10-23 21:12:30+00:00,https://github.com/tensorflow/tensorflow/pull/78615,[],[],
2609394054,pull_request,closed,,Update benchmark performance options to support the new GPU Delegate option.,"Update benchmark performance options to support the new GPU Delegate option.
",copybara-service[bot],2024-10-23 17:52:26+00:00,[],2024-10-29 18:53:53+00:00,2024-10-29 18:53:52+00:00,https://github.com/tensorflow/tensorflow/pull/78614,[],[],
2609273185,pull_request,closed,,Move GpuDriver::GetDriverVersion into the Executor classes.,"Move GpuDriver::GetDriverVersion into the Executor classes.
",copybara-service[bot],2024-10-23 17:02:20+00:00,[],2024-10-23 19:48:07+00:00,2024-10-23 19:48:07+00:00,https://github.com/tensorflow/tensorflow/pull/78612,[],[],
2609209312,pull_request,closed,,Use cached driver version from ComputeCapability in nvptx_compiler instead of re-fetching via GpuDriver::GetDriverVersion.,"Use cached driver version from ComputeCapability in nvptx_compiler instead of re-fetching via GpuDriver::GetDriverVersion.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18564 from openxla:fix_op_profiler_crashes 911b3cfee7d2f43859a3e4784847be8088aa2c30
",copybara-service[bot],2024-10-23 16:35:02+00:00,[],2024-10-23 17:54:16+00:00,2024-10-23 17:54:15+00:00,https://github.com/tensorflow/tensorflow/pull/78611,[],[],
2609000632,pull_request,closed,,[MHLO] Make tests for MHLO->HLO conversion tolerant of different integer suffixes in the generated HLO.,"[MHLO] Make tests for MHLO->HLO conversion tolerant of different integer suffixes in the generated HLO.

Change in preparation for another change that will cause different IDs to be emitted.
",copybara-service[bot],2024-10-23 15:20:43+00:00,[],2024-10-23 17:41:07+00:00,2024-10-23 17:41:07+00:00,https://github.com/tensorflow/tensorflow/pull/78609,[],[],
2608998570,pull_request,closed,,PR #18287: Pass the compile options for deserialization via PJRT C API,"PR #18287: Pass the compile options for deserialization via PJRT C API

Imported from GitHub PR https://github.com/openxla/xla/pull/18287

This enables JAX to supply different device assignment when deserializing single-device executables from compilation cache.

Fixes https://github.com/openxla/xla/issues/18286.
Copybara import of the project:

--
35b505bf81e90fa6762c6d45d5abb99028032769 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Pass the compile options for deserialization via PJRT C API

--
c983f61f9c61e9e1ed52f3676d590d83a2455e63 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Add compile options comment, reorder fields

--
182b4a6da6f9e584bc84ec84f88b88d9add508db by Jaroslav Sevcik <jsevcik@nvidia.com>:

Fix a little use-after-free

--
cee998286ae98cc29e2096fd52bd22caac67a5fe by Jaroslav Sevcik <jsevcik@nvidia.com>:

Rename field, improve comments

--
2b9fbd992458795c1d5bf4da5c41e69c2b55df55 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Bump minor version, changelog update

Merging this change closes #18287

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18287 from jaro-sevcik:deserialize-compile-options 2b9fbd992458795c1d5bf4da5c41e69c2b55df55
",copybara-service[bot],2024-10-23 15:20:03+00:00,[],2024-10-23 16:38:52+00:00,2024-10-23 16:38:52+00:00,https://github.com/tensorflow/tensorflow/pull/78608,[],[],
2608978056,pull_request,closed,,Internal change only,"Internal change only
",copybara-service[bot],2024-10-23 15:12:53+00:00,['changm'],2024-10-23 20:55:11+00:00,2024-10-23 20:55:09+00:00,https://github.com/tensorflow/tensorflow/pull/78607,[],[],
2608973182,pull_request,closed,,[xla:scatterExpander] Extend ScatterToLoop transformation to generate correct,"[xla:scatterExpander] Extend ScatterToLoop transformation to generate correct
code in the presence of explicit batch dimensions.

Explicit batch dimensions were recently added to scatter instructions in
https://github.com/openxla/stablehlo/pull/2084.

This CL extends the pass to consider explicit operand batch dimensions when
computing the while-loop init-value shape and the operand indices.
",copybara-service[bot],2024-10-23 15:11:19+00:00,['bixia1'],2024-10-24 18:24:01+00:00,2024-10-24 18:24:00+00:00,https://github.com/tensorflow/tensorflow/pull/78606,[],[],
2608857136,pull_request,closed,,[XLA:GPU] Re-land AllGatherDynamicSliceOptimizer in GPU compiler.,"[XLA:GPU] Re-land AllGatherDynamicSliceOptimizer in GPU compiler.

1. Fixed AG not matching dynamic slice dimension.
2. Made the pass more configurable.
",copybara-service[bot],2024-10-23 14:37:20+00:00,[],2024-10-24 08:45:37+00:00,2024-10-24 08:45:36+00:00,https://github.com/tensorflow/tensorflow/pull/78605,[],[],
2608753842,pull_request,closed,,Add IfrtIrCompileOptions proto,"Add IfrtIrCompileOptions proto
",copybara-service[bot],2024-10-23 14:06:36+00:00,[],2024-10-28 19:20:15+00:00,2024-10-28 19:20:13+00:00,https://github.com/tensorflow/tensorflow/pull/78604,[],[],
2608462127,pull_request,open,,Integrate Triton up to [68aa962e67baa191cec5aac173255abdba80db1a](https://github.com/openai/triton/commits/68aa962e67baa191cec5aac173255abdba80db1a),"Integrate Triton up to [68aa962e67baa191cec5aac173255abdba80db1a](https://github.com/openai/triton/commits/68aa962e67baa191cec5aac173255abdba80db1a)
",copybara-service[bot],2024-10-23 12:39:39+00:00,[],2024-10-23 12:39:39+00:00,,https://github.com/tensorflow/tensorflow/pull/78603,[],[],
2608341238,pull_request,closed,,Integrate LLVM at llvm/llvm-project@f58ce1152703,"Integrate LLVM at llvm/llvm-project@f58ce1152703

Updates LLVM usage to match
[f58ce1152703](https://github.com/llvm/llvm-project/commit/f58ce1152703)
",copybara-service[bot],2024-10-23 11:59:15+00:00,[],2024-10-23 16:29:28+00:00,2024-10-23 16:29:27+00:00,https://github.com/tensorflow/tensorflow/pull/78602,[],[],
2608328188,pull_request,closed,,Add a random UUID to the fingerprint proto.,"Add a random UUID to the fingerprint proto.
",copybara-service[bot],2024-10-23 11:54:42+00:00,[],2024-10-23 14:49:30+00:00,2024-10-23 14:49:29+00:00,https://github.com/tensorflow/tensorflow/pull/78601,[],[],
2608238072,pull_request,closed,,PR #18413: [XLA:CPU][oneDNN] Refactor and parameterize oneDNN convolution tests,"PR #18413: [XLA:CPU][oneDNN] Refactor and parameterize oneDNN convolution tests

Imported from GitHub PR https://github.com/openxla/xla/pull/18413

This PR refactors and parametrizes the existing tests in the oneDNN convolution test file. Each test now runs with F32, BF16 and F16 precisions on supported hardware.
Copybara import of the project:

--
396244d4681c3a15ef02efd0dd325ca84b54a5d2 by Akhil Goel <akhil.goel@intel.com>:

Refactor oneDNN convolution tests

--
52aa72063a8c90d9100ad10dc26211dd23c95e2b by Akhil Goel <akhil.goel@intel.com>:

Address review comments

--
17fb54715acd335a92d42f430e4bdc1ddd0ca3fc by Akhil Goel <akhil.goel@intel.com>:

Address review comments

--
2507d5fbee91d902657befb0f42b38516dd731fc by Akhil Goel <akhil.goel@intel.com>:

Declare templates as const char*

Merging this change closes #18413

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18413 from Intel-tensorflow:akhil/conv_fusions_3_a 2507d5fbee91d902657befb0f42b38516dd731fc
",copybara-service[bot],2024-10-23 11:25:38+00:00,[],2024-10-24 10:02:55+00:00,2024-10-24 10:02:54+00:00,https://github.com/tensorflow/tensorflow/pull/78600,[],"[{'comment_id': 2431799131, 'issue_id': 2608238072, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78600/checks?check_run_id=31943994514) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 23, 11, 25, 43, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-23 11:25:43 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78600/checks?check_run_id=31943994514) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2608130265,pull_request,closed,,Updated oss tflite schema to reflect the changes.,"Updated oss tflite schema to reflect the changes.
",copybara-service[bot],2024-10-23 10:43:54+00:00,[],2024-10-24 16:27:38+00:00,2024-10-24 16:27:36+00:00,https://github.com/tensorflow/tensorflow/pull/78599,[],[],
2608046879,pull_request,closed,,PR #18623: Fix while loop analysis,"PR #18623: Fix while loop analysis

Imported from GitHub PR https://github.com/openxla/xla/pull/18623

This PR reverts the unsafe changes to while loop analysis in PR #15417. If the loop induction variable is passed to a custom-call and the output of that custom-call is used as the loop induction variable, we cannot safely assume that the custom-call returns the loop induction variable unchanged. This PR removes this unsafe relaxation.
Copybara import of the project:

--
adbfb3edb33d4d847fcebf51a06f385fe85f7e73 by Shraiysh Vaishay <svaishay@nvidia.com>:

Fix while loop analysis

This PR reverts the unsafe changes to while loop analysis in PR #15417.
If the loop induction variable is passed to a custom-call and the output
of that custom-call is used as the loop induction variable, we cannot
safely assume that the custom-call returns the loop induction variable
unchanged. This PR removes this unsafe relaxation.

Merging this change closes #18623

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18623 from shraiysh:fix_while_loop_analysis adbfb3edb33d4d847fcebf51a06f385fe85f7e73
",copybara-service[bot],2024-10-23 10:13:32+00:00,[],2024-10-23 10:59:18+00:00,2024-10-23 10:59:17+00:00,https://github.com/tensorflow/tensorflow/pull/78598,[],[],
2607988660,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 09:53:38+00:00,[],2024-10-23 09:53:38+00:00,,https://github.com/tensorflow/tensorflow/pull/78597,[],[],
2607825759,pull_request,open,,Integrate LLVM at llvm/llvm-project@9b7be3ebe5c1,"Integrate LLVM at llvm/llvm-project@9b7be3ebe5c1

Updates LLVM usage to match
[9b7be3ebe5c1](https://github.com/llvm/llvm-project/commit/9b7be3ebe5c1)
",copybara-service[bot],2024-10-23 09:01:43+00:00,[],2024-10-23 09:01:43+00:00,,https://github.com/tensorflow/tensorflow/pull/78595,[],[],
2607722149,pull_request,closed,,Fix cl_khr_command_buffer function definition following API update,"Fix cl_khr_command_buffer function definition following API update
",copybara-service[bot],2024-10-23 08:27:00+00:00,[],2024-10-23 16:15:21+00:00,2024-10-23 16:15:19+00:00,https://github.com/tensorflow/tensorflow/pull/78594,[],[],
2607706293,pull_request,closed,,Remove dynamic tensor checks,"Remove dynamic tensor checks
",copybara-service[bot],2024-10-23 08:20:53+00:00,['alankelly'],2024-10-23 18:32:00+00:00,2024-10-23 18:31:59+00:00,https://github.com/tensorflow/tensorflow/pull/78593,[],[],
2607626655,pull_request,open,,PR #17259: Adding Strictness level to PGLE accuracy checker.,"PR #17259: Adding Strictness level to PGLE accuracy checker.

Imported from GitHub PR https://github.com/openxla/xla/pull/17259

Values for the new flag: `xla_gpu_pgle_accuracy_checker: {OFF, WARN, ERROR}`
Copybara import of the project:

--
86ccf83eb4ba4310e68cff7c92c2020fa7b1f3c7 by Shraiysh Vaishay <svaishay@nvidia.com>:

Add xla_gpu_pgle_accuracy_checker to set strictness levels

xla_gpu_pgle_accuracy_checker can take the values {OFF, WARN, ERROR}
and this flag decides what will be done when there are missing
instructions in PGLE profile: either do nothing (OFF), warn about it
(WARN) or halt compilation (ERROR)

Merging this change closes #17259

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17259 from shraiysh:pgle_strictness_levels 86ccf83eb4ba4310e68cff7c92c2020fa7b1f3c7
",copybara-service[bot],2024-10-23 07:50:13+00:00,[],2024-10-23 07:50:13+00:00,,https://github.com/tensorflow/tensorflow/pull/78592,[],[],
2607507741,pull_request,closed,,Reverts 3d95d466084fbb1412619bb35e5e0fb9e74d851e,"Reverts 3d95d466084fbb1412619bb35e5e0fb9e74d851e
",copybara-service[bot],2024-10-23 07:00:40+00:00,[],2024-10-23 08:02:24+00:00,2024-10-23 08:02:23+00:00,https://github.com/tensorflow/tensorflow/pull/78590,[],[],
2607488755,pull_request,closed,,Add GetMetadata to opaque lite/c/c_api_opaque.,"Add GetMetadata to opaque lite/c/c_api_opaque.

Rather trivial, function already exists on the regular TfLiteContext.
",copybara-service[bot],2024-10-23 06:54:12+00:00,['LukeBoyer'],2024-10-29 21:44:03+00:00,2024-10-29 21:44:02+00:00,https://github.com/tensorflow/tensorflow/pull/78589,[],[],
2607464909,pull_request,closed,,"Add median, p5 and p95 latency to TFLite benchmark tool results.","Add median, p5 and p95 latency to TFLite benchmark tool results.
",copybara-service[bot],2024-10-23 06:43:56+00:00,[],2024-11-05 03:41:44+00:00,2024-11-05 03:41:43+00:00,https://github.com/tensorflow/tensorflow/pull/78588,[],[],
2607421023,pull_request,open,,PR #78037: Fix documentation ,"PR #78037: Fix documentation 

Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/78037

This pull request includes minor updates to the documentation files `CONTRIBUTING.md` and `SECURITY.md`. The changes correct formatting issues and clarify the text.

Documentation updates:

* [`CONTRIBUTING.md`](diffhunk://#diff-eca12c0a30e25b4b46522ebf89465a03ba72a03f540796c979137931d8f92055L236-R237): Fixed a formatting issue in the description of unsupported Docker images for development. (`tensorflow/tensorflow:devel` and `tensorflow/tensorflow:devel-gpu`) are no longer supported for development.
* [`SECURITY.md`](diffhunk://#diff-f6ed156e4bf5c791680662464b94ea5d753f219ee816b385f67870e2c0d7d4c7L169-R169): Corrected a typographical error in the section outlining the recognition of vulnerabilities.
Copybara import of the project:

--
b8dc3fe58831660c5fe2e387e6013c9e95389ef7 by Ankur Singh <ankursingh91002@gmail.com>:

fix typo
--
a8be9e2dbeaba73b8901bb3926cdc4e5ab5b14b6 by Ankur Singh <ankursingh91002@gmail.com>:

removed extra period
--
48bb7716787375ccbceb0d357cc232fe5675b711 by Mihai Maruseac <mihai.maruseac@gmail.com>:

Fix wording about unsupported images

Merging this change closes #78037

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/78037 from ankur0904:fix-documentation 48bb7716787375ccbceb0d357cc232fe5675b711
",copybara-service[bot],2024-10-23 06:23:52+00:00,[],2024-10-23 06:23:52+00:00,,https://github.com/tensorflow/tensorflow/pull/78587,[],[],
2607367323,pull_request,closed,,Fix typos in documentation strings,"Hi, Team
I observed few typos in the documentation strings and I have fixed those typos so please do the needful. Thank you.",Venkat6871,2024-10-23 05:56:38+00:00,['gbaned'],2024-10-27 00:17:54+00:00,2024-10-27 00:17:54+00:00,https://github.com/tensorflow/tensorflow/pull/78586,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small')]",[],
2607355190,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:51:39+00:00,[],2024-10-23 10:09:11+00:00,2024-10-23 10:09:11+00:00,https://github.com/tensorflow/tensorflow/pull/78585,[],[],
2607348525,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:47:47+00:00,[],2024-10-23 09:28:58+00:00,,https://github.com/tensorflow/tensorflow/pull/78584,[],[],
2607348389,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:47:43+00:00,[],2024-10-29 09:45:22+00:00,2024-10-29 09:45:22+00:00,https://github.com/tensorflow/tensorflow/pull/78583,[],[],
2607342586,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:45:29+00:00,[],2024-10-23 07:52:51+00:00,,https://github.com/tensorflow/tensorflow/pull/78582,[],[],
2607334661,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:41:19+00:00,[],2024-10-23 06:22:36+00:00,,https://github.com/tensorflow/tensorflow/pull/78581,[],[],
2607334280,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:41:01+00:00,[],2024-10-23 05:41:01+00:00,,https://github.com/tensorflow/tensorflow/pull/78580,[],[],
2607332521,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18441 from Intel-tensorflow:mabuzain/fixing-bug-in-algsimp f5f617ded891733e5cbe8fe2483b3d3dc05bcb62
",copybara-service[bot],2024-10-23 05:39:40+00:00,[],2024-10-24 09:51:35+00:00,2024-10-24 09:51:34+00:00,https://github.com/tensorflow/tensorflow/pull/78579,[],[],
2607327632,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:38:19+00:00,[],2024-10-23 05:38:19+00:00,,https://github.com/tensorflow/tensorflow/pull/78578,[],[],
2607311815,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:31:35+00:00,[],2024-10-23 05:31:35+00:00,,https://github.com/tensorflow/tensorflow/pull/78577,[],[],
2607304955,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 05:28:39+00:00,[],2024-10-23 08:01:46+00:00,,https://github.com/tensorflow/tensorflow/pull/78576,[],[],
2607217300,pull_request,closed,,test,test,shuern,2024-10-23 04:46:03+00:00,['gbaned'],2024-10-23 12:05:32+00:00,2024-10-23 04:46:22+00:00,https://github.com/tensorflow/tensorflow/pull/78575,"[('size:XS', 'CL Change Size: Extra Small')]","[{'comment_id': 2430882716, 'issue_id': 2607217300, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78575/checks?check_run_id=31927068290) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 23, 4, 46, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431906570, 'issue_id': 2607217300, 'author': 'mihaimaruseac', 'body': ""Please don't spam"", 'created_at': datetime.datetime(2024, 10, 23, 12, 5, 27, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-23 04:46:08 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78575/checks?check_run_id=31927068290) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

mihaimaruseac on (2024-10-23 12:05:27 UTC): Please don't spam

"
2607194466,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/76626 from sandeepgupta12:master 218fff0b2be03c50779d8532c750d18dc66da283
",copybara-service[bot],2024-10-23 04:34:47+00:00,[],2024-10-23 07:15:02+00:00,,https://github.com/tensorflow/tensorflow/pull/78574,[],[],
2607191774,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:33:22+00:00,[],2024-10-23 04:33:22+00:00,,https://github.com/tensorflow/tensorflow/pull/78573,[],[],
2607186684,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:31:25+00:00,[],2024-10-23 04:31:25+00:00,,https://github.com/tensorflow/tensorflow/pull/78572,[],[],
2607186091,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:31:05+00:00,[],2024-10-23 04:31:05+00:00,,https://github.com/tensorflow/tensorflow/pull/78571,[],[],
2607184534,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:30:24+00:00,[],2024-10-23 04:30:24+00:00,,https://github.com/tensorflow/tensorflow/pull/78570,[],[],
2607175448,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:25:27+00:00,[],2024-10-23 04:25:27+00:00,,https://github.com/tensorflow/tensorflow/pull/78569,[],[],
2607174517,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:24:49+00:00,[],2024-10-23 04:24:49+00:00,,https://github.com/tensorflow/tensorflow/pull/78568,[],[],
2607167257,pull_request,closed,,Add dep on cuda_driver from cuda_executor since cuda_executor relies on the implementation of GpuDriver::CreateGraph in cuda_driver.,"Add dep on cuda_driver from cuda_executor since cuda_executor relies on the implementation of GpuDriver::CreateGraph in cuda_driver.
",copybara-service[bot],2024-10-23 04:20:22+00:00,['BrianWieder'],2024-10-23 15:25:35+00:00,2024-10-23 15:25:33+00:00,https://github.com/tensorflow/tensorflow/pull/78567,[],[],
2607166915,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:20:07+00:00,[],2024-10-23 04:20:07+00:00,,https://github.com/tensorflow/tensorflow/pull/78566,[],[],
2607165239,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:19:06+00:00,[],2024-10-23 04:19:06+00:00,,https://github.com/tensorflow/tensorflow/pull/78565,[],[],
2607165106,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:19:00+00:00,[],2024-10-23 04:19:00+00:00,,https://github.com/tensorflow/tensorflow/pull/78564,[],[],
2607164416,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18441 from Intel-tensorflow:mabuzain/fixing-bug-in-algsimp f5f617ded891733e5cbe8fe2483b3d3dc05bcb62
",copybara-service[bot],2024-10-23 04:18:37+00:00,[],2024-10-24 09:03:56+00:00,,https://github.com/tensorflow/tensorflow/pull/78563,[],[],
2607163438,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:17:57+00:00,[],2024-10-23 04:17:57+00:00,,https://github.com/tensorflow/tensorflow/pull/78562,[],[],
2607163190,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:17:48+00:00,[],2024-10-23 04:17:48+00:00,,https://github.com/tensorflow/tensorflow/pull/78561,[],[],
2607161496,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:16:57+00:00,[],2024-10-23 04:16:57+00:00,,https://github.com/tensorflow/tensorflow/pull/78560,[],[],
2607161468,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 04:16:55+00:00,[],2024-10-23 04:16:55+00:00,,https://github.com/tensorflow/tensorflow/pull/78559,[],[],
2607106239,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 03:44:05+00:00,[],2024-10-23 03:44:05+00:00,,https://github.com/tensorflow/tensorflow/pull/78558,[],[],
2607099626,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 03:41:02+00:00,[],2024-10-23 03:41:02+00:00,,https://github.com/tensorflow/tensorflow/pull/78557,[],[],
2607095595,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 03:40:05+00:00,[],2024-10-23 03:40:05+00:00,,https://github.com/tensorflow/tensorflow/pull/78556,[],[],
2607092878,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 03:39:07+00:00,[],2024-10-23 03:39:07+00:00,,https://github.com/tensorflow/tensorflow/pull/78555,[],[],
2607087684,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 03:35:54+00:00,[],2024-10-23 03:35:54+00:00,,https://github.com/tensorflow/tensorflow/pull/78554,[],[],
2607082968,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-23 03:33:37+00:00,[],2024-10-23 03:33:37+00:00,,https://github.com/tensorflow/tensorflow/pull/78553,[],[],
2607038412,pull_request,closed,,[IFRT] Add IFRT IR passes for compiling atom programs.,"[IFRT] Add IFRT IR passes for compiling atom programs.
",copybara-service[bot],2024-10-23 03:04:08+00:00,[],2024-10-24 21:21:25+00:00,2024-10-24 21:21:24+00:00,https://github.com/tensorflow/tensorflow/pull/78552,[],[],
2607009904,pull_request,closed,,Set up a ragged dot HLO instruction.,"Set up a ragged dot HLO instruction.
",copybara-service[bot],2024-10-23 02:48:01+00:00,[],2024-11-13 18:38:21+00:00,2024-11-13 18:38:19+00:00,https://github.com/tensorflow/tensorflow/pull/78551,[],[],
2606863964,pull_request,closed,,Add GC support for PyTreeRegistry.,"Add GC support for PyTreeRegistry.

Move the default PyTreeRegistry to be managed by the Python runtime rather than C++ to simplify the cleanup of the default registry.
",copybara-service[bot],2024-10-23 01:17:12+00:00,['BrianWieder'],2024-10-31 18:35:57+00:00,2024-10-31 18:35:56+00:00,https://github.com/tensorflow/tensorflow/pull/78550,[],[],
2606751536,pull_request,closed,,Add explicit GPU platforms to exhaustive tests,"Add explicit GPU platforms to exhaustive tests

Platform `""gpu""` adds the `""gpu_any""` platform, which runs on any available GPU, which could be P100, V100, H100, B100. However, we were not explicitly generating those targets to verify if they would pass. Fortunately, they do seem to pass already so no extra work is necessary.

Lastly, removes `gpu_any` and `gpu_amd_any` as backends since it's not helpful for test flakes if we're not sure what the actual backend was that flaked.
",copybara-service[bot],2024-10-22 23:34:05+00:00,[],2024-12-02 22:17:46+00:00,2024-12-02 22:17:45+00:00,https://github.com/tensorflow/tensorflow/pull/78549,[],[],
2606672984,pull_request,closed,,[XLA Metrics] Add GenericPassMetrics proto support,"[XLA Metrics] Add GenericPassMetrics proto support
",copybara-service[bot],2024-10-22 22:41:59+00:00,[],2024-10-31 17:10:11+00:00,2024-10-31 17:10:10+00:00,https://github.com/tensorflow/tensorflow/pull/78548,"[('ready to pull', 'PR ready for merge process')]",[],
2606649490,pull_request,open,,No-op change for OSS,"No-op change for OSS
",copybara-service[bot],2024-10-22 22:26:12+00:00,['ddunl'],2024-11-01 22:18:56+00:00,,https://github.com/tensorflow/tensorflow/pull/78547,[],[],
2606639951,pull_request,closed,,[xla:cpu][oneDNN] Add missing header and deps for OneDnnFusionConfig.,"[xla:cpu][oneDNN] Add missing header and deps for OneDnnFusionConfig.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18564 from openxla:fix_op_profiler_crashes 911b3cfee7d2f43859a3e4784847be8088aa2c30
",copybara-service[bot],2024-10-22 22:18:10+00:00,[],2024-10-23 18:05:12+00:00,2024-10-23 18:05:12+00:00,https://github.com/tensorflow/tensorflow/pull/78546,[],[],
2606637501,pull_request,closed,,"Convert any compute on host memory into host compute, including dynamic-slice.","Convert any compute on host memory into host compute, including dynamic-slice.
",copybara-service[bot],2024-10-22 22:16:06+00:00,['SandSnip3r'],2024-11-15 14:10:35+00:00,2024-11-15 14:10:33+00:00,https://github.com/tensorflow/tensorflow/pull/78545,[],[],
2606587255,pull_request,closed,,[StableHLO] Fix VhloToVersion to target the patch v0 opset,"[StableHLO] Fix VhloToVersion to target the patch v0 opset

Opset changes warrant a minor version bump, so this conversion assumes patch v0 since it is written against the opset at version `X.Y.0`.
",copybara-service[bot],2024-10-22 21:45:23+00:00,['GleasonK'],2024-10-22 23:01:30+00:00,2024-10-22 23:01:29+00:00,https://github.com/tensorflow/tensorflow/pull/78544,[],[],
2606549966,pull_request,open,,Reverts 2fa3c1f627991965d19a14d7de6287521412cd39,"Reverts 2fa3c1f627991965d19a14d7de6287521412cd39
",copybara-service[bot],2024-10-22 21:26:21+00:00,[],2024-10-22 21:26:21+00:00,,https://github.com/tensorflow/tensorflow/pull/78543,[],[],
2606500338,pull_request,closed,,Stop using DeviceMemoryAllocator where it's not needed.,"Stop using DeviceMemoryAllocator where it's not needed.
",copybara-service[bot],2024-10-22 21:01:46+00:00,[],2024-10-23 17:21:45+00:00,2024-10-23 17:21:45+00:00,https://github.com/tensorflow/tensorflow/pull/78542,[],[],
2606454362,pull_request,closed,,Fix `HloHardwareIndependentTestBase` const correctness.,"Fix `HloHardwareIndependentTestBase` const correctness.

Member functions in `HloHardwareIndependentTestBase` largely don't need to be
mutating. This patch makes them `const`. This patch also makes functions that
don't require access to `this` static.
",copybara-service[bot],2024-10-22 20:42:48+00:00,[],2024-10-23 18:21:27+00:00,2024-10-23 18:21:25+00:00,https://github.com/tensorflow/tensorflow/pull/78541,[],[],
2606449997,pull_request,closed,,Make `GetDebugOptionsForTest` const.,"Make `GetDebugOptionsForTest` const.

GetDebugOptionsForTest does not need mutating access to `this`.
",copybara-service[bot],2024-10-22 20:40:28+00:00,[],2024-10-23 15:37:00+00:00,2024-10-23 15:36:59+00:00,https://github.com/tensorflow/tensorflow/pull/78540,[],[],
2606401689,pull_request,closed,,Add quantization support for TF custom ops in specific cases.,"Add quantization support for TF custom ops in specific cases.

Adds quantization support for TF custom ops marked with the following attrs:
* ""_output_quantized"" = true
* ""_support_output_type_float_in_quantized_op"" = true
* ""_output_types"" = [<list of types matching outputs>]

This is a very specific case of an op which is typically the final op in the
graph and receives quantized inputs and produces float outputs. A concrete
example of an op that meets this criteria is the commonly used
`tf.TFLite_Detection_PostProcess` op.

This change helps to achieve full-integer quantization on some graphs that
are currently only partially quantized with the MLIR converter.
",copybara-service[bot],2024-10-22 20:16:28+00:00,['arfaian'],2024-10-24 17:49:01+00:00,2024-10-24 17:48:59+00:00,https://github.com/tensorflow/tensorflow/pull/78539,[],[],
2606385885,pull_request,open,,Align method signature in .h and .cc files.,"Align method signature in .h and .cc files.
",copybara-service[bot],2024-10-22 20:08:42+00:00,[],2024-10-22 20:08:42+00:00,,https://github.com/tensorflow/tensorflow/pull/78538,[],[],
2606373808,pull_request,closed,,Fix flex:delegate target in LiteRT by exposing viable targets and cleaning deps for tensorflow targets,"Fix flex:delegate target in LiteRT by exposing viable targets and cleaning deps for tensorflow targets
",copybara-service[bot],2024-10-22 20:02:32+00:00,['ecalubaquib'],2024-10-24 19:09:56+00:00,2024-10-24 19:09:55+00:00,https://github.com/tensorflow/tensorflow/pull/78537,[],[],
2606321164,pull_request,closed,,Support rewriting parameters in the BatchFunction op,"Support rewriting parameters in the BatchFunction op
",copybara-service[bot],2024-10-22 19:39:59+00:00,['lh-pc'],2024-11-11 23:23:17+00:00,2024-11-11 23:23:16+00:00,https://github.com/tensorflow/tensorflow/pull/78536,[],[],
2606311452,pull_request,closed,,[IFRT] Add pass to convert a ifrt.reshard to an ifrt.call.,"[IFRT] Add pass to convert a ifrt.reshard to an ifrt.call.
",copybara-service[bot],2024-10-22 19:35:04+00:00,[],2024-10-23 02:36:49+00:00,2024-10-23 02:36:48+00:00,https://github.com/tensorflow/tensorflow/pull/78535,[],[],
2606261435,pull_request,open,,[hlo-translate] Use  `mlir::mlirTranslateMain` in xla_translate_main.cc.,"[hlo-translate] Use  `mlir::mlirTranslateMain` in xla_translate_main.cc.

Tool will reuse the predefined options instead defining them. All the existing options are supported by `mlir::mlirTranslateMain`
",copybara-service[bot],2024-10-22 19:10:11+00:00,[],2024-10-23 21:22:20+00:00,,https://github.com/tensorflow/tensorflow/pull/78534,[],[],
2606191703,pull_request,closed,,"Adjust XLA dependencies on stream_executor targets to prefer narrower dependencies rather than the large ""stream_executor"" dependency.","Adjust XLA dependencies on stream_executor targets to prefer narrower dependencies rather than the large ""stream_executor"" dependency.
",copybara-service[bot],2024-10-22 18:36:12+00:00,[],2024-10-22 23:24:19+00:00,2024-10-22 23:24:18+00:00,https://github.com/tensorflow/tensorflow/pull/78533,[],[],
2606048763,pull_request,open,,"[XLA] Add support for sharing computations to XlaBuilder, and use it in MHLO to HLO conversion.","[XLA] Add support for sharing computations to XlaBuilder, and use it in MHLO to HLO conversion.

Currently XlaBuilder, by construction, always creates a copy of any subcomputations that are passed to, say, Call. If the same computation is passed to multiple Calls, then it is duplicated each time.

This change changes XlaBuilder to allow creating a subcomputation once and reusing it multiple times, and changes the MHLO to HLO conversion code to use it.

To achieve reuse, we need to be able to refer to a computation embedded in an XlaBuilder multiple times. The current XlaComputation type passed into builder methods contains a copy of the computation; instead we need something more like a reference. This change introduces a new handle class XlaComputationId that refers to a computation embedded in an XlaBuilder or its parents. A inner computation can be created once and used multiple times by passing the resulting XlaComputationId where previously an XlaComputation was expected.

To maintain backwards compatibility with existing XlaBuilder users, we keep overloads that accept `XlaComputation` as well, deferring any migration of those users to a possible future change.

We add two ways to build an XlaComputationId:
* a method `XlaBuilder::AddSubComputation`, which adds an `XlaComputation` to a builder and returns its ID. This method primarily exists for backwards compatibility.
* a method `XlaBuilder::BuildSubComputation`, which adds the contents of a sub-builder to its parent as an an embedded computation.

as well as a helper that turns out to be helpful for the MHLO->HLO conversion case where we want to treat the entry function the same way as other functions;
* a new overload `XlaBuilder::Build(XlaComputationId)` that can be used to convert an embedded computation into an `XlaComputation`.
",copybara-service[bot],2024-10-22 17:23:21+00:00,[],2024-10-24 19:51:07+00:00,,https://github.com/tensorflow/tensorflow/pull/78532,[],[],
2605923243,pull_request,closed,,[XLA:GPU] Add a flag to create new Triton fusions in Priority Fusion pass.,"[XLA:GPU] Add a flag to create new Triton fusions in Priority Fusion pass.

This also changes a bit how Priority Fusion works with Triton fusion:

* `--xla_gpu_experimental_enable_triton_softmax_priority_fusion` enables `SoftmaxRewriterTriton`, but doesn't affect `PriorityFusion`.
* By default Priority Fusion doesn't create new Triton fusions. If there is a Generic Triton fusion that was created before, Priority Fusion will try to fuse more into it regardless of flags. Current default state is that there are no generic Triton fusions created in the pipeline (only GEMMs), so it doesn't affect end users.
* With `--xla_gpu_experimental_enable_triton_heroless_priority_fusion`, `PriorityFusion` will try to tile any new producer-consumer fusion and target to Triton.
",copybara-service[bot],2024-10-22 16:23:27+00:00,[],2024-10-24 12:12:29+00:00,2024-10-24 12:12:27+00:00,https://github.com/tensorflow/tensorflow/pull/78530,[],[],
2605884650,pull_request,closed,,xla_gpu_compile_test: Remove unneeded --config=cuda requirement.,"xla_gpu_compile_test: Remove unneeded --config=cuda requirement.
",copybara-service[bot],2024-10-22 16:04:17+00:00,[],2024-10-22 16:36:50+00:00,2024-10-22 16:36:48+00:00,https://github.com/tensorflow/tensorflow/pull/78529,[],[],
2605831636,pull_request,closed,,Logs the maximum total memory across all time steps in the Auto Sharding solution.,"Logs the maximum total memory across all time steps in the Auto Sharding solution.
",copybara-service[bot],2024-10-22 15:42:57+00:00,[],2024-10-22 17:57:38+00:00,2024-10-22 17:57:37+00:00,https://github.com/tensorflow/tensorflow/pull/78528,[],[],
2605589253,pull_request,closed,,[XLA:GPU] Inline element type replacement into CreateGep method (NFC),"[XLA:GPU] Inline element type replacement into CreateGep method (NFC)
",copybara-service[bot],2024-10-22 14:13:29+00:00,['akuegel'],2024-10-22 15:02:25+00:00,2024-10-22 15:02:24+00:00,https://github.com/tensorflow/tensorflow/pull/78527,[],[],
2605502556,pull_request,closed,,[GpuCommandBuffer] Move graph instantiation into subclasses,"[GpuCommandBuffer] Move graph instantiation into subclasses

This moves the `GraphInstantiate` calls from `GpuCommandBuffer` into its subclasses. The required GpuDriver function gets also moved into the subclass .cc files.
",copybara-service[bot],2024-10-22 13:42:43+00:00,[],2024-10-30 10:05:18+00:00,2024-10-30 10:05:17+00:00,https://github.com/tensorflow/tensorflow/pull/78526,[],[],
2605491546,pull_request,closed,,[GpuCommandBuffer] Move GraphDebugDotPrint calls into command buffer subclasses,"[GpuCommandBuffer] Move GraphDebugDotPrint calls into command buffer subclasses

Also inlines the GpuDriver call.
",copybara-service[bot],2024-10-22 13:39:09+00:00,[],2024-10-29 14:43:24+00:00,2024-10-29 14:43:22+00:00,https://github.com/tensorflow/tensorflow/pull/78525,[],[],
2605482297,pull_request,closed,,[GpuCommandBuffer] Move conditional node creation to subclasses,"[GpuCommandBuffer] Move conditional node creation to subclasses

`CreateConditionalNode` becames a pure virtual function declaration and gets implemented in `CudaCommandBuffer` and `RocmCommandBuffer`.

Both implementations inline their GpuDriver calls.
",copybara-service[bot],2024-10-22 13:35:33+00:00,[],2024-10-29 13:59:55+00:00,2024-10-29 13:59:53+00:00,https://github.com/tensorflow/tensorflow/pull/78524,[],[],
2605479283,pull_request,closed,,[XLA:GPU] Strip the null character when dumping the ptxas warning.,"[XLA:GPU] Strip the null character when dumping the ptxas warning.

The ptxas output contains trailing newline AND null character, which prevented previous attempt in https://github.com/openxla/xla/pull/18381. Actually, LOG already stripts trailing newlines (but not null characters), so this change includes rolling back https://github.com/openxla/xla/pull/18381.
",copybara-service[bot],2024-10-22 13:34:19+00:00,[],2024-10-23 21:44:14+00:00,2024-10-23 21:44:14+00:00,https://github.com/tensorflow/tensorflow/pull/78523,[],[],
2605456113,pull_request,closed,,[GpuCommandBuffer] Make CreateConditionalNode handle a single node instead of having CreateConditionalNodes,"[GpuCommandBuffer] Make CreateConditionalNode handle a single node instead of having CreateConditionalNodes

`CreateConditionalNode` is more composable and can be moved into the subclasses this way.
",copybara-service[bot],2024-10-22 13:25:13+00:00,[],2024-10-29 13:06:31+00:00,2024-10-29 13:06:30+00:00,https://github.com/tensorflow/tensorflow/pull/78522,[],[],
2605445949,pull_request,closed,,[GpuCommandBuffer] Move nested command buffer creation into CreateConditionalNodes,"[GpuCommandBuffer] Move nested command buffer creation into CreateConditionalNodes

With that change `GpuCommandBuffer` doesn't need to know about `GpuGraphHandle`s anymore since they are handled in `CreateConditionalNodes`.
",copybara-service[bot],2024-10-22 13:21:11+00:00,[],2024-10-29 11:56:55+00:00,2024-10-29 11:56:54+00:00,https://github.com/tensorflow/tensorflow/pull/78521,[],[],
2605426952,pull_request,closed,,[GpuCommandBuffer] Rename CreateConditionalCommand to ConditionalCommand,"[GpuCommandBuffer] Rename CreateConditionalCommand to ConditionalCommand

This aligns the function name with the naming scheme that is used everywhere else in the class. `Create...` functions are factory functions for new command nodes. Functions that add or update nodes are just named by the type of the node.
",copybara-service[bot],2024-10-22 13:14:23+00:00,[],2024-10-29 10:28:34+00:00,2024-10-29 10:28:33+00:00,https://github.com/tensorflow/tensorflow/pull/78520,[],[],
2605421125,pull_request,closed,,[GpuCommandBuffer] Move launches of set-condition-kernels entirely into subclasses,"[GpuCommandBuffer] Move launches of set-condition-kernels entirely into subclasses

The platform specific set-condition-kernels used to be accessed by `GpuCommandBuffer` through pure virtual factory function. This is not enough though since these kernels get a `GpuGraphConditionalHandle` as a parameter. To avoid having this handle in `GpuCommandBuffer`, this change moves the CommandBuffer launch call into the subclasses.

These launch functions can take a `GraphConditional` pointer and retrieve the `GpuGraphConditionalHandle` before launching the kernel.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/78136 from vsilyaev:pull_request/Correct_syntax_for_ARM_assembly 5fb05f6eff5aaf89c357ecd0cbd090e3cefb8fc1
",copybara-service[bot],2024-10-22 13:11:58+00:00,[],2024-10-29 09:08:49+00:00,2024-10-29 09:08:48+00:00,https://github.com/tensorflow/tensorflow/pull/78519,[],[],
2605416927,pull_request,closed,,Introduce base class GraphConditional,"Introduce base class GraphConditional

A `GraphConditional` represents a conditional in a command buffer and is an opaque handle that can be passed to set-condition kernels. (A set-condition kernel sets the value of the conditional based on whether the associated nested commmand buffer should be executed or not.)

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/78711 from tensorflow:gaikwadrahul8-patch-1 cebb1cbbb19b08a44a3c6ab7ecb2c8e3bfd964d4
",copybara-service[bot],2024-10-22 13:10:16+00:00,[],2024-10-29 08:35:07+00:00,2024-10-29 08:35:07+00:00,https://github.com/tensorflow/tensorflow/pull/78518,[],[],
2605411614,pull_request,closed,,[XLA:GPU] Hook in GpuReduceScatterCombiner into a gpu_compiler.cc.,"[XLA:GPU] Hook in GpuReduceScatterCombiner into a gpu_compiler.cc.
",copybara-service[bot],2024-10-22 13:07:58+00:00,[],2024-11-01 09:57:56+00:00,2024-11-01 09:57:55+00:00,https://github.com/tensorflow/tensorflow/pull/78517,[],[],
2605388840,pull_request,closed,,[GpuCommandBuffer] Move GraphGetNodeCount calls into subclasses,"[GpuCommandBuffer] Move GraphGetNodeCount calls into subclasses

- Introduce pure virtual function `GpuCommandBuffer::GetNodeCount() const` which returns the number of nodes in the underlying graph
- Replace direct `GpuDriver::GraphGetNodeCount` calls by calls to `GpuCommandBuffer::GetNodeCount`
- Inline `GpuDriver::GraphGetNodeCount` into the implementations of `GpuCommandBuffer::GetNodeCount`
",copybara-service[bot],2024-10-22 12:59:30+00:00,[],2024-10-29 07:35:28+00:00,2024-10-29 07:35:27+00:00,https://github.com/tensorflow/tensorflow/pull/78516,[],[],
2605373029,pull_request,closed,,PR #18562: Compute cost tool: add an option to print costs of each instruction.,"PR #18562: Compute cost tool: add an option to print costs of each instruction.

Imported from GitHub PR https://github.com/openxla/xla/pull/18562


Copybara import of the project:

--
314f9646442329c3cf99b5b339e81866d37d241c by Ilia Sergachev <isergachev@nvidia.com>:

Compute cost tool: add an option to print costs of each instruction.

--
4e5ea3ba30209e76d3ffd09a3d70dcc526200552 by Ilia Sergachev <isergachev@nvidia.com>:

address review comments

Merging this change closes #18562

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18562 from openxla:compute_cost_all 4e5ea3ba30209e76d3ffd09a3d70dcc526200552
",copybara-service[bot],2024-10-22 12:53:02+00:00,[],2024-10-22 13:22:51+00:00,2024-10-22 13:22:49+00:00,https://github.com/tensorflow/tensorflow/pull/78515,[],[],
2605371345,pull_request,closed,,Removed unused GpuDriver functions,"Removed unused GpuDriver functions
",copybara-service[bot],2024-10-22 12:52:20+00:00,[],2024-10-28 21:22:22+00:00,2024-10-28 21:22:21+00:00,https://github.com/tensorflow/tensorflow/pull/78514,[],[],
2605366411,pull_request,closed,,[GpuCommandBuffer] Move LaunchGraph call into subclasses,"[GpuCommandBuffer] Move LaunchGraph call into subclasses

- Adds a pure virtual function declaration `LaunchGraph` to GpuCommandBuffer which submits an executable graph
- Move GpuDriver function `GraphLaunch` into implementation of `CudaCommandBuffer::LaunchGraph`.
",copybara-service[bot],2024-10-22 12:50:20+00:00,[],2024-10-28 20:21:50+00:00,2024-10-28 20:21:49+00:00,https://github.com/tensorflow/tensorflow/pull/78513,[],[],
2605336709,pull_request,closed,,[GpuCommandBuffer] Refactor DisableBarrierExecution,"[GpuCommandBuffer] Refactor DisableBarrierExecution

This makes `DisableBarrierExecution` operate on a `CommandBuffer` pointer and a `GraphNodeHandle` instead of `GpuGraphExec` and `GpuGraphNode` handles directly.

All the code that needs to know about handles is moved into the backend specific subclasses.
",copybara-service[bot],2024-10-22 12:37:45+00:00,[],2024-10-28 18:49:10+00:00,2024-10-28 18:49:09+00:00,https://github.com/tensorflow/tensorflow/pull/78512,[],[],
2605316595,pull_request,closed,,[XLA] Clean up code so it also works with Vector and not just Tensor types,"[XLA] Clean up code so it also works with Vector and not just Tensor types
",copybara-service[bot],2024-10-22 12:29:35+00:00,['d0k'],2024-10-23 13:17:02+00:00,2024-10-23 13:17:00+00:00,https://github.com/tensorflow/tensorflow/pull/78510,[],[],
2605272221,pull_request,closed,,[XLA:GPU] Add AllGatherDynamicSliceSimplifier to the compiler pipeline.,"[XLA:GPU] Add AllGatherDynamicSliceSimplifier to the compiler pipeline.

This PR:
1. Integrates the AllGatherDynamicSliceSimplifier to gpu compiler pipeline.
2. Fixes includes in the AllGatherDynamicSliceSimplifier pass code.
",copybara-service[bot],2024-10-22 12:10:13+00:00,[],2024-10-22 15:25:04+00:00,2024-10-22 15:25:03+00:00,https://github.com/tensorflow/tensorflow/pull/78509,[],[],
2605086516,pull_request,open,,PR #18562: Compute cost tool: add an option to print costs of each instruction.,"PR #18562: Compute cost tool: add an option to print costs of each instruction.

Imported from GitHub PR https://github.com/openxla/xla/pull/18562


Copybara import of the project:

--
314f9646442329c3cf99b5b339e81866d37d241c by Ilia Sergachev <isergachev@nvidia.com>:

Compute cost tool: add an option to print costs of each instruction.

--
4e5ea3ba30209e76d3ffd09a3d70dcc526200552 by Ilia Sergachev <isergachev@nvidia.com>:

address review comments

Merging this change closes #18562

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18562 from openxla:compute_cost_all 4e5ea3ba30209e76d3ffd09a3d70dcc526200552
",copybara-service[bot],2024-10-22 10:54:35+00:00,[],2024-10-22 10:54:35+00:00,,https://github.com/tensorflow/tensorflow/pull/78507,[],[],
2604991849,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 10:17:55+00:00,[],2024-10-22 10:17:55+00:00,,https://github.com/tensorflow/tensorflow/pull/78506,[],[],
2604919210,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:55:14+00:00,[],2024-10-22 09:55:14+00:00,,https://github.com/tensorflow/tensorflow/pull/78505,[],[],
2604917172,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:54:32+00:00,[],2024-10-22 09:54:32+00:00,,https://github.com/tensorflow/tensorflow/pull/78504,[],[],
2604916115,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:54:10+00:00,[],2024-10-22 09:54:10+00:00,,https://github.com/tensorflow/tensorflow/pull/78503,[],[],
2604914482,pull_request,closed,,Automated Code Change,"Automated Code Change

Reverts 91bb94cdfa6c22dcb6a4ce460717b9450307e561
",copybara-service[bot],2024-10-22 09:53:37+00:00,[],2024-10-25 04:03:47+00:00,2024-10-25 04:03:45+00:00,https://github.com/tensorflow/tensorflow/pull/78502,[],[],
2604910744,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:52:18+00:00,[],2024-10-23 07:01:04+00:00,2024-10-23 07:01:03+00:00,https://github.com/tensorflow/tensorflow/pull/78501,[],[],
2604910679,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:52:16+00:00,[],2024-10-22 09:52:16+00:00,,https://github.com/tensorflow/tensorflow/pull/78500,[],[],
2604907748,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:51:14+00:00,[],2024-10-22 09:51:14+00:00,,https://github.com/tensorflow/tensorflow/pull/78499,[],[],
2604904401,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:50:05+00:00,[],2024-10-22 09:50:05+00:00,,https://github.com/tensorflow/tensorflow/pull/78498,[],[],
2604899234,pull_request,closed,,PR #18558: [GPU][NFC] Add HLO op profiler build test.,"PR #18558: [GPU][NFC] Add HLO op profiler build test.

Imported from GitHub PR https://github.com/openxla/xla/pull/18558

hlo_op_profiler_run.cc wasn't compiled regularly and got build failures from time to time.
Copybara import of the project:

--
803e56364b08f7353f14e95f7281a0ff095974b0 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU][NFC] Add HLO op profiler build test.

hlo_op_profiler_run.cc wasn't compiled regularly and got build failures
from time to time.

--
fa66e38db01364968ac5fdb6cff10d12d8d0793c by Ilia Sergachev <isergachev@nvidia.com>:

add build dependency

Merging this change closes #18558

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18558 from openxla:add_hlo_op_profiler_build_test fa66e38db01364968ac5fdb6cff10d12d8d0793c
",copybara-service[bot],2024-10-22 09:48:08+00:00,[],2024-10-22 13:33:12+00:00,2024-10-22 13:33:11+00:00,https://github.com/tensorflow/tensorflow/pull/78497,[],[],
2604892753,pull_request,closed,,PR #18564: [GPU] Fix HLO op profiler: verify generated HLO modules before profiling them.,"PR #18564: [GPU] Fix HLO op profiler: verify generated HLO modules before profiling them.

Imported from GitHub PR https://github.com/openxla/xla/pull/18564

re-opening accidentally closed https://github.com/openxla/xla/pull/18391
Copybara import of the project:

--
6a394c59ca6e8116d08c46705dd00d80a4b631a8 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix HLO op profiler: verify generated HLO modules before profiling them.

--
1592fb396596dc028b39a741904d37aefbf5accb by Ilia Sergachev <isergachev@nvidia.com>:

add build dependency

--
2c3ae88f7f0ac8a9bbe924800d0ba493a12818c4 by Ilia Sergachev <isergachev@nvidia.com>:

fix after rebase

--
911b3cfee7d2f43859a3e4784847be8088aa2c30 by Ilia Sergachev <isergachev@nvidia.com>:

skip also the added test without config=cuda

Merging this change closes #18564

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18564 from openxla:fix_op_profiler_crashes 911b3cfee7d2f43859a3e4784847be8088aa2c30
",copybara-service[bot],2024-10-22 09:45:58+00:00,[],2024-10-23 16:59:50+00:00,2024-10-23 16:59:48+00:00,https://github.com/tensorflow/tensorflow/pull/78496,[],[],
2604889089,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:45:00+00:00,[],2024-10-22 09:45:00+00:00,,https://github.com/tensorflow/tensorflow/pull/78495,[],[],
2604887911,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:44:39+00:00,[],2024-10-22 09:44:39+00:00,,https://github.com/tensorflow/tensorflow/pull/78494,[],[],
2604886534,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:44:16+00:00,[],2024-10-22 09:44:16+00:00,,https://github.com/tensorflow/tensorflow/pull/78493,[],[],
2604881233,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:42:34+00:00,[],2024-10-22 09:42:34+00:00,,https://github.com/tensorflow/tensorflow/pull/78492,[],[],
2604876969,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 09:41:15+00:00,[],2024-10-22 09:41:15+00:00,,https://github.com/tensorflow/tensorflow/pull/78491,[],[],
2604875163,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18185 from PragmaTwice:patch-1 71fcc0ebb2373cae0b713eba535cc52bd504ac68
",copybara-service[bot],2024-10-22 09:40:33+00:00,[],2024-10-22 09:40:33+00:00,,https://github.com/tensorflow/tensorflow/pull/78490,[],[],
2604859445,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18185 from PragmaTwice:patch-1 71fcc0ebb2373cae0b713eba535cc52bd504ac68
",copybara-service[bot],2024-10-22 09:35:05+00:00,[],2024-10-22 09:35:05+00:00,,https://github.com/tensorflow/tensorflow/pull/78489,[],[],
2604822757,pull_request,closed,,PR #18435: Shape inference: check that atan2 inputs are float or complex.,"PR #18435: Shape inference: check that atan2 inputs are float or complex.

Imported from GitHub PR https://github.com/openxla/xla/pull/18435


Copybara import of the project:

--
7e286e3bcccadc5a585f629a92fa910867bb08a2 by Ilia Sergachev <isergachev@nvidia.com>:

Shape inference: check that atan2 inputs are float or complex.

Merging this change closes #18435

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18435 from openxla:fix_atan2_shape_inference 7e286e3bcccadc5a585f629a92fa910867bb08a2
",copybara-service[bot],2024-10-22 09:21:41+00:00,[],2024-10-22 11:51:57+00:00,2024-10-22 11:51:55+00:00,https://github.com/tensorflow/tensorflow/pull/78488,[],[],
2604805233,pull_request,closed,,PR #18438: Shape inference: mark complex cbrt unsupported.,"PR #18438: Shape inference: mark complex cbrt unsupported.

Imported from GitHub PR https://github.com/openxla/xla/pull/18438


Copybara import of the project:

--
52774dd4396cb12e30aed312b7979d752d161a75 by Ilia Sergachev <isergachev@nvidia.com>:

Shape inference: mark complex cbrt unsupported.

Merging this change closes #18438

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18438 from openxla:fix_complex_cbrt_shape_inference 52774dd4396cb12e30aed312b7979d752d161a75
",copybara-service[bot],2024-10-22 09:14:25+00:00,[],2024-10-22 11:05:33+00:00,2024-10-22 11:05:32+00:00,https://github.com/tensorflow/tensorflow/pull/78487,[],[],
2604762691,pull_request,closed,,[XLA:GPU] Make IsFusible return true for Triton fusions.,"[XLA:GPU] Make IsFusible return true for Triton fusions.

Triton fusion are fusible as far as Priority Fusion is concern, so we ended up checking for that separately in multiple places.
",copybara-service[bot],2024-10-22 08:58:44+00:00,[],2024-10-22 10:04:16+00:00,2024-10-22 10:04:14+00:00,https://github.com/tensorflow/tensorflow/pull/78486,[],[],
2604729025,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 08:46:50+00:00,[],2024-10-23 05:05:18+00:00,2024-10-23 05:05:18+00:00,https://github.com/tensorflow/tensorflow/pull/78484,[],[],
2604692737,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-22 08:33:46+00:00,[],2024-10-22 10:27:51+00:00,2024-10-22 10:27:50+00:00,https://github.com/tensorflow/tensorflow/pull/78483,[],[],
2604638580,pull_request,closed,,Separate ranges and runtime vars in indexing map serialization,"Separate ranges and runtime vars in indexing map serialization
",copybara-service[bot],2024-10-22 08:12:21+00:00,[],2024-10-22 11:34:27+00:00,2024-10-22 11:34:26+00:00,https://github.com/tensorflow/tensorflow/pull/78482,[],[],
2604609035,pull_request,closed,,PR #18535: [ROCm] Fix //xla/stream_executor/rocm:rocm_timer_test_gpu_amd_any,"PR #18535: [ROCm] Fix //xla/stream_executor/rocm:rocm_timer_test_gpu_amd_any

Imported from GitHub PR https://github.com/openxla/xla/pull/18535


Copybara import of the project:

--
34045acf1fcd50717a4f2e6f5c5908620f0131b9 by Dragan Mladjenovic <Dragan.Mladjenovic@amd.com>:

[ROCm] Fix //xla/stream_executor/rocm:rocm_timer_test_gpu_amd_any

Merging this change closes #18535

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18535 from ROCm:rocm_timer 34045acf1fcd50717a4f2e6f5c5908620f0131b9
",copybara-service[bot],2024-10-22 07:59:38+00:00,[],2024-10-22 08:26:15+00:00,2024-10-22 08:26:14+00:00,https://github.com/tensorflow/tensorflow/pull/78481,[],[],
2604391153,pull_request,closed,,Construct RE2 in ConfigurationEntry constructor rather than on every Matches(),"Construct RE2 in ConfigurationEntry constructor rather than on every Matches()

Originally, ConfigurationEntry::Matches() constructs a RE2 of test_id_rex_,
which takes about 0.15ms. Since the Matches() is called number of regex
multiplied by number of tests times, this takes extra ~2 min in total to run all
the tests in stable_delegate_test_suite with a 300 lines acceleration config.

We could construct the RE2 in advance on construction of ConfigurationEntry.
This could save us lots of time when using acceleration config.
",copybara-service[bot],2024-10-22 06:22:40+00:00,[],2024-10-24 04:53:40+00:00,2024-10-24 04:53:39+00:00,https://github.com/tensorflow/tensorflow/pull/78480,[],[],
2604374585,pull_request,closed,,PR #18572: Fix some comments formatting.,"PR #18572: Fix some comments formatting.

Imported from GitHub PR https://github.com/openxla/xla/pull/18572


Copybara import of the project:

--
cec5ed8e7364ed8d72836c7cde94c49cfa2ce3cb by Shawn Wang <shawnw@nvidia.com>:

fix comments format

Merging this change closes #18572

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18572 from shawnwang18:shawnw/fix_comments cec5ed8e7364ed8d72836c7cde94c49cfa2ce3cb
",copybara-service[bot],2024-10-22 06:12:21+00:00,[],2024-10-22 08:11:57+00:00,2024-10-22 08:11:57+00:00,https://github.com/tensorflow/tensorflow/pull/78479,[],[],
2604359638,pull_request,closed,,Fix debug log argument order,"Fix debug log argument order
",copybara-service[bot],2024-10-22 06:02:19+00:00,[],2024-10-22 23:38:42+00:00,2024-10-22 23:38:42+00:00,https://github.com/tensorflow/tensorflow/pull/78478,[],[],
2604213651,pull_request,open,,"Update the comment to clarify that the `operands_in_alternate_memory_maps_` also includes window prefetched operands. This is because, like those fully prefetched operands, window prefetch operands make allocations in the alternate memory. These allocations cause the operands to be included in the `operands_in_alternate_memory_maps`. This is an intended behavior. Also add a test to explicitly show this effect.","Update the comment to clarify that the `operands_in_alternate_memory_maps_` also includes window prefetched operands. This is because, like those fully prefetched operands, window prefetch operands make allocations in the alternate memory. These allocations cause the operands to be included in the `operands_in_alternate_memory_maps`. This is an intended behavior. Also add a test to explicitly show this effect.
",copybara-service[bot],2024-10-22 04:33:12+00:00,[],2024-10-22 04:33:12+00:00,,https://github.com/tensorflow/tensorflow/pull/78477,[],[],
2604121705,pull_request,closed,,[IFRT] Add passes to lower shardings to mhlo.sharding and to remove IFRT attributes,"[IFRT] Add passes to lower shardings to mhlo.sharding and to remove IFRT attributes
",copybara-service[bot],2024-10-22 03:27:05+00:00,[],2024-10-22 19:14:10+00:00,2024-10-22 19:14:07+00:00,https://github.com/tensorflow/tensorflow/pull/78476,[],[],
2604012354,pull_request,closed,,[HLO Componentization] Add deprecation warning to aliased build targets.,"[HLO Componentization] Add deprecation warning to aliased build targets.

This step towards encouraging extrenal projects to migrate to the already
migrated hlo sub-components.
",copybara-service[bot],2024-10-22 01:44:19+00:00,['sdasgup3'],2024-10-22 16:15:39+00:00,2024-10-22 16:15:38+00:00,https://github.com/tensorflow/tensorflow/pull/78474,[],[],
2603975392,pull_request,closed,,Integrate LLVM at llvm/llvm-project@7dc2542ac24f,"Integrate LLVM at llvm/llvm-project@7dc2542ac24f

Updates LLVM usage to match
[7dc2542ac24f](https://github.com/llvm/llvm-project/commit/7dc2542ac24f)
",copybara-service[bot],2024-10-22 01:06:57+00:00,[],2024-10-22 09:55:54+00:00,2024-10-22 09:55:52+00:00,https://github.com/tensorflow/tensorflow/pull/78473,[],[],
2603924891,pull_request,open,,Refactor tests to not use set_use_bfloat16 so they can support other types in the future.,"Refactor tests to not use set_use_bfloat16 so they can support other types in the future.
",copybara-service[bot],2024-10-22 00:08:51+00:00,[],2024-10-22 14:13:56+00:00,,https://github.com/tensorflow/tensorflow/pull/78472,[],[],
2603885410,pull_request,closed,,Pass a char* instead of string_view to avoid crashes.,"Pass a char* instead of string_view to avoid crashes.
",copybara-service[bot],2024-10-21 23:36:54+00:00,[],2024-10-22 18:52:08+00:00,2024-10-22 18:52:07+00:00,https://github.com/tensorflow/tensorflow/pull/78471,[],[],
2603861913,pull_request,closed,,Fix a bug in SPMD partitioner during pre-processing of pad->slice pattern.,"Fix a bug in SPMD partitioner during pre-processing of pad->slice pattern.
",copybara-service[bot],2024-10-21 23:17:44+00:00,[],2024-10-22 16:51:46+00:00,2024-10-22 16:51:44+00:00,https://github.com/tensorflow/tensorflow/pull/78470,[],[],
2603860233,pull_request,closed,,[xla] Add a print option for HLO value tracking,"[xla] Add a print option for HLO value tracking
",copybara-service[bot],2024-10-21 23:16:19+00:00,['jcai19'],2024-10-22 00:51:50+00:00,2024-10-22 00:51:50+00:00,https://github.com/tensorflow/tensorflow/pull/78469,[],[],
2603842254,pull_request,open,,Implement serialization strategies. Integrate current (metadata) strategy in existing tool,"Implement serialization strategies. Integrate current (metadata) strategy in existing tool
",copybara-service[bot],2024-10-21 23:02:28+00:00,['ecalubaquib'],2024-10-22 00:35:19+00:00,,https://github.com/tensorflow/tensorflow/pull/78468,[],[],
2603809181,pull_request,closed,,"#sdy add shardy CPU config for all JAX tests, disabling any known failing test cases.","#sdy add shardy CPU config for all JAX tests, disabling any known failing test cases.

Only test cases breaking on CPU are related to:
- pure callbacks
- export
- shard alike

Note that `layout_test` is broken on TPU, leaving a comment saying to enable it.

Also fixed `shard_map_test` test that was broken when running Shardy on one TPU, and `aot_test` which was breaking due to calling a different C++ StableHLO compilation function.
",copybara-service[bot],2024-10-21 22:42:12+00:00,[],2024-10-30 18:53:14+00:00,2024-10-30 18:53:13+00:00,https://github.com/tensorflow/tensorflow/pull/78467,[],[],
2603778502,pull_request,closed,,Copy and rework flatbuffer_conversions.h into compiler,"Copy and rework flatbuffer_conversions.h into compiler

Reverts d84b856d969201974a8bd1c5a93f75fbd08ea465
",copybara-service[bot],2024-10-21 22:18:11+00:00,[],2024-10-29 19:52:01+00:00,2024-10-29 19:52:00+00:00,https://github.com/tensorflow/tensorflow/pull/78465,[],[],
2603773132,pull_request,closed,,Update RELEASE.md to move TFLite SignatureRunner to the right section,,rtg0795,2024-10-21 22:13:28+00:00,[],2024-12-23 16:49:26+00:00,2024-10-21 23:10:20+00:00,https://github.com/tensorflow/tensorflow/pull/78464,[],[],
2603756265,pull_request,closed,,Update version numbers for TensorFlow 2.18.0,"Before merging this PR, please double check that it has correctly updated
`core/public/version.h`, `tools/pip_package/setup.py`, and
`tensorflow/tensorflow.bzl`. Also review the execution notes below:

```
Major: 2 -> 2
Minor: 18 -> 18
Patch: 0 -> 0

No lingering old version strings ""2.18.0-rc2"" found in source directory 
""tensorflow/"". Good.
No lingering old version strings ""2.18.0rc2"" found in source directory 
""tensorflow/"". Good.
```",tensorflow-jenkins,2024-10-21 22:00:16+00:00,[],2024-10-21 23:09:36+00:00,2024-10-21 23:09:36+00:00,https://github.com/tensorflow/tensorflow/pull/78463,[],[],
2603700140,pull_request,closed,,Use clean_dep function from lite/core/shims/cc_library_with_tflite.bzl macro,"Use clean_dep function from lite/core/shims/cc_library_with_tflite.bzl macro
",copybara-service[bot],2024-10-21 21:28:18+00:00,['ecalubaquib'],2024-10-22 00:08:57+00:00,2024-10-22 00:08:56+00:00,https://github.com/tensorflow/tensorflow/pull/78462,[],[],
2603603626,pull_request,closed,,Update hermetic CUDA docs.,"Update hermetic CUDA docs.
",copybara-service[bot],2024-10-21 20:34:12+00:00,[],2024-10-24 18:58:36+00:00,2024-10-24 18:58:35+00:00,https://github.com/tensorflow/tensorflow/pull/78461,[],[],
2603586335,pull_request,open,,Extracted CopyOnWrite to a separate file and added tests.,"Extracted CopyOnWrite to a separate file and added tests.
",copybara-service[bot],2024-10-21 20:26:17+00:00,[],2024-10-22 06:13:46+00:00,,https://github.com/tensorflow/tensorflow/pull/78460,[],[],
2603574224,pull_request,closed,,[logging] Improve error logs to suggest checking the scheduler events when a process crashed.,"[logging] Improve error logs to suggest checking the scheduler events when a process crashed.
",copybara-service[bot],2024-10-21 20:19:08+00:00,[],2024-10-22 17:03:51+00:00,2024-10-22 17:03:51+00:00,https://github.com/tensorflow/tensorflow/pull/78459,[],[],
2603484620,pull_request,closed,,[XLA:GPU] Always unroll small loops.,"[XLA:GPU] Always unroll small loops.

Unroll loops with a trip count of 4 or smaller. Those loops were emitter with the intention to be unrolled later. Not unrolling them causes significant performance regressions on large kernels, because the PTX we emit from LLVM will have explicit an stack allocated in local memory that means a lot of unnecessary HBM reads/writes.
",copybara-service[bot],2024-10-21 19:35:30+00:00,[],2024-10-22 08:43:03+00:00,2024-10-22 08:43:01+00:00,https://github.com/tensorflow/tensorflow/pull/78458,[],[],
2603447995,pull_request,closed,,Add `tensorflow/lite/c/builtin_op_data.h` to the list of public C API headers.,"Add `tensorflow/lite/c/builtin_op_data.h` to the list of public C API headers.

We are already including `tensorflow/lite/core/c/builtin_op_data.h`,
which is a private header, but the corresponding public header was
not being included.

This header file is needed for delegates to examine the operands of
builtin ops.  We'd prefer that delegates use this public header in
`tensorflow/lite/c` rather than the corresponding private one from
`core/` in `tensorflow/lite/core/c/', for better compatibility
with TF Lite in Play services.

Also, this file was already listed as a public API header at
<https://www.tensorflow.org/guide/versions#separate_version_number_for_tensorflow_lite_extension_apis>.
",copybara-service[bot],2024-10-21 19:17:37+00:00,[],2024-10-23 13:32:49+00:00,2024-10-23 13:32:48+00:00,https://github.com/tensorflow/tensorflow/pull/78457,[],[],
2603441110,pull_request,closed,,Add slice Op legalization to QC compiler plugin.,"Add slice Op legalization to QC compiler plugin.
",copybara-service[bot],2024-10-21 19:15:05+00:00,[],2024-10-25 00:23:22+00:00,2024-10-25 00:23:21+00:00,https://github.com/tensorflow/tensorflow/pull/78456,[],[],
2603334893,pull_request,open,,"Small bug fixes, nullptr checks, extra logging to get apply plugin to work for qcc. Add a binary target option to the custom build macros.","Small bug fixes, nullptr checks, extra logging to get apply plugin to work for qcc. Add a binary target option to the custom build macros.
",copybara-service[bot],2024-10-21 18:24:42+00:00,['LukeBoyer'],2024-10-21 18:24:44+00:00,,https://github.com/tensorflow/tensorflow/pull/78455,[],[],
2603330883,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@1c0b6065,"Integrate StableHLO at openxla/stablehlo@1c0b6065
",copybara-service[bot],2024-10-21 18:22:31+00:00,['GleasonK'],2024-10-22 19:31:44+00:00,2024-10-22 19:31:42+00:00,https://github.com/tensorflow/tensorflow/pull/78454,[],[],
2603322506,pull_request,closed,,[GpuCommandBuffer] Move CreateBarrierNode to subclasses,"[GpuCommandBuffer] Move CreateBarrierNode to subclasses

This declares the node factory function `CreateBarrierNode` pure virtual and moves its implementation into `CudaCommandBuffer` and `RocmCommandBuffer`.
",copybara-service[bot],2024-10-21 18:18:31+00:00,[],2024-10-28 17:29:24+00:00,2024-10-28 17:29:22+00:00,https://github.com/tensorflow/tensorflow/pull/78453,[],[],
2603318982,pull_request,closed,,[GpuCommandBuffer] Move Trace function into subclasses,"[GpuCommandBuffer] Move Trace function into subclasses

This moves `GpuCommandBuffer::Trace` entirely into the subclasses (CudaCommandBuffer and RocmCommandBuffer)
",copybara-service[bot],2024-10-21 18:16:36+00:00,[],2024-10-28 18:19:28+00:00,2024-10-28 18:19:27+00:00,https://github.com/tensorflow/tensorflow/pull/78452,[],[],
2603277864,pull_request,closed,,Move default load_ir_module and nvptx_libdevice_path to default directory,"Move default load_ir_module and nvptx_libdevice_path to default directory
",copybara-service[bot],2024-10-21 17:55:14+00:00,[],2024-10-21 23:44:13+00:00,2024-10-21 23:44:13+00:00,https://github.com/tensorflow/tensorflow/pull/78451,[],[],
2603273653,pull_request,closed,,Fix test failure on cuda build,"Fix test failure on cuda build
",copybara-service[bot],2024-10-21 17:53:31+00:00,[],2024-10-21 19:00:14+00:00,2024-10-21 19:00:14+00:00,https://github.com/tensorflow/tensorflow/pull/78450,[],[],
2603270784,pull_request,closed,,Internal change only.,"Internal change only.
",copybara-service[bot],2024-10-21 17:52:14+00:00,[],2024-10-22 18:37:51+00:00,2024-10-22 18:37:49+00:00,https://github.com/tensorflow/tensorflow/pull/78449,[],[],
2603265893,pull_request,closed,,[XLA] Small speedups to the latency hiding scheduler.,"[XLA] Small speedups to the latency hiding scheduler.

* change GetResourcesFromInstruction to return an absl::Span<> rather than copying the resources vector. This appears to be safe: no callers appear to mutate the resource map while the absl::Span<> is alive.
* fix GetResourcesFromInstruction to only do a single hash lookup, rather than two.
* make GetResourcesFromInstruction non-virtual, change GPU implementation to override GetResourcesFromInstructionImpl instead.
* move recursively_compute_resource_map into an out-of-line helper function. Simplify its invariants so it performs the async_in_computation_cache_ lookup and insertion, which both simplifies the code and avoids a double hash lookup.
",copybara-service[bot],2024-10-21 17:49:36+00:00,[],2024-10-22 12:37:10+00:00,2024-10-22 12:37:09+00:00,https://github.com/tensorflow/tensorflow/pull/78448,[],[],
2603264635,pull_request,closed,,Alphabetically order link titles to make docs more discoverable.,"Alphabetically order link titles to make docs more discoverable.
",copybara-service[bot],2024-10-21 17:49:00+00:00,['ghpvnist'],2024-10-21 18:46:07+00:00,2024-10-21 18:46:06+00:00,https://github.com/tensorflow/tensorflow/pull/78447,[],[],
2603261011,pull_request,closed,,Close code formatting in docstring to avoid formatting prose as code as well.,"Close code formatting in docstring to avoid formatting prose as code as well.

No functional changes.
",copybara-service[bot],2024-10-21 17:47:19+00:00,[],2024-10-22 16:24:38+00:00,2024-10-22 16:24:37+00:00,https://github.com/tensorflow/tensorflow/pull/78446,[],[],
2603250020,pull_request,closed,,[GpuCommandBuffer] Move GraphAddMemcpyD2DNode into subclasses,"[GpuCommandBuffer] Move GraphAddMemcpyD2DNode into subclasses

- Create a pure virtual functions for memcpy node creation and update
- Implements both methods for both platforms in the subclasses
",copybara-service[bot],2024-10-21 17:42:43+00:00,[],2024-10-28 12:27:32+00:00,2024-10-28 12:27:30+00:00,https://github.com/tensorflow/tensorflow/pull/78445,[],[],
2603248207,pull_request,closed,,[GpuCommandBuffer] Move GraphAddKernelNode logic into subclasses,"[GpuCommandBuffer] Move GraphAddKernelNode logic into subclasses

- Adds pure virtual functions for creating and updating kernel nodes
- Implements both methods for both platforms in the subclasses
",copybara-service[bot],2024-10-21 17:41:49+00:00,[],2024-10-28 14:41:27+00:00,2024-10-28 14:41:26+00:00,https://github.com/tensorflow/tensorflow/pull/78444,[],[],
2603244177,pull_request,closed,,[GpuCommandBuffer] Move GraphAddMemsetNode into subclasses,"[GpuCommandBuffer] Move GraphAddMemsetNode into subclasses

- Declares a pure virtual function for memset node creation and update
- Implements both methods for both platforms in the subclasses
",copybara-service[bot],2024-10-21 17:39:31+00:00,[],2024-10-28 11:05:41+00:00,2024-10-28 11:05:39+00:00,https://github.com/tensorflow/tensorflow/pull/78443,[],[],
2603241710,pull_request,closed,,[GpuCommandBuffer] Move GraphAddChildNode logic into subclasses,"[GpuCommandBuffer] Move GraphAddChildNode logic into subclasses

- Declares pure virtual functions for child node creation and update
- Implements both for both platforms in the subclasses
",copybara-service[bot],2024-10-21 17:38:05+00:00,[],2024-10-28 13:45:48+00:00,2024-10-28 13:45:47+00:00,https://github.com/tensorflow/tensorflow/pull/78442,[],[],
2603221324,pull_request,closed,,[XLA:GPU] Remove unused allocator in gemm_fusion_autotuner.cc,"[XLA:GPU] Remove unused allocator in gemm_fusion_autotuner.cc
",copybara-service[bot],2024-10-21 17:29:30+00:00,[],2024-10-21 20:07:20+00:00,2024-10-21 20:07:18+00:00,https://github.com/tensorflow/tensorflow/pull/78441,[],[],
2603207564,pull_request,closed,,[XLA:GPU] Split out some nvptx functions from gpu_backend_lib into separate targets.,"[XLA:GPU] Split out some nvptx functions from gpu_backend_lib into separate targets.
",copybara-service[bot],2024-10-21 17:22:23+00:00,[],2024-10-21 19:41:06+00:00,2024-10-21 19:41:05+00:00,https://github.com/tensorflow/tensorflow/pull/78440,[],[],
2603153455,pull_request,closed,,[GpuCommandBuffer] Introduce an opaque handle type as a replacement for `GraphNodeHandle`,"[GpuCommandBuffer] Introduce an opaque handle type as a replacement for `GraphNodeHandle`

`GraphNodeHandle` is an alias for either `CUgraphNode` or `hipGraphNode_t`. We want to move all backend specific code into subclasses. So as a first step this change:

- Introduces an opaque handle `GraphNodeHandle` which can be converted to and from the backend specific types.
- Makes a lot of places in GpuCommandBuffer use the new handle instead of the platform specific types directly.
",copybara-service[bot],2024-10-21 16:56:42+00:00,[],2024-10-28 07:38:58+00:00,2024-10-28 07:38:57+00:00,https://github.com/tensorflow/tensorflow/pull/78439,[],[],
2603139610,pull_request,closed,,[XLA:GPU] Split out llvm_gpu_backend utils functions into separate targets.,"[XLA:GPU] Split out llvm_gpu_backend utils functions into separate targets.
",copybara-service[bot],2024-10-21 16:50:49+00:00,[],2024-10-21 17:54:26+00:00,2024-10-21 17:54:26+00:00,https://github.com/tensorflow/tensorflow/pull/78438,[],[],
2602926325,pull_request,closed,,[xla:cpu] Add lowering from xla_cpu.load to LLVM,"[xla:cpu] Add lowering from xla_cpu.load to LLVM

Convert xla_cpu.load tensor to LLVM pointer to tensor base address
",copybara-service[bot],2024-10-21 15:33:02+00:00,['ezhulenev'],2024-10-21 15:55:45+00:00,2024-10-21 15:55:44+00:00,https://github.com/tensorflow/tensorflow/pull/78437,[],[],
2602911284,pull_request,closed,,[XLA:GPU] support the hlo rewrite for the dot BF16_BF16_F32_X6 algorithm.,"[XLA:GPU] support the hlo rewrite for the dot BF16_BF16_F32_X6 algorithm.

Now when we have all the pieces of the puzzle for X3 algorithm we could easily add its equivalent for X6.
",copybara-service[bot],2024-10-21 15:27:54+00:00,[],2024-10-21 22:37:41+00:00,2024-10-21 22:37:40+00:00,https://github.com/tensorflow/tensorflow/pull/78436,[],[],
2602883759,pull_request,closed,,PR #18310: [XLA:GPU} Add lowering rule from `dynamic_address_computation` fusion to command buffer `DynamicSliceFusionCmd` ,"PR #18310: [XLA:GPU} Add lowering rule from `dynamic_address_computation` fusion to command buffer `DynamicSliceFusionCmd` 

Imported from GitHub PR https://github.com/openxla/xla/pull/18310

This PR adds lowering rules for dynamic_address_computation custom fusion to DynamicSliceFusion Cmd of command buffer.  Currently it only supports the case when the Slice offset value is constant value. 
Copybara import of the project:

--
00987f6e5a7b3ecd06b74e8fb590a875f48fbca5 by Shawn Wang <shawnw@nvidia.com>:

Lowering dynamic slice fusion to command buffer

--
eb986fe8e045c1029c0153f88750249ed6f6ac8d by Shawn Wang <shawnw@nvidia.com>:

fix for comments

Merging this change closes #18310

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18310 from shawnwang18:shawnw/add_command_buffer_dynamic_slice_lowering_rule eb986fe8e045c1029c0153f88750249ed6f6ac8d
",copybara-service[bot],2024-10-21 15:18:34+00:00,[],2024-10-21 16:19:43+00:00,2024-10-21 16:19:42+00:00,https://github.com/tensorflow/tensorflow/pull/78435,[],[],
2602577725,pull_request,closed,,[Triton] Allow reorderValues to handle downcast with dot_op layout on 16-bit -> 8-bit in the same way it handles 8-bit -> 16-bit. We already needed to do something similar for 16/32 bits previously.,"[Triton] Allow reorderValues to handle downcast with dot_op layout on 16-bit -> 8-bit in the same way it handles 8-bit -> 16-bit. We already needed to do something similar for 16/32 bits previously.
",copybara-service[bot],2024-10-21 13:33:15+00:00,[],2024-10-25 14:25:12+00:00,2024-10-25 14:25:11+00:00,https://github.com/tensorflow/tensorflow/pull/78433,[],[],
2602487753,pull_request,open,,Integrate LLVM at llvm/llvm-project@d80b9cf713fd,"Integrate LLVM at llvm/llvm-project@d80b9cf713fd

Updates LLVM usage to match
[d80b9cf713fd](https://github.com/llvm/llvm-project/commit/d80b9cf713fd)
",copybara-service[bot],2024-10-21 13:00:45+00:00,[],2024-10-21 14:18:20+00:00,,https://github.com/tensorflow/tensorflow/pull/78432,[],[],
2602384144,pull_request,open,,Integrate Triton up to [68aa962e67baa191cec5aac173255abdba80db1a](https://github.com/openai/triton/commits/68aa962e67baa191cec5aac173255abdba80db1a),"Integrate Triton up to [68aa962e67baa191cec5aac173255abdba80db1a](https://github.com/openai/triton/commits/68aa962e67baa191cec5aac173255abdba80db1a)
",copybara-service[bot],2024-10-21 12:21:50+00:00,[],2024-10-21 12:21:50+00:00,,https://github.com/tensorflow/tensorflow/pull/78430,[],[],
2602376188,pull_request,open,,Fix a bug in the calibrator when trying to log null calibration values. Copy of https://github.com/tensorflow/tensorflow/pull/76955.,"Fix a bug in the calibrator when trying to log null calibration values. Copy of https://github.com/tensorflow/tensorflow/pull/76955.
",copybara-service[bot],2024-10-21 12:18:26+00:00,[],2024-10-21 12:18:26+00:00,,https://github.com/tensorflow/tensorflow/pull/78429,[],[],
2601959141,pull_request,closed,,Create a new class StatWithPercentiles that inherits Stat.,"Create a new class StatWithPercentiles that inherits Stat.

A StatWithPercentiles object keeps track of the values added to it, and supports computing percentile values.
",copybara-service[bot],2024-10-21 09:40:51+00:00,[],2024-10-24 04:15:27+00:00,2024-10-24 04:15:25+00:00,https://github.com/tensorflow/tensorflow/pull/78425,[],[],
2601929745,pull_request,open,,Integrate Triton up to [68aa962e67baa191cec5aac173255abdba80db1a](https://github.com/openai/triton/commits/68aa962e67baa191cec5aac173255abdba80db1a),"Integrate Triton up to [68aa962e67baa191cec5aac173255abdba80db1a](https://github.com/openai/triton/commits/68aa962e67baa191cec5aac173255abdba80db1a)
",copybara-service[bot],2024-10-21 09:31:25+00:00,[],2024-10-28 10:38:46+00:00,,https://github.com/tensorflow/tensorflow/pull/78424,[],[],
2601843412,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 08:56:49+00:00,[],2024-10-21 08:56:49+00:00,,https://github.com/tensorflow/tensorflow/pull/78423,[],[],
2601835797,pull_request,closed,,PR #18527: [XLA:CPU][oneDNN] Refactor population of oneDNN post-ops,"PR #18527: [XLA:CPU][oneDNN] Refactor population of oneDNN post-ops

Imported from GitHub PR https://github.com/openxla/xla/pull/18527

This PR refactors the code that populates post-ops for oneDNN primitive and moves it to onednn_util so that it can be re-used by other primitive kinds in the future.
Copybara import of the project:

--
69e22d1bbc5ff8791d914f5bc69e2cb86ffdeaeb by Akhil Goel <akhil.goel@intel.com>:

Refactor post-op population

Merging this change closes #18527

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18527 from Intel-tensorflow:akhil/conv_fusions_3_b 69e22d1bbc5ff8791d914f5bc69e2cb86ffdeaeb
",copybara-service[bot],2024-10-21 08:54:27+00:00,[],2024-10-21 09:44:50+00:00,2024-10-21 09:44:49+00:00,https://github.com/tensorflow/tensorflow/pull/78422,[],"[{'comment_id': 2426034430, 'issue_id': 2601835797, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78422/checks?check_run_id=31814537072) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 21, 8, 54, 32, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-21 08:54:32 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/78422/checks?check_run_id=31814537072) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2601731738,pull_request,open,,[XLA:GPU] Extend ReduceScatterCombiner to combine pipelined collectives as much as possible.,"[XLA:GPU] Extend ReduceScatterCombiner to combine pipelined collectives as much as possible.

This is particularly useful in FSDP/HSDP where gradient propagation can be done fully in the i+1th iteration. It takes the responsibility of the user to set the `xla_gpu_all_gather_combine_threshold_bytes` by themselves.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18292 from Cjkkkk:fix_dus_fusion_alias_analysis 6a3b3c20505ef8171702e117b219520fcc14fd5e
",copybara-service[bot],2024-10-21 08:13:24+00:00,[],2024-10-21 09:45:01+00:00,,https://github.com/tensorflow/tensorflow/pull/78421,[],[],
2601670327,pull_request,closed,,PR #18185: Fix dead source code path in XLAFramework dialect,"PR #18185: Fix dead source code path in XLAFramework dialect

Imported from GitHub PR https://github.com/openxla/xla/pull/18185

`tensorflow/compiler/xla/` has already been moved. Seems now we can just use `xla/` since XLA became a standalone project.
Copybara import of the project:

--
71fcc0ebb2373cae0b713eba535cc52bd504ac68 by Twice <twice@apache.org>:

Fix dead source code path in XLAFramework dialect

Merging this change closes #18185

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18185 from PragmaTwice:patch-1 71fcc0ebb2373cae0b713eba535cc52bd504ac68
",copybara-service[bot],2024-10-21 07:48:38+00:00,[],2024-10-22 09:32:18+00:00,2024-10-22 09:32:17+00:00,https://github.com/tensorflow/tensorflow/pull/78420,[],[],
2601665918,pull_request,closed,,PR #18296: [Rocm] fix arch,"PR #18296: [Rocm] fix arch

Imported from GitHub PR https://github.com/openxla/xla/pull/18296


Copybara import of the project:

--
d7396f02c524568bdf342ba3fae1860df45d8219 by Ruturaj4 <ruturaj.vaidya@amd.com>:

[Rocm] fix arch

Merging this change closes #18296

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18296 from ROCm:ci_arch_fix d7396f02c524568bdf342ba3fae1860df45d8219
",copybara-service[bot],2024-10-21 07:46:52+00:00,[],2024-10-21 10:56:56+00:00,2024-10-21 10:56:55+00:00,https://github.com/tensorflow/tensorflow/pull/78419,[],[],
2601663492,pull_request,closed,,PR #18062: [ROCm] Fix gemm_rewriter_test for AMD GCN Arch,"PR #18062: [ROCm] Fix gemm_rewriter_test for AMD GCN Arch

Imported from GitHub PR https://github.com/openxla/xla/pull/18062

https://github.com/openxla/xla/pull/16841 removes scaling factor constants in gemm_rewriter for FP8 data types. This patch address the same in the gemm_rewriter_test
Copybara import of the project:

--
be4da5b8de0785d43e18dbdb0773307870084e32 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Fix gemm_rewriter_test for AMD GCN Arch

https://github.com/openxla/xla/pull/16841 removes scaling factor
constants in gemm_rewriter for FP8 data types. This patch address
the same in the gemm_rewriter_test

Merging this change closes #18062

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18062 from ROCm:ci_fix_gemm_rewriter_fp8_tests_20241008 be4da5b8de0785d43e18dbdb0773307870084e32
",copybara-service[bot],2024-10-21 07:45:59+00:00,[],2024-10-21 08:33:11+00:00,2024-10-21 08:33:10+00:00,https://github.com/tensorflow/tensorflow/pull/78418,[],[],
2601607292,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 07:23:44+00:00,[],2024-10-21 09:12:05+00:00,,https://github.com/tensorflow/tensorflow/pull/78417,[],[],
2601380983,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18185 from PragmaTwice:patch-1 71fcc0ebb2373cae0b713eba535cc52bd504ac68
",copybara-service[bot],2024-10-21 05:35:44+00:00,[],2024-10-22 09:33:42+00:00,,https://github.com/tensorflow/tensorflow/pull/78416,[],[],
2601379134,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:34:42+00:00,[],2024-10-21 09:05:27+00:00,2024-10-21 09:05:27+00:00,https://github.com/tensorflow/tensorflow/pull/78415,[],[],
2601378632,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:34:23+00:00,[],2024-10-21 05:34:23+00:00,,https://github.com/tensorflow/tensorflow/pull/78414,[],[],
2601375984,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:32:22+00:00,[],2024-10-21 05:32:22+00:00,,https://github.com/tensorflow/tensorflow/pull/78413,[],[],
2601373564,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:30:25+00:00,[],2024-10-22 04:28:53+00:00,,https://github.com/tensorflow/tensorflow/pull/78412,[],[],
2601369578,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:27:16+00:00,[],2024-10-21 05:27:16+00:00,,https://github.com/tensorflow/tensorflow/pull/78411,[],[],
2601367534,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:25:35+00:00,[],2024-10-21 05:25:35+00:00,,https://github.com/tensorflow/tensorflow/pull/78410,[],[],
2601363464,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:22:28+00:00,[],2024-10-21 05:22:28+00:00,,https://github.com/tensorflow/tensorflow/pull/78409,[],[],
2601357782,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:18:12+00:00,[],2024-10-21 05:18:12+00:00,,https://github.com/tensorflow/tensorflow/pull/78408,[],[],
2601357084,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:17:38+00:00,[],2024-10-24 07:14:11+00:00,,https://github.com/tensorflow/tensorflow/pull/78407,[],[],
2601354268,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 05:15:23+00:00,[],2024-10-24 09:11:45+00:00,2024-10-24 09:11:44+00:00,https://github.com/tensorflow/tensorflow/pull/78406,[],[],
2601317160,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 04:50:20+00:00,[],2024-10-21 04:50:20+00:00,,https://github.com/tensorflow/tensorflow/pull/78405,[],[],
2601267347,pull_request,open,,Implement the post-processing step that adds the actual bytecode offset and size to the flatbuffer after serialization.,"Implement the post-processing step that adds the actual bytecode offset and size to the flatbuffer after serialization.
",copybara-service[bot],2024-10-21 04:14:42+00:00,['LukeBoyer'],2024-10-22 00:47:49+00:00,,https://github.com/tensorflow/tensorflow/pull/78404,[],[],
2601243603,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 03:59:03+00:00,[],2024-10-21 08:12:03+00:00,2024-10-21 08:12:01+00:00,https://github.com/tensorflow/tensorflow/pull/78403,[],[],
2601194977,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-21 03:29:45+00:00,[],2024-10-21 03:29:45+00:00,,https://github.com/tensorflow/tensorflow/pull/78402,[],[],
2601192759,pull_request,closed,,Add uint8_t buffer wrappers. These are used to manage and interact with the raw buffers returned from the flatbuffers api. They take into account that flatbuffer-buffers may be left padded.,"Add uint8_t buffer wrappers. These are used to manage and interact with the raw buffers returned from the flatbuffers api. They take into account that flatbuffer-buffers may be left padded.
",copybara-service[bot],2024-10-21 03:28:30+00:00,['LukeBoyer'],2024-10-21 20:16:34+00:00,2024-10-21 20:16:30+00:00,https://github.com/tensorflow/tensorflow/pull/78401,[],[],
2601123379,pull_request,closed,,"Create a public library LiteRtTensorBuffer, LiteRtTensorBufferRequirements, and LiteRtEvent","Create a public library LiteRtTensorBuffer, LiteRtTensorBufferRequirements, and LiteRtEvent
",copybara-service[bot],2024-10-21 02:33:24+00:00,[],2024-10-21 18:27:03+00:00,2024-10-21 18:27:01+00:00,https://github.com/tensorflow/tensorflow/pull/78400,[],[],
2600951290,pull_request,closed,,[xla:WhileLoopUnroller] Fix MatchShapeCoveringDynamicIndexInstruction.,"[xla:WhileLoopUnroller] Fix MatchShapeCoveringDynamicIndexInstruction.

For DynamicSlice, ensure that the slice shape is of size 1 on the dimension
where the induction variable is used to index into the input and matches the
input shapes on all other dimensions.

Add a test.
",copybara-service[bot],2024-10-20 23:04:51+00:00,['bixia1'],2024-10-22 22:24:52+00:00,2024-10-22 22:24:51+00:00,https://github.com/tensorflow/tensorflow/pull/78399,[],[],
2600705559,pull_request,closed,,Create an ABI-stable C API for logging,"Create an ABI-stable C API for logging
",copybara-service[bot],2024-10-20 17:20:18+00:00,[],2024-10-21 22:10:46+00:00,2024-10-21 22:10:45+00:00,https://github.com/tensorflow/tensorflow/pull/78398,[],[],
2600262393,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 09:55:44+00:00,[],2024-10-20 09:55:44+00:00,,https://github.com/tensorflow/tensorflow/pull/78397,[],[],
2600114291,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 07:08:56+00:00,[],2024-10-25 06:11:42+00:00,2024-10-25 06:11:41+00:00,https://github.com/tensorflow/tensorflow/pull/78394,[],[],
2600111986,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 07:07:50+00:00,[],2024-10-20 07:07:50+00:00,,https://github.com/tensorflow/tensorflow/pull/78393,[],[],
2600106257,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 07:03:16+00:00,[],2024-10-27 04:52:15+00:00,2024-10-27 04:52:15+00:00,https://github.com/tensorflow/tensorflow/pull/78392,[],[],
2600060927,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 06:21:16+00:00,[],2024-10-20 06:21:16+00:00,,https://github.com/tensorflow/tensorflow/pull/78391,[],[],
2599935344,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:56:48+00:00,[],2024-10-20 03:56:48+00:00,,https://github.com/tensorflow/tensorflow/pull/78389,[],[],
2599930227,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:53:45+00:00,[],2024-10-20 03:53:45+00:00,,https://github.com/tensorflow/tensorflow/pull/78388,[],[],
2599928029,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:53:03+00:00,[],2024-10-20 03:53:03+00:00,,https://github.com/tensorflow/tensorflow/pull/78387,[],[],
2599928013,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:53:02+00:00,[],2024-10-20 03:53:02+00:00,,https://github.com/tensorflow/tensorflow/pull/78386,[],[],
2599927939,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:52:52+00:00,[],2024-10-22 03:50:01+00:00,2024-10-22 03:50:01+00:00,https://github.com/tensorflow/tensorflow/pull/78385,[],[],
2599926766,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:51:14+00:00,[],2024-10-20 03:51:14+00:00,,https://github.com/tensorflow/tensorflow/pull/78384,[],[],
2599926523,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:50:45+00:00,[],2024-10-20 03:50:45+00:00,,https://github.com/tensorflow/tensorflow/pull/78383,[],[],
2599922249,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:47:12+00:00,[],2024-10-20 03:47:12+00:00,,https://github.com/tensorflow/tensorflow/pull/78382,[],[],
2599921887,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:47:00+00:00,[],2024-10-20 03:47:00+00:00,,https://github.com/tensorflow/tensorflow/pull/78381,[],[],
2599921284,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:46:28+00:00,[],2024-10-21 04:24:56+00:00,,https://github.com/tensorflow/tensorflow/pull/78380,[],[],
2599920827,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:45:01+00:00,[],2024-10-22 06:22:51+00:00,2024-10-22 06:22:49+00:00,https://github.com/tensorflow/tensorflow/pull/78379,[],[],
2599920589,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:44:01+00:00,[],2024-10-20 03:44:01+00:00,,https://github.com/tensorflow/tensorflow/pull/78378,[],[],
2599918176,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:41:36+00:00,[],2024-10-20 03:41:36+00:00,,https://github.com/tensorflow/tensorflow/pull/78377,[],[],
2599917144,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:40:54+00:00,[],2024-10-22 04:31:49+00:00,,https://github.com/tensorflow/tensorflow/pull/78376,[],[],
2599917067,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:40:41+00:00,[],2024-10-20 03:40:41+00:00,,https://github.com/tensorflow/tensorflow/pull/78375,[],[],
2599916498,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:40:22+00:00,[],2024-10-22 05:59:12+00:00,2024-10-22 05:59:11+00:00,https://github.com/tensorflow/tensorflow/pull/78374,[],[],
2599914791,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:37:52+00:00,[],2024-10-22 04:33:56+00:00,,https://github.com/tensorflow/tensorflow/pull/78373,[],[],
2599914392,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:36:10+00:00,[],2024-10-20 03:36:10+00:00,,https://github.com/tensorflow/tensorflow/pull/78372,[],[],
2599911894,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:34:26+00:00,[],2024-10-20 03:34:26+00:00,,https://github.com/tensorflow/tensorflow/pull/78371,[],[],
2599911738,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:33:59+00:00,[],2024-10-22 10:51:38+00:00,2024-10-22 10:51:37+00:00,https://github.com/tensorflow/tensorflow/pull/78370,[],[],
2599909579,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:32:15+00:00,[],2024-10-20 03:32:15+00:00,,https://github.com/tensorflow/tensorflow/pull/78369,[],[],
2599907227,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:31:04+00:00,[],2024-10-20 03:31:04+00:00,,https://github.com/tensorflow/tensorflow/pull/78368,[],[],
2599902195,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-20 03:29:08+00:00,[],2024-10-20 03:29:08+00:00,,https://github.com/tensorflow/tensorflow/pull/78367,[],[],
