id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2421840153,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-22 03:35:23+00:00,[],2024-07-22 03:35:23+00:00,,https://github.com/tensorflow/tensorflow/pull/72266,[],[],
2421837908,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-22 03:32:31+00:00,[],2024-07-22 03:32:31+00:00,,https://github.com/tensorflow/tensorflow/pull/72265,[],[],
2421827992,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-22 03:24:26+00:00,[],2024-07-22 03:24:26+00:00,,https://github.com/tensorflow/tensorflow/pull/72264,[],[],
2421826673,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-22 03:23:39+00:00,[],2024-07-22 03:23:39+00:00,,https://github.com/tensorflow/tensorflow/pull/72263,[],[],
2421801525,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-22 03:05:11+00:00,[],2024-07-23 08:26:16+00:00,,https://github.com/tensorflow/tensorflow/pull/72262,[],[],
2421766860,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-22 02:26:31+00:00,[],2024-07-22 02:26:31+00:00,,https://github.com/tensorflow/tensorflow/pull/72261,[],[],
2421649757,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 23:33:28+00:00,[],2024-07-21 23:33:28+00:00,,https://github.com/tensorflow/tensorflow/pull/72260,[],[],
2421450625,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 15:10:20+00:00,[],2024-07-21 15:10:20+00:00,,https://github.com/tensorflow/tensorflow/pull/72258,[],[],
2421413249,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 13:47:10+00:00,[],2024-07-21 13:47:10+00:00,,https://github.com/tensorflow/tensorflow/pull/72256,[],[],
2421294581,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 08:37:10+00:00,[],2024-07-21 08:37:10+00:00,,https://github.com/tensorflow/tensorflow/pull/72254,[],[],
2421252782,pull_request,closed,,[XLA:GPU] Remove wrong expectation from skipped Triton support test.,"[XLA:GPU] Remove wrong expectation from skipped Triton support test.

This was not caught because the test is commented out, but we definitely don't
intend to fulfill that expectation once we re-enable that test.
",copybara-service[bot],2024-07-21 06:36:48+00:00,[],2024-07-29 20:17:16+00:00,2024-07-29 20:17:16+00:00,https://github.com/tensorflow/tensorflow/pull/72253,[],[],
2421235593,pull_request,closed,,Legalize mhlo.gather to tfl,"Legalize mhlo.gather to tfl
",copybara-service[bot],2024-07-21 05:45:19+00:00,['LukeBoyer'],2024-07-22 23:59:22+00:00,2024-07-22 23:59:21+00:00,https://github.com/tensorflow/tensorflow/pull/72252,[],[],
2421182345,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:41:54+00:00,[],2024-07-21 02:41:54+00:00,,https://github.com/tensorflow/tensorflow/pull/72251,[],[],
2421182064,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:40:43+00:00,[],2024-07-21 02:40:43+00:00,,https://github.com/tensorflow/tensorflow/pull/72250,[],[],
2421181945,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:40:07+00:00,[],2024-07-21 02:40:07+00:00,,https://github.com/tensorflow/tensorflow/pull/72249,[],[],
2421181549,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:38:30+00:00,[],2024-07-21 04:20:38+00:00,2024-07-21 04:20:37+00:00,https://github.com/tensorflow/tensorflow/pull/72248,[],[],
2421181314,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:37:33+00:00,[],2024-07-21 02:37:33+00:00,,https://github.com/tensorflow/tensorflow/pull/72247,[],[],
2421181235,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:37:16+00:00,[],2024-07-21 02:37:16+00:00,,https://github.com/tensorflow/tensorflow/pull/72246,[],[],
2421180979,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:36:14+00:00,[],2024-07-22 09:47:59+00:00,2024-07-22 09:47:58+00:00,https://github.com/tensorflow/tensorflow/pull/72245,[],[],
2421180827,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:35:32+00:00,[],2024-07-21 02:35:32+00:00,,https://github.com/tensorflow/tensorflow/pull/72244,[],[],
2421180280,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:33:06+00:00,[],2024-07-21 07:36:28+00:00,,https://github.com/tensorflow/tensorflow/pull/72243,[],[],
2421180073,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:32:11+00:00,[],2024-07-21 02:32:11+00:00,,https://github.com/tensorflow/tensorflow/pull/72242,[],[],
2421179858,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:31:06+00:00,[],2024-07-21 02:31:06+00:00,,https://github.com/tensorflow/tensorflow/pull/72241,[],[],
2421179184,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:28:22+00:00,[],2024-07-21 02:28:22+00:00,,https://github.com/tensorflow/tensorflow/pull/72240,[],[],
2421178433,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:25:23+00:00,[],2024-07-22 04:39:34+00:00,2024-07-22 04:39:33+00:00,https://github.com/tensorflow/tensorflow/pull/72239,[],[],
2421178272,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-21 02:24:53+00:00,[],2024-07-21 02:24:53+00:00,,https://github.com/tensorflow/tensorflow/pull/72238,[],[],
2421149551,pull_request,open,,Integrate LLVM at llvm/llvm-project@f1d3fe7aae78,"Integrate LLVM at llvm/llvm-project@f1d3fe7aae78

Updates LLVM usage to match
[f1d3fe7aae78](https://github.com/llvm/llvm-project/commit/f1d3fe7aae78)
",copybara-service[bot],2024-07-21 00:50:33+00:00,[],2024-07-21 02:02:38+00:00,,https://github.com/tensorflow/tensorflow/pull/72236,[],[],
2421060715,pull_request,closed,,Create theorems-lab,theorems lab ,Theorems-lab,2024-07-20 21:23:20+00:00,['gbaned'],2024-07-20 21:52:18+00:00,2024-07-20 21:52:09+00:00,https://github.com/tensorflow/tensorflow/pull/72234,"[('size:XS', 'CL Change Size: Extra Small'), ('invalid', 'Hacktoberfest spam PR')]","[{'comment_id': 2241298239, 'issue_id': 2421060715, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72234/checks?check_run_id=27703835727) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 20, 21, 23, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241298372, 'issue_id': 2421060715, 'author': 'Theorems-lab', 'body': 'theorems', 'created_at': datetime.datetime(2024, 7, 20, 21, 23, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2241305077, 'issue_id': 2421060715, 'author': 'mihaimaruseac', 'body': ""Please don't spam"", 'created_at': datetime.datetime(2024, 7, 20, 21, 52, 9, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-20 21:23:24 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72234/checks?check_run_id=27703835727) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

Theorems-lab (Issue Creator) on (2024-07-20 21:23:59 UTC): theorems

mihaimaruseac on (2024-07-20 21:52:09 UTC): Please don't spam

"
2421057743,pull_request,closed,,[XLA:MSA] Support slice instruction in runtime simulator,"[XLA:MSA] Support slice instruction in runtime simulator

This patch includes the slice instruction overhead into the runtime simulator. The slice instruction introduces async transfer between default<->alternate memory space, which is the same as the copy-start copy-done instruction, except the slice instructions have different way to calculate the transfer bytes.
",copybara-service[bot],2024-07-20 21:12:34+00:00,[],2024-07-26 01:20:58+00:00,2024-07-26 01:20:58+00:00,https://github.com/tensorflow/tensorflow/pull/72233,[],[],
2421038269,pull_request,closed,,Switch from `PyEval_CallObject` to `PyObject_Call`,"https://github.com/python/cpython/issues/105107 Remove deprecate PyEval_CallObject() function.

> There are replacement functions like PyObject_Call() and PyObject_CallFunction() which exist since Python 3.0 at least and so is backward compatible.",shadchin,2024-07-20 20:02:59+00:00,['gbaned'],2024-10-15 08:12:48+00:00,2024-10-15 06:47:05+00:00,https://github.com/tensorflow/tensorflow/pull/72232,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small')]","[{'comment_id': 2244300186, 'issue_id': 2421038269, 'author': 'keerthanakadiri', 'body': 'Hi @rohan100jain , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 7, 23, 5, 44, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2270801751, 'issue_id': 2421038269, 'author': 'keerthanakadiri', 'body': 'Hi @rohan100jain , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 8, 6, 9, 19, 53, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298012056, 'issue_id': 2421038269, 'author': 'keerthanakadiri', 'body': 'Hi @rohan100jain , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 8, 20, 5, 43, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2311694285, 'issue_id': 2421038269, 'author': 'keerthanakadiri', 'body': 'Hi @rohan100jain , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 8, 27, 6, 41, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2324019152, 'issue_id': 2421038269, 'author': 'keerthanakadiri', 'body': 'Hi @rohan100jain , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 9, 2, 7, 33, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2354723516, 'issue_id': 2421038269, 'author': 'keerthanakadiri', 'body': 'Hi @rohan100jain , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 9, 17, 7, 11, 5, tzinfo=datetime.timezone.utc)}, {'comment_id': 2367704480, 'issue_id': 2421038269, 'author': 'keerthanakadiri', 'body': 'Hi @rohan100jain , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 9, 23, 9, 40, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2368555786, 'issue_id': 2421038269, 'author': 'shadchin', 'body': '@keerthanakadiri\r\nCan anyone else take a look at this PR?', 'created_at': datetime.datetime(2024, 9, 23, 15, 1, 45, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-07-23 05:44:48 UTC): Hi @rohan100jain , Can you please review this PR? Thank you

keerthanakadiri on (2024-08-06 09:19:53 UTC): Hi @rohan100jain , Can you please review this PR? Thank you

keerthanakadiri on (2024-08-20 05:43:14 UTC): Hi @rohan100jain , Can you please review this PR? Thank you

keerthanakadiri on (2024-08-27 06:41:44 UTC): Hi @rohan100jain , Can you please review this PR? Thank you

keerthanakadiri on (2024-09-02 07:33:26 UTC): Hi @rohan100jain , Can you please review this PR? Thank you

keerthanakadiri on (2024-09-17 07:11:05 UTC): Hi @rohan100jain , Can you please review this PR? Thank you

keerthanakadiri on (2024-09-23 09:40:24 UTC): Hi @rohan100jain , Can you please review this PR? Thank you

shadchin (Issue Creator) on (2024-09-23 15:01:45 UTC): @keerthanakadiri
Can anyone else take a look at this PR?

"
2420984082,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-20 17:21:04+00:00,[],2024-07-22 11:50:04+00:00,2024-07-22 11:50:03+00:00,https://github.com/tensorflow/tensorflow/pull/72231,[],[],
2420970445,pull_request,open,,PR #15029: Skip emitting Triton kernel when deserializing from cache,"PR #15029: Skip emitting Triton kernel when deserializing from cache

Imported from GitHub PR https://github.com/openxla/xla/pull/15029

This change avoids running final part of the Triton kernel emission when deserializing form cache. This can make a 0.5-1s difference on larger Pallas kernels (we see ~600ms/2x improvement in deserialization time of a step/update function with Pallas attention kernel).
Copybara import of the project:

--
700c1704ff124042185a5b3e8dba82b5eca6bc34 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Skip emitting Triton kernel when deserializing

--
69505da4cd81a35c390f6301f4a474eb2d0c0c67 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Address reviewer comments

Merging this change closes #15029

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15029 from jaro-sevcik:avoid-triton-compilation-on-deserialization 69505da4cd81a35c390f6301f4a474eb2d0c0c67
",copybara-service[bot],2024-07-20 16:42:37+00:00,[],2024-07-22 09:22:41+00:00,,https://github.com/tensorflow/tensorflow/pull/72230,[],[],
2420707521,pull_request,closed,,[XLA:GPU] Add A100-80 autotuning entries for the gpu_compiler_test.,"[XLA:GPU] Add A100-80 autotuning entries for the gpu_compiler_test.
",copybara-service[bot],2024-07-20 08:07:27+00:00,[],2024-07-20 09:52:45+00:00,2024-07-20 09:52:45+00:00,https://github.com/tensorflow/tensorflow/pull/72229,[],[],
2420531621,pull_request,closed,,Legalize reduction ops mhlo -> tfl.,"Legalize reduction ops mhlo -> tfl.
",copybara-service[bot],2024-07-20 03:32:46+00:00,['LukeBoyer'],2024-07-22 22:28:09+00:00,2024-07-22 22:28:08+00:00,https://github.com/tensorflow/tensorflow/pull/72228,[],[],
2420405207,pull_request,closed,,Add APIs to set BufferHandle for SignatureRunner,"Add APIs to set BufferHandle for SignatureRunner

Added two APIs of SetInputBufferHandle(), SetOutputBufferHandle() which are
SignatureRunner version of Interpreter::SetBufferHandle().

Also refactored Subgraph::SetBufferHandleImpl() to share the logic with
Interpreter API and SignatureRunner API.
",copybara-service[bot],2024-07-20 00:24:44+00:00,['terryheo'],2024-07-23 01:15:41+00:00,2024-07-23 01:15:40+00:00,https://github.com/tensorflow/tensorflow/pull/72227,[],[],
2420401064,pull_request,open,,Integrate LLVM at llvm/llvm-project@84658fb82b67,"Integrate LLVM at llvm/llvm-project@84658fb82b67

Updates LLVM usage to match
[84658fb82b67](https://github.com/llvm/llvm-project/commit/84658fb82b67)
",copybara-service[bot],2024-07-20 00:14:40+00:00,[],2024-07-21 00:19:29+00:00,,https://github.com/tensorflow/tensorflow/pull/72226,[],[],
2420398547,pull_request,open,,Fix the efficient reshard path in device_put when you want to go from 1 mesh to another with different device assignments.,"Fix the efficient reshard path in device_put when you want to go from 1 mesh to another with different device assignments.

The old code lead to the wrong answer as shown in the test added in this PR.

Reverts aeeeef0ba125dd2b28b59c5d144dd0a237a780c4
",copybara-service[bot],2024-07-20 00:09:23+00:00,['yashk2810'],2024-07-20 00:09:24+00:00,,https://github.com/tensorflow/tensorflow/pull/72225,[],[],
2420393420,pull_request,closed,,Add UnfoldSplatConstantPass to before HLO to TFLite legalization.,"Add UnfoldSplatConstantPass to before HLO to TFLite legalization.

This pass is needed to avoid folding splat constants with broadcasts, which can cause bloated model size.
",copybara-service[bot],2024-07-19 23:59:35+00:00,['sirakiin'],2024-07-22 18:38:57+00:00,2024-07-22 18:38:57+00:00,https://github.com/tensorflow/tensorflow/pull/72224,[],[],
2420324582,pull_request,open,,Integrate LLVM at llvm/llvm-project@22eb290a9696,"Integrate LLVM at llvm/llvm-project@22eb290a9696

Updates LLVM usage to match
[22eb290a9696](https://github.com/llvm/llvm-project/commit/22eb290a9696)
",copybara-service[bot],2024-07-19 23:37:46+00:00,[],2024-07-19 23:37:46+00:00,,https://github.com/tensorflow/tensorflow/pull/72223,[],[],
2420313521,pull_request,closed,,PR #71852: Move handling of TF_CUDNN_DETERMINISTIC from XLA to TF.,"PR #71852: Move handling of TF_CUDNN_DETERMINISTIC from XLA to TF.

Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/71852

The environment variable is TF-specific; controlling the behavior of determinism in XLA through the numeric options argument is more explicit.

Related XLA PR after this is committed will be https://github.com/openxla/xla/pull/14310.

Copybara import of the project:

--
9868a120f0aee55286a18f69e303023ba39e03a8 by Ilia Sergachev <isergachev@nvidia.com>:

Move handling of TF_CUDNN_DETERMINISTIC from XLA to TF.

The environment variable is TF-specific; controlling the behavior of
determinism in XLA through numeric options is more explicit.

--
e33ce1a52ff5ab553648814de38628dc71366d07 by Ilia Sergachev <isergachev@nvidia.com>:

Apply buildifier formatting fix

Merging this change closes #71852

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/71852 from sergachev:determinism_env_var e33ce1a52ff5ab553648814de38628dc71366d07
",copybara-service[bot],2024-07-19 23:31:37+00:00,[],2024-07-23 02:29:38+00:00,2024-07-23 02:29:37+00:00,https://github.com/tensorflow/tensorflow/pull/72222,[],[],
2420269685,pull_request,closed,,Increase memory limit for ASAN test.,"Increase memory limit for ASAN test.

Reverts aeeeef0ba125dd2b28b59c5d144dd0a237a780c4
",copybara-service[bot],2024-07-19 23:23:06+00:00,[],2024-07-20 00:06:07+00:00,2024-07-20 00:06:05+00:00,https://github.com/tensorflow/tensorflow/pull/72221,[],[],
2420129638,pull_request,closed,,Reverts 1a98f7480924c696d76f182913e35c6b185f2be4,"Reverts 1a98f7480924c696d76f182913e35c6b185f2be4
",copybara-service[bot],2024-07-19 22:39:05+00:00,['BlaziusMaximus'],2024-07-22 20:24:48+00:00,2024-07-22 20:24:47+00:00,https://github.com/tensorflow/tensorflow/pull/72220,[],[],
2420078792,pull_request,closed,,Legalize mhlo.pad to tfl,"Legalize mhlo.pad to tfl
",copybara-service[bot],2024-07-19 22:20:19+00:00,['LukeBoyer'],2024-07-21 21:13:45+00:00,2024-07-21 21:13:45+00:00,https://github.com/tensorflow/tensorflow/pull/72219,[],[],
2420065701,pull_request,closed,,Use Stream::CreateEventBasedTimer instead of old GpuTimer::Create function.,"Use Stream::CreateEventBasedTimer instead of old GpuTimer::Create function.
",copybara-service[bot],2024-07-19 22:17:21+00:00,[],2024-07-20 22:34:13+00:00,2024-07-20 22:34:12+00:00,https://github.com/tensorflow/tensorflow/pull/72218,[],[],
2420028482,pull_request,closed,,[XLA] Add option to make cross-program prefetch more permissive.,"[XLA] Add option to make cross-program prefetch more permissive.
",copybara-service[bot],2024-07-19 21:57:42+00:00,[],2024-07-24 15:16:26+00:00,2024-07-24 15:16:25+00:00,https://github.com/tensorflow/tensorflow/pull/72217,[],[],
2420005687,pull_request,closed,,[ColocatePredecessorTreesPass] Lower log level for `ShouldRunPass()`.,"[ColocatePredecessorTreesPass] Lower log level for `ShouldRunPass()`.

Reverts aeeeef0ba125dd2b28b59c5d144dd0a237a780c4
",copybara-service[bot],2024-07-19 21:55:14+00:00,[],2024-07-19 23:25:50+00:00,2024-07-19 23:25:49+00:00,https://github.com/tensorflow/tensorflow/pull/72216,[],[],
2419972500,pull_request,closed,,[XLA] Avoid using OpSharding in hlo_parser.,"[XLA] Avoid using OpSharding in hlo_parser.
",copybara-service[bot],2024-07-19 21:42:39+00:00,[],2024-08-01 01:28:56+00:00,2024-08-01 01:28:56+00:00,https://github.com/tensorflow/tensorflow/pull/72215,[],[],
2419930680,pull_request,closed,,[SPMD:Bug-Fix] Add explicit divisibility check in GroupShardingOnReplicatedDim for logic which assumed,"[SPMD:Bug-Fix] Add explicit divisibility check in GroupShardingOnReplicatedDim for logic which assumed
```
 num_groups / (sharding.ReplicateOnLastTileDim() ? sharding.tile_assignment().dimensions().back() : 1)
```
was an integer.
",copybara-service[bot],2024-07-19 21:32:37+00:00,[],2024-08-02 00:19:01+00:00,2024-08-02 00:19:01+00:00,https://github.com/tensorflow/tensorflow/pull/72214,[],[],
2419873099,pull_request,open,,Remove the Windows-specific DEF file filtering logic from the TensorFlow BUILD file.,"Remove the Windows-specific DEF file filtering logic from the TensorFlow BUILD file.

Reverts aeeeef0ba125dd2b28b59c5d144dd0a237a780c4
",copybara-service[bot],2024-07-19 21:15:25+00:00,['ecalubaquib'],2024-07-19 22:53:50+00:00,,https://github.com/tensorflow/tensorflow/pull/72213,[],"[{'comment_id': 2240120612, 'issue_id': 2419873099, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72213/checks?check_run_id=27684108057) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 19, 21, 15, 32, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-19 21:15:32 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72213/checks?check_run_id=27684108057) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2419852002,pull_request,closed,,Use new Stream::CreateEventBasedTimer instead of old GpuTimer::Create call.,"Use new Stream::CreateEventBasedTimer instead of old GpuTimer::Create call.
",copybara-service[bot],2024-07-19 21:01:07+00:00,[],2024-07-19 22:47:49+00:00,2024-07-19 22:47:49+00:00,https://github.com/tensorflow/tensorflow/pull/72212,[],[],
2419845918,pull_request,closed,,"In `build.py`, stop trying to pull container after first successful pull","In `build.py`, stop trying to pull container after first successful pull

Reverts aeeeef0ba125dd2b28b59c5d144dd0a237a780c4
",copybara-service[bot],2024-07-19 20:57:58+00:00,['ddunl'],2024-07-19 22:53:59+00:00,2024-07-19 22:53:59+00:00,https://github.com/tensorflow/tensorflow/pull/72211,[],[],
2419844382,pull_request,closed,,Remove dependency of win_lib_files_for_exported_symbols from shim:shape,"Remove dependency of win_lib_files_for_exported_symbols from shim:shape
",copybara-service[bot],2024-07-19 20:57:12+00:00,['ecalubaquib'],2024-07-29 17:46:16+00:00,2024-07-29 17:46:15+00:00,https://github.com/tensorflow/tensorflow/pull/72210,[],"[{'comment_id': 2240092592, 'issue_id': 2419844382, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72210/checks?check_run_id=27683531333) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 19, 20, 57, 17, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-19 20:57:17 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72210/checks?check_run_id=27683531333) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2419830681,pull_request,closed,,Use new Stream::CreateEventBasedTimer interface to create GpuTimers in stream_executor directories.,"Use new Stream::CreateEventBasedTimer interface to create GpuTimers in stream_executor directories.
",copybara-service[bot],2024-07-19 20:50:14+00:00,[],2024-07-20 17:22:33+00:00,2024-07-20 17:22:32+00:00,https://github.com/tensorflow/tensorflow/pull/72209,[],[],
2419805264,pull_request,closed,,Remove unused `aws_support` and `hdfs_support` configs,"Remove unused `aws_support` and `hdfs_support` configs
",copybara-service[bot],2024-07-19 20:30:39+00:00,['ddunl'],2024-07-23 20:49:08+00:00,2024-07-23 20:49:07+00:00,https://github.com/tensorflow/tensorflow/pull/72208,[],[],
2419712531,pull_request,closed,,Copy python_utils wrapper to be used within mlir,"Copy python_utils wrapper to be used within mlir
",copybara-service[bot],2024-07-19 19:41:08+00:00,[],2024-07-24 23:34:06+00:00,2024-07-24 23:34:05+00:00,https://github.com/tensorflow/tensorflow/pull/72207,[],[],
2419712321,pull_request,closed,,internal visibility change only,"internal visibility change only
",copybara-service[bot],2024-07-19 19:40:56+00:00,[],2024-07-19 21:32:25+00:00,2024-07-19 21:32:24+00:00,https://github.com/tensorflow/tensorflow/pull/72206,[],[],
2419675698,pull_request,closed,,[easy] add missing space in log statement `Start UnwindOnError from function`,"[easy] add missing space in log statement `Start UnwindOnError from function`

This makes the start unwind log msg symmetric to `Finish UnwindOnError for function ` (notice trailing space)

Reverts f58a5f20b65855146a6e0f159c2f0ccacd095c48
",copybara-service[bot],2024-07-19 19:15:17+00:00,[],2024-07-19 21:41:29+00:00,2024-07-19 21:41:29+00:00,https://github.com/tensorflow/tensorflow/pull/72205,[],[],
2419663847,pull_request,closed,,Fix another optimizer which isn't using resource variables correctly.,"Fix another optimizer which isn't using resource variables correctly.

Reverts f58a5f20b65855146a6e0f159c2f0ccacd095c48
",copybara-service[bot],2024-07-19 19:09:20+00:00,[],2024-07-19 21:18:09+00:00,2024-07-19 21:18:09+00:00,https://github.com/tensorflow/tensorflow/pull/72204,[],[],
2419648657,pull_request,closed,,Fix acos decomposition for non-complex arguments,"Fix acos decomposition for non-complex arguments

The previous decomposition was incorrect for x == -1, which should return pi.
",copybara-service[bot],2024-07-19 19:02:27+00:00,['GleasonK'],2024-07-20 02:34:45+00:00,2024-07-20 02:34:44+00:00,https://github.com/tensorflow/tensorflow/pull/72203,[],[],
2419598819,pull_request,open,,Fix a typo in multi_process_runner.py,"Fix a typo in multi_process_runner.py

Reverts f58a5f20b65855146a6e0f159c2f0ccacd095c48
",copybara-service[bot],2024-07-19 18:34:27+00:00,[],2024-07-19 18:34:27+00:00,,https://github.com/tensorflow/tensorflow/pull/72201,[],[],
2419591722,pull_request,closed,,Remove OptimizeGlobalTensorsPass and FreezeGlobalTensorsPass from PostVarFreezing phase of TFLite Converter.,"Remove OptimizeGlobalTensorsPass and FreezeGlobalTensorsPass from PostVarFreezing phase of TFLite Converter.

These passes are not needed for TFLite conversion.

Reverts 91df7e393aa1361a215e7bc6e70480aff6111b41
",copybara-service[bot],2024-07-19 18:30:36+00:00,['vamsimanchala'],2024-07-26 19:41:41+00:00,2024-07-26 19:41:40+00:00,https://github.com/tensorflow/tensorflow/pull/72200,[],[],
2419580820,pull_request,closed,,Rollback due to internal breaking change,"Rollback due to internal breaking change

Reverts efc89fa94b37d378faaffb31ebc127c8ac42dcb7
",copybara-service[bot],2024-07-19 18:24:38+00:00,['changm'],2024-07-19 20:22:33+00:00,2024-07-19 20:22:33+00:00,https://github.com/tensorflow/tensorflow/pull/72199,[],[],
2419483309,pull_request,closed,,[IFRT] Introduce pass to merge reshards with the same src and dst. ,"[IFRT] Introduce pass to merge reshards with the same src and dst. 

This optimizes the reshards to use a single RPC call instead of multiple RPC calls. 
It currently merges only when the src is func BlockArg or an ifrt Op with `outputs` of type IfrtArrayType, and for any destination.
",copybara-service[bot],2024-07-19 17:37:00+00:00,[],2024-07-23 13:54:42+00:00,2024-07-23 13:54:41+00:00,https://github.com/tensorflow/tensorflow/pull/72197,[],[],
2419482061,pull_request,closed,,PR #14900: [PJRT:GPU] Propagate arg and result info from MLIR to XLA Compile method,"PR #14900: [PJRT:GPU] Propagate arg and result info from MLIR to XLA Compile method

Imported from GitHub PR https://github.com/openxla/xla/pull/14900

In MLIR flavor of the PjRtStreamExecutorClient::Compile method, we now transfer the argument layouts and result layout from MLIR code to compile options.

If compile options already specified argument layouts, we ignore layouts from MLIR.

We also make sure that the argument/result layouts are preserved when SPMD needs to canonicalize layouts after resharding parameters and/or layouts.
Copybara import of the project:

--
bbe0015acb39a22de293049a35f6ea847c63c720 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Revert ""Reverts 5b619ac97f0b15cdadf1eb67ac2d5234a17dbfea""

This reverts commit e21e3e0165c83ee659f4d681ac606b9fc6ad4172.

--
b33b94463837ff35b3f30e9b5727ebe57e324a90 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Fix and test

--
9c4f6e7c5de7101a9658f0807ba48d3baa8e32a6 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Make sure the callback only mutates local data

--
179adcb1e1930f0a4912b907f3c6d8eef553efed by Jaroslav Sevcik <jsevcik@nvidia.com>:

Bake argument layouts into options, use them in canonicalization callback

--
1042f7ee78f5ee8d45ccfd57f67d3657b5a9cf07 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Change shardings to only use 2 GPUs

Merging this change closes #14900

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14900 from jaro-sevcik:preserve-argument-layouts-on-canonicalization 1042f7ee78f5ee8d45ccfd57f67d3657b5a9cf07
",copybara-service[bot],2024-07-19 17:36:01+00:00,[],2024-07-23 07:49:52+00:00,2024-07-23 07:49:51+00:00,https://github.com/tensorflow/tensorflow/pull/72196,[],[],
2419475753,pull_request,closed,,"r2.17 cherry-pick: 314385ab894 ""Bump minSdkVersion of TFL Android libs to 21.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/314385ab894368074cc109121de7359c12839b04,tensorflow-jenkins,2024-07-19 17:30:56+00:00,[],2024-10-15 18:13:08+00:00,2024-10-15 18:13:05+00:00,https://github.com/tensorflow/tensorflow/pull/72195,[],"[{'comment_id': 2243780050, 'issue_id': 2419475753, 'author': 'junjiang-lab', 'body': 'Context (b/346609094): TFL Android libs are built with NDK API 21. This bump is to match the reality.', 'created_at': datetime.datetime(2024, 7, 22, 20, 42, 37, tzinfo=datetime.timezone.utc)}]","junjiang-lab on (2024-07-22 20:42:37 UTC): Context (b/346609094): TFL Android libs are built with NDK API 21. This bump is to match the reality.

"
2419469397,pull_request,closed,,"r2.17 cherry-pick: 864b3590015 ""Include necessary .h files in the aar lib.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/864b3590015e51d7538d39689e25dad3a1afe5fe,tensorflow-jenkins,2024-07-19 17:26:09+00:00,[],2024-07-23 15:55:48+00:00,2024-07-23 15:55:46+00:00,https://github.com/tensorflow/tensorflow/pull/72194,[],"[{'comment_id': 2243782337, 'issue_id': 2419469397, 'author': 'junjiang-lab', 'body': 'Context (b/344865814): Tensorflow-lite-2.16.1.aar downloaded from Maven doesn’t include all .h files to build c++ code. This would fix the build error when using TF Lite C API via CMake.', 'created_at': datetime.datetime(2024, 7, 22, 20, 44, 11, tzinfo=datetime.timezone.utc)}]","junjiang-lab on (2024-07-22 20:44:11 UTC): Context (b/344865814): Tensorflow-lite-2.16.1.aar downloaded from Maven doesn’t include all .h files to build c++ code. This would fix the build error when using TF Lite C API via CMake.

"
2419381719,pull_request,closed,,Reverts 5c92d9f35258c44bdaa17184604c1a3af450fb5e,"Reverts 5c92d9f35258c44bdaa17184604c1a3af450fb5e
",copybara-service[bot],2024-07-19 16:50:23+00:00,[],2024-07-19 18:37:38+00:00,2024-07-19 18:37:37+00:00,https://github.com/tensorflow/tensorflow/pull/72193,[],[],
2419317597,pull_request,closed,,[XLA:GPU] Always initialize all members of `DeviceDescription`.,"[XLA:GPU] Always initialize all members of `DeviceDescription`.

`DeviceDescription` has two constructors and it seems neither of them is guaranteed to initialize all members. E.g. the default constructor missed the `l2_cache_size_` and `fpus_per_core_` fields.

This change moves all initialization directly to the field definition. This has two benefits:
- if any constructor does not explicitly initialize a field, the initializer from the definition of the field will be used.
- It will be less likely to forget to initialize a field when adding new fields.
",copybara-service[bot],2024-07-19 16:29:29+00:00,[],2024-07-19 17:36:47+00:00,2024-07-19 17:36:47+00:00,https://github.com/tensorflow/tensorflow/pull/72192,[],[],
2419315757,pull_request,open,,"Add a pass to deduplicate channel ids, call on MHLO->HLO conversion.","Add a pass to deduplicate channel ids, call on MHLO->HLO conversion.

This pattern can be introduced if a collective op appears in a JAX JIT'ed function. If that function has multiple calls and gets inlined, we have duplicate channel IDs which is invalid.
",copybara-service[bot],2024-07-19 16:29:01+00:00,['GleasonK'],2024-07-22 14:37:33+00:00,,https://github.com/tensorflow/tensorflow/pull/72191,[],[],
2419292171,pull_request,closed,,Make `typeToTfLiteType` `const`-friendly.,"Make `typeToTfLiteType` `const`-friendly.

Asking for a `const` type would return `kTfLiteNoType`.
",copybara-service[bot],2024-07-19 16:19:02+00:00,['qukhan'],2024-07-19 17:52:07+00:00,2024-07-19 17:52:06+00:00,https://github.com/tensorflow/tensorflow/pull/72190,[],[],
2419285015,pull_request,closed,,[XLA:Python] More fixes for nanobind 2.0.,"[XLA:Python] More fixes for nanobind 2.0.

Mark several more enum types as arithmetic since some downstream users cast to and from integer types.
",copybara-service[bot],2024-07-19 16:14:54+00:00,[],2024-07-19 18:52:18+00:00,2024-07-19 18:52:17+00:00,https://github.com/tensorflow/tensorflow/pull/72189,[],[],
2419230780,pull_request,closed,,[XLA:GPU] Support RTVars in symbolic tile analysis.,"[XLA:GPU] Support RTVars in symbolic tile analysis.
",copybara-service[bot],2024-07-19 15:38:10+00:00,[],2024-07-22 10:46:40+00:00,2024-07-22 10:46:38+00:00,https://github.com/tensorflow/tensorflow/pull/72188,[],[],
2419216031,pull_request,closed,,Disable test in msan to fix builds.,"Disable test in msan to fix builds.
",copybara-service[bot],2024-07-19 15:28:50+00:00,[],2024-07-19 16:08:41+00:00,2024-07-19 16:08:40+00:00,https://github.com/tensorflow/tensorflow/pull/72187,[],[],
2419192303,pull_request,closed,,[XLA:GPU] Only compute tile offset indexing maps for instructions when it is needed.,"[XLA:GPU] Only compute tile offset indexing maps for instructions when it is needed.

Computing tile offset indexing maps is very expensive and not always necessary. When we're at Cost Model/Tiling stage, we only use the indexing map to deduplicate instruction. We can predict if we'll need an indexing map for a particular instruction by computation and comparing a parts of the hash.
",copybara-service[bot],2024-07-19 15:17:08+00:00,[],2024-07-23 11:20:06+00:00,2024-07-23 11:20:05+00:00,https://github.com/tensorflow/tensorflow/pull/72186,[],[],
2419141480,pull_request,open,,Switch to the new Windows presubmit.,"Switch to the new Windows presubmit.
",copybara-service[bot],2024-07-19 14:51:11+00:00,['belitskiy'],2024-07-19 14:51:17+00:00,,https://github.com/tensorflow/tensorflow/pull/72185,[],"[{'comment_id': 2239396432, 'issue_id': 2419141480, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72185/checks?check_run_id=27670202642) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 19, 14, 51, 17, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-19 14:51:17 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72185/checks?check_run_id=27670202642) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2419136452,pull_request,closed,,Remove unused ROCm include,"Remove unused ROCm include
",copybara-service[bot],2024-07-19 14:48:28+00:00,[],2024-07-19 17:08:50+00:00,2024-07-19 17:08:49+00:00,https://github.com/tensorflow/tensorflow/pull/72184,[],[],
2419085162,pull_request,closed,,Reverts f58a5f20b65855146a6e0f159c2f0ccacd095c48,"Reverts f58a5f20b65855146a6e0f159c2f0ccacd095c48
",copybara-service[bot],2024-07-19 14:36:12+00:00,[],2024-07-19 19:05:54+00:00,2024-07-19 19:05:54+00:00,https://github.com/tensorflow/tensorflow/pull/72183,[],[],
2419042688,pull_request,closed,,Make `Interpreter::typed_tensor` support `const` types.,"Make `Interpreter::typed_tensor` support `const` types.

`typeToTfLiteType<T>` returns `kTfLiteNoType` if the given type is `const`.
",copybara-service[bot],2024-07-19 14:20:18+00:00,['qukhan'],2024-07-19 15:49:17+00:00,2024-07-19 15:49:16+00:00,https://github.com/tensorflow/tensorflow/pull/72182,[],[],
2419036415,pull_request,closed,,#sdy Initial set of changes to allow for lowering to the Shardy dialect.,"#sdy Initial set of changes to allow for lowering to the Shardy dialect.

The OpenXLA project is working on an open source, MLIR, named-axis based propagation (and in the future SP<D partitioning) system that will be dialect agnostic (would work for any dialect - MHLO, StableHLO, YourDialect). We plan on having frontends like JAX and PyTorch target this when using XLA and wanting SPMD propagation/partitioning. See www.github.com/openxla/shardy for more info.

Currently Shardy is implemented inside the XLA compiler, requiring us to round-trip between StableHLO and HLO with `mhlo.sharding`s. But we will eventually make Shardy the first pass in the XLA pipeline while it's still working on StableHLO. Partitioning (the system that adds the collectives like all-gathers/all-reduces) will still be the GSPMD Partitioner, but next year the Shardy partitioner will be developed, allowing for propagation and partitioning to be completely in MLIR and the first pass in the pipeline. So then we'd have:
1. Traced jaxpr
2. Jaxpr -> StableHLO
3. StableHLO with Shardy propagation
4. StableHLO with Shardy partitioning
5. StableHLO -> HLO
6. XLA optimizations

The following test:

```py
def test_sdy_lowering(self):
  mesh = jtu.create_global_mesh((4, 2), ('x', 'y'))
  np_inp = np.arange(16).reshape(8, 2)
  s = jax.sharding.NamedSharding(mesh, P('x', 'y'))
  arr = jax.device_put(np_inp, s)

  @partial(jax.jit, out_shardings=s)
  def f(x):
    return x * 2

  print(f.lower(arr).as_text())
```

outputs:

```
module @jit_f attributes {mhlo.num_partitions = 8 : i32, mhlo.num_replicas = 1 : i32} {
  sdy.mesh @mesh = <""x""=4, ""y""=2>
  func.func public @main(%arg0: tensor<8x2xi64> {mhlo.layout_mode = ""{1,0}"", sdy.sharding = #sdy.sharding<@mesh, [{""x""}, {""y""}]>}) -> (tensor<8x2xi64> {jax.result_info = """", mhlo.layout_mode = ""default"", sdy.sharding = #sdy.sharding<@mesh, [{""x""}, {""y""}]>}) {
    %c = stablehlo.constant dense<2> : tensor<i64>
    %0 = stablehlo.broadcast_in_dim %c, dims = [] : (tensor<i64>) -> tensor<8x2xi64>
    %1 = stablehlo.multiply %arg0, %0 : tensor<8x2xi64>
    return %1 : tensor<8x2xi64>
  }
}
```

Shardy will be hidden behind the `jax_use_shardy_partitioner` flag initially before becoming enabled by default in the future.
",copybara-service[bot],2024-07-19 14:18:07+00:00,[],2024-07-23 12:59:19+00:00,2024-07-23 12:59:18+00:00,https://github.com/tensorflow/tensorflow/pull/72181,[],[],
2418695086,pull_request,closed,,[XLA:GPU] Pass operand to the construction of TiledHloInstruction.,"[XLA:GPU] Pass operand to the construction of TiledHloInstruction.

We use `tile_offset_indexing` to distinguish between tiles of the same instruction. 
Composing and simplifying indexing maps is expensive. For instruction inside the fusion that are not load/store, comparing `operand` pointers is a cheaper way to achieve the same effect. This change is a preparation to compute `tile_offset_indexing` only when necessary.
",copybara-service[bot],2024-07-19 11:43:40+00:00,[],2024-07-19 13:05:21+00:00,2024-07-19 13:05:20+00:00,https://github.com/tensorflow/tensorflow/pull/72179,[],[],
2418675951,pull_request,open,,PR #14968: [GPU] Enable sharding of autotuning by default.,"PR #14968: [GPU] Enable sharding of autotuning by default.

Imported from GitHub PR https://github.com/openxla/xla/pull/14968

Requires https://github.com/openxla/xla/pull/14881

@PatriosTheGreat 
Copybara import of the project:

--
94562fa1e73d8031832c0c0ed78b064cc7248aea by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Enable sharding of autotuning by default.

Merging this change closes #14968

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14968 from openxla:enable_sharded_autotuning 94562fa1e73d8031832c0c0ed78b064cc7248aea
",copybara-service[bot],2024-07-19 11:32:09+00:00,[],2024-07-19 11:49:43+00:00,,https://github.com/tensorflow/tensorflow/pull/72178,[],[],
2418642535,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 11:09:44+00:00,[],2024-07-19 11:09:44+00:00,,https://github.com/tensorflow/tensorflow/pull/72177,[],[],
2418635759,pull_request,closed,,PR #15050: Quantized Collectives,"PR #15050: Quantized Collectives

Imported from GitHub PR https://github.com/openxla/xla/pull/15050

Introduces a pass that can reduce the amount of data transferred in all-gather, all-to-all, collective-broadcast and collective-permute ops by exchanging the collective with a subsequent quantization or conversion to a narrower type.
Copybara import of the project:

--
658710e6d4b518fc2efc860279ef31cf1cf9d8ea by Philipp Hack <phack@nvidia.com>:

Adds a pass that exchanges collectives with subsequent quantizations or narrowing type conversions.

Merging this change closes #15050

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15050 from philipphack:u_collective_quant_xla 658710e6d4b518fc2efc860279ef31cf1cf9d8ea
",copybara-service[bot],2024-07-19 11:05:13+00:00,[],2024-07-19 13:24:31+00:00,2024-07-19 13:24:30+00:00,https://github.com/tensorflow/tensorflow/pull/72176,[],[],
2418635426,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 11:05:00+00:00,[],2024-07-19 11:05:00+00:00,,https://github.com/tensorflow/tensorflow/pull/72175,[],[],
2418612206,pull_request,closed,,[XLA:GPU][MLIR-based emitters] Add a pattern that can shrink/refine bounds.,"[XLA:GPU][MLIR-based emitters] Add a pattern that can shrink/refine bounds.

Right now, it can refine ranges of dims/symbols based on the ranges of the
induction variables.

This is needed to update apply_indexing ops after the peeling is done.
",copybara-service[bot],2024-07-19 10:50:19+00:00,['pifon2a'],2024-07-25 13:16:48+00:00,2024-07-25 13:16:46+00:00,https://github.com/tensorflow/tensorflow/pull/72174,[],[],
2418554624,pull_request,open,,Reverts aeeeef0ba125dd2b28b59c5d144dd0a237a780c4,"Reverts aeeeef0ba125dd2b28b59c5d144dd0a237a780c4
",copybara-service[bot],2024-07-19 10:15:11+00:00,[],2024-07-19 18:48:06+00:00,,https://github.com/tensorflow/tensorflow/pull/72173,[],[],
2418546632,pull_request,closed,,Fix constraint check in the shared memory phase of row reductions.,"Fix constraint check in the shared memory phase of row reductions.

The problem is that indexing map creation shrinks the size of the
d0 dimension (thread ID), which in the case of the test I added,
results in only the first 20 threads producing a value for the
shuffle. But then we do an unmasked shuffle with the entire warp,
which means we get some undefined values.
",copybara-service[bot],2024-07-19 10:10:22+00:00,[],2024-07-19 10:31:29+00:00,2024-07-19 10:31:29+00:00,https://github.com/tensorflow/tensorflow/pull/72172,[],[],
2418540307,pull_request,closed,,Remove some debug logging.,"Remove some debug logging.

Probably accidentally submitted at some point.
",copybara-service[bot],2024-07-19 10:06:40+00:00,[],2024-07-19 11:22:50+00:00,2024-07-19 11:22:48+00:00,https://github.com/tensorflow/tensorflow/pull/72171,[],[],
2418535762,pull_request,closed,,Verify that wgmma is used for memory bound shapes,"Verify that wgmma is used for memory bound shapes
",copybara-service[bot],2024-07-19 10:04:06+00:00,['gflegar'],2024-07-19 12:19:44+00:00,2024-07-19 12:19:43+00:00,https://github.com/tensorflow/tensorflow/pull/72170,[],[],
2418524039,pull_request,closed,,PR #15002: Add unique channel id enforcer pass,"PR #15002: Add unique channel id enforcer pass

Imported from GitHub PR https://github.com/openxla/xla/pull/15002

We have found it is not guaranteed after all transformations, partitioning, while loop unrolling etc that all channel ids will be unique.
Rather than debug this throughout XLA it is simpler to just add a pass that mandates unique channel ids, and changes channel ids to make them unique.

Issue: #14600 
Copybara import of the project:

--
476473182f6211b298b6d88d6a06bb128b7978ed by ptoulme-aws <ptoulme@amazon.com>:

Add unique channel id enforcer pass

Merging this change closes #15002

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15002 from ptoulme-aws:unique_channel_id_new 476473182f6211b298b6d88d6a06bb128b7978ed
",copybara-service[bot],2024-07-19 09:57:27+00:00,[],2024-07-19 12:01:10+00:00,2024-07-19 12:01:10+00:00,https://github.com/tensorflow/tensorflow/pull/72169,[],[],
2418504442,pull_request,open,,Integrate LLVM at llvm/llvm-project@5b54f36fb607,"Integrate LLVM at llvm/llvm-project@5b54f36fb607

Updates LLVM usage to match
[5b54f36fb607](https://github.com/llvm/llvm-project/commit/5b54f36fb607)
",copybara-service[bot],2024-07-19 09:46:52+00:00,[],2024-07-19 12:19:05+00:00,,https://github.com/tensorflow/tensorflow/pull/72168,[],[],
2418501760,pull_request,closed,,PR #14968: [GPU] Enable sharding of autotuning by default.,"PR #14968: [GPU] Enable sharding of autotuning by default.

Imported from GitHub PR https://github.com/openxla/xla/pull/14968

Requires https://github.com/openxla/xla/pull/14881

@PatriosTheGreat 
Copybara import of the project:

--
94562fa1e73d8031832c0c0ed78b064cc7248aea by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Enable sharding of autotuning by default.

Merging this change closes #14968

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14968 from openxla:enable_sharded_autotuning 94562fa1e73d8031832c0c0ed78b064cc7248aea
",copybara-service[bot],2024-07-19 09:45:20+00:00,[],2024-07-19 11:42:20+00:00,2024-07-19 11:42:19+00:00,https://github.com/tensorflow/tensorflow/pull/72167,[],[],
2418427381,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 09:08:00+00:00,[],2024-07-19 09:08:00+00:00,,https://github.com/tensorflow/tensorflow/pull/72164,[],[],
2418424862,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 09:06:27+00:00,[],2024-07-20 05:54:14+00:00,2024-07-20 05:54:13+00:00,https://github.com/tensorflow/tensorflow/pull/72163,[],[],
2418413005,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 08:59:57+00:00,[],2024-07-20 08:28:28+00:00,2024-07-20 08:28:28+00:00,https://github.com/tensorflow/tensorflow/pull/72162,[],[],
2418406242,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 08:56:05+00:00,[],2024-07-19 08:56:05+00:00,,https://github.com/tensorflow/tensorflow/pull/72161,[],[],
2418401196,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 08:53:08+00:00,[],2024-07-20 05:28:04+00:00,2024-07-20 05:28:03+00:00,https://github.com/tensorflow/tensorflow/pull/72160,[],[],
2418386941,pull_request,open,,PR #13425: [ROCM] gemm precision settings for autotuner,"PR #13425: [ROCM] gemm precision settings for autotuner

Imported from GitHub PR https://github.com/openxla/xla/pull/13425

Here we add a new flag **xla_gpu_autotune_gemm_rtol** which controls the relative precision used by the BufferComparator (defaults to **0.1**).

Also I added one more ""paranoid"" level 5 for **xla_gpu_autotune_level** which forces the autotuner to discard solutions with accuracy problems. Long time I was under impression that the autotuner already does it, however this is not the case as outlined [here](https://github.com/ROCm/xla/blob/6301f04c50c7637a65b3e0c6f40be628aa00947f/xla/service/gpu/stream_executor_util.cc#L640). BufferComparator just prints out the error message but **keeps wrong solutions** as possible candidates which could lead to a great confusion. So, the autotune level 5 is supposed to discard solutions with accuracy problems.

Besides, I also did some small refactoring on BufferComparator to simplify the source code and added **verbose** flag in order to mute error messages if needed.

@xla-rotation: could you please have a look?
Copybara import of the project:

--
cab53b672f9546fe4b811d09cf998b105dc8be01 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

added precision settings for autotuner and buffer_comparator small refactoring, added verbose flag

Merging this change closes #13425

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/13425 from ROCm:ci_gemm_autotuner_precision_check cab53b672f9546fe4b811d09cf998b105dc8be01
",copybara-service[bot],2024-07-19 08:44:35+00:00,[],2024-07-19 08:44:35+00:00,,https://github.com/tensorflow/tensorflow/pull/72159,[],[],
2418282214,pull_request,open,,PR #15050: Quantized Collectives,"PR #15050: Quantized Collectives

Imported from GitHub PR https://github.com/openxla/xla/pull/15050

Introduces a pass that can reduce the amount of data transferred in all-gather, all-to-all, collective-broadcast and collective-permute ops by exchanging the collective with a subsequent quantization or conversion to a narrower type.
Copybara import of the project:

--
658710e6d4b518fc2efc860279ef31cf1cf9d8ea by Philipp Hack <phack@nvidia.com>:

Adds a pass that exchanges collectives with subsequent quantizations or narrowing type conversions.

Merging this change closes #15050

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15050 from philipphack:u_collective_quant_xla 658710e6d4b518fc2efc860279ef31cf1cf9d8ea
",copybara-service[bot],2024-07-19 07:43:51+00:00,[],2024-07-19 13:20:22+00:00,,https://github.com/tensorflow/tensorflow/pull/72158,[],[],
2418091625,pull_request,open,,Add //learning/gemini/kvcoding/... to ndarray_tensor_allow_list,"Add //learning/gemini/kvcoding/... to ndarray_tensor_allow_list
",copybara-service[bot],2024-07-19 06:22:29+00:00,[],2024-07-19 19:17:47+00:00,,https://github.com/tensorflow/tensorflow/pull/72155,[],[],
2417977621,pull_request,closed,,Pad -> Slice Pad for negative pad vals in prepare_hlo,"Pad -> Slice Pad for negative pad vals in prepare_hlo
",copybara-service[bot],2024-07-19 05:38:34+00:00,['LukeBoyer'],2024-07-21 20:52:23+00:00,2024-07-21 20:52:22+00:00,https://github.com/tensorflow/tensorflow/pull/72154,[],[],
2417913283,pull_request,closed,,Reverts 27482443cf1f68797bc19add1fc9b1bef448a3f2,"Reverts 27482443cf1f68797bc19add1fc9b1bef448a3f2
",copybara-service[bot],2024-07-19 05:05:39+00:00,[],2024-07-19 08:43:01+00:00,2024-07-19 08:43:00+00:00,https://github.com/tensorflow/tensorflow/pull/72153,[],[],
2417905543,pull_request,open,,Rollback of sparse optimizers race condition fix,"Rollback of sparse optimizers race condition fix

Reverts d4d41956d58299764ab19a020fb3abd65875b930
",copybara-service[bot],2024-07-19 04:57:10+00:00,['JW1992'],2024-07-19 16:15:44+00:00,,https://github.com/tensorflow/tensorflow/pull/72152,[],[],
2417818274,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 03:53:45+00:00,[],2024-07-19 03:53:45+00:00,,https://github.com/tensorflow/tensorflow/pull/72151,[],[],
2417812616,pull_request,closed,,[XLA:UNSTACKER] Add a function to detect effectively static dynamic-slice instructions inside unrollable loops.,"[XLA:UNSTACKER] Add a function to detect effectively static dynamic-slice instructions inside unrollable loops.
",copybara-service[bot],2024-07-19 03:46:11+00:00,[],2024-07-19 04:14:29+00:00,2024-07-19 04:14:28+00:00,https://github.com/tensorflow/tensorflow/pull/72150,[],[],
2417811752,pull_request,open,,Improve int2 support,"Improve int2 support
",copybara-service[bot],2024-07-19 03:44:59+00:00,[],2024-07-20 04:24:03+00:00,,https://github.com/tensorflow/tensorflow/pull/72149,[],[],
2417807979,pull_request,closed,,Integrate LLVM at llvm/llvm-project@dd7d81ea49bf,"Integrate LLVM at llvm/llvm-project@dd7d81ea49bf

Updates LLVM usage to match
[dd7d81ea49bf](https://github.com/llvm/llvm-project/commit/dd7d81ea49bf)
",copybara-service[bot],2024-07-19 03:39:52+00:00,[],2024-07-19 06:49:58+00:00,2024-07-19 06:49:58+00:00,https://github.com/tensorflow/tensorflow/pull/72148,[],[],
2417802011,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 03:33:11+00:00,[],2024-07-19 03:33:11+00:00,,https://github.com/tensorflow/tensorflow/pull/72147,[],[],
2417801014,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 03:31:53+00:00,[],2024-07-19 09:01:01+00:00,2024-07-19 09:01:01+00:00,https://github.com/tensorflow/tensorflow/pull/72146,[],[],
2417791548,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 03:21:04+00:00,[],2024-07-19 03:55:29+00:00,,https://github.com/tensorflow/tensorflow/pull/72145,[],[],
2417786924,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 03:20:35+00:00,[],2024-07-19 03:20:35+00:00,,https://github.com/tensorflow/tensorflow/pull/72144,[],[],
2417760550,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-19 03:11:44+00:00,[],2024-07-20 05:47:04+00:00,2024-07-20 05:47:03+00:00,https://github.com/tensorflow/tensorflow/pull/72143,[],[],
2417755098,pull_request,closed,,Unify shape-covering instruction finding in while_initializer_removal pass with  while_loop_unroller pass,"Unify shape-covering instruction finding in while_initializer_removal pass with  while_loop_unroller pass
",copybara-service[bot],2024-07-19 03:05:01+00:00,[],2024-07-19 03:43:22+00:00,2024-07-19 03:43:22+00:00,https://github.com/tensorflow/tensorflow/pull/72142,[],[],
2417751073,pull_request,closed,,Fix crash in AllReduceBlueConnect when multiple partitions are used.,"Fix crash in AllReduceBlueConnect when multiple partitions are used.

Also, the pass now only runs when the all-reduce op has specific values for CollectiveOpGroupMode: kCrossReplica and kFlattenedID. Previously, the pass crashed with any mode other than kCrossReplica. I'm not sure when the two other modes, kCrossPartition and kCrossReplicaAndPartition, are used in JAX programs, and am unsure how to create HLO which uses these modes, so I decided not to support them for now.
",copybara-service[bot],2024-07-19 02:59:58+00:00,['reedwm'],2024-07-22 19:55:41+00:00,2024-07-22 19:55:40+00:00,https://github.com/tensorflow/tensorflow/pull/72141,[],[],
2417628788,pull_request,closed,,[XLA:Unstacker] Correctly handle DynamicGte and DynamicTuple in loop unroller.,"[XLA:Unstacker] Correctly handle DynamicGte and DynamicTuple in loop unroller.

Previously we were assuming that the dynamic index in all of the DynamicGte and DynamicTuple instructions in an unrollable loop body are the induction variable  of the surrounding loop. This cl relaxes this assumption and supports the cases where the dynamic index expression is any expression involving the induction variable as long as it can be evaluated at compile time.
",copybara-service[bot],2024-07-19 01:17:44+00:00,[],2024-07-19 02:34:07+00:00,2024-07-19 02:34:07+00:00,https://github.com/tensorflow/tensorflow/pull/72140,[],[],
2417606643,pull_request,closed,,Fix comment of GetParticipatingDevicesGroups.,"Fix comment of GetParticipatingDevicesGroups.

The example was previously wrong. The example was already tested here https://github.com/openxla/xla/blob/6dfc6ace222f7e10a2c04c1fa0bcd856d066cce3/xla/service/collective_ops_utils_test.cc#L382 and now the example matches the test.

Another example was also added.
",copybara-service[bot],2024-07-19 00:40:15+00:00,['reedwm'],2024-07-19 21:25:20+00:00,2024-07-19 21:25:19+00:00,https://github.com/tensorflow/tensorflow/pull/72139,[],[],
2417599023,pull_request,open,,Integrate LLVM at llvm/llvm-project@f270a4dd6667,"Integrate LLVM at llvm/llvm-project@f270a4dd6667

Updates LLVM usage to match
[f270a4dd6667](https://github.com/llvm/llvm-project/commit/f270a4dd6667)
",copybara-service[bot],2024-07-19 00:27:22+00:00,[],2024-07-19 00:27:22+00:00,,https://github.com/tensorflow/tensorflow/pull/72138,[],[],
2417594830,pull_request,closed,,Add another pattern for unsacking with some refactoring to other patterns.,"Add another pattern for unsacking with some refactoring to other patterns.

This cl adds support for the below pattern:

fusion(stackd, loop_iteration_var)
 computation {
   p0 = parameter(0)
   p1 = parameter(1)
   slice = dynamic-slice(p0, p1, zero)
   broadcast = broadcast(constant)
   add = add(slice, broadcast)
   ROOT reduce = reduce(add, zero), apply=+
}
",copybara-service[bot],2024-07-19 00:20:34+00:00,[],2024-07-19 01:15:28+00:00,2024-07-19 01:15:27+00:00,https://github.com/tensorflow/tensorflow/pull/72137,[],[],
2417583242,pull_request,open,,Increase the default timeout from 200s to 300s to improve the flaky test: //learning/brain/distribute/python/failure_handling:mwms_resize_job_test,"Increase the default timeout from 200s to 300s to improve the flaky test: //learning/brain/distribute/python/failure_handling:mwms_resize_job_test
",copybara-service[bot],2024-07-19 00:02:01+00:00,[],2024-07-19 18:02:23+00:00,,https://github.com/tensorflow/tensorflow/pull/72136,[],[],
2417554795,pull_request,open,,Use static link mode,"Use static link mode
",copybara-service[bot],2024-07-18 23:16:09+00:00,['JW1992'],2024-07-18 23:16:10+00:00,,https://github.com/tensorflow/tensorflow/pull/72135,[],[],
2417545232,pull_request,closed,,Add matmul test case to collective_permute_decomposer test,"Add matmul test case to collective_permute_decomposer test
",copybara-service[bot],2024-07-18 23:02:46+00:00,[],2024-07-29 23:23:40+00:00,2024-07-29 23:23:40+00:00,https://github.com/tensorflow/tensorflow/pull/72134,[],[],
2417541914,pull_request,closed,,#tf-data Add names and event traces to multi device iterators to help debugging.,"#tf-data Add names and event traces to multi device iterators to help debugging.
",copybara-service[bot],2024-07-18 23:00:15+00:00,[],2024-07-19 17:44:29+00:00,2024-07-19 17:44:27+00:00,https://github.com/tensorflow/tensorflow/pull/72133,[],[],
2417510180,pull_request,closed,,Fix comment formatting in HloRematerialization.,"Fix comment formatting in HloRematerialization.
",copybara-service[bot],2024-07-18 22:21:41+00:00,['SandSnip3r'],2024-07-18 23:45:10+00:00,2024-07-18 23:45:09+00:00,https://github.com/tensorflow/tensorflow/pull/72132,[],[],
2417489228,pull_request,open,,Add size printing for HLO model DebugInfo,"Add size printing for HLO model DebugInfo
",copybara-service[bot],2024-07-18 22:00:00+00:00,[],2024-07-18 22:00:00+00:00,,https://github.com/tensorflow/tensorflow/pull/72131,[],[],
2417484703,pull_request,open,,Integrate LLVM at llvm/llvm-project@574dbe3e9cda,"Integrate LLVM at llvm/llvm-project@574dbe3e9cda

Updates LLVM usage to match
[574dbe3e9cda](https://github.com/llvm/llvm-project/commit/574dbe3e9cda)
",copybara-service[bot],2024-07-18 21:55:47+00:00,[],2024-07-19 00:20:13+00:00,,https://github.com/tensorflow/tensorflow/pull/72130,[],[],
2417456452,pull_request,closed,,Separate post processing and resharding insertion into two separate functions. Also rename AutoShardingOption::post_process --> AutoShardingOption::insert_resharding_reshapes.,"Separate post processing and resharding insertion into two separate functions. Also rename AutoShardingOption::post_process --> AutoShardingOption::insert_resharding_reshapes.
",copybara-service[bot],2024-07-18 21:33:40+00:00,[],2024-07-19 00:17:11+00:00,2024-07-19 00:17:10+00:00,https://github.com/tensorflow/tensorflow/pull/72129,[],[],
2417452981,pull_request,closed,,[XLA] Cleaning up algebraic simplifier headers as suggested by clang-tidy,"[XLA] Cleaning up algebraic simplifier headers as suggested by clang-tidy
",copybara-service[bot],2024-07-18 21:30:24+00:00,[],2024-07-22 17:00:25+00:00,2024-07-22 17:00:24+00:00,https://github.com/tensorflow/tensorflow/pull/72128,[],[],
2417449832,pull_request,closed,,Replace Copybara rule with `#if TSL_IS_IN_OSS`,"Replace Copybara rule with `#if TSL_IS_IN_OSS`

Current rule to replace `DownCastToGenerated` is only necessary due to old protobuf version

Reverts 5c92d9f35258c44bdaa17184604c1a3af450fb5e
",copybara-service[bot],2024-07-18 21:27:32+00:00,['ddunl'],2024-07-19 19:17:29+00:00,2024-07-19 19:17:28+00:00,https://github.com/tensorflow/tensorflow/pull/72127,[],[],
2417440198,pull_request,closed,,[xla:gpu] Fix a bug in `IsContiguousSlice` for strided slices,"[xla:gpu] Fix a bug in `IsContiguousSlice` for strided slices

+ re-enable dynamic slice fusion
",copybara-service[bot],2024-07-18 21:20:05+00:00,['ezhulenev'],2024-07-19 00:23:49+00:00,2024-07-19 00:23:48+00:00,https://github.com/tensorflow/tensorflow/pull/72126,[],[],
2417383610,pull_request,open,,move lite/kernels/shim/shape.cc(h) to compiler/mlir/lite/kernels/shim/shape.cc(h),"move lite/kernels/shim/shape.cc(h) to compiler/mlir/lite/kernels/shim/shape.cc(h)
",copybara-service[bot],2024-07-18 20:57:45+00:00,['ecalubaquib'],2024-07-19 16:25:25+00:00,,https://github.com/tensorflow/tensorflow/pull/72125,[],"[{'comment_id': 2237565632, 'issue_id': 2417383610, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72125/checks?check_run_id=27637686335) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 18, 20, 57, 50, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-18 20:57:50 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72125/checks?check_run_id=27637686335) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2417356990,pull_request,closed,,Rename `tsl::testing::kIsOpenSource` to `tsl::kIsOpenSource` and move to `platform.h`,"Rename `tsl::testing::kIsOpenSource` to `tsl::kIsOpenSource` and move to `platform.h`

This will allow it to be used outside of tests.
",copybara-service[bot],2024-07-18 20:39:21+00:00,['ddunl'],2024-07-18 23:53:25+00:00,2024-07-18 23:53:24+00:00,https://github.com/tensorflow/tensorflow/pull/72124,[],[],
2417307601,pull_request,closed,,"Create a base class for GpuTimer, and a method to create objects of that class on Stream.","Create a base class for GpuTimer, and a method to create objects of that class on Stream.
",copybara-service[bot],2024-07-18 20:10:43+00:00,[],2024-07-19 20:29:27+00:00,2024-07-19 20:29:26+00:00,https://github.com/tensorflow/tensorflow/pull/72123,[],[],
2417291957,pull_request,closed,,TupleSimplifier needs to update schedule if there is a schedule.,"TupleSimplifier needs to update schedule if there is a schedule.
Fix the wrong module passed in hlo_runner_pjrt.cc.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15446 from tzunghanjuang:add-PassesIncGen-to-ChloPasses 9542a7494b2a2abb39240f68e64afa9b8b1b5573
",copybara-service[bot],2024-07-18 19:59:26+00:00,[],2024-07-30 22:00:54+00:00,2024-07-30 22:00:53+00:00,https://github.com/tensorflow/tensorflow/pull/72122,[],[],
2417195464,pull_request,closed,,Update TFLite Converter to use the following steps/passes instead of `tf_saved_model::FreezeVariables` function call-,"Update TFLite Converter to use the following steps/passes instead of `tf_saved_model::FreezeVariables` function call-

1. `Lift` Resource Variable as GlobalTensorOps, during SavedModel Import.

2. `OptimizeGlobalTensorsPass` to mark the immutable GlobalTensorOps as such.

3. `FreezeGlobalTensorsPass` to freeze the immutable GlobalTensorOps.

4. `UnfreezeMutableGlobalTensorsPass`, to unfreeze the mutable variables and move them into a session initializer.
",copybara-service[bot],2024-07-18 19:15:16+00:00,['vamsimanchala'],2024-07-23 14:30:42+00:00,2024-07-23 14:30:41+00:00,https://github.com/tensorflow/tensorflow/pull/72121,[],[],
2417188684,pull_request,closed,,Remove deprecated TfLiteOperatorCreateWithData function,"Remove deprecated TfLiteOperatorCreateWithData function

Since it is an alias of TfLiteOperatorCreate()
",copybara-service[bot],2024-07-18 19:10:40+00:00,[],2024-07-18 23:16:45+00:00,2024-07-18 23:16:45+00:00,https://github.com/tensorflow/tensorflow/pull/72119,[],[],
2417173648,pull_request,closed,,Internal change only.,"Internal change only.
",copybara-service[bot],2024-07-18 19:00:20+00:00,['BlaziusMaximus'],2024-07-19 18:44:57+00:00,2024-07-19 18:44:56+00:00,https://github.com/tensorflow/tensorflow/pull/72118,[],[],
2417082861,pull_request,open,,Add constructor overloads for DeviceList.,"Add constructor overloads for DeviceList.
",copybara-service[bot],2024-07-18 18:26:24+00:00,[],2024-07-18 18:55:06+00:00,,https://github.com/tensorflow/tensorflow/pull/72117,[],[],
2417059775,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@531816f0,"Integrate StableHLO at openxla/stablehlo@531816f0
",copybara-service[bot],2024-07-18 18:17:05+00:00,['sdasgup3'],2024-07-19 22:59:50+00:00,2024-07-19 22:59:48+00:00,https://github.com/tensorflow/tensorflow/pull/72116,[],[],
2417057543,pull_request,closed,,[xla:cpu] Refactor EmitTargetElementLoop,"[xla:cpu] Refactor EmitTargetElementLoop
",copybara-service[bot],2024-07-18 18:15:36+00:00,[],2024-07-24 23:29:54+00:00,2024-07-24 23:29:53+00:00,https://github.com/tensorflow/tensorflow/pull/72115,[],"[{'comment_id': 2237205877, 'issue_id': 2417057543, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72115/checks?check_run_id=27631302897) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 18, 18, 15, 41, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-18 18:15:41 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72115/checks?check_run_id=27631302897) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2417054512,pull_request,closed,,[xla:cpu] Allow monkey patching for compute_function_,"[xla:cpu] Allow monkey patching for compute_function_

This allows an easy IrEmitter code reuse from IrEmitter2
",copybara-service[bot],2024-07-18 18:13:32+00:00,[],2024-07-24 13:42:37+00:00,2024-07-24 13:42:37+00:00,https://github.com/tensorflow/tensorflow/pull/72114,[],"[{'comment_id': 2237202695, 'issue_id': 2417054512, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72114/checks?check_run_id=27631218685) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 18, 18, 13, 37, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-18 18:13:37 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72114/checks?check_run_id=27631218685) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2417031122,pull_request,closed,,Replace Copybara rule with `#ifdef` for initialization of `MPSolver`,"Replace Copybara rule with `#ifdef` for initialization of `MPSolver`
",copybara-service[bot],2024-07-18 17:59:56+00:00,['ddunl'],2024-07-18 19:18:36+00:00,2024-07-18 19:18:35+00:00,https://github.com/tensorflow/tensorflow/pull/72113,[],[],
2416997431,pull_request,open,,Remove authoring from the api generator.,"Remove authoring from the api generator.
",copybara-service[bot],2024-07-18 17:38:48+00:00,['ecalubaquib'],2024-07-18 17:38:55+00:00,,https://github.com/tensorflow/tensorflow/pull/72112,[],"[{'comment_id': 2237145633, 'issue_id': 2416997431, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72112/checks?check_run_id=27629779655) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 18, 17, 38, 54, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-18 17:38:54 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72112/checks?check_run_id=27629779655) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2416967972,pull_request,closed,,Add support for conv 3d (no padding) in mhlo->tfl,"Add support for conv 3d (no padding) in mhlo->tfl
",copybara-service[bot],2024-07-18 17:19:13+00:00,['LukeBoyer'],2024-07-23 05:10:26+00:00,2024-07-23 05:10:26+00:00,https://github.com/tensorflow/tensorflow/pull/72111,[],[],
2416964483,pull_request,open,,Integrate LLVM at llvm/llvm-project@290184880ae2,"Integrate LLVM at llvm/llvm-project@290184880ae2

Updates LLVM usage to match
[290184880ae2](https://github.com/llvm/llvm-project/commit/290184880ae2)
",copybara-service[bot],2024-07-18 17:16:48+00:00,[],2024-07-18 17:16:48+00:00,,https://github.com/tensorflow/tensorflow/pull/72110,[],[],
2416961344,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.
",copybara-service[bot],2024-07-18 17:15:12+00:00,[],2024-07-18 17:15:12+00:00,,https://github.com/tensorflow/tensorflow/pull/72109,[],[],
2416953756,pull_request,closed,,Revert to fix tests,"Revert to fix tests

Reverts 117a62ac439ed87eb26f67208be60e01c21960de
",copybara-service[bot],2024-07-18 17:10:10+00:00,[],2024-07-18 18:33:40+00:00,2024-07-18 18:33:39+00:00,https://github.com/tensorflow/tensorflow/pull/72107,[],[],
2416889204,pull_request,open,,Fix usage of llvm::MemoryBuffer in ptx_compilation_test,"Fix usage of llvm::MemoryBuffer in ptx_compilation_test

MemoryBuffer's factory function has a check for a null terminator which needs to be disabled
when loading binary data.

This slipped through because LLVM checks are only active in debug builds.
",copybara-service[bot],2024-07-18 16:29:00+00:00,[],2024-07-18 16:29:00+00:00,,https://github.com/tensorflow/tensorflow/pull/72105,[],[],
2416867957,pull_request,closed,,Move macros in `third_party/mkl_dnn/build_defs.bzl` to `tsl/mkl/build_defs.bzl`,"Move macros in `third_party/mkl_dnn/build_defs.bzl` to `tsl/mkl/build_defs.bzl`
",copybara-service[bot],2024-07-18 16:17:13+00:00,['ddunl'],2024-07-20 00:29:37+00:00,2024-07-20 00:29:36+00:00,https://github.com/tensorflow/tensorflow/pull/72104,[],[],
2416763988,pull_request,closed,,[XLA:Python] Update bindings for compatibility with nanobind 2.0.,"[XLA:Python] Update bindings for compatibility with nanobind 2.0.

The main change works around the redefinition of nb::enum_ in nanobind 2.
",copybara-service[bot],2024-07-18 15:43:53+00:00,[],2024-07-19 00:43:17+00:00,2024-07-19 00:43:16+00:00,https://github.com/tensorflow/tensorflow/pull/72103,[],[],
2416738812,pull_request,closed,,Add PTX Compilation support via libnvjitlink,"Add PTX Compilation support via libnvjitlink

This is adding support for compiling PTX to CUBIN by using NVIDIA's libnvjitlink
library.
",copybara-service[bot],2024-07-18 15:30:43+00:00,[],2024-08-07 10:35:23+00:00,2024-08-07 10:35:22+00:00,https://github.com/tensorflow/tensorflow/pull/72102,[],[],
2416700183,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.
",copybara-service[bot],2024-07-18 15:15:02+00:00,[],2024-07-18 15:15:02+00:00,,https://github.com/tensorflow/tensorflow/pull/72101,[],[],
2416676514,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.
",copybara-service[bot],2024-07-18 15:05:37+00:00,[],2024-07-18 15:05:37+00:00,,https://github.com/tensorflow/tensorflow/pull/72100,[],[],
2416635756,pull_request,closed,,[XLA:GPU] Fix Triton codegen for `BroadcastOp`s of scalars.,"[XLA:GPU] Fix Triton codegen for `BroadcastOp`s of scalars.

`BroadcastOp`s maps an input of rank `N` to an output of the same rank, where
`1` dimensions are broadcasted into the corresponding target dimension as
needed.

This property was previously not enforced in the Triton verifier, and codegen
seems to have worked correctly without---likely due to constant folding fixing
the state of things before we'd reach a call to the verifier.

In order to make sure such issues do not fall through in the future, also move
the call to `mlir::verify` right after the `TTIR` has been emitted, as opposed
to after MLIR `CSE` and canonicalization passes.
",copybara-service[bot],2024-07-18 14:48:25+00:00,[],2024-07-18 15:32:50+00:00,2024-07-18 15:32:49+00:00,https://github.com/tensorflow/tensorflow/pull/72099,[],[],
2416527731,pull_request,closed,,[XLA:CPU] Add support for `transpose` to thunk runtime.,"[XLA:CPU] Add support for `transpose` to thunk runtime.


In old runtime, if `transpose` is not rewritten by any HLO pass, it is handled by the elemental generator. This commit introduces the same behavior to thunks runtime, also adds test case verifying that case (was missing).

Thunk runtime already supports all other ops to which transpose is rewritten, so no further changes are required. Turned on `transpose` tests for thunks runtime.
",copybara-service[bot],2024-07-18 14:19:08+00:00,[],2024-07-22 09:13:27+00:00,2024-07-22 09:13:25+00:00,https://github.com/tensorflow/tensorflow/pull/72098,[],"[{'comment_id': 2236659129, 'issue_id': 2416527731, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72098/checks?check_run_id=27620178839) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 18, 14, 19, 14, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-18 14:19:14 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72098/checks?check_run_id=27620178839) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2416364416,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.
",copybara-service[bot],2024-07-18 13:18:30+00:00,[],2024-07-18 13:18:30+00:00,,https://github.com/tensorflow/tensorflow/pull/72096,[],[],
2416316601,pull_request,closed,,Reverts changelist 653584347,"Reverts changelist 653584347
",copybara-service[bot],2024-07-18 13:07:10+00:00,[],2024-07-18 13:34:49+00:00,2024-07-18 13:34:48+00:00,https://github.com/tensorflow/tensorflow/pull/72095,[],[],
2416304648,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.

Reverts 303b8e5ec1cab37679df40280f9e6702650316d5
",copybara-service[bot],2024-07-18 13:01:24+00:00,[],2024-07-18 13:01:24+00:00,,https://github.com/tensorflow/tensorflow/pull/72094,[],[],
2416256952,pull_request,closed,,"#sdy check if ""shmap_body"" is contained in the function name and not just a prefix of it.","#sdy check if ""shmap_body"" is contained in the function name and not just a prefix of it.

We've observed cases where a prefix is added to the name before the ""shmap_body"".
",copybara-service[bot],2024-07-18 12:40:22+00:00,[],2024-07-18 14:12:08+00:00,2024-07-18 14:12:08+00:00,https://github.com/tensorflow/tensorflow/pull/72093,[],[],
2416253819,pull_request,closed,,Reverts 303b8e5ec1cab37679df40280f9e6702650316d5,"Reverts 303b8e5ec1cab37679df40280f9e6702650316d5
",copybara-service[bot],2024-07-18 12:39:01+00:00,[],2024-07-18 13:03:30+00:00,2024-07-18 13:03:29+00:00,https://github.com/tensorflow/tensorflow/pull/72092,[],[],
2416229956,pull_request,closed,,Enable mlir transpose emitter by default.,"Enable mlir transpose emitter by default.
",copybara-service[bot],2024-07-18 12:28:25+00:00,['akuegel'],2024-07-18 20:34:16+00:00,2024-07-18 20:34:15+00:00,https://github.com/tensorflow/tensorflow/pull/72091,[],[],
2416136832,pull_request,open,,Integrate LLVM at llvm/llvm-project@290184880ae2,"Integrate LLVM at llvm/llvm-project@290184880ae2

Updates LLVM usage to match
[290184880ae2](https://github.com/llvm/llvm-project/commit/290184880ae2)

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14829 from Tixxx:tixxx/flatten_call_graph 9cf04c57f5cc185ac888fe791a1104d273307243
",copybara-service[bot],2024-07-18 11:39:53+00:00,[],2024-07-18 11:39:53+00:00,,https://github.com/tensorflow/tensorflow/pull/72090,[],[],
2416064201,pull_request,closed,,Update file visibility in BUILD files.,"Update file visibility in BUILD files.
",copybara-service[bot],2024-07-18 10:59:01+00:00,[],2024-07-19 12:43:42+00:00,2024-07-19 12:43:41+00:00,https://github.com/tensorflow/tensorflow/pull/72089,[],[],
2415914911,pull_request,closed,,PR #14829: [NVIDIA GPU] Flatten call graph after collective pipeliner pass,"PR #14829: [NVIDIA GPU] Flatten call graph after collective pipeliner pass

Imported from GitHub PR https://github.com/openxla/xla/pull/14829

After moving the collective pipeliner pass after post layout optimization passes, we need to call flatten call graph after pipeliners have run so call sites are unique. We didnt need to do this before because layout assignment(which is after previous location of collective pipeline) runs flattenCallGraph.
Copybara import of the project:

--
e993caeda3ebf7285d762f18b801c1f5ab0f0a38 by TJ Xu <tjx@nvidia.com>:

Flatten call graph after collective pipeliner pass

--
9cf04c57f5cc185ac888fe791a1104d273307243 by TJ Xu <tjx@nvidia.com>:

added e2e test with explanation of the crash

Merging this change closes #14829

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14829 from Tixxx:tixxx/flatten_call_graph 9cf04c57f5cc185ac888fe791a1104d273307243
",copybara-service[bot],2024-07-18 09:56:04+00:00,[],2024-07-18 12:17:04+00:00,2024-07-18 12:17:03+00:00,https://github.com/tensorflow/tensorflow/pull/72088,[],[],
2415911616,pull_request,closed,,Remove affine fuzz test for now.,"Remove affine fuzz test for now.

This can't be built right now because the grammar bzl is broken in
the version of fuzztest we're using.
",copybara-service[bot],2024-07-18 09:55:00+00:00,[],2024-07-19 07:09:59+00:00,2024-07-19 07:09:58+00:00,https://github.com/tensorflow/tensorflow/pull/72087,[],[],
2415907060,pull_request,open,,PR #14968: [GPU] Enable sharding of autotuning by default.,"PR #14968: [GPU] Enable sharding of autotuning by default.

Imported from GitHub PR https://github.com/openxla/xla/pull/14968

Requires https://github.com/openxla/xla/pull/14881

@PatriosTheGreat 
Copybara import of the project:

--
94562fa1e73d8031832c0c0ed78b064cc7248aea by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Enable sharding of autotuning by default.

Merging this change closes #14968

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14968 from openxla:enable_sharded_autotuning 94562fa1e73d8031832c0c0ed78b064cc7248aea
",copybara-service[bot],2024-07-18 09:53:34+00:00,[],2024-07-18 09:53:34+00:00,,https://github.com/tensorflow/tensorflow/pull/72086,[],[],
2415842962,pull_request,closed,,PR #14865: [NVIDIA GPU] Add debug flag for syntactic sugar,"PR #14865: [NVIDIA GPU] Add debug flag for syntactic sugar

Imported from GitHub PR https://github.com/openxla/xla/pull/14865

This is a followup PR of https://github.com/openxla/xla/pull/14344. Originally the issue was HLO dumping and NVTX marker naming are inconsistent, with https://github.com/openxla/xla/pull/14344 now both of them are wrapped by syntactic sugar. There are some cases, especially when debugging, the original naming without syntactic sugar is helpful. This PR adds a debug flag to control the syntactic sugar of both HLO dumping and NVTX marker.
Copybara import of the project:

--
28d0b4595e9db52d205cb219c2e25a9cc7a5c18c by Terry Sun <tesun@nvidia.com>:

debug flag for syntax sugar

--
0db7f704f41b8984fab65a420ac58fb6d55c2ce3 by Terry Sun <tesun@nvidia.com>:

proper default

--
c10a7cbf05956e3d0facb06554d457bfff82fe4b by Terry Sun <tesun@nvidia.com>:

same flag for nvtx marker

--
8dc14d17631bbacc3bc063158e5bebb605860947 by Terry Sun <tesun@nvidia.com>:

add comment for flag

--
4b1ba992c4e90d3b99044b0d15f0d61cdc08fa59 by Terry Sun <tesun@nvidia.com>:

formatting

Merging this change closes #14865

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14865 from terryysun:terryysun/syntax_sugar_debug_flag 4b1ba992c4e90d3b99044b0d15f0d61cdc08fa59
",copybara-service[bot],2024-07-18 09:26:44+00:00,[],2024-07-18 10:48:00+00:00,2024-07-18 10:47:59+00:00,https://github.com/tensorflow/tensorflow/pull/72085,[],[],
2415837842,pull_request,closed,,[XLA:GPU] Add arbitrary axis support to the Triton reduce emitter.,"[XLA:GPU] Add arbitrary axis support to the Triton reduce emitter.
",copybara-service[bot],2024-07-18 09:24:21+00:00,[],2024-07-19 18:17:54+00:00,2024-07-19 18:17:53+00:00,https://github.com/tensorflow/tensorflow/pull/72084,[],[],
2415819813,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14865 from terryysun:terryysun/syntax_sugar_debug_flag 4b1ba992c4e90d3b99044b0d15f0d61cdc08fa59
",copybara-service[bot],2024-07-18 09:15:43+00:00,[],2024-07-18 10:29:40+00:00,,https://github.com/tensorflow/tensorflow/pull/72083,[],[],
2415799705,pull_request,closed,,[XLA:CPU] Support `SliceToDynamic` custom call thunk,"[XLA:CPU] Support `SliceToDynamic` custom call thunk

Additionally turn on the `set_dimension_size` test for thunk runtime (`set_dimension_size` op is rewritten as `SliceToDynamic`, that's why it has been turned off so far).
",copybara-service[bot],2024-07-18 09:05:44+00:00,[],2024-07-19 10:00:08+00:00,2024-07-19 10:00:07+00:00,https://github.com/tensorflow/tensorflow/pull/72082,[],"[{'comment_id': 2236004635, 'issue_id': 2415799705, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72082/checks?check_run_id=27605718745) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 18, 9, 5, 49, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-18 09:05:49 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72082/checks?check_run_id=27605718745) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2415604358,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 07:31:02+00:00,[],2024-07-18 07:31:02+00:00,,https://github.com/tensorflow/tensorflow/pull/72080,[],[],
2415539385,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 06:57:14+00:00,[],2024-07-19 04:29:50+00:00,,https://github.com/tensorflow/tensorflow/pull/72079,[],[],
2415491656,pull_request,open,,Update google_fuzztest dependency to newest revision.,"Update google_fuzztest dependency to newest revision.

Disable riegeli usage in google_fuzztest
",copybara-service[bot],2024-07-18 06:30:35+00:00,['akuegel'],2024-07-18 08:22:37+00:00,,https://github.com/tensorflow/tensorflow/pull/72078,[],[],
2415483137,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14829 from Tixxx:tixxx/flatten_call_graph 9cf04c57f5cc185ac888fe791a1104d273307243
",copybara-service[bot],2024-07-18 06:25:12+00:00,[],2024-07-18 11:42:11+00:00,,https://github.com/tensorflow/tensorflow/pull/72077,[],[],
2415238305,pull_request,closed,,Handle manual sharding gracefully in `xla::ifrt::HloSharding`,"Handle manual sharding gracefully in `xla::ifrt::HloSharding`

Calling `TileOffsetForDevice`/`TileLimitForDevice` for manual sharding triggers CHECK-fail. Instead, this CL makes `xla::ifrt::HloSharding::IndexDomains()` gracefully return an error for manual sharding. `Disassemble()` uses the global shape as the shard shape by convention.

Also, this CL introduces a fast path for the disassembly logic for even shardings, where we don't need to call `IndexDomains()` to identify the shard shapes. This could be useful since `Disassemble()` is typically used more frequently than `IndexDomains()` [1].
",copybara-service[bot],2024-07-18 05:08:10+00:00,[],2024-07-18 21:25:33+00:00,2024-07-18 21:25:32+00:00,https://github.com/tensorflow/tensorflow/pull/72076,[],[],
2415211762,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:46:52+00:00,[],2024-07-18 04:46:52+00:00,,https://github.com/tensorflow/tensorflow/pull/72075,[],[],
2415211599,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:46:41+00:00,[],2024-07-18 04:46:41+00:00,,https://github.com/tensorflow/tensorflow/pull/72074,[],[],
2415210033,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:44:59+00:00,[],2024-07-18 04:44:59+00:00,,https://github.com/tensorflow/tensorflow/pull/72073,[],[],
2415205208,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14829 from Tixxx:tixxx/flatten_call_graph 9cf04c57f5cc185ac888fe791a1104d273307243
",copybara-service[bot],2024-07-18 04:39:34+00:00,[],2024-07-18 12:07:58+00:00,,https://github.com/tensorflow/tensorflow/pull/72072,[],[],
2415204144,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14829 from Tixxx:tixxx/flatten_call_graph 9cf04c57f5cc185ac888fe791a1104d273307243
",copybara-service[bot],2024-07-18 04:38:26+00:00,[],2024-07-18 12:23:19+00:00,,https://github.com/tensorflow/tensorflow/pull/72071,[],[],
2415200216,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:33:55+00:00,[],2024-07-18 04:33:55+00:00,,https://github.com/tensorflow/tensorflow/pull/72070,[],[],
2415198574,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:32:02+00:00,[],2024-07-19 03:52:56+00:00,,https://github.com/tensorflow/tensorflow/pull/72069,[],[],
2415197246,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:30:40+00:00,[],2024-07-18 06:00:42+00:00,,https://github.com/tensorflow/tensorflow/pull/72068,[],[],
2415196912,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:30:20+00:00,[],2024-07-18 07:17:15+00:00,,https://github.com/tensorflow/tensorflow/pull/72067,[],[],
2415194018,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:27:00+00:00,[],2024-07-23 08:08:42+00:00,2024-07-23 08:08:41+00:00,https://github.com/tensorflow/tensorflow/pull/72066,[],[],
2415190362,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:22:36+00:00,[],2024-07-18 04:22:36+00:00,,https://github.com/tensorflow/tensorflow/pull/72065,[],[],
2415186178,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:17:35+00:00,[],2024-07-18 04:17:35+00:00,,https://github.com/tensorflow/tensorflow/pull/72064,[],[],
2415166947,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-18 04:00:18+00:00,[],2024-07-18 04:00:18+00:00,,https://github.com/tensorflow/tensorflow/pull/72063,[],[],
2415161227,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14900 from jaro-sevcik:preserve-argument-layouts-on-canonicalization 1042f7ee78f5ee8d45ccfd57f67d3657b5a9cf07
",copybara-service[bot],2024-07-18 03:53:59+00:00,[],2024-07-23 07:53:59+00:00,,https://github.com/tensorflow/tensorflow/pull/72062,[],[],
2415135622,pull_request,closed,,Check for rank before legalizing mhlo.conv,"Check for rank before legalizing mhlo.conv
",copybara-service[bot],2024-07-18 03:29:33+00:00,['LukeBoyer'],2024-07-18 04:06:09+00:00,2024-07-18 04:06:08+00:00,https://github.com/tensorflow/tensorflow/pull/72061,[],[],
2415115301,pull_request,closed,,Explicitly set mlir_emitter_level on reduction and transpose tests.,"Explicitly set mlir_emitter_level on reduction and transpose tests.

These tests mostly do not seem particularly valuable. We should
revisit them after launching the corresponding MLIR emitters
and turn them into more accurate tests or execution tests or 
delete them.
",copybara-service[bot],2024-07-18 03:08:21+00:00,[],2024-07-18 06:17:22+00:00,2024-07-18 06:17:22+00:00,https://github.com/tensorflow/tensorflow/pull/72060,[],[],
2415105855,pull_request,closed,,Update comment in conv header.,"Update comment in conv header.
",copybara-service[bot],2024-07-18 02:59:07+00:00,['LukeBoyer'],2024-07-18 04:24:56+00:00,2024-07-18 04:24:55+00:00,https://github.com/tensorflow/tensorflow/pull/72059,[],[],
2414985909,pull_request,open,,Integrate LLVM at llvm/llvm-project@81704f694689,"Integrate LLVM at llvm/llvm-project@81704f694689

Updates LLVM usage to match
[81704f694689](https://github.com/llvm/llvm-project/commit/81704f694689)
",copybara-service[bot],2024-07-18 01:37:10+00:00,[],2024-07-18 01:37:10+00:00,,https://github.com/tensorflow/tensorflow/pull/72058,[],[],
2414896785,pull_request,open,,Add llvm-style cast methods to xla::ifrt::Sharding class so that users don't have to add LLVM visibility.,"Add llvm-style cast methods to xla::ifrt::Sharding class so that users don't have to add LLVM visibility.
",copybara-service[bot],2024-07-18 00:28:24+00:00,[],2024-07-22 21:20:54+00:00,,https://github.com/tensorflow/tensorflow/pull/72057,[],[],
2414785374,pull_request,closed,,Move all MKL config settings to `tsl/mkl`,"Move all MKL config settings to `tsl/mkl`

Followup will delete `third_party/tensorflow/third_party/mkl/build_defs.bzl`
",copybara-service[bot],2024-07-17 23:11:04+00:00,['ddunl'],2024-07-18 01:24:11+00:00,2024-07-18 01:24:11+00:00,https://github.com/tensorflow/tensorflow/pull/72056,[],[],
2414782774,pull_request,closed,,Add metrics to track ifrt usage in tfrt,"Add metrics to track ifrt usage in tfrt
",copybara-service[bot],2024-07-17 23:07:57+00:00,[],2024-07-19 23:58:27+00:00,2024-07-19 23:58:27+00:00,https://github.com/tensorflow/tensorflow/pull/72055,[],[],
2414777760,pull_request,closed,,Change the visibility of legalize_tf passes to only the current users,"Change the visibility of legalize_tf passes to only the current users

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/63077 from tensorflow:SuryanarayanaY-patch-11 eeb7e19c8bc12d6bd233145637ab407293e99a21
",copybara-service[bot],2024-07-17 23:02:27+00:00,[],2024-07-18 22:07:31+00:00,2024-07-18 22:07:30+00:00,https://github.com/tensorflow/tensorflow/pull/72054,[],[],
2414767570,pull_request,closed,,Remove dead code from HloRematerialization and fix comment.,"Remove dead code from HloRematerialization and fix comment.
",copybara-service[bot],2024-07-17 22:58:24+00:00,['SandSnip3r'],2024-07-18 07:39:43+00:00,2024-07-18 07:39:41+00:00,https://github.com/tensorflow/tensorflow/pull/72053,[],[],
2414752383,pull_request,open,,change quantization_utils dependency on tensor_utils to within mlir,"change quantization_utils dependency on tensor_utils to within mlir
",copybara-service[bot],2024-07-17 22:51:53+00:00,[],2024-07-25 17:33:22+00:00,,https://github.com/tensorflow/tensorflow/pull/72052,[],[],
2414731648,pull_request,closed,,Move optional checking for creating GpuTimers into callsites to remove convenience method.,"Move optional checking for creating GpuTimers into callsites to remove convenience method.
",copybara-service[bot],2024-07-17 22:29:24+00:00,[],2024-07-18 18:14:40+00:00,2024-07-18 18:14:39+00:00,https://github.com/tensorflow/tensorflow/pull/72051,[],[],
2414730063,pull_request,open,,Internal copybara refactoring change,"Internal copybara refactoring change
",copybara-service[bot],2024-07-17 22:28:20+00:00,['ddunl'],2024-07-17 23:39:11+00:00,,https://github.com/tensorflow/tensorflow/pull/72050,[],[],
2414724373,pull_request,open,,Part of the initial commit for the diff tool. Needed a unique fingerprint to distinguish between XLA Expressions in the immediate future.,"Part of the initial commit for the diff tool. Needed a unique fingerprint to distinguish between XLA Expressions in the immediate future.
",copybara-service[bot],2024-07-17 22:25:35+00:00,['pifon2a'],2024-07-22 22:42:35+00:00,,https://github.com/tensorflow/tensorflow/pull/72049,[],[],
2414661566,pull_request,open,,Internal copybara refactor,"Internal copybara refactor
",copybara-service[bot],2024-07-17 21:52:22+00:00,['ddunl'],2024-07-17 21:52:23+00:00,,https://github.com/tensorflow/tensorflow/pull/72048,[],[],
2414640828,pull_request,closed,,Remove unused CreateIfNeeded method.,"Remove unused CreateIfNeeded method.
",copybara-service[bot],2024-07-17 21:35:20+00:00,[],2024-07-18 00:26:37+00:00,2024-07-18 00:26:36+00:00,https://github.com/tensorflow/tensorflow/pull/72047,[],[],
2414639776,pull_request,open,,Annotation Stack must always contains the full stack as profiler could start at any time,"Annotation Stack must always contains the full stack as profiler could start at any time
",copybara-service[bot],2024-07-17 21:34:25+00:00,[],2024-07-20 00:16:43+00:00,,https://github.com/tensorflow/tensorflow/pull/72046,[],[],
2414611390,pull_request,closed,,[xla:cpu] Fix msan error in topk test,"[xla:cpu] Fix msan error in topk test

Reverts db06762633d89088a76d80b97b9e334aa6eaf95b
",copybara-service[bot],2024-07-17 21:15:50+00:00,['ezhulenev'],2024-07-17 23:04:05+00:00,2024-07-17 23:04:04+00:00,https://github.com/tensorflow/tensorflow/pull/72045,[],[],
2414573412,pull_request,closed,,Improve int2 support,"Improve int2 support
",copybara-service[bot],2024-07-17 21:03:06+00:00,[],2024-07-20 04:23:24+00:00,2024-07-20 04:23:23+00:00,https://github.com/tensorflow/tensorflow/pull/72044,[],[],
2414565034,pull_request,open,,Added a memory argument to PjRtClient::CreateViewOfDeviceBuffer,"Added a memory argument to PjRtClient::CreateViewOfDeviceBuffer

This is needed to support kDLCUDAHost and kDLROCM DLPack devices in JAX.

Note that none of the client implementations actually use the new argument
in any meaningful way. I sprinkled a few TODOs in the code an I plan to
address them in a follow up.
",copybara-service[bot],2024-07-17 20:59:41+00:00,['superbobry'],2024-07-18 11:59:23+00:00,,https://github.com/tensorflow/tensorflow/pull/72043,[],[],
2414551529,pull_request,closed,,Calculate replica id from global id directly using the partition count.,"Calculate replica id from global id directly using the partition count.
",copybara-service[bot],2024-07-17 20:50:44+00:00,[],2024-07-18 15:13:07+00:00,2024-07-18 15:13:06+00:00,https://github.com/tensorflow/tensorflow/pull/72042,[],[],
2414545743,pull_request,closed,,[xla:ffi] Don't forget to register handlers with canonical platform name,"[xla:ffi] Don't forget to register handlers with canonical platform name

Fix for a broken test

Reverts db06762633d89088a76d80b97b9e334aa6eaf95b
",copybara-service[bot],2024-07-17 20:46:45+00:00,['ezhulenev'],2024-07-17 23:53:31+00:00,2024-07-17 23:53:30+00:00,https://github.com/tensorflow/tensorflow/pull/72041,[],[],
2414534889,pull_request,open,,Tesing a change a change to trigger a build test,"Tesing a change a change to trigger a build test
",copybara-service[bot],2024-07-17 20:40:07+00:00,['ecalubaquib'],2024-07-17 23:13:03+00:00,,https://github.com/tensorflow/tensorflow/pull/72040,[],"[{'comment_id': 2234241586, 'issue_id': 2414534889, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72040/checks?check_run_id=27584192734) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 17, 20, 40, 12, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-17 20:40:12 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/72040/checks?check_run_id=27584192734) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2414522938,pull_request,open,,Disable msan for topk_test_cpu_thunks,"Disable msan for topk_test_cpu_thunks
",copybara-service[bot],2024-07-17 20:31:50+00:00,[],2024-07-17 21:06:22+00:00,,https://github.com/tensorflow/tensorflow/pull/72039,[],[],
2414494647,pull_request,closed,,[XLA:SPMD] Fix dot partitioning illegal broadcast.,"[XLA:SPMD] Fix dot partitioning illegal broadcast.
",copybara-service[bot],2024-07-17 20:19:33+00:00,['Tongfei-Guo'],2024-07-17 21:45:16+00:00,2024-07-17 21:45:15+00:00,https://github.com/tensorflow/tensorflow/pull/72038,[],[],
2414484895,pull_request,closed,,Split a larger test into two smaller ones.,"Split a larger test into two smaller ones.
",copybara-service[bot],2024-07-17 20:16:02+00:00,[],2024-07-17 21:31:59+00:00,2024-07-17 21:31:58+00:00,https://github.com/tensorflow/tensorflow/pull/72037,[],[],
2414472232,pull_request,open,,Reverts changelist 653319684,"Reverts changelist 653319684
",copybara-service[bot],2024-07-17 20:09:34+00:00,[],2024-07-17 20:09:34+00:00,,https://github.com/tensorflow/tensorflow/pull/72036,[],[],
2414468722,pull_request,open,,Add more logs to ColocatePredecessorTreesPass.,"Add more logs to ColocatePredecessorTreesPass.
",copybara-service[bot],2024-07-17 20:07:59+00:00,[],2024-07-17 20:07:59+00:00,,https://github.com/tensorflow/tensorflow/pull/72035,[],[],
2414462964,pull_request,closed,,[xla:gpu] Add ShardyXLA to the GPU SPMD pipeline.,"[xla:gpu] Add ShardyXLA to the GPU SPMD pipeline.
",copybara-service[bot],2024-07-17 20:04:56+00:00,['bixia1'],2024-07-18 17:06:24+00:00,2024-07-18 17:06:23+00:00,https://github.com/tensorflow/tensorflow/pull/72034,[],[],
2414349549,pull_request,closed,,Integrate LLVM at llvm/llvm-project@5ff3ff33ff93,"Integrate LLVM at llvm/llvm-project@5ff3ff33ff93

Updates LLVM usage to match
[5ff3ff33ff93](https://github.com/llvm/llvm-project/commit/5ff3ff33ff93)
",copybara-service[bot],2024-07-17 19:02:30+00:00,[],2024-07-18 06:44:25+00:00,2024-07-18 06:44:24+00:00,https://github.com/tensorflow/tensorflow/pull/72033,[],[],
2414338125,pull_request,closed,,Update base test case for circular pipelining to include matmul operation,"Update base test case for circular pipelining to include matmul operation
",copybara-service[bot],2024-07-17 18:55:22+00:00,[],2024-07-21 22:01:11+00:00,2024-07-21 22:01:10+00:00,https://github.com/tensorflow/tensorflow/pull/72032,[],[],
2414300576,pull_request,open,,Add StableHLO conversion path to tf_to_tfl_flatbuffer,"Add StableHLO conversion path to tf_to_tfl_flatbuffer
",copybara-service[bot],2024-07-17 18:31:28+00:00,['vamsimanchala'],2024-07-18 02:58:32+00:00,,https://github.com/tensorflow/tensorflow/pull/72031,[],[],
2414207906,pull_request,closed,,Don't mask out zero elements on the diagonal of the matrix when inverting triangular matrices.,"Don't mask out zero elements on the diagonal of the matrix when inverting triangular matrices.

The intent of this code seems to have been to mask out zeros that were part of padding on the diagonal. However, this isn't correct: if there is a zero on the diagonal, we very much want to get an inf or nan! We also appear to now pad with the identity matrix.

Fixes https://github.com/google/jax/issues/3589
Fixes https://github.com/google/jax/issues/15429

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14865 from terryysun:terryysun/syntax_sugar_debug_flag 4b1ba992c4e90d3b99044b0d15f0d61cdc08fa59
",copybara-service[bot],2024-07-17 17:54:30+00:00,[],2024-07-18 12:32:25+00:00,2024-07-18 12:32:24+00:00,https://github.com/tensorflow/tensorflow/pull/72030,[],[],
2414201584,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.
",copybara-service[bot],2024-07-17 17:51:46+00:00,[],2024-07-17 17:51:46+00:00,,https://github.com/tensorflow/tensorflow/pull/72029,[],[],
2414177476,pull_request,closed,,[xla:ffi] Always use canonical platform name for FFI handler registration and lookup,"[xla:ffi] Always use canonical platform name for FFI handler registration and lookup

+ Use xla:util error constructors instead of absl::XyzError to automatically capture error stack trace

Fix for https://github.com/openxla/xla/issues/14889
",copybara-service[bot],2024-07-17 17:41:03+00:00,['ezhulenev'],2024-07-17 20:05:58+00:00,2024-07-17 20:05:58+00:00,https://github.com/tensorflow/tensorflow/pull/72028,[],[],
2414161983,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/71976 from quicbrtal:improve-serialized-load-times 24e0668225bebacadd9151b33fda251014af9c38
",copybara-service[bot],2024-07-17 17:31:38+00:00,[],2024-07-17 17:31:38+00:00,,https://github.com/tensorflow/tensorflow/pull/72027,[],[],
2414148222,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/71976 from quicbrtal:improve-serialized-load-times 24e0668225bebacadd9151b33fda251014af9c38
",copybara-service[bot],2024-07-17 17:24:05+00:00,[],2024-07-17 17:24:05+00:00,,https://github.com/tensorflow/tensorflow/pull/72026,[],[],
2414132275,pull_request,closed,,Bump up the IFRT Proxy client's minimum version to 3,"Bump up the IFRT Proxy client's minimum version to 3

Protocol version 3 has been introduced one month ago, so it is safe to deprecate the older versions from the client. The server should still support the older versions until the compatibility window passes.
",copybara-service[bot],2024-07-17 17:16:12+00:00,[],2024-07-17 19:51:01+00:00,2024-07-17 19:51:01+00:00,https://github.com/tensorflow/tensorflow/pull/72025,[],[],
2414128391,pull_request,closed,,[xla:cpu] Add benchmarks for Topk operation,"[xla:cpu] Add benchmarks for Topk operation

Thunks version is ~3-4x faster:

--------------------------------------------------------------------------------
Benchmark: CLASSIC                                          Time             CPU 
--------------------------------------------------------------------------------
BM_TopK_BF16/k:4/batch:4/length:64/process_time        68664 ns        68777 ns 
BM_TopK_BF16/k:4/batch:16/length:16/process_time       23481 ns        23505 ns 
BM_TopK_BF16/k:4/batch:64/length:4/process_time        12662 ns        12680 ns 
BM_TopK_BF16/k:16/batch:4/length:64/process_time       66882 ns        66972 ns 
BM_TopK_BF16/k:16/batch:16/length:16/process_time      23776 ns        23823 ns 
BM_TopK_BF16/k:16/batch:64/length:16/process_time      92941 ns        93055 ns 
BM_TopK_BF16/k:64/batch:4/length:64/process_time       79143 ns        79238 ns 
BM_TopK_BF16/k:64/batch:16/length:64/process_time     254667 ns       255522 ns  
BM_TopK_BF16/k:64/batch:64/length:64/process_time    1010894 ns      1012135 ns  

vs

-------------------------------------------------------------------------------
Benchmark: THUNKS                                         Time             CPU
-------------------------------------------------------------------------------
BM_TopK_BF16/k:4/batch:4/length:64/process_time        17362 ns        17408 ns
BM_TopK_BF16/k:4/batch:16/length:16/process_time       11685 ns        11711 ns
BM_TopK_BF16/k:4/batch:64/length:4/process_time         8401 ns         8425 ns
BM_TopK_BF16/k:16/batch:4/length:64/process_time       17600 ns        17603 ns
BM_TopK_BF16/k:16/batch:16/length:16/process_time      12746 ns        12749 ns
BM_TopK_BF16/k:16/batch:64/length:16/process_time      48528 ns        48588 ns
BM_TopK_BF16/k:64/batch:4/length:64/process_time       17791 ns        17849 ns
BM_TopK_BF16/k:64/batch:16/length:64/process_time      74860 ns        75267 ns
BM_TopK_BF16/k:64/batch:64/length:64/process_time     317068 ns       317588 ns
",copybara-service[bot],2024-07-17 17:14:20+00:00,['ezhulenev'],2024-07-17 18:55:52+00:00,2024-07-17 18:55:51+00:00,https://github.com/tensorflow/tensorflow/pull/72024,[],[],
2414091898,pull_request,closed,,Define an option to specify different IFRT client.,"Define an option to specify different IFRT client.
",copybara-service[bot],2024-07-17 16:55:04+00:00,[],2024-07-18 07:11:33+00:00,2024-07-18 07:11:32+00:00,https://github.com/tensorflow/tensorflow/pull/72023,[],[],
2414083729,pull_request,open,,Update Shardy to latest commit.,"Update Shardy to latest commit.
",copybara-service[bot],2024-07-17 16:49:32+00:00,[],2024-07-17 16:49:32+00:00,,https://github.com/tensorflow/tensorflow/pull/72022,[],[],
2414076011,pull_request,closed,,Add ability to dump graph in .pb format with an envvar TF_DUMP_GRAPH_FMT,"Add ability to dump graph in .pb format with an envvar TF_DUMP_GRAPH_FMT
",copybara-service[bot],2024-07-17 16:44:41+00:00,[],2024-07-23 20:41:48+00:00,2024-07-23 20:41:47+00:00,https://github.com/tensorflow/tensorflow/pull/72021,[],[],
2414027930,pull_request,closed,,[xla:cpu] Implement Sort operation with custom comparator,"[xla:cpu] Implement Sort operation with custom comparator

+ Enabled xla/tests:topk_test that relies on sort operation
",copybara-service[bot],2024-07-17 16:15:21+00:00,['ezhulenev'],2024-07-17 18:26:49+00:00,2024-07-17 18:26:48+00:00,https://github.com/tensorflow/tensorflow/pull/72020,[],[],
2413993863,pull_request,closed,,[XLA:GPU][IndexAnalysis] Permute symbols of the composed indexing map only if needed.,"[XLA:GPU][IndexAnalysis] Permute symbols of the composed indexing map only if needed.
",copybara-service[bot],2024-07-17 15:59:53+00:00,['pifon2a'],2024-07-17 16:29:16+00:00,2024-07-17 16:29:15+00:00,https://github.com/tensorflow/tensorflow/pull/72019,[],[],
2413832489,pull_request,closed,,Add tests for PTX compilation in NVPTXCompiler,"Add tests for PTX compilation in NVPTXCompiler

NVPTXCompiler (and the whole Compiler class hierarchy for that matter)
is a pretty monolithic component with very little test coverage.

The whole things needs a rearchitecturing to make it properly testable,
but for now I'm trying to strike a balance between not changing too many
things and allowing me to add NVJitLink support with decent coverage.

So this is adding a test harness for PTX compilation that supports
all the different compilation methods that we have.

It's also fixing a bunch of bugs that I found along the way:

1. `NVPTXCompiler::ChooseLinkingMethod` caches its decision but doesn't flush the cache when some of its input change. I resolved that by entirely removing caching. The expensive part (launching external tools like ptxas and parsing its version number) is already cached separately, so I don't expect any change to compilation times.
2. `nvlink` and linking through the driver API didn't take the requested compute capability into account. I believe it was infering the architecture from the linker inputs which made it kinda work. But I saw that we were generating sm_90 kernels when we should generate sm_90a kernels to achieve parity between all the linking methods.

NVJitlink support will come in a separate change.
",copybara-service[bot],2024-07-17 14:51:40+00:00,[],2024-07-18 14:55:01+00:00,2024-07-18 14:55:00+00:00,https://github.com/tensorflow/tensorflow/pull/72018,[],[],
2413680401,pull_request,closed,,[XLA:GPU] Fix ClangTidy warnings.,"[XLA:GPU] Fix ClangTidy warnings.

A few headers have been added with the corresponding build dependencies to hlo_constant_folding*.
",copybara-service[bot],2024-07-17 13:50:28+00:00,[],2024-07-17 17:17:34+00:00,2024-07-17 17:17:33+00:00,https://github.com/tensorflow/tensorflow/pull/72017,[],[],
2413647673,pull_request,closed,,[XLA:GPU][NFC] First commit splitting out `triton_fusion_emitter_test.cc` into several BUILD targets.,"[XLA:GPU][NFC] First commit splitting out `triton_fusion_emitter_test.cc` into several BUILD targets.

The file is for now split into two files, which still both require a device to
run:

1. `triton_fusion_emitter_device_test.cc`, which is intended to contain all
the tests for the new Triton emitters that require a device to run;
2. `triton_fusion_emitter_device_legacy_test.cc`, which is
`triton_fusion_emitter_device_test.cc`'s counterpart for the legacy GEMM
codegen path.

Eventually, the tests will be split further into `lowering` test files, which
will contain all the tests that do not require a device to run.

Also make sure to not run the optimization pipeline in tests for the new
Triton emitter---this is unnecessary and was a previous oversight.
",copybara-service[bot],2024-07-17 13:36:01+00:00,[],2024-07-18 14:36:05+00:00,2024-07-18 14:36:05+00:00,https://github.com/tensorflow/tensorflow/pull/72016,[],[],
2413600240,pull_request,closed,,Fix side output detection in transpose emitter.,"Fix side output detection in transpose emitter.

Copies can be transposes, because HLO is great. No test change
because this is covered by gpu/tests:transpose_emitter_test_gpu.
",copybara-service[bot],2024-07-17 13:15:31+00:00,[],2024-07-17 19:13:21+00:00,2024-07-17 19:13:20+00:00,https://github.com/tensorflow/tensorflow/pull/72015,[],[],
2413496737,pull_request,closed,,[XLA:GPU][NFC] Refactor `MatchesTritonCompatibleClosedReductionDiamondImpl` to decrease the function's cognitive complexity.,"[XLA:GPU][NFC] Refactor `MatchesTritonCompatibleClosedReductionDiamondImpl` to decrease the function's cognitive complexity.
",copybara-service[bot],2024-07-17 12:29:32+00:00,[],2024-07-17 17:43:52+00:00,2024-07-17 17:43:51+00:00,https://github.com/tensorflow/tensorflow/pull/72013,[],[],
2413474278,pull_request,closed,,Add IndexingMapAttr to XLA GPU Dialect,"Add IndexingMapAttr to XLA GPU Dialect

I will create an mlir test for the parser/printer & add it to ApplyIndexingOp in subsequent cls.
",copybara-service[bot],2024-07-17 12:21:23+00:00,[],2024-07-22 10:54:00+00:00,2024-07-22 10:53:59+00:00,https://github.com/tensorflow/tensorflow/pull/72012,[],[],
2413379808,pull_request,closed,,Separate xla gpu dialect into it's own td file,"Separate xla gpu dialect into it's own td file
",copybara-service[bot],2024-07-17 11:37:35+00:00,[],2024-07-17 16:50:44+00:00,2024-07-17 16:50:43+00:00,https://github.com/tensorflow/tensorflow/pull/72011,[],[],
2413183642,pull_request,closed,,Use cl_khr_command_buffer extension with clvk,"Use cl_khr_command_buffer extension with clvk
",copybara-service[bot],2024-07-17 10:00:14+00:00,[],2024-07-17 18:18:55+00:00,2024-07-17 18:18:54+00:00,https://github.com/tensorflow/tensorflow/pull/72010,[],[],
2413171196,pull_request,closed,,PR #14966: [NFC][GPU] Cleanup the definition of BinaryMap.,"PR #14966: [NFC][GPU] Cleanup the definition of BinaryMap.

Imported from GitHub PR https://github.com/openxla/xla/pull/14966


Copybara import of the project:

--
da70c50c1a48bd0da9f3db2e0d185ce45bdeb8de by Ilia Sergachev <isergachev@nvidia.com>:

[NFC][GPU] Cleanup the definition of BinaryMap.

Merging this change closes #14966

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14966 from openxla:cleanup da70c50c1a48bd0da9f3db2e0d185ce45bdeb8de
",copybara-service[bot],2024-07-17 09:54:37+00:00,[],2024-07-17 14:02:50+00:00,2024-07-17 14:02:49+00:00,https://github.com/tensorflow/tensorflow/pull/72009,[],[],
2413106652,pull_request,closed,,PR #14956: [ROCM][NFC] gemm_algorithm_picker/test: refactoring in preparation for precision settings integration,"PR #14956: [ROCM][NFC] gemm_algorithm_picker/test: refactoring in preparation for precision settings integration

Imported from GitHub PR https://github.com/openxla/xla/pull/14956

These is refactoring extracted from the original PR: https://github.com/openxla/xla/pull/13425

I have added **return_algo_index** parameter to GetBestAlgorithm function in order to avoid double conversion: algorithm -> index and then index -> algorithm. This part was quite misleading and hard to follow in the code as to why this was necessary.
The reason for this is because, cu/hipblasLt return an **opaque object** as an algorithm ID which cannot be saved within an HLO. Therefore, we needed an index of the algorithm here. In contrast, cu/hipblas return a 32-bit int algorithm ID which can readily be stoded in HLO (gemm_backend_config). 

Besides, I also simplified the respective test by unifiying some copy-paste stuff.

@xla-rotation: could you have a look please ?

Copybara import of the project:

--
691c0f9407b5784710ad72bc23d862ecdb0dfe8e by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

small refactoring in preparation for precision settings integration

--
682efe9618eef603fd168f0cf16eb8c65b1834eb by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

adressing reviewer comments

--
3ce7e30de1841333bf5a31a74812d7bb0845e558 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

fixing typo

Merging this change closes #14956

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14956 from ROCm:ci_gemm_alg_picker_refactor 3ce7e30de1841333bf5a31a74812d7bb0845e558
",copybara-service[bot],2024-07-17 09:23:06+00:00,[],2024-07-17 11:02:30+00:00,2024-07-17 11:02:29+00:00,https://github.com/tensorflow/tensorflow/pull/72008,[],[],
2413070625,pull_request,closed,,PR #14964: [ROCm] Fix an issue with undefined __oclc_ABI_version symbol.,"PR #14964: [ROCm] Fix an issue with undefined __oclc_ABI_version symbol.

Imported from GitHub PR https://github.com/openxla/xla/pull/14964


Copybara import of the project:

--
e1691462396648278cc0d64615a574e9fb45836e by Zoran Jovanovic <zjovanov@amd.com>:

[ROCm] Fix an issue with undefined __oclc_ABI_version symbol.

Merging this change closes #14964

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14964 from ROCm:ci_oclc_abi_version e1691462396648278cc0d64615a574e9fb45836e
",copybara-service[bot],2024-07-17 09:05:50+00:00,[],2024-07-17 10:29:36+00:00,2024-07-17 10:29:35+00:00,https://github.com/tensorflow/tensorflow/pull/72007,[],[],
2413015121,pull_request,closed,,[XLA:GPU] Use `tsl::testing::kIsOpenSource` instead of a copybara rewrite.,"[XLA:GPU] Use `tsl::testing::kIsOpenSource` instead of a copybara rewrite.
",copybara-service[bot],2024-07-17 08:39:09+00:00,[],2024-07-17 10:20:57+00:00,2024-07-17 10:20:56+00:00,https://github.com/tensorflow/tensorflow/pull/72005,[],[],
2413000922,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 08:32:05+00:00,[],2024-07-18 04:32:24+00:00,,https://github.com/tensorflow/tensorflow/pull/72004,[],[],
2413000674,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 08:31:58+00:00,[],2024-07-17 11:28:40+00:00,,https://github.com/tensorflow/tensorflow/pull/72003,[],[],
2412963908,pull_request,closed,,PR #14950: [XLA:GPU] Register python callback on sycl platform,"PR #14950: [XLA:GPU] Register python callback on sycl platform

Imported from GitHub PR https://github.com/openxla/xla/pull/14950


Copybara import of the project:

--
9ea4dd7cd70737862f124f77ebe66854247aa06a by Sheng, Yang <yang.sheng@intel.com>:

[XLA:GPU] Register python callback on sycl platform

Merging this change closes #14950

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14950 from Intel-tensorflow:yang/sycl-callback 9ea4dd7cd70737862f124f77ebe66854247aa06a
",copybara-service[bot],2024-07-17 08:13:47+00:00,[],2024-07-17 10:37:36+00:00,2024-07-17 10:37:35+00:00,https://github.com/tensorflow/tensorflow/pull/72001,[],[],
2412961900,pull_request,closed,,[XLA:GPU] Move Triton emitter logic and tests under `service/gpu/fusions/triton`.,"[XLA:GPU] Move Triton emitter logic and tests under `service/gpu/fusions/triton`.

The `service/gpu` BUILD file is completely unwieldy---this is a small
contribution to move towards a more reasonable directory structure.

Reverts 303b8e5ec1cab37679df40280f9e6702650316d5
",copybara-service[bot],2024-07-17 08:12:45+00:00,[],2024-07-18 13:53:57+00:00,2024-07-18 13:53:57+00:00,https://github.com/tensorflow/tensorflow/pull/72000,[],[],
2412862899,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 07:22:24+00:00,[],2024-07-18 04:44:07+00:00,,https://github.com/tensorflow/tensorflow/pull/71999,[],[],
2412858415,pull_request,closed,,Add folder for empty AtomicRMW bodies.,"Add folder for empty AtomicRMW bodies.

In case the original body consisted of a no-op (e.g. multiply with constant
1.0), the body can become empty after canonicalization. We should fold such
AtomicRMW ops away.
",copybara-service[bot],2024-07-17 07:19:55+00:00,['akuegel'],2024-07-17 08:34:57+00:00,2024-07-17 08:34:56+00:00,https://github.com/tensorflow/tensorflow/pull/71998,[],[],
2412853165,pull_request,closed,,Integrate LLVM at llvm/llvm-project@0913547d0e39,"Integrate LLVM at llvm/llvm-project@0913547d0e39

Updates LLVM usage to match
[0913547d0e39](https://github.com/llvm/llvm-project/commit/0913547d0e39)
",copybara-service[bot],2024-07-17 07:16:51+00:00,[],2024-07-17 13:55:35+00:00,2024-07-17 13:55:34+00:00,https://github.com/tensorflow/tensorflow/pull/71997,[],[],
2412800175,pull_request,closed,,Add support for non-trivial feature group counts that code for standard convs (and not depthwise conv).,"Add support for non-trivial feature group counts that code for standard convs (and not depthwise conv).
",copybara-service[bot],2024-07-17 06:47:55+00:00,['LukeBoyer'],2024-07-17 21:11:50+00:00,2024-07-17 21:11:50+00:00,https://github.com/tensorflow/tensorflow/pull/71996,[],[],
2412792179,pull_request,closed,,[Xprof] Fix overlapping lines in host offload op.,"[Xprof] Fix overlapping lines in host offload op.

This creates minimal number of lines in trace view to print non-overlap host offload ops.
",copybara-service[bot],2024-07-17 06:43:41+00:00,[],2024-07-18 19:36:25+00:00,2024-07-18 19:36:25+00:00,https://github.com/tensorflow/tensorflow/pull/71995,[],[],
2412712601,pull_request,closed,,Add support for non-trivial RHS dilations in MHLO->TFL,"Add support for non-trivial RHS dilations in MHLO->TFL
",copybara-service[bot],2024-07-17 05:54:32+00:00,['LukeBoyer'],2024-07-17 20:48:39+00:00,2024-07-17 20:48:39+00:00,https://github.com/tensorflow/tensorflow/pull/71994,[],[],
2412712050,pull_request,closed,,Add support for non-trivial strides for conv in MHLO->TFL.,"Add support for non-trivial strides for conv in MHLO->TFL.
",copybara-service[bot],2024-07-17 05:54:09+00:00,['LukeBoyer'],2024-07-17 20:56:30+00:00,2024-07-17 20:56:29+00:00,https://github.com/tensorflow/tensorflow/pull/71993,[],[],
2412691127,pull_request,closed,,Add proto pyclif build rules,"Add proto pyclif build rules
",copybara-service[bot],2024-07-17 05:36:10+00:00,[],2024-07-26 14:09:04+00:00,2024-07-26 14:09:03+00:00,https://github.com/tensorflow/tensorflow/pull/71992,[],[],
2412572841,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:53:15+00:00,[],2024-07-17 08:00:29+00:00,,https://github.com/tensorflow/tensorflow/pull/71991,[],[],
2412571949,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:52:06+00:00,[],2024-07-17 03:52:06+00:00,,https://github.com/tensorflow/tensorflow/pull/71990,[],[],
2412566980,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:47:30+00:00,[],2024-07-17 08:58:01+00:00,,https://github.com/tensorflow/tensorflow/pull/71989,[],[],
2412564388,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:44:18+00:00,[],2024-07-17 08:53:34+00:00,2024-07-17 08:53:33+00:00,https://github.com/tensorflow/tensorflow/pull/71988,[],[],
2412564114,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:43:58+00:00,[],2024-07-17 08:59:37+00:00,,https://github.com/tensorflow/tensorflow/pull/71987,[],[],
2412563991,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:43:50+00:00,[],2024-07-17 07:01:30+00:00,,https://github.com/tensorflow/tensorflow/pull/71986,[],[],
2412560694,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:40:08+00:00,[],2024-07-17 06:52:59+00:00,2024-07-17 06:52:58+00:00,https://github.com/tensorflow/tensorflow/pull/71985,[],[],
2412557726,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:36:33+00:00,[],2024-07-20 04:47:50+00:00,2024-07-20 04:47:49+00:00,https://github.com/tensorflow/tensorflow/pull/71984,[],[],
2412557564,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-17 03:36:21+00:00,[],2024-07-17 08:34:51+00:00,,https://github.com/tensorflow/tensorflow/pull/71983,[],[],
2412556495,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/71879 from tensorflow:dependabot/pip/setuptools-70.0.0 21c53b126cd09b4af995698bd5ef14fcb43759f3
",copybara-service[bot],2024-07-17 03:35:16+00:00,[],2024-07-17 03:35:16+00:00,,https://github.com/tensorflow/tensorflow/pull/71982,[],[],
2412552598,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/71879 from tensorflow:dependabot/pip/setuptools-70.0.0 21c53b126cd09b4af995698bd5ef14fcb43759f3
",copybara-service[bot],2024-07-17 03:30:36+00:00,[],2024-07-17 03:30:36+00:00,,https://github.com/tensorflow/tensorflow/pull/71981,[],[],
2412552033,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/71879 from tensorflow:dependabot/pip/setuptools-70.0.0 21c53b126cd09b4af995698bd5ef14fcb43759f3
",copybara-service[bot],2024-07-17 03:29:58+00:00,[],2024-07-17 03:29:58+00:00,,https://github.com/tensorflow/tensorflow/pull/71980,[],[],
2412496435,pull_request,open,,Integrate LLVM at llvm/llvm-project@0913547d0e39,"Integrate LLVM at llvm/llvm-project@0913547d0e39

Updates LLVM usage to match
[0913547d0e39](https://github.com/llvm/llvm-project/commit/0913547d0e39)
",copybara-service[bot],2024-07-17 02:42:33+00:00,[],2024-07-17 06:27:14+00:00,,https://github.com/tensorflow/tensorflow/pull/71979,[],[],
2412477462,pull_request,closed,,[xla:cpu] NFC: Clean up SortThunk templates,"[xla:cpu] NFC: Clean up SortThunk templates

1. Delete Ref<Ts...> default constructor by declaring an explicit one. Similar to how regular reference can't be uninitialized, Ref<Ts...> also should not be created out of thin air.
2. Rename Store to Assign, because it's really a reference assignment.
",copybara-service[bot],2024-07-17 02:25:42+00:00,['ezhulenev'],2024-07-17 03:22:27+00:00,2024-07-17 03:22:26+00:00,https://github.com/tensorflow/tensorflow/pull/71978,[],[],
2412335666,pull_request,closed,,Add EventType enum type to TraceEvent proto.,"Add EventType enum type to TraceEvent proto.
",copybara-service[bot],2024-07-17 01:02:52+00:00,[],2024-07-17 02:23:14+00:00,2024-07-17 02:23:14+00:00,https://github.com/tensorflow/tensorflow/pull/71977,[],[],
2412332689,pull_request,closed,,Improve load time on serialized entries.,"From profiling slow load times of serialized GPUv2 delegate data, a lot of unnecessary time is spent re-allocating memory as part of the call to std::string::append. By pre-allocating the correct size, we save a lot of time.

This patch was developed in 2022 (pardon the slow turn-around) and I no longer have the exact profiling details. However, my notes say that on an arbitrary but complex model, GetData() was previously taking 50ms; with this patch, it takes 18ms.",quicbrtal,2024-07-17 01:01:47+00:00,['gbaned'],2024-07-17 17:37:23+00:00,2024-07-17 17:37:23+00:00,https://github.com/tensorflow/tensorflow/pull/71976,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small')]",[],
2412271318,pull_request,closed,,Reverts e8b7317f5bfade022cb81b6475f2d35582bab58d,"Reverts e8b7317f5bfade022cb81b6475f2d35582bab58d
",copybara-service[bot],2024-07-17 00:15:03+00:00,[],2024-07-17 02:37:56+00:00,2024-07-17 02:37:56+00:00,https://github.com/tensorflow/tensorflow/pull/71975,[],[],
2412254954,pull_request,closed,,Update WORKSPACE,"
1. **Documentation**:
   - Comments have been added to explain the purpose of each section or step in the code. This helps improve code readability and understanding for other developers who may work with the code in the future.

2. **Error Handling**:
   - Although not explicitly added in the code snippet, error handling mechanisms should be implemented to handle any potential failures that may occur during the initialization process. This ensures that the setup process can gracefully recover from errors.

3. **Dependency Updates**:
   - It is recommended to regularly check for updates to dependencies like `rules_java` and TensorFlow and update the versions accordingly. This ensures that the workspace stays up-to-date with the latest features and bug fixes.

4. **Testing**:
   - The suggestion to define test targets within the workspace is made to ensure that the setup is working correctly. Testing helps validate the configuration and ensures that dependencies are properly configured.

5. **Build Targets**:
   - Defining build targets for specific projects within the workspace allows for building and running TensorFlow applications. This enables developers to easily build and test their projects within the configured environment.

6. **Environment Configuration**:
   - Setting up specific environment variables or configurations needed for TensorFlow ensures that the workspace is properly configured to support the TensorFlow environment.

7. **Version Control**:
   - The recommendation to ensure proper version control for the workspace configuration is important for tracking changes and facilitating collaboration among team members working on the project.

8. **Optimizations**:
   - The suggestion to optimize the build process, such as caching dependencies or parallelizing build tasks, can improve the efficiency and speed of the build process.

By incorporating these additions, the code becomes more robust, maintainable, and efficient, making it easier for developers to work with the TensorFlow workspace setup.",yashpratap914,2024-07-16 23:58:44+00:00,['gbaned'],2024-07-17 13:29:58+00:00,2024-07-17 13:29:55+00:00,https://github.com/tensorflow/tensorflow/pull/71974,"[('size:S', 'CL Change Size: Small')]","[{'comment_id': 2232031925, 'issue_id': 2412254954, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/71974/checks?check_run_id=27536633975) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 16, 23, 58, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2232795637, 'issue_id': 2412254954, 'author': 'keerthanakadiri', 'body': 'Hi @yashpratap914, Can you please sign CLA ? & use a proper commit message / PR title, not Update < file >. See https://cbea.ms/git-commit/', 'created_at': datetime.datetime(2024, 7, 17, 8, 59, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233327261, 'issue_id': 2412254954, 'author': 'mihaimaruseac', 'body': 'Please don\'t use ""add file""/""update file""/""fix file""/etc. commit messages. These are hard to reason about when looking at the history of the file/repository. Instead, please write explanatory git commit messages.\r\n\r\nThe commit message is also the title of the PR if the PR has only one commit. It is thus twice important to have commit messages that are relevant, as PRs would be easier to understand and easier to analyze in search results.\r\n\r\nFor how to write good quality git commit messages, please consult https://cbea.ms/git-commit/', 'created_at': datetime.datetime(2024, 7, 17, 13, 27, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2233331823, 'issue_id': 2412254954, 'author': 'mihaimaruseac', 'body': 'This looks like spam. The opening message looks generated by GenAI. The code change have not been tested and are removing useful functionality.\r\n\r\nClosing due to risk of this being used to just farm popularity (https://socket.dev/blog/openssf-warns-of-reputation-farming-using-closed-github-issues-and-prs) and reporting to GitHub.', 'created_at': datetime.datetime(2024, 7, 17, 13, 29, 55, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-16 23:58:48 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/71974/checks?check_run_id=27536633975) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

keerthanakadiri on (2024-07-17 08:59:00 UTC): Hi @yashpratap914, Can you please sign CLA ? & use a proper commit message / PR title, not Update < file >. See https://cbea.ms/git-commit/

mihaimaruseac on (2024-07-17 13:27:46 UTC): Please don't use ""add file""/""update file""/""fix file""/etc. commit messages. These are hard to reason about when looking at the history of the file/repository. Instead, please write explanatory git commit messages.

The commit message is also the title of the PR if the PR has only one commit. It is thus twice important to have commit messages that are relevant, as PRs would be easier to understand and easier to analyze in search results.

For how to write good quality git commit messages, please consult https://cbea.ms/git-commit/

mihaimaruseac on (2024-07-17 13:29:55 UTC): This looks like spam. The opening message looks generated by GenAI. The code change have not been tested and are removing useful functionality.

Closing due to risk of this being used to just farm popularity (https://socket.dev/blog/openssf-warns-of-reputation-farming-using-closed-github-issues-and-prs) and reporting to GitHub.

"
2412200465,pull_request,closed,,[XLA] Update HloInstructionProto and proto conversion to support ReplicaGroupV2.,"[XLA] Update HloInstructionProto and proto conversion to support ReplicaGroupV2.
",copybara-service[bot],2024-07-16 23:16:50+00:00,[],2024-07-17 23:33:43+00:00,2024-07-17 23:33:42+00:00,https://github.com/tensorflow/tensorflow/pull/71973,[],[],
2412137766,pull_request,closed,,Fix ShapeUtil comment,"Fix ShapeUtil comment
",copybara-service[bot],2024-07-16 22:22:19+00:00,['SandSnip3r'],2024-07-17 00:56:16+00:00,2024-07-17 00:56:16+00:00,https://github.com/tensorflow/tensorflow/pull/71972,[],[],
2412126195,pull_request,closed,,Minor changes/simplifications,"Minor changes/simplifications
1. Remove a redundant assignment in AllInfinityCosts
2. Update a function comment per the style guide
3. Generalize ToString(StableHashMap) to have both keys abd values templated. This allows us to print DimMap objects for debugging.
",copybara-service[bot],2024-07-16 22:11:39+00:00,[],2024-07-17 19:58:27+00:00,2024-07-17 19:58:26+00:00,https://github.com/tensorflow/tensorflow/pull/71971,[],[],
2412114442,pull_request,closed,,Int4 conv op Hybrid fix,"Int4 conv op Hybrid fix
",copybara-service[bot],2024-07-16 22:01:49+00:00,['turbotoribio'],2024-07-18 00:16:44+00:00,2024-07-18 00:16:43+00:00,https://github.com/tensorflow/tensorflow/pull/71970,[],[],
2412097779,pull_request,closed,,Add function to print a compact 2D map of occupied heap memory vs time as ASCII art for easier debugging.,"Add function to print a compact 2D map of occupied heap memory vs time as ASCII art for easier debugging.
",copybara-service[bot],2024-07-16 21:47:27+00:00,['subhankarshah'],2024-07-31 22:39:53+00:00,2024-07-31 22:39:52+00:00,https://github.com/tensorflow/tensorflow/pull/71969,[],[],
2412086390,pull_request,closed,,Expand test targets ran for XLA CPU builds,"Expand test targets ran for XLA CPU builds

This change was informed by conversations on https://github.com/openxla/xla/pull/14778, thank you to all involved!
",copybara-service[bot],2024-07-16 21:38:59+00:00,['ddunl'],2024-07-17 01:03:26+00:00,2024-07-17 01:03:25+00:00,https://github.com/tensorflow/tensorflow/pull/71968,[],[],
2412077558,pull_request,closed,,Refactor TSL's config_settings,"Refactor TSL's config_settings
",copybara-service[bot],2024-07-16 21:31:53+00:00,['ddunl'],2024-07-17 02:30:32+00:00,2024-07-17 02:30:31+00:00,https://github.com/tensorflow/tensorflow/pull/71967,[],[],
2412068641,pull_request,closed,,Add more logs to ColocatePredecessorTreesPass.,"Add more logs to ColocatePredecessorTreesPass.
",copybara-service[bot],2024-07-16 21:24:37+00:00,[],2024-07-17 20:40:45+00:00,2024-07-17 20:40:44+00:00,https://github.com/tensorflow/tensorflow/pull/71966,[],[],
2412004840,pull_request,closed,,Move Stream::DoHostCallbackWithStatus implementation to derived classes of Stream.,"Move Stream::DoHostCallbackWithStatus implementation to derived classes of Stream.

This avoids eventual down_casts to the correct kind of stream in all the StreamExecutor derived classes that were happening.
",copybara-service[bot],2024-07-16 20:38:28+00:00,[],2024-07-19 19:11:40+00:00,2024-07-19 19:11:40+00:00,https://github.com/tensorflow/tensorflow/pull/71964,[],[],
2411964486,pull_request,closed,,Allow specifying input ranges via tests in the prepare-quantize pass.,"Allow specifying input ranges via tests in the prepare-quantize pass.
",copybara-service[bot],2024-07-16 20:11:49+00:00,['arfaian'],2024-07-17 19:31:25+00:00,2024-07-17 19:31:24+00:00,https://github.com/tensorflow/tensorflow/pull/71963,[],[],
2411958969,pull_request,closed,,Add end to end tests for ICI Weight Distribution in MLIR bridge,"Add end to end tests for ICI Weight Distribution in MLIR bridge
",copybara-service[bot],2024-07-16 20:08:10+00:00,[],2024-07-16 21:07:26+00:00,2024-07-16 21:07:25+00:00,https://github.com/tensorflow/tensorflow/pull/71962,[],[],
2411933508,pull_request,closed,,[XLA:SPMD] allow sharding-aware CSE to combine compatible sharding.,"[XLA:SPMD] allow sharding-aware CSE to combine compatible sharding.
1. Allow CSE to skip given instructions.
2. Do not CSE instruction with prior shardings in sharding propagation.
",copybara-service[bot],2024-07-16 19:51:53+00:00,['Tongfei-Guo'],2024-07-17 06:08:56+00:00,2024-07-17 06:08:55+00:00,https://github.com/tensorflow/tensorflow/pull/71961,[],[],
2411914203,pull_request,open,,[oneDNN] Refine oneDNN test cases to enable them with stock TF,"

Refine oneDNN test cases by removing #ifdef ENABLE_MKL constraint so that these tests run without --config=mkl.
That is to enable those test case with stock TF. ",gzmkl,2024-07-16 19:39:01+00:00,['gbaned'],2025-01-16 08:46:03+00:00,,https://github.com/tensorflow/tensorflow/pull/71960,"[('awaiting review', 'Pull request awaiting review'), ('size:S', 'CL Change Size: Small'), ('comp:core', 'issues related to core part of tensorflow')]","[{'comment_id': 2244304479, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 7, 23, 5, 48, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2270819229, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 8, 6, 9, 28, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298014597, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk  , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 8, 20, 5, 45, 47, tzinfo=datetime.timezone.utc)}, {'comment_id': 2311695660, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 8, 27, 6, 42, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326295621, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you', 'created_at': datetime.datetime(2024, 9, 3, 11, 35, 25, tzinfo=datetime.timezone.utc)}, {'comment_id': 2354724668, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 9, 17, 7, 11, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2367722675, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 9, 23, 9, 48, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2384879999, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 1, 6, 9, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401397924, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 9, 6, 12, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431517865, 'issue_id': 2411914203, 'author': 'keerthanakadiri', 'body': 'Hi @penpornk , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 23, 9, 40, 53, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-07-23 05:48:38 UTC): Hi @penpornk , Can you please review this PR? Thank you !

keerthanakadiri on (2024-08-06 09:28:09 UTC): Hi @penpornk , Can you please review this PR? Thank you !

keerthanakadiri on (2024-08-20 05:45:47 UTC): Hi @penpornk  , Can you please review this PR? Thank you

keerthanakadiri on (2024-08-27 06:42:44 UTC): Hi @penpornk , Can you please review this PR? Thank you

keerthanakadiri on (2024-09-03 11:35:25 UTC): Hi @penpornk , Can you please review this PR? Thank you

keerthanakadiri on (2024-09-17 07:11:49 UTC): Hi @penpornk , Can you please review this PR? Thank you !

keerthanakadiri on (2024-09-23 09:48:02 UTC): Hi @penpornk , Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-01 06:09:14 UTC): Hi @penpornk , Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-09 06:12:18 UTC): Hi @penpornk , Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-23 09:40:53 UTC): Hi @penpornk , Can you please review this PR? Thank you !

"
2411913662,pull_request,open,,Improve the error message for missing tensor value for a TF resource variable.,"Improve the error message for missing tensor value for a TF resource variable.
",copybara-service[bot],2024-07-16 19:38:41+00:00,['sdasgup3'],2024-07-16 19:38:42+00:00,,https://github.com/tensorflow/tensorflow/pull/71959,[],[],
2411890486,pull_request,closed,,Improve log statements in HostOffloadLegalize. Combine two loops over the same indices.,"Improve log statements in HostOffloadLegalize. Combine two loops over the same indices.
",copybara-service[bot],2024-07-16 19:23:13+00:00,['SandSnip3r'],2024-07-23 23:44:29+00:00,2024-07-23 23:44:28+00:00,https://github.com/tensorflow/tensorflow/pull/71958,[],[],
2411887372,pull_request,closed,,"Increase the CUDA/GPU wheel size limit to 610MB, due to the Clang-18 upgrade.","Increase the CUDA/GPU wheel size limit to 610MB, due to the Clang-18 upgrade.
",copybara-service[bot],2024-07-16 19:20:52+00:00,[],2024-07-16 20:34:12+00:00,2024-07-16 20:34:11+00:00,https://github.com/tensorflow/tensorflow/pull/71957,[],"[{'comment_id': 2231671438, 'issue_id': 2411887372, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/71957/checks?check_run_id=27527535966) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 16, 19, 20, 58, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-16 19:20:58 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/71957/checks?check_run_id=27527535966) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2411879793,pull_request,open,,#sdy Remove sdy_shell from github.,"#sdy Remove sdy_shell from github.
",copybara-service[bot],2024-07-16 19:16:06+00:00,['bixia1'],2024-07-16 21:15:29+00:00,,https://github.com/tensorflow/tensorflow/pull/71956,[],[],
2411854549,pull_request,open,,"Give XLA its own bazelrc, instead of copying TensorFlow's","Give XLA its own bazelrc, instead of copying TensorFlow's
",copybara-service[bot],2024-07-16 19:01:23+00:00,['ddunl'],2024-07-16 19:14:53+00:00,,https://github.com/tensorflow/tensorflow/pull/71955,[],[],
2411836601,pull_request,closed,,Fix a typo in the GCS URI.,"Fix a typo in the GCS URI.

For some reason, the extra slash causes `gsutil` to create a ""\"" folder in the bucket.
",copybara-service[bot],2024-07-16 18:52:48+00:00,['nitins17'],2024-07-16 21:54:29+00:00,2024-07-16 21:54:27+00:00,https://github.com/tensorflow/tensorflow/pull/71954,[],[],
2411807908,pull_request,closed,,Add support for transposing non standard output formats for convs,"Add support for transposing non standard output formats for convs
",copybara-service[bot],2024-07-16 18:40:08+00:00,['LukeBoyer'],2024-07-17 05:49:39+00:00,2024-07-17 05:49:38+00:00,https://github.com/tensorflow/tensorflow/pull/71953,[],[],
2411797810,pull_request,open,,Refactor batch transform logic into `xla_batch_transform`,"Refactor batch transform logic into `xla_batch_transform`
",copybara-service[bot],2024-07-16 18:35:29+00:00,['ddunl'],2024-07-16 18:35:30+00:00,,https://github.com/tensorflow/tensorflow/pull/71952,[],[],
2411764881,pull_request,closed,,Roll back automated lint fixes which caused a TPU build breakage.,"Roll back automated lint fixes which caused a TPU build breakage.

Reverts da6b16843ebbceb5ee654673045a671924f85783
",copybara-service[bot],2024-07-16 18:16:23+00:00,['belitskiy'],2024-07-16 19:30:26+00:00,2024-07-16 19:30:26+00:00,https://github.com/tensorflow/tensorflow/pull/71951,[],"[{'comment_id': 2231527503, 'issue_id': 2411764881, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/71951/checks?check_run_id=27524872242) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 16, 18, 16, 28, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-16 18:16:28 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/71951/checks?check_run_id=27524872242) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2411759544,pull_request,closed,,[XLA:MSA] Implement an auxiliary function (SimulateComputeInstruction) to simulate processing outstanding async copy instructions.,"[XLA:MSA] Implement an auxiliary function (SimulateComputeInstruction) to simulate processing outstanding async copy instructions.

When executing a computation instruction, there may be a time windows when default memory is not required (e.g., computation intensive instructions). This default memory idle time window can be used to process outstanding async copy instructions. We simulate this process in the ProcessAsyncCopyInTimeWindow function. This function tries to process outstanding async copy instructions that stored in default_read queue and default_write queue. To provide a more general interface, I wrap this function with a high-level function (SimulateComputeInstruction), which accepts a compute instruction as input.
",copybara-service[bot],2024-07-16 18:13:31+00:00,[],2024-07-24 19:29:28+00:00,2024-07-24 19:29:28+00:00,https://github.com/tensorflow/tensorflow/pull/71950,[],[],
2411756636,pull_request,closed,,[XLA:MSA] Implement an auxiliary function (SimulateAsyncCopyDone) to simulate the overhead of processing copy-done instruction.,"[XLA:MSA] Implement an auxiliary function (SimulateAsyncCopyDone) to simulate the overhead of processing copy-done instruction.

This CL implements a function to simulate the overhead of copy-done instructions. Specifically, there are two directions which share the bandwidth: default-read and default-write. Two directions will share the bandwidth equally. For example, when we process a default-read request, if there are also outstanding default-write process, we can only use half of the full bandwidth to process requests in each direction.
",copybara-service[bot],2024-07-16 18:12:18+00:00,[],2024-07-24 01:09:13+00:00,2024-07-24 01:09:13+00:00,https://github.com/tensorflow/tensorflow/pull/71949,[],[],
2411727382,pull_request,closed,,[xla:gpu] Add reproducer for memset + conditional CUDA graph update bug,"[xla:gpu] Add reproducer for memset + conditional CUDA graph update bug
",copybara-service[bot],2024-07-16 17:54:36+00:00,[],2024-08-08 19:04:28+00:00,2024-08-08 19:04:26+00:00,https://github.com/tensorflow/tensorflow/pull/71948,[],[],
2411713732,pull_request,closed,,Add float error distance to error message in literal_comparison,"Add float error distance to error message in literal_comparison

If the error spec specifies within_n_floats, we log the distance between the actual and expected values in floats.
",copybara-service[bot],2024-07-16 17:46:48+00:00,[],2024-07-18 02:14:58+00:00,2024-07-18 02:14:57+00:00,https://github.com/tensorflow/tensorflow/pull/71947,[],[],
2411686505,pull_request,closed,,Fix inline assembly validation error in PreventMmaV3LoopUnrollingPass,"Fix inline assembly validation error in PreventMmaV3LoopUnrollingPass

LLVM's verifier requires that the constraints match the inline asm op's input and output types. We had the output type set to i32, since it had to be something, but we did not specify that there is a single output in constraints. This caused `TritonGpuTest.TestPreventMMAV3LoopUnrolling` to fail when run in debug mode.
",copybara-service[bot],2024-07-16 17:28:22+00:00,['gflegar'],2024-07-17 08:02:07+00:00,2024-07-17 08:02:06+00:00,https://github.com/tensorflow/tensorflow/pull/71946,[],[],
