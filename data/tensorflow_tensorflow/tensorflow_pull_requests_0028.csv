id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2567688075,pull_request,closed,,[XLA:GPU] Introduce memory usage report for the eyeballing,"[XLA:GPU] Introduce memory usage report for the eyeballing

The current buffer-assignment dump is not very suitable for the eyeballing and it is in use by some scripts that parse its content.

Lets introduce ....-memory-usage-report.txt file that has summarised version of the memory allocation data that could be checked by eyes.

Let's sort the allocations by size (Z-A). As a result we will see the total requirements and them most memory consuming buffers together. And the biggest one will be at the top.

Let's dump the values in an allocation grouped by offset and ordered by size(Z-A) of the slice. Let's add the counted list of shapes that share the same offset.
",copybara-service[bot],2024-10-05 06:22:08+00:00,[],2024-10-05 06:57:17+00:00,2024-10-05 06:57:16+00:00,https://github.com/tensorflow/tensorflow/pull/77086,[],[],
2567685634,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-05 06:15:27+00:00,[],2024-10-05 06:15:27+00:00,,https://github.com/tensorflow/tensorflow/pull/77085,[],[],
2567616157,pull_request,closed,,Pull generic dynamic loading utils into core api. This will need to be reused for loading plugin .so from driver.,"Pull generic dynamic loading utils into core api. This will need to be reused for loading plugin .so from driver.
",copybara-service[bot],2024-10-05 03:03:15+00:00,['LukeBoyer'],2024-10-05 23:00:21+00:00,2024-10-05 23:00:20+00:00,https://github.com/tensorflow/tensorflow/pull/77084,[],[],
2567593883,pull_request,closed,,[XLA:GPU] Support 0D Tensors in the Generic Triton Emitter.,"[XLA:GPU] Support 0D Tensors in the Generic Triton Emitter.

The legacy MatMul emitter remains unchanged. We agreed internally to just copy all the functionality that it needs, as we'll be deleting it ""soon"" anyway.
",copybara-service[bot],2024-10-05 01:55:54+00:00,[],2024-10-07 14:25:47+00:00,2024-10-07 14:25:46+00:00,https://github.com/tensorflow/tensorflow/pull/77083,"[('ready to pull', 'PR ready for merge process')]",[],
2567589542,pull_request,open,,Test Docker copy.,"Test Docker copy.
",copybara-service[bot],2024-10-05 01:42:21+00:00,['quoctruong'],2024-10-08 17:24:08+00:00,,https://github.com/tensorflow/tensorflow/pull/77082,[],[],
2567548028,pull_request,open,,PR #17453: Reorder Collective Optimization Passes,"PR #17453: Reorder Collective Optimization Passes

Imported from GitHub PR https://github.com/openxla/xla/pull/17453

Moves the collective quantizer pass ahead of the collective pipeliner to preserve FP8 quantization and dequantization patterns preceded or followed by collectives without running the collective pipeliner post layout assignment. See #12866 and #15292.
Copybara import of the project:

--
d8e8f6349595c80b097840baa1e7076609fbd441 by Philipp Hack <phack@nvidia.com>:

Moves the collective quantizer pass before the collective pipeliner.

--
b34f2030368f4f52137d88e6cae262a203320612 by Philipp Hack <phack@nvidia.com>:

Moves the collective quantizer pass before the collective pipeliner.

Merging this change closes #17453

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17453 from philipphack:u_collective_passes_xla b34f2030368f4f52137d88e6cae262a203320612
",copybara-service[bot],2024-10-05 00:06:38+00:00,[],2024-10-05 00:32:23+00:00,,https://github.com/tensorflow/tensorflow/pull/77081,[],[],
2567547809,pull_request,open,,Move `tsl/protobuf/error_codes.proto` to `xla/tsl/protobuf`,"Move `tsl/protobuf/error_codes.proto` to `xla/tsl/protobuf`
",copybara-service[bot],2024-10-05 00:06:11+00:00,['ddunl'],2024-10-05 00:06:12+00:00,,https://github.com/tensorflow/tensorflow/pull/77080,[],[],
2567517069,pull_request,closed,,Remove stream_executor/platform/platform.h in favor of simply using tsl/platform/platform.h.,"Remove stream_executor/platform/platform.h in favor of simply using tsl/platform/platform.h.
",copybara-service[bot],2024-10-04 23:07:10+00:00,[],2024-10-07 17:37:22+00:00,2024-10-07 17:37:21+00:00,https://github.com/tensorflow/tensorflow/pull/77079,[],[],
2567516028,pull_request,closed,,Add code search link for events where source line is present,"Add code search link for events where source line is present
",copybara-service[bot],2024-10-04 23:05:26+00:00,[],2024-10-05 03:39:44+00:00,2024-10-05 03:39:43+00:00,https://github.com/tensorflow/tensorflow/pull/77078,[],[],
2567515065,pull_request,open,,Skip nextafter test with IFRT for unsupported dtype.,"Skip nextafter test with IFRT for unsupported dtype.

IFRT calls tf2xla's EncodePrimitiveTypeAsDataType function to get a TF dtype from an XLA dtype. But there is no TF dtype corresponding to XLA's F8E4M3B11FNUZ type.

Link to EncodePrimitiveTypeAsDataType: https://github.com/tensorflow/tensorflow/blob/ac3bde91780b649f6142a578f58f249314c3136d/tensorflow/compiler/tf2xla/type_util.cc#L98

Reverts 0927f90ce5d3c7a5dc26ee464ff86dbbd76e758d
",copybara-service[bot],2024-10-04 23:04:02+00:00,['reedwm'],2024-10-04 23:04:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77077,[],[],
2567512564,pull_request,open,,Integrate LLVM at llvm/llvm-project@82f5acfbec65,"Integrate LLVM at llvm/llvm-project@82f5acfbec65

Updates LLVM usage to match
[82f5acfbec65](https://github.com/llvm/llvm-project/commit/82f5acfbec65)

Reverts 0927f90ce5d3c7a5dc26ee464ff86dbbd76e758d
",copybara-service[bot],2024-10-04 23:00:29+00:00,[],2024-10-04 23:00:29+00:00,,https://github.com/tensorflow/tensorflow/pull/77076,[],[],
2567504799,pull_request,closed,,"Migrate presubmit job Linux x86 jobs to use the new ML build container cluster. The continuous and nightly job will be migrated next. Once all the jobs are migrated, the new `linux_x86_build` file will be removed and the old `linux_x86` env file will have its container replaced.","Migrate presubmit job Linux x86 jobs to use the new ML build container cluster. The continuous and nightly job will be migrated next. Once all the jobs are migrated, the new `linux_x86_build` file will be removed and the old `linux_x86` env file will have its container replaced.
",copybara-service[bot],2024-10-04 22:48:53+00:00,['quoctruong'],2024-10-15 17:46:34+00:00,2024-10-15 17:46:33+00:00,https://github.com/tensorflow/tensorflow/pull/77075,[],[],
2567487568,pull_request,closed,,Reverts fd154ab2da6146f049c383d79578f48395a702f5,"Reverts fd154ab2da6146f049c383d79578f48395a702f5
",copybara-service[bot],2024-10-04 22:24:27+00:00,[],2024-10-07 23:13:38+00:00,2024-10-07 23:13:37+00:00,https://github.com/tensorflow/tensorflow/pull/77074,[],[],
2567475181,pull_request,closed,,PR #17295: [ROCm] clang support,"PR #17295: [ROCm] clang support

Imported from GitHub PR https://github.com/openxla/xla/pull/17295

Brings up clang support for ROCm XLA. This is required to implement clang support for JAX+XLA for ROCm.

@draganmladjenovic @i-chaochen
Copybara import of the project:

--
b0f316408f62052125973cfff6f9371a91e84464 by Ruturaj4 <ruturaj.vaidya@amd.com>:

[ROCm] clang support

Merging this change closes #17295

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17295 from ROCm:ci_rv_clang b0f316408f62052125973cfff6f9371a91e84464
",copybara-service[bot],2024-10-04 22:08:51+00:00,[],2024-10-07 18:34:09+00:00,2024-10-07 18:34:08+00:00,https://github.com/tensorflow/tensorflow/pull/77073,[],[],
2567457508,pull_request,closed,,[tf:grappler] Add a new GeluExact pattern based on Erfc.,"[tf:grappler] Add a new GeluExact pattern based on Erfc.

This new pattern comes from the adjusted implementation of `tf.nn.gelu` from https://github.com/tensorflow/tensorflow/pull/76174

Reverts 08ec0d5d0579af7ddf4272aa609ae9f36c179530
",copybara-service[bot],2024-10-04 21:47:47+00:00,['penpornk'],2024-10-05 00:05:06+00:00,2024-10-05 00:05:05+00:00,https://github.com/tensorflow/tensorflow/pull/77071,[],[],
2567450264,pull_request,closed,,"Mark deprecated tensorflow::Status and tensorflow::errors::Code aliases as ABSL_DEPRECATE_AND_INLINE, using the macro only if it is already available, i.e. new code should use their definition directly.","Mark deprecated tensorflow::Status and tensorflow::errors::Code aliases as ABSL_DEPRECATE_AND_INLINE, using the macro only if it is already available, i.e. new code should use their definition directly.
",copybara-service[bot],2024-10-04 21:39:49+00:00,[],2024-10-06 14:03:17+00:00,2024-10-06 14:03:17+00:00,https://github.com/tensorflow/tensorflow/pull/77070,[],[],
2567445961,pull_request,closed,,Reverts 0927f90ce5d3c7a5dc26ee464ff86dbbd76e758d,"Reverts 0927f90ce5d3c7a5dc26ee464ff86dbbd76e758d
",copybara-service[bot],2024-10-04 21:35:17+00:00,[],2024-10-04 23:43:08+00:00,2024-10-04 23:43:07+00:00,https://github.com/tensorflow/tensorflow/pull/77069,[],[],
2567405098,pull_request,closed,,Finish prototype implementation for qnn compiler plugin. Currently only knows how to handle simple cases where there winds up being one partition with one float 2x2 mul op.,"Finish prototype implementation for qnn compiler plugin. Currently only knows how to handle simple cases where there winds up being one partition with one float 2x2 mul op.

See `qnn_compose_graph.cc` for main changes.

Also:
* Add ""ensure"" macro
* Add extra functionality to tensor wrapper.
",copybara-service[bot],2024-10-04 21:10:43+00:00,['LukeBoyer'],2024-10-04 23:09:57+00:00,2024-10-04 23:09:55+00:00,https://github.com/tensorflow/tensorflow/pull/77068,[],[],
2567398428,pull_request,closed,,CC wrapper for lrt op and basic lrt -> qnn op mapping,"CC wrapper for lrt op and basic lrt -> qnn op mapping
",copybara-service[bot],2024-10-04 21:07:59+00:00,['LukeBoyer'],2024-10-04 22:49:17+00:00,2024-10-04 22:49:17+00:00,https://github.com/tensorflow/tensorflow/pull/77067,[],[],
2567357239,pull_request,open,,Remove REE from jax_google.py allowlist.,"Remove REE from jax_google.py allowlist.
",copybara-service[bot],2024-10-04 20:55:18+00:00,['vamsimanchala'],2024-10-04 20:55:19+00:00,,https://github.com/tensorflow/tensorflow/pull/77066,[],[],
2567357164,pull_request,closed,,[IFRT] Extend Array assembly/disassembly operations to distinguish between addressable-shard and all-shard processing,"[IFRT] Extend Array assembly/disassembly operations to distinguish between addressable-shard and all-shard processing

IFRT's assembly/disassembly operations
(`Client::AssembleArrayFromSingleDeviceArray`,
`Array::DisassembleIntoSingleDeviceArrays`, and related methods in `Sharding`)
treated all shards equally without distinguishing the addressability of the
device of the shards. This had practical problems:

* When the user only has single-device arrays for addressable devices, and
asssemble them into a multi-shard array, the user is forced to use a `Sharding`
that only contains addressable devices. However, with SPMD, it is common to use
a `Sharding` that can express both adressable/non-addressable shards (e.g.,
`HloSharding`).

* When the user has a multi-shard array that spans both
addressable/non-addressable devices, disassembling the array into single-device
arrays would create a single-device array with no addressable devices, which is
often not well supported in the user code because the user code sometimes makes
a strong assumption that any array contains at least one addressable device.

On the other hand, making assembly/diassembly handle only addressable shards is
not future proof. An MPMD setup (not all inputs use a single device mesh) can
see an array with no addressable devices. Thus, changing assembly/diassembly
sematics to handle only addressable shards is too restrictive.

To resolve this single-device array addressability issue, this change makes it
explicit whether only addressable shards will be processed or all shards will
be processed in assembly/disassembly operations.

This change extends `Client::AssembleArrayFromSingleDeviceArray` and
`Array::DisassembleIntoSingleDeviceArrays` methods to be able to handle
addressable shards only.

It will be done in subsequent changes to make the IFRT user code to request
only addressable devices.
",copybara-service[bot],2024-10-04 20:55:14+00:00,[],2024-10-16 18:48:21+00:00,2024-10-16 18:48:21+00:00,https://github.com/tensorflow/tensorflow/pull/77065,[],[],
2567343822,pull_request,closed,,Include tsl/platform/dso_loader.h instead of the alias header files in stream_executor to unbreak TF windows pip creation.,"Include tsl/platform/dso_loader.h instead of the alias header files in stream_executor to unbreak TF windows pip creation.
",copybara-service[bot],2024-10-04 20:50:53+00:00,[],2024-10-04 22:15:59+00:00,2024-10-04 22:15:58+00:00,https://github.com/tensorflow/tensorflow/pull/77064,[],[],
2567341287,pull_request,open,,Add per-tensor quantization into dynamic range quantization execution path for TRANSPOSE_CONV layer (https://github.com/tensorflow/tensorflow/issues/76624),"Add per-tensor quantization into dynamic range quantization execution path for TRANSPOSE_CONV layer (https://github.com/tensorflow/tensorflow/issues/76624)
",copybara-service[bot],2024-10-04 20:50:00+00:00,['LukeBoyer'],2024-10-04 21:08:28+00:00,,https://github.com/tensorflow/tensorflow/pull/77063,[],[],
2567318108,pull_request,closed,,Add support for mhlo.abs(complex) in tflite legalize hlo pass.,"Add support for mhlo.abs(complex) in tflite legalize hlo pass.
",copybara-service[bot],2024-10-04 20:40:30+00:00,['vamsimanchala'],2024-10-05 00:12:51+00:00,2024-10-05 00:12:50+00:00,https://github.com/tensorflow/tensorflow/pull/77062,[],[],
2567294385,pull_request,closed,,Reverts 08ec0d5d0579af7ddf4272aa609ae9f36c179530,"Reverts 08ec0d5d0579af7ddf4272aa609ae9f36c179530
",copybara-service[bot],2024-10-04 20:27:38+00:00,[],2024-10-04 22:40:06+00:00,2024-10-04 22:40:06+00:00,https://github.com/tensorflow/tensorflow/pull/77061,[],[],
2567281998,pull_request,closed,,Reformat the BUILD file,"Reformat the BUILD file
",copybara-service[bot],2024-10-04 20:20:52+00:00,['yijie-yang'],2024-10-04 21:48:49+00:00,2024-10-04 21:48:49+00:00,https://github.com/tensorflow/tensorflow/pull/77060,[],[],
2567280193,pull_request,closed,,XLA:FFI: Improve error message when the wrong number of attributes are passed.,"XLA:FFI: Improve error message when the wrong number of attributes are passed.

It probably improves the user experience if we report the names of the attributes that were passed when this check fails (see https://github.com/jax-ml/jax/issues/24131, for example). It might also be worth listing the names of the expected parameters, but I didn't include that here yet.
",copybara-service[bot],2024-10-04 20:20:14+00:00,[],2024-10-04 22:00:02+00:00,2024-10-04 22:00:01+00:00,https://github.com/tensorflow/tensorflow/pull/77059,[],[],
2567272506,pull_request,closed,,CC wrapper for lrt tensors and basic lrt -> qnn tensor mapping,"CC wrapper for lrt tensors and basic lrt -> qnn tensor mapping
",copybara-service[bot],2024-10-04 20:16:25+00:00,['LukeBoyer'],2024-10-04 21:17:51+00:00,2024-10-04 21:17:49+00:00,https://github.com/tensorflow/tensorflow/pull/77058,[],[],
2567241643,pull_request,closed,,[XLA] Delete unused code intended to handle auto layout in HLO.,"[XLA] Delete unused code intended to handle auto layout in HLO.

The code is related to frontend HLO attributes that were supposed to mirror MLIR attributes, but in the end they didn't end up being used and HLO paths (in places where AUTO layout is handled at all) use different method.

This is preparation for more changes that will fix AUTO layout handling in non-MLIR invocations of XLA.
",copybara-service[bot],2024-10-04 20:00:29+00:00,[],2024-10-07 08:16:32+00:00,2024-10-07 08:16:30+00:00,https://github.com/tensorflow/tensorflow/pull/77056,[],[],
2567230282,pull_request,closed,,Add mhlo.FftOp legalization pattern for MHLO to TFLite RFFT2dOp.,"Add mhlo.FftOp legalization pattern for MHLO to TFLite RFFT2dOp.
",copybara-service[bot],2024-10-04 19:54:30+00:00,['vamsimanchala'],2024-10-04 20:54:23+00:00,2024-10-04 20:54:22+00:00,https://github.com/tensorflow/tensorflow/pull/77055,[],[],
2567183629,pull_request,closed,,cleanup: remove api_version from BUILD files,"cleanup: remove api_version from BUILD files
",copybara-service[bot],2024-10-04 19:32:57+00:00,[],2024-10-04 20:27:25+00:00,2024-10-04 20:27:24+00:00,https://github.com/tensorflow/tensorflow/pull/77054,[],[],
2567180644,pull_request,closed,,Define and use is_cuda_nvcc,"Define and use is_cuda_nvcc

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/76831 from snadampal:compute_library_def_runtime_fix b3c62ba5777fb192ca612bca8c20fff9797f99b9
",copybara-service[bot],2024-10-04 19:31:28+00:00,[],2024-10-04 22:31:02+00:00,2024-10-04 22:31:02+00:00,https://github.com/tensorflow/tensorflow/pull/77053,[],[],
2567151133,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@44a9acf2,"Integrate StableHLO at openxla/stablehlo@44a9acf2
",copybara-service[bot],2024-10-04 19:19:15+00:00,[],2024-10-04 23:01:05+00:00,2024-10-04 23:01:04+00:00,https://github.com/tensorflow/tensorflow/pull/77052,[],[],
2567016924,pull_request,open,,Grant building Dockerfile Kokoro's job piper scm permission to the kokoro directory path for internal toolings usage. Also the build config directory is here so the job will need permission to read it.,"Grant building Dockerfile Kokoro's job piper scm permission to the kokoro directory path for internal toolings usage. Also the build config directory is here so the job will need permission to read it.
",copybara-service[bot],2024-10-04 18:19:38+00:00,['quoctruong'],2024-10-04 19:35:26+00:00,,https://github.com/tensorflow/tensorflow/pull/77051,[],[],
2566987928,pull_request,closed,,[XLA:GPU] Allow kSend and kRecv to have no users if they are the root of a computation.,"[XLA:GPU] Allow kSend and kRecv to have no users if they are the root of a computation.
",copybara-service[bot],2024-10-04 18:06:10+00:00,[],2024-10-08 17:21:22+00:00,2024-10-08 17:21:22+00:00,https://github.com/tensorflow/tensorflow/pull/77050,[],[],
2566987459,pull_request,open,,Internal change only,"Internal change only

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/76831 from snadampal:compute_library_def_runtime_fix b3c62ba5777fb192ca612bca8c20fff9797f99b9
",copybara-service[bot],2024-10-04 18:06:00+00:00,[],2024-10-04 18:06:00+00:00,,https://github.com/tensorflow/tensorflow/pull/77049,[],[],
2566847364,pull_request,open,,Update copybara to handle gunit_no_google3 properly in problem dir.,"Update copybara to handle gunit_no_google3 properly in problem dir.
",copybara-service[bot],2024-10-04 17:14:09+00:00,['LukeBoyer'],2024-10-04 17:14:11+00:00,,https://github.com/tensorflow/tensorflow/pull/77047,[],[],
2566568955,pull_request,closed,,[XLA:GPU] Minor cleanup in select folder,"[XLA:GPU] Minor cleanup in select folder
",copybara-service[bot],2024-10-04 14:50:15+00:00,['frgossen'],2024-10-10 16:24:24+00:00,2024-10-10 16:24:23+00:00,https://github.com/tensorflow/tensorflow/pull/77046,[],[],
2566311543,pull_request,closed,,Include the input/output tensor variables to provide more information in the dimension mismatch error message,"Include the input/output tensor variables to provide more information in the dimension mismatch error message
",copybara-service[bot],2024-10-04 12:54:34+00:00,[],2024-10-07 16:51:51+00:00,2024-10-07 16:51:49+00:00,https://github.com/tensorflow/tensorflow/pull/77044,[],[],
2565991073,pull_request,closed,,PR #17173: [NVIDIA GPU] Optimize collective matmul loops when contracting dim is sharded,"PR #17173: [NVIDIA GPU] Optimize collective matmul loops when contracting dim is sharded

Imported from GitHub PR https://github.com/openxla/xla/pull/17173

When contracting dim is sharded, both LHS and RHS will be sharded and the partial dots' results will be accumulated. However the accumulation is done 1 step at a time which leads to a number of individual add kernels, these add kernels will impact overlap between gemms due to:
1. they each occupy SMs which prevent gemm overlap
2. they might be fused by gemm_rewriter which introduces data dependency between gemms

This pr optimizes it to get rid of partial accumulations, instead all partials will be concatenated into a contiguous buffer and a global reduction is applied on the buffer.
Copybara import of the project:

--
b90997cc33ca3b17ea8e7bbceefd6951a5f442be by TJ Xu <tjx@nvidia.com>:

Optimize allgather collective matmul loops when contracting dim is
sharded

--
a55b2f468d70623eaca90abb175c03d5c475dfd2 by TJ Xu <tjx@nvidia.com>:

Address pr comments

Merging this change closes #17173

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17173 from Tixxx:tixxx/cm_contracting a55b2f468d70623eaca90abb175c03d5c475dfd2
",copybara-service[bot],2024-10-04 10:06:00+00:00,[],2024-10-07 08:25:18+00:00,2024-10-07 08:25:17+00:00,https://github.com/tensorflow/tensorflow/pull/77043,[],[],
2565183933,pull_request,closed,,Divides the solver timeout budget equally across all mesh shapes & partial mesh shapes (instead of allowing each invocation to consume the full timeout budget).,"Divides the solver timeout budget equally across all mesh shapes & partial mesh shapes (instead of allowing each invocation to consume the full timeout budget).

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/76831 from snadampal:compute_library_def_runtime_fix b3c62ba5777fb192ca612bca8c20fff9797f99b9
",copybara-service[bot],2024-10-04 00:11:31+00:00,[],2024-10-04 20:00:14+00:00,2024-10-04 20:00:13+00:00,https://github.com/tensorflow/tensorflow/pull/77041,[],[],
2565172623,pull_request,open,,Remove unneeded dependencies on stream_executor/platform.,"Remove unneeded dependencies on stream_executor/platform.
",copybara-service[bot],2024-10-03 23:57:27+00:00,[],2024-10-03 23:57:27+00:00,,https://github.com/tensorflow/tensorflow/pull/77040,[],[],
2565157127,pull_request,closed,,Move to more constrained dependency in core/tpu/kernels targets.,"Move to more constrained dependency in core/tpu/kernels targets.
",copybara-service[bot],2024-10-03 23:36:57+00:00,[],2024-10-07 21:52:54+00:00,2024-10-07 21:52:52+00:00,https://github.com/tensorflow/tensorflow/pull/77039,[],[],
2565127728,pull_request,closed,,Refactored README for better organization and readability,,Varma0604,2024-10-03 22:58:52+00:00,['gbaned'],2024-10-04 13:29:01+00:00,2024-10-04 13:28:59+00:00,https://github.com/tensorflow/tensorflow/pull/77038,"[('size:L', 'CL Change Size: Large'), ('invalid', 'Hacktoberfest spam PR')]","[{'comment_id': 2392478915, 'issue_id': 2565127728, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77038/checks?check_run_id=31054863837) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 3, 22, 58, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392482718, 'issue_id': 2565127728, 'author': 'Varma0604', 'body': 'I have improved the README.md but have a few failed check could you please let me know how to bypass.', 'created_at': datetime.datetime(2024, 10, 3, 23, 2, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2392747994, 'issue_id': 2565127728, 'author': 'keerthanakadiri', 'body': 'Hi @Varma0604, Can you please sign CLA , thank you !', 'created_at': datetime.datetime(2024, 10, 4, 4, 5, 1, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-03 22:58:57 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/77038/checks?check_run_id=31054863837) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

Varma0604 (Issue Creator) on (2024-10-03 23:02:33 UTC): I have improved the README.md but have a few failed check could you please let me know how to bypass.

keerthanakadiri on (2024-10-04 04:05:01 UTC): Hi @Varma0604, Can you please sign CLA , thank you !

"
2565091905,pull_request,closed,,re-enabling some tests that had previously been failing,"re-enabling some tests that had previously been failing
",copybara-service[bot],2024-10-03 22:20:12+00:00,[],2024-10-07 18:21:33+00:00,2024-10-07 18:21:32+00:00,https://github.com/tensorflow/tensorflow/pull/77037,[],[],
2565087652,pull_request,open,,PR #17295: [ROCm] clang support,"PR #17295: [ROCm] clang support

Imported from GitHub PR https://github.com/openxla/xla/pull/17295

Brings up clang support for ROCm XLA. This is required to implement clang support for JAX+XLA for ROCm.

@draganmladjenovic @i-chaochen 
Copybara import of the project:

--
b0f316408f62052125973cfff6f9371a91e84464 by Ruturaj4 <ruturaj.vaidya@amd.com>:

[ROCm] clang support

Merging this change closes #17295

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17295 from ROCm:ci_rv_clang b0f316408f62052125973cfff6f9371a91e84464
",copybara-service[bot],2024-10-03 22:15:50+00:00,[],2024-10-03 22:15:50+00:00,,https://github.com/tensorflow/tensorflow/pull/77036,[],[],
2565053806,pull_request,open,,Add Open JDK to Dockerfile for ML Build container. This is needed for `code_check` build.,"Add Open JDK to Dockerfile for ML Build container. This is needed for `code_check` build.
",copybara-service[bot],2024-10-03 21:45:52+00:00,['quoctruong'],2024-10-03 21:45:54+00:00,,https://github.com/tensorflow/tensorflow/pull/77035,[],[],
2565050613,pull_request,closed,,Fix lint warnings.,"Fix lint warnings.
",copybara-service[bot],2024-10-03 21:43:19+00:00,[],2024-10-07 16:41:47+00:00,2024-10-07 16:41:47+00:00,https://github.com/tensorflow/tensorflow/pull/77034,[],[],
2565028659,pull_request,closed,,Expose stablehlo version through the PJRT C API.,"Expose stablehlo version through the PJRT C API.
",copybara-service[bot],2024-10-03 21:25:33+00:00,[],2024-10-07 17:57:27+00:00,2024-10-07 17:57:26+00:00,https://github.com/tensorflow/tensorflow/pull/77033,[],[],
2564993518,pull_request,closed,,Allow custom call computations to contain subcomputations,"Allow custom call computations to contain subcomputations
",copybara-service[bot],2024-10-03 20:59:25+00:00,[],2024-10-04 20:46:25+00:00,2024-10-04 20:46:24+00:00,https://github.com/tensorflow/tensorflow/pull/77032,[],[],
2564969878,pull_request,open,,PR #17173: [NVIDIA GPU] Optimize collective matmul loops when contracting dim is sharded,"PR #17173: [NVIDIA GPU] Optimize collective matmul loops when contracting dim is sharded

Imported from GitHub PR https://github.com/openxla/xla/pull/17173

When contracting dim is sharded, both LHS and RHS will be sharded and the partial dots' results will be accumulated. However the accumulation is done 1 step at a time which leads to a number of individual add kernels, these add kernels will impact overlap between gemms due to:
1. they each occupy SMs which prevent gemm overlap
2. they might be fused by gemm_rewriter which introduces data dependency between gemms

This pr optimizes it to get rid of partial accumulations, instead all partials will be concatenated into a contiguous buffer and a global reduction is applied on the buffer.
Copybara import of the project:

--
b90997cc33ca3b17ea8e7bbceefd6951a5f442be by TJ Xu <tjx@nvidia.com>:

Optimize allgather collective matmul loops when contracting dim is
sharded

--
a55b2f468d70623eaca90abb175c03d5c475dfd2 by TJ Xu <tjx@nvidia.com>:

Address pr comments

Merging this change closes #17173

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17173 from Tixxx:tixxx/cm_contracting a55b2f468d70623eaca90abb175c03d5c475dfd2
",copybara-service[bot],2024-10-03 20:43:09+00:00,[],2024-10-03 21:57:34+00:00,,https://github.com/tensorflow/tensorflow/pull/77031,[],[],
2564957856,pull_request,closed,,Pass down device_type in tf2xla api fallback path,"Pass down device_type in tf2xla api fallback path
",copybara-service[bot],2024-10-03 20:35:43+00:00,[],2024-10-07 23:01:11+00:00,2024-10-07 23:01:11+00:00,https://github.com/tensorflow/tensorflow/pull/77030,[],[],
2564918060,pull_request,closed,,Skip pipelining optimizations when a while loop has one or fewer iterations.,"Skip pipelining optimizations when a while loop has one or fewer iterations.
",copybara-service[bot],2024-10-03 20:09:33+00:00,['SandSnip3r'],2024-10-08 21:44:57+00:00,2024-10-08 21:44:57+00:00,https://github.com/tensorflow/tensorflow/pull/77029,[],[],
2564874757,pull_request,closed,,Introduce a more fine-grained target for stream_executor/platform/initialize.h.,"Introduce a more fine-grained target for stream_executor/platform/initialize.h.
",copybara-service[bot],2024-10-03 19:42:09+00:00,[],2024-10-04 23:17:58+00:00,2024-10-04 23:17:57+00:00,https://github.com/tensorflow/tensorflow/pull/77028,[],[],
2564865979,pull_request,open,,Split GpuCommandBuffer into a CUDA and a ROCm specific version,"Split GpuCommandBuffer into a CUDA and a ROCm specific version
",copybara-service[bot],2024-10-03 19:37:01+00:00,[],2024-10-03 22:41:17+00:00,,https://github.com/tensorflow/tensorflow/pull/77027,[],[],
2564857437,pull_request,open,,"Add an algebraic simplification pattern for multiply(add(conv(input, filter), bias), broadcast(constant)) -> add(conv(input, multiply(filter, broadcast(constant))), multiply(bias, broadcast(constant)))","Add an algebraic simplification pattern for multiply(add(conv(input, filter), bias), broadcast(constant)) -> add(conv(input, multiply(filter, broadcast(constant))), multiply(bias, broadcast(constant)))
",copybara-service[bot],2024-10-03 19:31:57+00:00,[],2024-10-03 19:31:57+00:00,,https://github.com/tensorflow/tensorflow/pull/77026,[],[],
2564792651,pull_request,closed,,Update version numbers for TensorFlow 2.18.0-rc1,"Before merging this PR, please double check that it has correctly updated
`core/public/version.h`, `tools/pip_package/setup.py`, and
`tensorflow/tensorflow.bzl`. Also review the execution notes below:

```
Major: 2 -> 2
Minor: 18 -> 18
Patch: 0 -> 0

No lingering old version strings ""2.18.0-rc0"" found in source directory 
""tensorflow/"". Good.
No lingering old version strings ""2.18.0rc0"" found in source directory 
""tensorflow/"". Good.
```",tensorflow-jenkins,2024-10-03 18:56:15+00:00,[],2024-10-03 20:49:39+00:00,2024-10-03 20:49:39+00:00,https://github.com/tensorflow/tensorflow/pull/77025,[],[],
2564789097,pull_request,closed,,"If the auto-sharding pass cannot find a solution for any of the mesh shapes tried, return an error message listing the errors encountered for each of the mesh shapes. This is intended to make debugging easier.","If the auto-sharding pass cannot find a solution for any of the mesh shapes tried, return an error message listing the errors encountered for each of the mesh shapes. This is intended to make debugging easier.

Reverts 343058c782ebe85b30c2b46e70d471febcbca8cf
",copybara-service[bot],2024-10-03 18:54:33+00:00,[],2024-10-04 21:26:10+00:00,2024-10-04 21:26:09+00:00,https://github.com/tensorflow/tensorflow/pull/77024,[],[],
2564724073,pull_request,closed,,Bump ml_dtypes commit hash to match TensorFlow's and XLA's.,"Bump ml_dtypes commit hash to match TensorFlow's and XLA's.

The commit hash is now 6f02f77c4fa624d8b467c36d1d959a9b49b07900, matching what is in TF at https://github.com/tensorflow/tensorflow/blob/master/third_party/py/ml_dtypes/workspace.bzl

This fixes a breakage caused by https://github.com/openxla/xla/pull/16585
",copybara-service[bot],2024-10-03 18:30:04+00:00,['reedwm'],2024-10-03 22:06:06+00:00,2024-10-03 22:06:04+00:00,https://github.com/tensorflow/tensorflow/pull/77023,[],[],
2564699624,pull_request,closed,,[XLA:GPU] Fix `GpuFloatSupport` for reductions.,"[XLA:GPU] Fix `GpuFloatSupport` for reductions.

Presumably, we can lower a reduction computation without normalizing it if
all the instructions in the reducer are supported.
",copybara-service[bot],2024-10-03 18:16:55+00:00,[],2024-10-04 20:20:28+00:00,2024-10-04 20:20:27+00:00,https://github.com/tensorflow/tensorflow/pull/77022,[],[],
2564634122,pull_request,closed,,"Host Offloading: Process ""MoveToHost"" instructions in the order they are executed.","Host Offloading: Process ""MoveToHost"" instructions in the order they are executed.

- This ensures we process ""MoveToHost"" instructions that reside at the beginning of a host memory instruction offload chain.
- This avoids processing MoveToHost instructions out of order, creating invalid instructions within a host memory instruction offload chain.
",copybara-service[bot],2024-10-03 17:39:48+00:00,[],2024-10-04 22:08:09+00:00,2024-10-04 22:08:08+00:00,https://github.com/tensorflow/tensorflow/pull/77021,[],[],
2564438608,pull_request,closed,,Abandons Auto Sharding if any partial mesh shape results in a suboptimal solution.,"Abandons Auto Sharding if any partial mesh shape results in a suboptimal solution.
",copybara-service[bot],2024-10-03 16:11:00+00:00,[],2024-10-03 17:08:53+00:00,2024-10-03 17:08:53+00:00,https://github.com/tensorflow/tensorflow/pull/77020,[],[],
2564375707,pull_request,open,,[TEST] Debug linking of mlir_fusion_opt,"[TEST] Debug linking of mlir_fusion_opt

For whatever reason it somestimes can't find cudnn. Let's find out why.
",copybara-service[bot],2024-10-03 15:38:55+00:00,[],2024-10-03 15:38:55+00:00,,https://github.com/tensorflow/tensorflow/pull/77019,[],[],
2564330331,pull_request,closed,,fix integer overflow in range,"Fixes #64081 

I modified the fix from the rolled back PR #76252 to check that the value of the unsigned size does not exceed the max value of the `int64_t` data type before casting it back to the signed type.",mattbahr,2024-10-03 15:17:00+00:00,['gbaned'],2024-10-15 00:49:00+00:00,2024-10-14 22:08:36+00:00,https://github.com/tensorflow/tensorflow/pull/77018,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:M', 'CL Change Size: Medium'), ('comp:core', 'issues related to core part of tensorflow')]","[{'comment_id': 2407449857, 'issue_id': 2564330331, 'author': 'mattbahr', 'body': '@mihaimaruseac Would you be ok with reviewing this since you were on the review for the original pull request?', 'created_at': datetime.datetime(2024, 10, 11, 13, 44, 56, tzinfo=datetime.timezone.utc)}, {'comment_id': 2408297592, 'issue_id': 2564330331, 'author': 'mattbahr', 'body': 'My initial approach testing for the failure case from the python ops was failing so I moved that test case over to the kernel tests. Tests are passing for me now.', 'created_at': datetime.datetime(2024, 10, 12, 1, 52, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412081872, 'issue_id': 2564330331, 'author': 'mattbahr', 'body': ""@mihaimaruseac @gbaned Is there anything holding up this PR internally? It looks like the change was imported successfully, but the feedback check hasn't run"", 'created_at': datetime.datetime(2024, 10, 14, 19, 46, 57, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412410932, 'issue_id': 2564330331, 'author': 'mihaimaruseac', 'body': 'It was blocked on an internal presubmit check, but it should get merged soon', 'created_at': datetime.datetime(2024, 10, 14, 22, 3, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412560383, 'issue_id': 2564330331, 'author': 'mihaimaruseac', 'body': ""This will get rolled back again. It still fails further down the line:\r\n\r\n```\r\nDetails\r\ntensorflow/core/kernels/ragged_range_op.cc: runtime error: signed integer overflow: -713794229 + -1849827689 cannot be represented in type 'int'\r\n    #0 0x55aa58fee7ba in tensorflow::RaggedRangeOp<int, long>::Compute(tensorflow::OpKernelContext*)\r\n    #1 0x55aa6e363e5c in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) \r\n...\r\n```\r\n\r\nIt's a test compiled with ASAN."", 'created_at': datetime.datetime(2024, 10, 15, 0, 7, 38, tzinfo=datetime.timezone.utc)}, {'comment_id': 2412599830, 'issue_id': 2564330331, 'author': 'mattbahr', 'body': ""Wow, ok if I have time this week, I'll see if I can get the tests compiling with ASAN on my system. Thanks for the info! And thanks for the review!"", 'created_at': datetime.datetime(2024, 10, 15, 0, 48, 58, tzinfo=datetime.timezone.utc)}]","mattbahr (Issue Creator) on (2024-10-11 13:44:56 UTC): @mihaimaruseac Would you be ok with reviewing this since you were on the review for the original pull request?

mattbahr (Issue Creator) on (2024-10-12 01:52:02 UTC): My initial approach testing for the failure case from the python ops was failing so I moved that test case over to the kernel tests. Tests are passing for me now.

mattbahr (Issue Creator) on (2024-10-14 19:46:57 UTC): @mihaimaruseac @gbaned Is there anything holding up this PR internally? It looks like the change was imported successfully, but the feedback check hasn't run

mihaimaruseac on (2024-10-14 22:03:12 UTC): It was blocked on an internal presubmit check, but it should get merged soon

mihaimaruseac on (2024-10-15 00:07:38 UTC): This will get rolled back again. It still fails further down the line:

```
Details
tensorflow/core/kernels/ragged_range_op.cc: runtime error: signed integer overflow: -713794229 + -1849827689 cannot be represented in type 'int'
    #0 0x55aa58fee7ba in tensorflow::RaggedRangeOp<int, long>::Compute(tensorflow::OpKernelContext*)
    #1 0x55aa6e363e5c in tensorflow::ThreadPoolDevice::Compute(tensorflow::OpKernel*, tensorflow::OpKernelContext*) 
...
```

It's a test compiled with ASAN.

mattbahr (Issue Creator) on (2024-10-15 00:48:58 UTC): Wow, ok if I have time this week, I'll see if I can get the tests compiling with ASAN on my system. Thanks for the info! And thanks for the review!

"
2564307991,pull_request,open,,Reverts 1ccfa5b8235b7a2b1cf6fe928504c5700931928d,"Reverts 1ccfa5b8235b7a2b1cf6fe928504c5700931928d
",copybara-service[bot],2024-10-03 15:06:47+00:00,[],2024-10-03 15:06:47+00:00,,https://github.com/tensorflow/tensorflow/pull/77017,[],[],
2564209001,pull_request,closed,,Reverts 8ae2f6513871e733949e9d613d67cc8a13c82f7f,"Reverts 8ae2f6513871e733949e9d613d67cc8a13c82f7f
",copybara-service[bot],2024-10-03 14:26:29+00:00,[],2024-10-03 14:59:39+00:00,2024-10-03 14:59:38+00:00,https://github.com/tensorflow/tensorflow/pull/77015,[],[],
2564132422,pull_request,closed,,[XLA:GPU] Move (gated) call to `FusionBlockLevelRewriter` after all possible,"[XLA:GPU] Move (gated) call to `FusionBlockLevelRewriter` after all possible
fusion passes are done.
",copybara-service[bot],2024-10-03 13:53:21+00:00,[],2024-10-03 17:45:33+00:00,2024-10-03 17:45:32+00:00,https://github.com/tensorflow/tensorflow/pull/77014,[],[],
2564004301,pull_request,closed,,PR #17819: Added use_enabled_free_threading flag to build nanobind with NB_FREE_THREADED=1,"PR #17819: Added use_enabled_free_threading flag to build nanobind with NB_FREE_THREADED=1

Imported from GitHub PR https://github.com/openxla/xla/pull/17819

Description:
- Added use_enabled_free_threading flag to build nanobind with NB_FREE_THREADED=1 
- Set nanobind version to tag v2.2.0: https://github.com/wjakob/nanobind/releases/tag/v2.2.0

Build command:
```bash
./configure.py --backend=CPU

bazel build --test_output=all --spawn_strategy=sandboxed --define=use_enabled_free_threading=true //xla/...
```

Copybara import of the project:

--
4af21a32cd2e7f57849665fddd137c300afc78b2 by vfdev-5 <vfdev.5@gmail.com>:

Added use_enabled_free_threading flag to build nanobind with NB_FREE_THREADED=1
Set nanobind version to tag v2.2.0

Merging this change closes #17819

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17819 from vfdev-5:use-latest-nanobind 4af21a32cd2e7f57849665fddd137c300afc78b2
",copybara-service[bot],2024-10-03 12:59:36+00:00,[],2024-10-07 20:57:23+00:00,2024-10-07 20:57:22+00:00,https://github.com/tensorflow/tensorflow/pull/77013,[],[],
2563997149,pull_request,closed,,#sdy add JAX Shardy support for memories.,"#sdy add JAX Shardy support for memories.
",copybara-service[bot],2024-10-03 12:56:19+00:00,[],2024-10-11 17:19:15+00:00,2024-10-11 17:19:14+00:00,https://github.com/tensorflow/tensorflow/pull/77012,[],[],
2563689717,pull_request,closed,,[XLA:GPU][Cleanup] Remove pre-Ampere paths in GEMM fusion autotuner.,"[XLA:GPU][Cleanup] Remove pre-Ampere paths in GEMM fusion autotuner.

These paths are dead, given that GEMM fusions are gated on the compute
capability being at least Ampere.

Fix includes as a side cleanup.
",copybara-service[bot],2024-10-03 10:30:39+00:00,[],2024-10-03 16:28:54+00:00,2024-10-03 16:28:52+00:00,https://github.com/tensorflow/tensorflow/pull/77011,[],[],
2563526579,pull_request,open,,Update GraphDef version to 2004.,"Update GraphDef version to 2004.
",copybara-service[bot],2024-10-03 09:13:53+00:00,[],2024-10-03 09:13:53+00:00,,https://github.com/tensorflow/tensorflow/pull/77010,[],[],
2563492198,pull_request,closed,,Integrate LLVM at llvm/llvm-project@00128a20eec2,"Integrate LLVM at llvm/llvm-project@00128a20eec2

Updates LLVM usage to match
[00128a20eec2](https://github.com/llvm/llvm-project/commit/00128a20eec2)
",copybara-service[bot],2024-10-03 08:57:11+00:00,[],2024-10-03 10:46:13+00:00,2024-10-03 10:46:12+00:00,https://github.com/tensorflow/tensorflow/pull/77009,[],[],
2563219848,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-03 06:22:16+00:00,[],2024-10-03 06:22:16+00:00,,https://github.com/tensorflow/tensorflow/pull/77008,[],[],
2563215798,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-03 06:19:03+00:00,[],2024-10-03 06:19:03+00:00,,https://github.com/tensorflow/tensorflow/pull/77007,[],[],
2563157907,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-03 05:29:58+00:00,[],2024-10-03 05:29:58+00:00,,https://github.com/tensorflow/tensorflow/pull/77006,[],[],
2563049669,pull_request,closed,,Add dso_loader as dependency to gpu_runtime_impl,"Add dso_loader as dependency to gpu_runtime_impl

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/76831 from snadampal:compute_library_def_runtime_fix b3c62ba5777fb192ca612bca8c20fff9797f99b9
",copybara-service[bot],2024-10-03 03:37:32+00:00,[],2024-10-04 20:10:16+00:00,2024-10-04 20:10:15+00:00,https://github.com/tensorflow/tensorflow/pull/77005,[],[],
2563041455,pull_request,closed,,Fix nextafter for FP8 FNUZ types.,"Fix nextafter for FP8 FNUZ types.

Before, it would return NaN if calling nextafter(negative_value_closest_to_zero, 1).
",copybara-service[bot],2024-10-03 03:31:04+00:00,['reedwm'],2024-10-04 21:03:25+00:00,2024-10-04 21:03:24+00:00,https://github.com/tensorflow/tensorflow/pull/77004,[],[],
2562995040,pull_request,closed,,[HLO Componentization] Create hlo/parser sub-component (Phase II).,"[HLO Componentization] Create hlo/parser sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/service --> xla/hlo/parser

Phase I takes care of
1. Migrating xla/service --> xla/hlo/parser
2. Setting up build aliases in xla/service ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-03 02:48:05+00:00,['sdasgup3'],2024-10-07 07:17:02+00:00,2024-10-07 07:17:01+00:00,https://github.com/tensorflow/tensorflow/pull/77003,[],[],
2562985166,pull_request,closed,,Avoid acquiring BufferSequencingEvent::mu_ twice in the case where the thread_pool executes the callbacks inline.,"Avoid acquiring BufferSequencingEvent::mu_ twice in the case where the thread_pool executes the callbacks inline.
",copybara-service[bot],2024-10-03 02:35:23+00:00,[],2024-10-03 04:23:18+00:00,2024-10-03 04:23:18+00:00,https://github.com/tensorflow/tensorflow/pull/77002,[],[],
2562971115,pull_request,closed,,Add Stat type for Source Stack to show in trace viewer,"Add Stat type for Source Stack to show in trace viewer

Reverts 0927f90ce5d3c7a5dc26ee464ff86dbbd76e758d
",copybara-service[bot],2024-10-03 02:17:20+00:00,[],2024-10-05 00:50:45+00:00,2024-10-05 00:50:44+00:00,https://github.com/tensorflow/tensorflow/pull/77001,[],[],
2562969990,pull_request,closed,,[HLO Componentization] Create hlo/tools sub-component (Phase I).,"[HLO Componentization] Create hlo/tools sub-component (Phase I).
This CL takes care of
1. Migrating xla/tools --> xla/hlo/tools
2. As there are no header or target dependencies of these tools, no aliases are setup.

Phase II will take care of migration of external projects dependencies from  xla/tools --> xla/hlo/tools
",copybara-service[bot],2024-10-03 02:15:45+00:00,['sdasgup3'],2024-10-03 19:37:34+00:00,2024-10-03 19:37:33+00:00,https://github.com/tensorflow/tensorflow/pull/77000,[],[],
2562949148,pull_request,closed,,PR #17453: Reorder Collective Optimization Passes,"PR #17453: Reorder Collective Optimization Passes

Imported from GitHub PR https://github.com/openxla/xla/pull/17453

Moves the collective quantizer pass ahead of the collective pipeliner to preserve FP8 quantization and dequantization patterns preceded or followed by collectives without running the collective pipeliner post layout assignment. See #12866 and #15292.
Copybara import of the project:

--
d8e8f6349595c80b097840baa1e7076609fbd441 by Philipp Hack <phack@nvidia.com>:

Moves the collective quantizer pass before the collective pipeliner.

--
b34f2030368f4f52137d88e6cae262a203320612 by Philipp Hack <phack@nvidia.com>:

Moves the collective quantizer pass before the collective pipeliner.


Merging this change closes #17453

Reverts 0927f90ce5d3c7a5dc26ee464ff86dbbd76e758d

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17453 from philipphack:u_collective_passes_xla b34f2030368f4f52137d88e6cae262a203320612
",copybara-service[bot],2024-10-03 01:49:11+00:00,[],2024-10-05 00:44:08+00:00,2024-10-05 00:44:06+00:00,https://github.com/tensorflow/tensorflow/pull/76999,[],[],
2562922875,pull_request,closed,,Remove unneeded dso_loader dependencies.,"Remove unneeded dso_loader dependencies.
",copybara-service[bot],2024-10-03 01:15:30+00:00,[],2024-10-03 01:41:17+00:00,2024-10-03 01:41:16+00:00,https://github.com/tensorflow/tensorflow/pull/76998,[],[],
2562914508,pull_request,closed,,Remove unneeded dso_loader dependency.,"Remove unneeded dso_loader dependency.
",copybara-service[bot],2024-10-03 01:04:17+00:00,[],2024-10-03 17:34:46+00:00,2024-10-03 17:34:45+00:00,https://github.com/tensorflow/tensorflow/pull/76997,[],[],
2562912536,pull_request,closed,,Remove unneeded dso_loader dep.,"Remove unneeded dso_loader dep.
",copybara-service[bot],2024-10-03 01:01:45+00:00,[],2024-10-03 03:56:33+00:00,2024-10-03 03:56:32+00:00,https://github.com/tensorflow/tensorflow/pull/76996,[],[],
2562909547,pull_request,closed,,Remove unneeded dso_loader.h header file inclusion.,"Remove unneeded dso_loader.h header file inclusion.
",copybara-service[bot],2024-10-03 00:57:47+00:00,[],2024-10-03 03:42:18+00:00,2024-10-03 03:42:18+00:00,https://github.com/tensorflow/tensorflow/pull/76995,[],[],
2562837733,pull_request,closed,,Remove unneeded stream_executor/platform/dso_loader.h.,"Remove unneeded stream_executor/platform/dso_loader.h.
",copybara-service[bot],2024-10-02 23:55:59+00:00,[],2024-10-03 00:53:05+00:00,2024-10-03 00:53:04+00:00,https://github.com/tensorflow/tensorflow/pull/76994,[],[],
2562812297,pull_request,closed,,sanity check of max_pool_v2 input argument.,"sanity check of max_pool_v2 input argument.
",copybara-service[bot],2024-10-02 23:24:57+00:00,['trisolaran'],2024-10-07 23:23:36+00:00,2024-10-07 23:23:35+00:00,https://github.com/tensorflow/tensorflow/pull/76993,[],[],
2562787399,pull_request,closed,,The original change broke the tensorflow build so is being reverted.,"The original change broke the tensorflow build so is being reverted.

Reverts 54fc2d6278a5d697418f3e9e88d5aed81a704cd1
",copybara-service[bot],2024-10-02 23:05:03+00:00,[],2024-10-02 23:49:34+00:00,2024-10-02 23:49:32+00:00,https://github.com/tensorflow/tensorflow/pull/76992,[],[],
2562716174,pull_request,closed,,"r2.18 cherry-pick: 4e9171c74a5 ""Enable Runtime Uptime Telemetry in TensorFlow-2.18.0.""",Refer to the original commit: https://github.com/tensorflow/tensorflow/commit/4e9171c74a58f2cbd8bc565f47b0e570ae2f218d,tensorflow-jenkins,2024-10-02 22:10:29+00:00,[],2024-10-02 22:46:52+00:00,2024-10-02 22:46:50+00:00,https://github.com/tensorflow/tensorflow/pull/76991,[],[],
2562708127,pull_request,closed,,Give `absl_error_model_builder` public visibility,"Give `absl_error_model_builder` public visibility
",copybara-service[bot],2024-10-02 22:02:52+00:00,['yijie-yang'],2024-10-04 23:35:35+00:00,2024-10-04 23:35:34+00:00,https://github.com/tensorflow/tensorflow/pull/76990,[],[],
2562638817,pull_request,closed,,[XLA:GPU] Fix comments in collective select folder,"[XLA:GPU] Fix comments in collective select folder
",copybara-service[bot],2024-10-02 21:05:34+00:00,['frgossen'],2024-10-03 20:25:19+00:00,2024-10-03 20:25:18+00:00,https://github.com/tensorflow/tensorflow/pull/76989,[],[],
2562542521,pull_request,closed,,OUT1,,lkeff,2024-10-02 20:06:48+00:00,['gbaned'],2024-10-03 13:03:29+00:00,2024-10-03 13:01:21+00:00,https://github.com/tensorflow/tensorflow/pull/76988,"[('size:M', 'CL Change Size: Medium'), ('invalid', 'Hacktoberfest spam PR'), ('docker', 'Pull requests that update Docker code')]","[{'comment_id': 2389581553, 'issue_id': 2562542521, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/76988/checks?check_run_id=30992870787) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 2, 20, 6, 53, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-02 20:06:53 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/76988/checks?check_run_id=30992870787) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2562525414,pull_request,closed,,PR #74090: Removing distutils leftover,"PR #74090: Removing distutils leftover

Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/74090

This aims to finish #58073. The patch is untested but follow https://setuptools.pypa.io/en/latest/deprecated/distutils-legacy.html.
I did not touch the install scripts.

Thanks,
Copybara import of the project:

--
fe3c0659eb168dc155f7d579255953dfc89b1387 by Alexis Praga <alexis.praga@gmail.com>:

Removing distutils leftover

--
57c24de0b367dd3ba78211f08ef4397014cff48f by Alexis Praga <alexis.praga@gmail.com>:

Fix linter error

--
9476971caa2e5805cecdfcad9b0f5a7f0e331d9e by Alexis Praga <alexis.praga@gmail.com>:

Correcting import order for linter

Shutil mainly

--
d74adacac6e544d75b6446d5565ec85bb4f25b6f by Alexis Praga <alexis.praga@gmail.com>:

Fix conflict between sysconfig

__init__py has :
  from tensorflow._api.v2 import sysconfig
which conflict with python sysconfig


Merging this change closes #74090

Reverts changelist a CL rolling back a previous version of this PR

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/74090 from apraga:no-distutil 52909d48fece0dec3c6b2e4b3673443bd83d46e3
",copybara-service[bot],2024-10-02 19:55:53+00:00,[],2024-10-02 22:16:14+00:00,2024-10-02 22:16:13+00:00,https://github.com/tensorflow/tensorflow/pull/76987,[],[],
2562484802,pull_request,closed,,Add missing cuda-only tags to stream_executor/cuda targets,"Add missing cuda-only tags to stream_executor/cuda targets
",copybara-service[bot],2024-10-02 19:29:44+00:00,[],2024-10-02 22:24:30+00:00,2024-10-02 22:24:29+00:00,https://github.com/tensorflow/tensorflow/pull/76986,[],[],
2562453029,pull_request,open,,PR #17858: [ROCm] Fix build brake caused by missing dso_loader.h includes,"PR #17858: [ROCm] Fix build brake caused by missing dso_loader.h includes

Imported from GitHub PR https://github.com/openxla/xla/pull/17858

The issue was introduced here -> https://github.com/openxla/xla/commit/b30b420510a89caa6ce9ae12c16add7e416e9034#diff-923ec2612240244a60ae28c17f798a7daeccbab84a8e9de9efd7ba96c311c763L115
Some of the ROCm files need `dso_loader.h`.
Copybara import of the project:

--
38531050acc09a96cef2423694f9e106611aaac0 by Milica Makevic <Milica.Makevic@amd.com>:

Return dso_loader.h includes for ROCm

Merging this change closes #17858

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17858 from ROCm:ci_hotfix_241002 38531050acc09a96cef2423694f9e106611aaac0
",copybara-service[bot],2024-10-02 19:09:49+00:00,[],2024-10-02 20:52:59+00:00,,https://github.com/tensorflow/tensorflow/pull/76985,[],[],
2562452778,pull_request,closed,,"Remove AutoShardingResult in favor of a boolean now that the value kModuleUnchangedNoShardingPerformed of the enum is unused, effectively making it a boolean. Also simplified away some dead code.","Remove AutoShardingResult in favor of a boolean now that the value kModuleUnchangedNoShardingPerformed of the enum is unused, effectively making it a boolean. Also simplified away some dead code.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16585 from apivovarov:float8_e4m3 ec1c723027012a816d7e17f268c5f034863696e6
",copybara-service[bot],2024-10-02 19:09:41+00:00,[],2024-10-02 21:25:33+00:00,2024-10-02 21:25:32+00:00,https://github.com/tensorflow/tensorflow/pull/76984,[],[],
2562449719,pull_request,open,,Integrate LLVM at llvm/llvm-project@485237413577,"Integrate LLVM at llvm/llvm-project@485237413577

Updates LLVM usage to match
[485237413577](https://github.com/llvm/llvm-project/commit/485237413577)
",copybara-service[bot],2024-10-02 19:07:44+00:00,[],2024-10-03 01:04:04+00:00,,https://github.com/tensorflow/tensorflow/pull/76983,[],[],
2562442743,pull_request,closed,,Migrate ConvertFunctionToMlir to established API to decouple from GraphDefImporter.,"Migrate ConvertFunctionToMlir to established API to decouple from GraphDefImporter.

Under the hood GraphDefImporter::Convert is called in the same fashion and no additional code is called so functionality is unchanged.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17776 from dimvar:dv-relax-precision-cudnn-test 9776386a2fd1b00f15ef1e1d518ce72f7fc2f4fe
",copybara-service[bot],2024-10-02 19:03:32+00:00,['rocketas'],2024-10-02 20:00:29+00:00,2024-10-02 20:00:28+00:00,https://github.com/tensorflow/tensorflow/pull/76982,[],[],
2562437718,pull_request,open,,Clear caches on jax exit.,"Clear caches on jax exit.
",copybara-service[bot],2024-10-02 19:00:20+00:00,['BrianWieder'],2024-10-02 19:00:21+00:00,,https://github.com/tensorflow/tensorflow/pull/76981,[],[],
2562436857,pull_request,closed,,[XLA:GPU] Remove the now obsolete `--xla_gpu_enable_triton_hopper` flag.,"[XLA:GPU] Remove the now obsolete `--xla_gpu_enable_triton_hopper` flag.

MMA_V3 has been enabled by default, and this only gated varying the number
of CTAs when autotuning matrix multiplications at this point.

This also fixes a bug where the number of CTAs was not being autotuned when
using exhaustive tiling.
",copybara-service[bot],2024-10-02 18:59:46+00:00,[],2024-10-03 15:09:05+00:00,2024-10-03 15:09:03+00:00,https://github.com/tensorflow/tensorflow/pull/76980,[],[],
2562432826,pull_request,open,,Internal change: fix non-copyable object from TF_ASSIGN_OR_RETURN,"Internal change: fix non-copyable object from TF_ASSIGN_OR_RETURN
",copybara-service[bot],2024-10-02 18:57:23+00:00,[],2024-10-02 19:48:03+00:00,,https://github.com/tensorflow/tensorflow/pull/76979,[],[],
2562419660,pull_request,open,,[XLA:SPMD] Propagate shardings backward along explicit batch dims in gather/scatter instructions.,"[XLA:SPMD] Propagate shardings backward along explicit batch dims in gather/scatter instructions.

We modify `GatherOperandShardingFromOutputParallelDimensions` and `ScatterUpdateShardingFromOutputParallelDimensions` to propagate shardings along the explicit batch dims in the backward direction (result -> operands).
",copybara-service[bot],2024-10-02 18:49:10+00:00,['frgossen'],2024-10-02 19:34:40+00:00,,https://github.com/tensorflow/tensorflow/pull/76978,[],[],
2562406820,pull_request,closed,,Add support for odml.update_external_kv_cache composite op in StableHLO to TFLite legalization.,"Add support for odml.update_external_kv_cache composite op in StableHLO to TFLite legalization.
",copybara-service[bot],2024-10-02 18:42:31+00:00,['hheydary'],2024-10-02 22:32:18+00:00,2024-10-02 22:32:17+00:00,https://github.com/tensorflow/tensorflow/pull/76977,[],[],
2562334810,pull_request,closed,,[XLA] Fix typos in comments and clean up includes in HloRematerialization.,"[XLA] Fix typos in comments and clean up includes in HloRematerialization.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17430 from ROCm:ci_use_shared_ptr_20240920 80eb83068d89982a743a69f83af9f351d6a829d6
",copybara-service[bot],2024-10-02 18:08:54+00:00,[],2024-10-02 21:33:43+00:00,2024-10-02 21:33:42+00:00,https://github.com/tensorflow/tensorflow/pull/76975,[],[],
2562295385,pull_request,closed,,Make rocm files use tsl DsoLoader functions instead of the stream_executor wrappers.,"Make rocm files use tsl DsoLoader functions instead of the stream_executor wrappers.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17430 from ROCm:ci_use_shared_ptr_20240920 80eb83068d89982a743a69f83af9f351d6a829d6
",copybara-service[bot],2024-10-02 17:51:57+00:00,[],2024-10-02 21:43:06+00:00,2024-10-02 21:43:05+00:00,https://github.com/tensorflow/tensorflow/pull/76974,[],[],
2562277048,pull_request,open,,Always use provided tmpdir if specified by user,"Always use provided tmpdir if specified by user
",copybara-service[bot],2024-10-02 17:40:25+00:00,[],2024-10-02 17:40:25+00:00,,https://github.com/tensorflow/tensorflow/pull/76973,[],[],
2562235009,pull_request,closed,,Simplify error handling in auto-sharding.,"Simplify error handling in auto-sharding.
",copybara-service[bot],2024-10-02 17:17:58+00:00,[],2024-10-02 20:49:42+00:00,2024-10-02 20:49:41+00:00,https://github.com/tensorflow/tensorflow/pull/76972,[],[],
2562222013,pull_request,open,,Integrate LLVM at llvm/llvm-project@6292f117c39b,"Integrate LLVM at llvm/llvm-project@6292f117c39b

Updates LLVM usage to match
[6292f117c39b](https://github.com/llvm/llvm-project/commit/6292f117c39b)
",copybara-service[bot],2024-10-02 17:09:59+00:00,[],2024-10-02 17:09:59+00:00,,https://github.com/tensorflow/tensorflow/pull/76971,[],[],
2562218209,pull_request,open,,[TFLite] Add feature to access `tflite::LoggerOptions` from C API,"# Overview

Issue: https://github.com/tensorflow/tensorflow/issues/74882

This PR will provide C API with a more detailed or suppressed way of logging by adding feature to access `tflite::LoggerOptions` from C API.

Here is [the code](https://gist.github.com/kokeshing/3ad87c17f0291811a3b6eb7d25c6678e) to verify the working of this PR.

# Changes

- Added `TfLiteLogSeverity` enum corresponding to `tflite::LogSeverity` enum
- Added binding functions for `tflite::LoggerOptions::GetMinimumLogSeverity()` and `tflite::LoggerOptions::SetMinimumLogSeverity()`
- Reflect in build config to explicitly use newly included files
- Added unit test

# Review points

- New APIs are implemented in the C experimental API since `tflite::LoggerOptions` is described as an experimental API in [logger.h](https://github.com/tensorflow/tensorflow/blob/67e9c596f345c27a47936a5492bf32115ebaefcb/tensorflow/lite/logger.h#L21).
- I could not use the `tflite::LogSeverity` enum definition directly because logger.h is a C++ header, so I had to define a new corresponding `TfLiteLogSeverity` enum in c_api_experimental.h.
  - To prevent the two definitions from mismatching, I added `LINT.IfChange` like the [`TfLiteType`](https://github.com/tensorflow/tensorflow/blob/67e9c596f345c27a47936a5492bf32115ebaefcb/tensorflow/lite/core/c/c_api_types.h#L123).
  - Like other C APIs, I named constants in the enum like constant names (e.g., kFooBar). However, constants in `tflite::LogSeverity` are named like macro (e.g., FOO_BAR).
- Is testing required? I added a test as well as [minimal_logging_test.cc](https://github.com/tensorflow/tensorflow/blob/67e9c596f345c27a47936a5492bf32115ebaefcb/tensorflow/lite/minimal_logging_test.cc#L63), but often there are no tests for other functions that just call the C++ API. 
- There is a part in [c_api_experimental_test.cc](https://github.com/tensorflow/tensorflow/blob/c30560b5bf0878ade38d6b3ae68b5c9d9436a33f/tensorflow/lite/core/c/c_api_experimental_test.cc) that is changed by clang-format, so I have applied it only to the part I implemented in this PR.

",kokeshing,2024-10-02 17:07:38+00:00,['gbaned'],2025-01-16 06:07:53+00:00,,https://github.com/tensorflow/tensorflow/pull/76970,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('size:M', 'CL Change Size: Medium')]","[{'comment_id': 2399046293, 'issue_id': 2562218209, 'author': 'keerthanakadiri', 'body': 'Hi @yishuangP, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 8, 7, 21, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431067608, 'issue_id': 2562218209, 'author': 'keerthanakadiri', 'body': 'Hi @yishuangP, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 23, 6, 50, 49, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469810686, 'issue_id': 2562218209, 'author': 'keerthanakadiri', 'body': 'Hi @kokeshing, Can you please resolve the conflicts? Thank you!', 'created_at': datetime.datetime(2024, 11, 12, 7, 45, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2470944731, 'issue_id': 2562218209, 'author': 'kokeshing', 'body': 'Hi @keerthanakadiri, I addressed the conflicts.\r\nIt has been confirmed that it works and passes the test again. Thank you!', 'created_at': datetime.datetime(2024, 11, 12, 16, 9, 42, tzinfo=datetime.timezone.utc)}, {'comment_id': 2562427662, 'issue_id': 2562218209, 'author': 'keerthanakadiri', 'body': 'Hi @haozha111, Could you please review this PR ? Thank you .', 'created_at': datetime.datetime(2024, 12, 26, 10, 43, 26, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-10-08 07:21:49 UTC): Hi @yishuangP, Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-23 06:50:49 UTC): Hi @yishuangP, Can you please review this PR? Thank you !

keerthanakadiri on (2024-11-12 07:45:24 UTC): Hi @kokeshing, Can you please resolve the conflicts? Thank you!

kokeshing (Issue Creator) on (2024-11-12 16:09:42 UTC): Hi @keerthanakadiri, I addressed the conflicts.
It has been confirmed that it works and passes the test again. Thank you!

keerthanakadiri on (2024-12-26 10:43:26 UTC): Hi @haozha111, Could you please review this PR ? Thank you .

"
2562194532,pull_request,open,,Fix the output range of the logistic op for 16x8 quantization mode,"The 16x8-quantized logistic op supports only symmetric quantization.

It's basically the same as 825fb23d5951d5713a072cbb94467e813c35e6b6, but for the logistic op.",tagunil,2024-10-02 16:57:35+00:00,['gbaned'],2025-01-16 06:09:28+00:00,,https://github.com/tensorflow/tensorflow/pull/76969,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('size:S', 'CL Change Size: Small')]","[{'comment_id': 2399507888, 'issue_id': 2562194532, 'author': 'keerthanakadiri', 'body': 'Hi @yishuangP, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 8, 10, 48, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413341247, 'issue_id': 2562194532, 'author': 'keerthanakadiri', 'body': 'Hi @yishuangP, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 15, 9, 15, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431068682, 'issue_id': 2562194532, 'author': 'keerthanakadiri', 'body': 'Hi @yishuangP, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 23, 6, 51, 32, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469814506, 'issue_id': 2562194532, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov ,Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 11, 12, 7, 47, 46, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-10-08 10:48:23 UTC): Hi @yishuangP, Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-15 09:15:33 UTC): Hi @yishuangP, Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-23 06:51:32 UTC): Hi @yishuangP, Can you please review this PR? Thank you !

keerthanakadiri on (2024-11-12 07:47:46 UTC): Hi @rdzhabarov ,Can you please review this PR? Thank you !

"
2562172659,pull_request,closed,,[XLA:Python] Fix more bugs in the weakref_lru_cache implementation.,"[XLA:Python] Fix more bugs in the weakref_lru_cache implementation.

a) MSVC's std::unordered_map says behavior is undefined if the hash function throws an exception (https://learn.microsoft.com/en-us/cpp/standard-library/unordered-map-class?view=msvc-170#emplace). That's easy to work around, though: we can just precompute all the hash functions.
b) my idiom for avoiding heterogenous lookups had a use after free problem: the weakref callback is called after the object is already in an invalid state. However, there's a much simpler solution: just create the weakref object and use it as a key unconditionally. Yes, this will mean we create more weak references than perhaps we had to otherwise. But this is simple and obviously correct.
",copybara-service[bot],2024-10-02 16:48:36+00:00,[],2024-10-02 18:47:33+00:00,2024-10-02 18:47:33+00:00,https://github.com/tensorflow/tensorflow/pull/76968,[],[],
2562169279,pull_request,closed,,Support non-hex byte representations for tfl.custom's custom_option field.,"Support non-hex byte representations for tfl.custom's custom_option field.

This only addresses parsing. Printing will continue to output in hex format.
Allowing non-hex representation removes a pain point associated with
hand-writing MLIR graphs with custom ops.
",copybara-service[bot],2024-10-02 16:47:08+00:00,['arfaian'],2024-10-07 17:28:53+00:00,2024-10-07 17:28:52+00:00,https://github.com/tensorflow/tensorflow/pull/76967,[],[],
2561997919,pull_request,closed,,"Add envvar **MLIR_BRIDGE_LOG_ENABLE_ONLY_TOP_LEVEL_PASSES**, which only logs passes that are only applied towards top-level operations (i.e., operations with no parent), unless explicitly disabled. This is to reduce the amount of MLIR-based TF2XLA bridge dumps during training jobs.","Add envvar **MLIR_BRIDGE_LOG_ENABLE_ONLY_TOP_LEVEL_PASSES**, which only logs passes that are only applied towards top-level operations (i.e., operations with no parent), unless explicitly disabled. This is to reduce the amount of MLIR-based TF2XLA bridge dumps during training jobs.
",copybara-service[bot],2024-10-02 15:22:44+00:00,[],2024-10-10 00:07:45+00:00,2024-10-10 00:07:43+00:00,https://github.com/tensorflow/tensorflow/pull/76966,[],[],
2561850360,pull_request,closed,,Associates names with individual input sharding combinations (rather than strategies).,"Associates names with individual input sharding combinations (rather than strategies).
",copybara-service[bot],2024-10-02 14:32:42+00:00,[],2024-10-02 23:58:39+00:00,2024-10-02 23:58:39+00:00,https://github.com/tensorflow/tensorflow/pull/76965,[],[],
2561786987,pull_request,closed,,[XLA:CPU] Return error when trying to create a view of an unaligned buffer.,"[XLA:CPU] Return error when trying to create a view of an unaligned buffer.
",copybara-service[bot],2024-10-02 14:05:31+00:00,[],2024-10-07 08:48:53+00:00,2024-10-07 08:48:52+00:00,https://github.com/tensorflow/tensorflow/pull/76964,[],"[{'comment_id': 2388735805, 'issue_id': 2561786987, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/76964/checks?check_run_id=30974792464) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 10, 2, 14, 5, 36, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-10-02 14:05:36 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/76964/checks?check_run_id=30974792464) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2561733965,pull_request,closed,,Integrate LLVM at llvm/llvm-project@6292f117c39b,"Integrate LLVM at llvm/llvm-project@6292f117c39b

Updates LLVM usage to match
[6292f117c39b](https://github.com/llvm/llvm-project/commit/6292f117c39b)
",copybara-service[bot],2024-10-02 13:42:41+00:00,[],2024-10-02 17:08:15+00:00,2024-10-02 17:08:14+00:00,https://github.com/tensorflow/tensorflow/pull/76963,[],[],
2561649501,pull_request,open,,Integrate LLVM at llvm/llvm-project@6292f117c39b,"Integrate LLVM at llvm/llvm-project@6292f117c39b

Updates LLVM usage to match
[6292f117c39b](https://github.com/llvm/llvm-project/commit/6292f117c39b)
",copybara-service[bot],2024-10-02 13:16:59+00:00,[],2024-10-02 13:16:59+00:00,,https://github.com/tensorflow/tensorflow/pull/76962,[],[],
2561529964,pull_request,closed,,Delete xla_client.execute_with_python_values.,"Delete xla_client.execute_with_python_values.

This is not a public API and exists only for testing.
",copybara-service[bot],2024-10-02 12:42:36+00:00,[],2024-10-02 15:11:18+00:00,2024-10-02 15:11:16+00:00,https://github.com/tensorflow/tensorflow/pull/76959,[],[],
2561518313,pull_request,closed,,Reverts d4c44d1167482ce853571af04119e806220df591,"Reverts d4c44d1167482ce853571af04119e806220df591
",copybara-service[bot],2024-10-02 12:38:28+00:00,[],2024-10-03 23:51:17+00:00,2024-10-03 23:51:15+00:00,https://github.com/tensorflow/tensorflow/pull/76958,[],[],
2561350453,pull_request,closed,,PR #17776: Relax the error tolerance of UnaryElementwiseTest.ElementwiseFusionExecutesCorrectly,"PR #17776: Relax the error tolerance of UnaryElementwiseTest.ElementwiseFusionExecutesCorrectly

Imported from GitHub PR https://github.com/openxla/xla/pull/17776

To avoid errors like the following on Blackwell:

Value of: RunAndCompare(hlo_test, ErrorSpec{ tolerance, tolerance})
Actual: false (
Mismatch count 199 (19.4336%) in shape f32[32,32] (1024 elements), abs bound 0.0005, rel bound 0.0005
Top relative error mismatches:
  actual             1.43806803, expected             1.43928146, index {8,13}, rel error 0.000843, abs error  0.00121
  actual              1.4577775, expected             1.45898616, index {8,0}, rel error 0.000828, abs error  0.00121
  actual             1.42510152, expected             1.42622399, index {8,20}, rel error 0.000787, abs error  0.00112
  actual             1.31515145, expected             1.31618464, index {22,13}, rel error 0.000785, abs error  0.00103
  actual             1.22491062, expected             1.22583544, index {5,27}, rel error 0.000754, abs error 0.000925
  
Copybara import of the project:

--
9776386a2fd1b00f15ef1e1d518ce72f7fc2f4fe by Dimitris Vardoulakis <dvardoulakis@nvidia.com>:

Relax the error tolerance of UnaryElementwiseTest.ElementwiseFusionExecutesCorrectly

Merging this change closes #17776

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17776 from dimvar:dv-relax-precision-cudnn-test 9776386a2fd1b00f15ef1e1d518ce72f7fc2f4fe
",copybara-service[bot],2024-10-02 11:38:14+00:00,[],2024-10-02 19:24:03+00:00,2024-10-02 19:24:02+00:00,https://github.com/tensorflow/tensorflow/pull/76956,[],[],
2561339553,pull_request,open,,Add null pointer check for an output tensor calibration,"Otherwise it segfaults while trying to log the WHILE op.

It's the simplest possible fix for #75140. I believe that it makes sense to fix the crash now, and look for the proper way to fix the calibration logic later.",tagunil,2024-10-02 11:33:43+00:00,['gbaned'],2025-01-16 06:10:51+00:00,,https://github.com/tensorflow/tensorflow/pull/76955,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('size:XS', 'CL Change Size: Extra Small'), ('prtype:bugfix', 'PR to fix a bug')]","[{'comment_id': 2399510011, 'issue_id': 2561339553, 'author': 'keerthanakadiri', 'body': 'Hi @yishuangP, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 8, 10, 49, 29, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413351125, 'issue_id': 2561339553, 'author': 'keerthanakadiri', 'body': 'Hi @yishuangP, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 15, 9, 19, 18, tzinfo=datetime.timezone.utc)}, {'comment_id': 2469817585, 'issue_id': 2561339553, 'author': 'keerthanakadiri', 'body': 'Hi @majiddadashi, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 11, 12, 7, 49, 45, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-10-08 10:49:29 UTC): Hi @yishuangP, Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-15 09:19:18 UTC): Hi @yishuangP, Can you please review this PR? Thank you !

keerthanakadiri on (2024-11-12 07:49:45 UTC): Hi @majiddadashi, Can you please review this PR? Thank you !

"
2561294313,pull_request,closed,,"[XLA:GPU] Unify DimVar, RangeVar and RTVar.","[XLA:GPU] Unify DimVar, RangeVar and RTVar.
",copybara-service[bot],2024-10-02 11:15:59+00:00,['pifon2a'],2024-10-02 14:26:22+00:00,2024-10-02 14:26:21+00:00,https://github.com/tensorflow/tensorflow/pull/76954,[],[],
2561147559,pull_request,open,,[XLA:GPU][Emitters] Remove name from comparison operator for DimVar/RangeVar/RTVar.,"[XLA:GPU][Emitters] Remove name from comparison operator for DimVar/RangeVar/RTVar.
",copybara-service[bot],2024-10-02 09:59:20+00:00,['pifon2a'],2024-10-02 09:59:21+00:00,,https://github.com/tensorflow/tensorflow/pull/76953,[],[],
2561018128,pull_request,closed,,Update visibility of the BUILD target,"Update visibility of the BUILD target

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17776 from dimvar:dv-relax-precision-cudnn-test 9776386a2fd1b00f15ef1e1d518ce72f7fc2f4fe
",copybara-service[bot],2024-10-02 09:00:47+00:00,[],2024-10-02 20:55:46+00:00,2024-10-02 20:55:45+00:00,https://github.com/tensorflow/tensorflow/pull/76952,[],[],
2560959934,pull_request,closed,,[XLA:GPU][Emitters] Remove comparison operator for DimVar/RangeVar/RTVar.,"[XLA:GPU][Emitters] Remove comparison operator for DimVar/RangeVar/RTVar.
",copybara-service[bot],2024-10-02 08:29:01+00:00,['pifon2a'],2024-10-02 09:58:08+00:00,2024-10-02 09:58:07+00:00,https://github.com/tensorflow/tensorflow/pull/76951,[],[],
2560947917,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 08:24:13+00:00,[],2024-10-02 08:24:13+00:00,,https://github.com/tensorflow/tensorflow/pull/76950,[],[],
2560843915,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:25:45+00:00,['sdasgup3'],2024-10-14 02:42:17+00:00,2024-10-14 02:42:16+00:00,https://github.com/tensorflow/tensorflow/pull/76949,[],[],
2560842502,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:24:49+00:00,['sdasgup3'],2024-10-14 20:35:34+00:00,2024-10-14 20:35:34+00:00,https://github.com/tensorflow/tensorflow/pull/76948,[],[],
2560837400,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:21:25+00:00,['sdasgup3'],2024-10-03 18:23:34+00:00,2024-10-03 18:23:32+00:00,https://github.com/tensorflow/tensorflow/pull/76947,[],[],
2560835393,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:20:04+00:00,['sdasgup3'],2024-10-03 14:08:38+00:00,2024-10-03 14:08:38+00:00,https://github.com/tensorflow/tensorflow/pull/76946,[],[],
2560834682,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:19:36+00:00,['sdasgup3'],2024-10-03 14:18:29+00:00,2024-10-03 14:18:27+00:00,https://github.com/tensorflow/tensorflow/pull/76945,[],[],
2560833616,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:18:54+00:00,['sdasgup3'],2024-10-03 18:34:56+00:00,2024-10-03 18:34:55+00:00,https://github.com/tensorflow/tensorflow/pull/76944,[],[],
2560833552,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:18:52+00:00,['sdasgup3'],2024-10-04 23:51:00+00:00,2024-10-04 23:50:58+00:00,https://github.com/tensorflow/tensorflow/pull/76943,[],[],
2560828387,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:15:23+00:00,['sdasgup3'],2024-10-05 02:33:21+00:00,2024-10-05 02:33:20+00:00,https://github.com/tensorflow/tensorflow/pull/76942,[],[],
2560827632,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-02 07:14:52+00:00,['sdasgup3'],2024-10-02 17:40:07+00:00,2024-10-02 17:40:06+00:00,https://github.com/tensorflow/tensorflow/pull/76941,[],[],
2560797491,pull_request,closed,,Rename static tensor weights from LrtBuffer to LrtWeights,"Rename static tensor weights from LrtBuffer to LrtWeights

This is because we'll be using LrtBuffer or LrtTensorBuffer for the dynamic
buffer associated with a runtime tensor
",copybara-service[bot],2024-10-02 06:54:38+00:00,[],2024-10-03 20:41:22+00:00,2024-10-03 20:41:22+00:00,https://github.com/tensorflow/tensorflow/pull/76940,[],[],
2560774309,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 06:38:54+00:00,[],2024-10-02 06:38:54+00:00,,https://github.com/tensorflow/tensorflow/pull/76939,[],[],
2560767484,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 06:33:00+00:00,[],2024-10-02 06:33:00+00:00,,https://github.com/tensorflow/tensorflow/pull/76938,[],[],
2560719384,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:47:29+00:00,[],2024-10-02 05:47:29+00:00,,https://github.com/tensorflow/tensorflow/pull/76937,[],[],
2560719155,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:47:16+00:00,[],2024-10-02 05:47:16+00:00,,https://github.com/tensorflow/tensorflow/pull/76936,[],[],
2560717543,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:45:34+00:00,[],2024-10-02 05:45:34+00:00,,https://github.com/tensorflow/tensorflow/pull/76935,[],[],
2560717095,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:45:06+00:00,[],2024-10-02 05:45:06+00:00,,https://github.com/tensorflow/tensorflow/pull/76934,[],[],
2560716324,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:44:18+00:00,[],2024-10-02 05:44:18+00:00,,https://github.com/tensorflow/tensorflow/pull/76933,[],[],
2560716258,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:44:15+00:00,[],2024-10-08 03:54:56+00:00,2024-10-08 03:54:55+00:00,https://github.com/tensorflow/tensorflow/pull/76932,[],[],
2560715996,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:43:59+00:00,[],2024-10-02 05:43:59+00:00,,https://github.com/tensorflow/tensorflow/pull/76931,[],[],
2560715378,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:43:19+00:00,[],2024-10-02 05:43:19+00:00,,https://github.com/tensorflow/tensorflow/pull/76930,[],[],
2560714760,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:42:38+00:00,[],2024-10-07 02:21:30+00:00,,https://github.com/tensorflow/tensorflow/pull/76929,[],[],
2560692340,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:17:25+00:00,[],2024-10-03 05:23:18+00:00,2024-10-03 05:23:18+00:00,https://github.com/tensorflow/tensorflow/pull/76928,[],[],
2560691256,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 05:16:10+00:00,[],2024-10-02 05:16:10+00:00,,https://github.com/tensorflow/tensorflow/pull/76927,[],[],
2560633978,pull_request,closed,,Adds num_features to SparsecoreLayoutProto.,"Adds num_features to SparsecoreLayoutProto.
",copybara-service[bot],2024-10-02 04:08:06+00:00,[],2024-10-02 13:42:48+00:00,2024-10-02 13:42:47+00:00,https://github.com/tensorflow/tensorflow/pull/76926,[],[],
2560607495,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-02 03:35:37+00:00,[],2024-10-02 03:35:37+00:00,,https://github.com/tensorflow/tensorflow/pull/76925,[],[],
2560596246,pull_request,closed,,Clean-up. Remove unused argument from `InferGatherScatterParallelShardingFromOperandSharding`.,"Clean-up. Remove unused argument from `InferGatherScatterParallelShardingFromOperandSharding`.
",copybara-service[bot],2024-10-02 03:20:44+00:00,[],2024-10-02 21:57:45+00:00,2024-10-02 21:57:44+00:00,https://github.com/tensorflow/tensorflow/pull/76924,[],[],
2560578760,pull_request,closed,,[JAX] Add PyClient::GetAllDevices() and expose it as a private JAX backend API,"[JAX] Add PyClient::GetAllDevices() and expose it as a private JAX backend API

JAX backend forwards `xla::ifrt::Client::GetAllDevices()` to
`xla::PyClient::GetAllDevices()`, which is accessible via JAX
`backend._get_all_devices()`. This API is a transitional private backend API
that is used for building an experimental API (finding colocated CPU devices)
and should not be used by any other code.
",copybara-service[bot],2024-10-02 02:59:40+00:00,[],2024-10-08 18:37:30+00:00,2024-10-08 18:37:29+00:00,https://github.com/tensorflow/tensorflow/pull/76923,[],[],
2560577429,pull_request,closed,,[XLA:SPMD] Propagate shardings backward along explicit batch dims in gather/scatter instructions.,"[XLA:SPMD] Propagate shardings backward along explicit batch dims in gather/scatter instructions.

We modify `GatherOperandShardingFromOutputParallelDimensions` and `ScatterUpdateShardingFromOutputParallelDimensions` to propagate shardings along the explicit batch dims in the backward direction (result -> operands).
",copybara-service[bot],2024-10-02 02:57:59+00:00,[],2024-10-02 19:36:36+00:00,2024-10-02 19:36:35+00:00,https://github.com/tensorflow/tensorflow/pull/76922,[],[],
2560536333,pull_request,closed,,"If all inputs are identical, use Identity instead of IdentityN.","If all inputs are identical, use Identity instead of IdentityN.
",copybara-service[bot],2024-10-02 02:10:09+00:00,[],2024-10-03 00:40:11+00:00,2024-10-03 00:40:10+00:00,https://github.com/tensorflow/tensorflow/pull/76921,[],[],
2560435927,pull_request,open,,Integrate LLVM at llvm/llvm-project@a5cd5d351ddb,"Integrate LLVM at llvm/llvm-project@a5cd5d351ddb

Updates LLVM usage to match
[a5cd5d351ddb](https://github.com/llvm/llvm-project/commit/a5cd5d351ddb)
",copybara-service[bot],2024-10-02 00:35:01+00:00,[],2024-10-02 00:35:01+00:00,,https://github.com/tensorflow/tensorflow/pull/76920,[],[],
2560391548,pull_request,closed,,Fix an IFRT Proxy version compatibility bug introduced by `ExecuteOptions::fill_status`,"Fix an IFRT Proxy version compatibility bug introduced by `ExecuteOptions::fill_status`

Since `fill_status` was implicitly true before the field was introduced, we should have overridden the `fill_status` from the deserialized options. Without that, the client->server behaves incorrectly when the client is old (doesn't set `fill_status` but expects the future to be populated by the server) but the server is new (has `fill_status` in the proto and assumes that the client set it to false).
",copybara-service[bot],2024-10-01 23:42:35+00:00,[],2024-10-02 02:09:55+00:00,2024-10-02 02:09:54+00:00,https://github.com/tensorflow/tensorflow/pull/76919,[],[],
2560367489,pull_request,open,,[HLO Componentization] Create hlo/parser sub-component (Phase II).,"[HLO Componentization] Create hlo/parser sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/service --> xla/hlo/parser

Phase I takes care of
1. Migrating xla/service --> xla/hlo/parser
2. Setting up build aliases in xla/service ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-10-01 23:12:52+00:00,['sdasgup3'],2024-10-02 17:32:39+00:00,,https://github.com/tensorflow/tensorflow/pull/76918,[],[],
2560339551,pull_request,closed,,Algebraic simplifier: simplify exp(0) to 1.,"Algebraic simplifier: simplify exp(0) to 1.
",copybara-service[bot],2024-10-01 22:45:12+00:00,[],2024-10-09 00:48:56+00:00,2024-10-09 00:48:55+00:00,https://github.com/tensorflow/tensorflow/pull/76917,[],[],
2560330568,pull_request,closed,,PR #17828: Fix pylint C0301: Line too long in xla_client_test.py,"PR #17828: Fix pylint C0301: Line too long in xla_client_test.py

Imported from GitHub PR https://github.com/openxla/xla/pull/17828

Currently Tensorflow CI build (triggered by XLA copybara-service bot) fails with the following pylint errors:
```bash
************* Module python.xla_client_test
third_party/xla/xla/python/xla_client_test.py:3182:0: C0301: Line too long (99/80) (line-too-long)
third_party/xla/xla/python/xla_client_test.py:3185:0: C0301: Line too long (86/80) (line-too-long)
third_party/xla/xla/python/xla_client_test.py:3360:0: C0301: Line too long (87/80) (line-too-long)
```

links:
- https://github.com/tensorflow/tensorflow/commit/dd2c1e9d94cfe5c471b5788917a2f74140d9b144
- https://github.com/tensorflow/tensorflow/actions/runs/11130353052/job/30929504884

This PR fixes the issue
Copybara import of the project:

--
481b02de6385029dc9cf2ec4462791d3f18f3ac2 by Alexander Pivovarov <pivovaa@amazon.com>:

Fix pylint C0301: Line too long in xla_client_test.py

Merging this change closes #17828

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17828 from apivovarov:fix_pylint_xla_client_test.py 481b02de6385029dc9cf2ec4462791d3f18f3ac2
",copybara-service[bot],2024-10-01 22:36:04+00:00,[],2024-10-01 23:29:28+00:00,2024-10-01 23:29:27+00:00,https://github.com/tensorflow/tensorflow/pull/76916,[],[],
2560318456,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@f7f8e4e3,"Integrate StableHLO at openxla/stablehlo@f7f8e4e3

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17776 from dimvar:dv-relax-precision-cudnn-test 9776386a2fd1b00f15ef1e1d518ce72f7fc2f4fe
",copybara-service[bot],2024-10-01 22:24:26+00:00,[],2024-10-02 20:40:11+00:00,2024-10-02 20:40:10+00:00,https://github.com/tensorflow/tensorflow/pull/76915,[],[],
2560271591,pull_request,closed,,"Fix a bug in OverestimateReshardingCost, which failed to take into account the fact that a replicated strategy is also a ""tile maximal"" strategy.","Fix a bug in OverestimateReshardingCost, which failed to take into account the fact that a replicated strategy is also a ""tile maximal"" strategy.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17776 from dimvar:dv-relax-precision-cudnn-test 9776386a2fd1b00f15ef1e1d518ce72f7fc2f4fe
",copybara-service[bot],2024-10-01 21:49:29+00:00,[],2024-10-02 20:27:46+00:00,2024-10-02 20:27:45+00:00,https://github.com/tensorflow/tensorflow/pull/76914,"[('ready to pull', 'PR ready for merge process')]",[],
2560264070,pull_request,closed,,Use tsl DsoLoader functions instead of stream_executor aliases.,"Use tsl DsoLoader functions instead of stream_executor aliases.
",copybara-service[bot],2024-10-01 21:42:59+00:00,[],2024-10-02 16:54:31+00:00,2024-10-02 16:54:31+00:00,https://github.com/tensorflow/tensorflow/pull/76913,[],[],
2560259947,pull_request,closed,,[StableHLO] Pin StableHLOv0.19.0 for older PJRT plugins.,"[StableHLO] Pin StableHLOv0.19.0 for older PJRT plugins.

This is a temporary measure to allow plugins to update to latest jaxlib.
",copybara-service[bot],2024-10-01 21:39:28+00:00,['GleasonK'],2024-10-02 15:44:20+00:00,2024-10-02 15:44:19+00:00,https://github.com/tensorflow/tensorflow/pull/76912,[],[],
2560254290,pull_request,closed,,Use tsl DsoLoader function instead of stream_executor aliases.,"Use tsl DsoLoader function instead of stream_executor aliases.
",copybara-service[bot],2024-10-01 21:34:55+00:00,[],2024-10-01 22:44:30+00:00,2024-10-01 22:44:29+00:00,https://github.com/tensorflow/tensorflow/pull/76911,[],[],
2560241873,pull_request,closed,,Stop using stream_executor aliases to tsl DsoLoader functions.,"Stop using stream_executor aliases to tsl DsoLoader functions.
",copybara-service[bot],2024-10-01 21:25:33+00:00,[],2024-10-01 22:33:18+00:00,2024-10-01 22:33:17+00:00,https://github.com/tensorflow/tensorflow/pull/76910,[],[],
2560229675,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 21:16:16+00:00,[],2024-10-03 01:50:41+00:00,2024-10-03 01:50:40+00:00,https://github.com/tensorflow/tensorflow/pull/76909,[],[],
2560226294,pull_request,closed,,Remove unneeded dso_loader.h include from ROCM files.,"Remove unneeded dso_loader.h include from ROCM files.
",copybara-service[bot],2024-10-01 21:13:44+00:00,[],2024-10-01 22:27:11+00:00,2024-10-01 22:27:09+00:00,https://github.com/tensorflow/tensorflow/pull/76907,[],[],
2560178185,pull_request,closed,,Allow simple host call that uses host tensor as parameter/result in,"Allow simple host call that uses host tensor as parameter/result in
linear layout. This cl only handles very simple host call patterns.
A more thorough implementation of propagation of T(1)S(5) will be done
later.

This cl doesn't handle host call that passes/returns tensors that
live on device with linear layout either, which will also be impelmented
separately.
",copybara-service[bot],2024-10-01 20:44:16+00:00,[],2024-10-18 01:29:02+00:00,2024-10-18 01:29:01+00:00,https://github.com/tensorflow/tensorflow/pull/76906,[],[],
2560172691,pull_request,closed,,Remove unneeded stream_executor/platform/port.h inclusion.,"Remove unneeded stream_executor/platform/port.h inclusion.
",copybara-service[bot],2024-10-01 20:40:36+00:00,[],2024-10-02 18:32:45+00:00,2024-10-02 18:32:45+00:00,https://github.com/tensorflow/tensorflow/pull/76905,[],[],
2560161608,pull_request,closed,,Stop using unneeded stream_executor/platform/port.h header file & dependency.,"Stop using unneeded stream_executor/platform/port.h header file & dependency.
",copybara-service[bot],2024-10-01 20:33:49+00:00,[],2024-10-01 21:53:59+00:00,2024-10-01 21:53:58+00:00,https://github.com/tensorflow/tensorflow/pull/76904,[],[],
2560157491,pull_request,closed,,Stop using unneeded stream_executor/platform/port.h in stream_executor files.,"Stop using unneeded stream_executor/platform/port.h in stream_executor files.
",copybara-service[bot],2024-10-01 20:31:33+00:00,[],2024-10-03 05:58:40+00:00,2024-10-03 05:58:40+00:00,https://github.com/tensorflow/tensorflow/pull/76903,[],[],
2560090224,pull_request,closed,,Stop using SE_PREDICT_TRUE in favor of the ABSL variant.,"Stop using SE_PREDICT_TRUE in favor of the ABSL variant.
",copybara-service[bot],2024-10-01 19:54:25+00:00,[],2024-10-01 21:43:13+00:00,2024-10-01 21:43:12+00:00,https://github.com/tensorflow/tensorflow/pull/76902,[],[],
2560073420,pull_request,closed,,Use TF_PREDICT_TRUE in gpu_device_functions.h rather than the SE aliases.,"Use TF_PREDICT_TRUE in gpu_device_functions.h rather than the SE aliases.
",copybara-service[bot],2024-10-01 19:47:36+00:00,[],2024-10-01 22:08:35+00:00,2024-10-01 22:08:34+00:00,https://github.com/tensorflow/tensorflow/pull/76901,[],[],
2560067598,pull_request,open,,Simplify STREAM_EXECUTOR_REGISTER_MODULE_INITIALIZER support to be the same in all environments.,"Simplify STREAM_EXECUTOR_REGISTER_MODULE_INITIALIZER support to be the same in all environments.

Also removed some unneeded related macros.
",copybara-service[bot],2024-10-01 19:45:16+00:00,[],2024-10-01 19:45:16+00:00,,https://github.com/tensorflow/tensorflow/pull/76900,[],[],
2559968237,pull_request,closed,,Reverts 605c30f71ae57a7507570069c4a72ac0bc181e02,"Reverts 605c30f71ae57a7507570069c4a72ac0bc181e02
",copybara-service[bot],2024-10-01 18:54:50+00:00,[],2024-10-01 19:36:03+00:00,2024-10-01 19:36:02+00:00,https://github.com/tensorflow/tensorflow/pull/76899,[],[],
2559965544,pull_request,closed,,Use the XNNPack `static_reduce` operation to delegate SUM and MEAN.,"Use the XNNPack `static_reduce` operation to delegate SUM and MEAN.

- Update the XNNPack version.
- Create `VisitReduceNode` that implements generic delegation used in
  `VisitSumNode` and `VisitMeanNode`.
- Merge the tests for `mean` and `sum` into `reduce`.
- Merge non/signed/unsigned quantized tests.
",copybara-service[bot],2024-10-01 18:53:11+00:00,['qukhan'],2024-10-24 19:59:33+00:00,2024-10-24 19:59:32+00:00,https://github.com/tensorflow/tensorflow/pull/76898,[],[],
2559957063,pull_request,closed,,Update comments to reflect the renaming of original_value,"Update comments to reflect the renaming of original_value

This updates the comments to reflect the renaming of original_value attribute of HloInstruction to origin in cl/676573775.
",copybara-service[bot],2024-10-01 18:48:07+00:00,['jcai19'],2024-10-01 19:18:57+00:00,2024-10-01 19:18:56+00:00,https://github.com/tensorflow/tensorflow/pull/76897,[],[],
2559934832,pull_request,closed,,copy the legalize tf passes under lite/stablehlo,"copy the legalize tf passes under lite/stablehlo
",copybara-service[bot],2024-10-01 18:35:37+00:00,[],2024-10-03 17:22:21+00:00,2024-10-03 17:22:20+00:00,https://github.com/tensorflow/tensorflow/pull/76896,[],[],
2559886672,pull_request,closed,,[XLA_UNSTACKER] Fix a bug in xla unstacker which would triggered when there are multiple uses of unstackable operand at the loop root.,"[XLA_UNSTACKER] Fix a bug in xla unstacker which would triggered when there are multiple uses of unstackable operand at the loop root.
",copybara-service[bot],2024-10-01 18:07:58+00:00,[],2024-10-08 00:27:37+00:00,2024-10-08 00:27:37+00:00,https://github.com/tensorflow/tensorflow/pull/76895,[],[],
2559865388,pull_request,closed,,Don't generate Kotlin proto implementations for `:coordination_service` or `:protos_all`,"Don't generate Kotlin proto implementations for `:coordination_service` or `:protos_all`
",copybara-service[bot],2024-10-01 17:59:33+00:00,['ddunl'],2024-10-01 18:56:01+00:00,2024-10-01 18:56:00+00:00,https://github.com/tensorflow/tensorflow/pull/76894,[],[],
2559816200,pull_request,open,,Use RunAndCheckHloRewrite in collective_permute_cycle_decomposer_test.cc,"Use RunAndCheckHloRewrite in collective_permute_cycle_decomposer_test.cc
",copybara-service[bot],2024-10-01 17:30:44+00:00,[],2024-10-01 17:42:18+00:00,,https://github.com/tensorflow/tensorflow/pull/76893,"[('ready to pull', 'PR ready for merge process')]",[],
2559774081,pull_request,open,,[xla:gpu] Disable Conditions in cuda graphs by default,"[xla:gpu] Disable Conditions in cuda graphs by default

Reverts e081db68a13da5cb86b6bb14e5856866b45321f5
",copybara-service[bot],2024-10-01 17:04:30+00:00,[],2024-10-01 17:04:30+00:00,,https://github.com/tensorflow/tensorflow/pull/76892,[],[],
2559765875,pull_request,closed,,Use RunAndCheckHloRewrite in collective_select_folder_test.cc,"Use RunAndCheckHloRewrite in collective_select_folder_test.cc
",copybara-service[bot],2024-10-01 16:59:35+00:00,[],2024-10-03 19:48:37+00:00,2024-10-03 19:48:36+00:00,https://github.com/tensorflow/tensorflow/pull/76890,[],[],
2559723217,pull_request,closed,,Update no_nccl_support config_setting.,"Update no_nccl_support config_setting.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17776 from dimvar:dv-relax-precision-cudnn-test 9776386a2fd1b00f15ef1e1d518ce72f7fc2f4fe
",copybara-service[bot],2024-10-01 16:35:19+00:00,[],2024-10-02 21:02:04+00:00,2024-10-02 21:02:03+00:00,https://github.com/tensorflow/tensorflow/pull/76889,[],[],
2559722635,pull_request,closed,,[StableHLO] Improve the PJRT parsing error message to include StableHLO version and portable artifact version.,"[StableHLO] Improve the PJRT parsing error message to include StableHLO version and portable artifact version.

This uses a hypothetical ""future"" portable artifact, serialized targeting StableHLO v2.0.0 and using an op `vhlo.constant_v99`.

```
/tmp/t2.mlir:3:10: error: unregistered operation 'vhlo.constant_v99' found in dialect ('vhlo') that does not allow unknown operations
/tmp/t2.mlir:3:10: note: see current operation: %0 = ""vhlo.constant_v99""() <#vhlo.tensor_v1<dense<1.000000e+00> : tensor<f32>>> : () -> !vhlo.tensor_v1<!vhlo.f32_v1>
/tmp/t2.mlir:3:10: note: in bytecode version 6 produced by: StableHLO_v2.0.0
<unknown>:0: error: Failed to parse using StableHLO v1.7.5, this could indicate forward incompatibility, >12w old unsupported plugin, or a portable artifact that needs to be further downgraded.
```
",copybara-service[bot],2024-10-01 16:35:00+00:00,['GleasonK'],2024-10-01 19:29:05+00:00,2024-10-01 19:29:04+00:00,https://github.com/tensorflow/tensorflow/pull/76888,[],[],
2559666440,pull_request,closed,,Remove no_nccl_support build condition,"Remove no_nccl_support build condition
",copybara-service[bot],2024-10-01 16:05:01+00:00,[],2024-10-01 17:56:13+00:00,2024-10-01 17:56:12+00:00,https://github.com/tensorflow/tensorflow/pull/76887,[],[],
2559547121,pull_request,closed,,#sdy import `CallOp`s with `backend_configs` to `NamedComputationOp`s.,"#sdy import `CallOp`s with `backend_configs` to `NamedComputationOp`s.

Needed to make sure host callbacks in XLA aren't inlined but also propagated through.
",copybara-service[bot],2024-10-01 15:13:57+00:00,[],2024-10-07 16:21:41+00:00,2024-10-07 16:21:40+00:00,https://github.com/tensorflow/tensorflow/pull/76886,[],[],
2559541040,pull_request,closed,,#sdy export NamedComputationOps with backend_configs to CallOps.,"#sdy export NamedComputationOps with backend_configs to CallOps.

Needed to make sure host callbacks in XLA aren't inlined but also propagated through.
",copybara-service[bot],2024-10-01 15:12:04+00:00,[],2024-10-07 17:38:08+00:00,2024-10-07 17:17:10+00:00,https://github.com/tensorflow/tensorflow/pull/76885,[],[],
2559513720,pull_request,closed,,Integrate LLVM at llvm/llvm-project@bf25ecb6caff,"Integrate LLVM at llvm/llvm-project@bf25ecb6caff

Updates LLVM usage to match
[bf25ecb6caff](https://github.com/llvm/llvm-project/commit/bf25ecb6caff)
",copybara-service[bot],2024-10-01 15:04:26+00:00,[],2024-10-02 10:48:26+00:00,2024-10-02 10:48:26+00:00,https://github.com/tensorflow/tensorflow/pull/76884,[],[],
2559321498,pull_request,closed,,Add FP8 support to reverse_test,"Add FP8 support to reverse_test
",copybara-service[bot],2024-10-01 13:51:48+00:00,[],2024-10-02 01:44:36+00:00,2024-10-02 01:44:35+00:00,https://github.com/tensorflow/tensorflow/pull/76883,[],[],
2558996555,pull_request,closed,,[XLA:GPU] Fix left shift overflow in Triton.,"[XLA:GPU] Fix left shift overflow in Triton.

UBSan detected that the shift is happening on an int32 variable, but the shift amount could be larger than what int32 supports.
",copybara-service[bot],2024-10-01 11:50:58+00:00,[],2024-10-01 19:53:00+00:00,2024-10-01 19:52:59+00:00,https://github.com/tensorflow/tensorflow/pull/76882,[],[],
2558932560,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 11:20:36+00:00,[],2024-10-01 11:20:36+00:00,,https://github.com/tensorflow/tensorflow/pull/76881,[],[],
2558931188,pull_request,closed,,"[XLA:GPU] Forbid 0D tensors in the generic Triton emitter, except for special cases.","[XLA:GPU] Forbid 0D tensors in the generic Triton emitter, except for special cases.
",copybara-service[bot],2024-10-01 11:19:54+00:00,[],2024-10-03 13:31:43+00:00,2024-10-03 13:31:41+00:00,https://github.com/tensorflow/tensorflow/pull/76880,[],[],
2558759823,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17544 from ROCm:ci_pass_arch_to_crosstool_20240924 aba828b02a32aeca576086e8e41aa8b6f70e4f39
",copybara-service[bot],2024-10-01 10:00:52+00:00,[],2024-10-01 10:00:52+00:00,,https://github.com/tensorflow/tensorflow/pull/76879,[],[],
2558705392,pull_request,closed,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17544 from ROCm:ci_pass_arch_to_crosstool_20240924 aba828b02a32aeca576086e8e41aa8b6f70e4f39
",copybara-service[bot],2024-10-01 09:39:58+00:00,['sdasgup3'],2024-10-01 12:26:19+00:00,2024-10-01 12:26:18+00:00,https://github.com/tensorflow/tensorflow/pull/76878,[],[],
2558696716,pull_request,closed,,[XLA:GPU] Clean up symbol visibility in Triton Fusion emitter,"[XLA:GPU] Clean up symbol visibility in Triton Fusion emitter
",copybara-service[bot],2024-10-01 09:36:18+00:00,[],2024-10-02 14:09:12+00:00,2024-10-02 14:09:11+00:00,https://github.com/tensorflow/tensorflow/pull/76877,[],[],
2558638206,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17746 from emmanuel-ferdman:main 679a3871a7cfa10160a123fddded728fd6a61853
",copybara-service[bot],2024-10-01 09:11:02+00:00,[],2024-10-01 09:11:02+00:00,,https://github.com/tensorflow/tensorflow/pull/76876,[],[],
2558628863,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 09:06:49+00:00,[],2024-10-02 08:19:32+00:00,2024-10-02 08:19:31+00:00,https://github.com/tensorflow/tensorflow/pull/76875,[],[],
2558625758,pull_request,closed,,[XLA:GPU] Generalize the Reduce-Precision in MHLO to also work on Tensors and use it in a Triton emitter.,"[XLA:GPU] Generalize the Reduce-Precision in MHLO to also work on Tensors and use it in a Triton emitter.
",copybara-service[bot],2024-10-01 09:05:26+00:00,[],2024-10-02 09:37:28+00:00,2024-10-02 09:37:26+00:00,https://github.com/tensorflow/tensorflow/pull/76874,[],[],
2558611919,pull_request,closed,,PR #17754: [NFC] Extract common builder code into hlo_creation_utils,"PR #17754: [NFC] Extract common builder code into hlo_creation_utils

Imported from GitHub PR https://github.com/openxla/xla/pull/17754

Added `XlaComputationToHloComputation` helper function to `hlo_creation_utils` and replace the uses.

Copybara import of the project:

--
f9cbfd2cee78f6160eab9436121d4dfa2c89d168 by Sergey Kozub <skozub@nvidia.com>:

Extract common builder code into hlo_creation_utils

Merging this change closes #17754

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17754 from openxla:skozub/xla_builder f9cbfd2cee78f6160eab9436121d4dfa2c89d168
",copybara-service[bot],2024-10-01 08:59:07+00:00,[],2024-10-07 11:13:16+00:00,2024-10-07 11:13:15+00:00,https://github.com/tensorflow/tensorflow/pull/76873,[],[],
2558608711,pull_request,closed,,PR #17430: [ROCm] Use unique_ptr for TupleHandle in pjrt_se_client,"PR #17430: [ROCm] Use unique_ptr for TupleHandle in pjrt_se_client

Imported from GitHub PR https://github.com/openxla/xla/pull/17430

On older gcc (specifically in Ubuntu-20.04) and absl copy operator fails to copy created TupleHandle into an existing variable. Instead use unique_ptr to accompalish the same
Copybara import of the project:

--
80eb83068d89982a743a69f83af9f351d6a829d6 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Use unique_ptr for TupleHandle in pjrt_se_client

On older gcc (specifically in Ubuntu-20.04) and absl copy operator
fails to copy created TupleHandle into an existing variable.
Instead use unique_ptr to accompalish the same

Merging this change closes #17430

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17430 from ROCm:ci_use_shared_ptr_20240920 80eb83068d89982a743a69f83af9f351d6a829d6
",copybara-service[bot],2024-10-01 08:57:37+00:00,[],2024-10-02 21:11:44+00:00,2024-10-02 21:11:44+00:00,https://github.com/tensorflow/tensorflow/pull/76872,[],[],
2558598884,pull_request,closed,,Bump ubuntu from `8a37d68` to `dfc1087` in /tensorflow/tools/gcs_test,"Bumps ubuntu from `8a37d68` to `dfc1087`.


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ubuntu&package-manager=docker&previous-version=24.04&new-version=24.04)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2024-10-01 08:53:28+00:00,['gbaned'],2024-10-03 15:29:58+00:00,2024-10-03 15:29:57+00:00,https://github.com/tensorflow/tensorflow/pull/76871,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small'), ('dependencies', 'Pull requests that update a dependency file'), ('docker', 'Pull requests that update Docker code')]",[],
2558587093,pull_request,closed,,PR #17746: Update XlaBuilder reference,"PR #17746: Update XlaBuilder reference

Imported from GitHub PR https://github.com/openxla/xla/pull/17746

# PR Summary
PR #17622 moved the location of `xla_builder.cc`. This PR adjusts sources to changes.
Copybara import of the project:

--
679a3871a7cfa10160a123fddded728fd6a61853 by Emmanuel Ferdman <emmanuelferdman@gmail.com>:

Update XlaBuilder reference

Signed-off-by: Emmanuel Ferdman <emmanuelferdman@gmail.com>

Merging this change closes #17746

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17746 from emmanuel-ferdman:main 679a3871a7cfa10160a123fddded728fd6a61853
",copybara-service[bot],2024-10-01 08:49:39+00:00,[],2024-10-01 09:36:21+00:00,2024-10-01 09:36:20+00:00,https://github.com/tensorflow/tensorflow/pull/76870,[],[],
2558542509,pull_request,closed,,[XLA:GPU] Introduce the `FusionBlockLevelRewriter` pass.,"[XLA:GPU] Introduce the `FusionBlockLevelRewriter` pass.

This pass transforms every fusion it can into one that is block-level, and tile
parameters are derived using the indexing performance model.

The pass is off by default, and can be toggled on using the
`--xla_gpu_experimental_enable_fusion_block_level_rewriter` flag.
",copybara-service[bot],2024-10-01 08:31:35+00:00,[],2024-10-02 14:58:16+00:00,2024-10-02 14:58:15+00:00,https://github.com/tensorflow/tensorflow/pull/76869,[],[],
2558509735,pull_request,closed,,Bump ubuntu from `adbb901` to `58b8789` in /tensorflow/tools/tf_sig_build_dockerfiles,"Bumps ubuntu from `adbb901` to `58b8789`.


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=ubuntu&package-manager=docker&previous-version=22.04&new-version=22.04)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)


</details>",dependabot[bot],2024-10-01 08:16:35+00:00,['gbaned'],2024-10-03 15:56:14+00:00,2024-10-03 15:56:13+00:00,https://github.com/tensorflow/tensorflow/pull/76868,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small'), ('dependencies', 'Pull requests that update a dependency file'), ('docker', 'Pull requests that update Docker code')]",[],
2558501699,pull_request,closed,,Bump the github-actions group with 5 updates,"Bumps the github-actions group with 5 updates:

| Package | From | To |
| --- | --- | --- |
| [actions/checkout](https://github.com/actions/checkout) | `4.1.7` | `4.2.0` |
| [google/osv-scanner-action](https://github.com/google/osv-scanner-action) | `1.8.4` | `1.8.5` |
| [peter-evans/create-pull-request](https://github.com/peter-evans/create-pull-request) | `6.1.0` | `7.0.5` |
| [github/codeql-action](https://github.com/github/codeql-action) | `3.26.6` | `3.26.10` |
| [docker/build-push-action](https://github.com/docker/build-push-action) | `6.7.0` | `6.9.0` |

Updates `actions/checkout` from 4.1.7 to 4.2.0
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/actions/checkout/releases"">actions/checkout's releases</a>.</em></p>
<blockquote>
<h2>v4.2.0</h2>
<h2>What's Changed</h2>
<ul>
<li>Add Ref and Commit outputs by <a href=""https://github.com/lucacome""><code>@lucacome</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1180"">actions/checkout#1180</a></li>
<li>Dependabot updates in <a href=""https://redirect.github.com/actions/checkout/pull/1777"">actions/checkout#1777</a> &amp; <a href=""https://redirect.github.com/actions/checkout/pull/1872"">actions/checkout#1872</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/yasonk""><code>@yasonk</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1869"">actions/checkout#1869</a></li>
<li><a href=""https://github.com/lucacome""><code>@lucacome</code></a> made their first contribution in <a href=""https://redirect.github.com/actions/checkout/pull/1180"">actions/checkout#1180</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/actions/checkout/compare/v4.1.7...v4.2.0"">https://github.com/actions/checkout/compare/v4.1.7...v4.2.0</a></p>
</blockquote>
</details>
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/actions/checkout/blob/main/CHANGELOG.md"">actions/checkout's changelog</a>.</em></p>
<blockquote>
<h1>Changelog</h1>
<h2>v4.2.0</h2>
<ul>
<li>Add Ref and Commit outputs by <a href=""https://github.com/lucacome""><code>@lucacome</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1180"">actions/checkout#1180</a></li>
<li>Dependency updates by <a href=""https://github.com/dependabot""><code>@dependabot</code></a>- <a href=""https://redirect.github.com/actions/checkout/pull/1777"">actions/checkout#1777</a>, <a href=""https://redirect.github.com/actions/checkout/pull/1872"">actions/checkout#1872</a></li>
</ul>
<h2>v4.1.7</h2>
<ul>
<li>Bump the minor-npm-dependencies group across 1 directory with 4 updates by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1739"">actions/checkout#1739</a></li>
<li>Bump actions/checkout from 3 to 4 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1697"">actions/checkout#1697</a></li>
<li>Check out other refs/* by commit by <a href=""https://github.com/orhantoy""><code>@orhantoy</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1774"">actions/checkout#1774</a></li>
<li>Pin actions/checkout's own workflows to a known, good, stable version. by <a href=""https://github.com/jww3""><code>@jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1776"">actions/checkout#1776</a></li>
</ul>
<h2>v4.1.6</h2>
<ul>
<li>Check platform to set archive extension appropriately by <a href=""https://github.com/cory-miller""><code>@cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1732"">actions/checkout#1732</a></li>
</ul>
<h2>v4.1.5</h2>
<ul>
<li>Update NPM dependencies by <a href=""https://github.com/cory-miller""><code>@cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1703"">actions/checkout#1703</a></li>
<li>Bump github/codeql-action from 2 to 3 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1694"">actions/checkout#1694</a></li>
<li>Bump actions/setup-node from 1 to 4 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1696"">actions/checkout#1696</a></li>
<li>Bump actions/upload-artifact from 2 to 4 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1695"">actions/checkout#1695</a></li>
<li>README: Suggest <code>user.email</code> to be <code>41898282+github-actions[bot]@users.noreply.github.com</code> by <a href=""https://github.com/cory-miller""><code>@cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1707"">actions/checkout#1707</a></li>
</ul>
<h2>v4.1.4</h2>
<ul>
<li>Disable <code>extensions.worktreeConfig</code> when disabling <code>sparse-checkout</code> by <a href=""https://github.com/jww3""><code>@jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1692"">actions/checkout#1692</a></li>
<li>Add dependabot config by <a href=""https://github.com/cory-miller""><code>@cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1688"">actions/checkout#1688</a></li>
<li>Bump the minor-actions-dependencies group with 2 updates by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1693"">actions/checkout#1693</a></li>
<li>Bump word-wrap from 1.2.3 to 1.2.5 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1643"">actions/checkout#1643</a></li>
</ul>
<h2>v4.1.3</h2>
<ul>
<li>Check git version before attempting to disable <code>sparse-checkout</code> by <a href=""https://github.com/jww3""><code>@jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1656"">actions/checkout#1656</a></li>
<li>Add SSH user parameter by <a href=""https://github.com/cory-miller""><code>@cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1685"">actions/checkout#1685</a></li>
<li>Update <code>actions/checkout</code> version in <code>update-main-version.yml</code> by <a href=""https://github.com/jww3""><code>@jww3</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1650"">actions/checkout#1650</a></li>
</ul>
<h2>v4.1.2</h2>
<ul>
<li>Fix: Disable sparse checkout whenever <code>sparse-checkout</code> option is not present <a href=""https://github.com/dscho""><code>@dscho</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1598"">actions/checkout#1598</a></li>
</ul>
<h2>v4.1.1</h2>
<ul>
<li>Correct link to GitHub Docs by <a href=""https://github.com/peterbe""><code>@peterbe</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1511"">actions/checkout#1511</a></li>
<li>Link to release page from what's new section by <a href=""https://github.com/cory-miller""><code>@cory-miller</code></a> in <a href=""https://redirect.github.com/actions/checkout/pull/1514"">actions/checkout#1514</a></li>
</ul>
<h2>v4.1.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1396"">Add support for partial checkout filters</a></li>
</ul>
<h2>v4.0.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1067"">Support fetching without the --progress option</a></li>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1436"">Update to node20</a></li>
</ul>
<h2>v3.6.0</h2>
<ul>
<li><a href=""https://redirect.github.com/actions/checkout/pull/1377"">Fix: Mark test scripts with Bash'isms to be run via Bash</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/actions/checkout/commit/d632683dd7b4114ad314bca15554477dd762a938""><code>d632683</code></a> Prepare 4.2.0 release (<a href=""https://redirect.github.com/actions/checkout/issues/1878"">#1878</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/6d193bf28034eafb982f37bd894289fe649468fc""><code>6d193bf</code></a> Bump braces from 3.0.2 to 3.0.3 (<a href=""https://redirect.github.com/actions/checkout/issues/1777"">#1777</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/db0cee9a514becbbd4a101a5fbbbf47865ee316c""><code>db0cee9</code></a> Bump the minor-npm-dependencies group across 1 directory with 4 updates (<a href=""https://redirect.github.com/actions/checkout/issues/1872"">#1872</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/b6849436894e144dbce29d7d7fda2ae3bf9d8365""><code>b684943</code></a> Add Ref and Commit outputs (<a href=""https://redirect.github.com/actions/checkout/issues/1180"">#1180</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/2d7d9f7ff5b310f983d059b68785b3c74d8b8edd""><code>2d7d9f7</code></a> Provide explanation for where user email came from (<a href=""https://redirect.github.com/actions/checkout/issues/1869"">#1869</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/9a9194f87191a7e9055e3e9b95b8cfb13023bb08""><code>9a9194f</code></a> Bump docker/build-push-action from 5.3.0 to 6.5.0 (<a href=""https://redirect.github.com/actions/checkout/issues/1832"">#1832</a>)</li>
<li><a href=""https://github.com/actions/checkout/commit/dd960bd3c3f080561a1810e32349ac211ecec7d4""><code>dd960bd</code></a> Bump docker/login-action in the minor-actions-dependencies group (<a href=""https://redirect.github.com/actions/checkout/issues/1831"">#1831</a>)</li>
<li>See full diff in <a href=""https://github.com/actions/checkout/compare/692973e3d937129bcbf40652eb9f2f61becf3332...d632683dd7b4114ad314bca15554477dd762a938"">compare view</a></li>
</ul>
</details>
<br />

Updates `google/osv-scanner-action` from 1.8.4 to 1.8.5
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/google/osv-scanner-action/releases"">google/osv-scanner-action's releases</a>.</em></p>
<blockquote>
<h2>v1.8.5</h2>
<p>This updates OSV-Scanner to v1.8.5.</p>
<h2>What's Changed</h2>
<ul>
<li>chore(deps): update workflows by <a href=""https://github.com/renovate-bot""><code>@renovate-bot</code></a> in <a href=""https://redirect.github.com/google/osv-scanner-action/pull/34"">google/osv-scanner-action#34</a></li>
<li>fix: Use force checkout on second checkout for PR scanning by <a href=""https://github.com/another-rex""><code>@another-rex</code></a> in <a href=""https://redirect.github.com/google/osv-scanner-action/pull/41"">google/osv-scanner-action#41</a></li>
<li>chore: update to v1.8.5 by <a href=""https://github.com/cuixq""><code>@cuixq</code></a> in <a href=""https://redirect.github.com/google/osv-scanner-action/pull/42"">google/osv-scanner-action#42</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/cuixq""><code>@cuixq</code></a> made their first contribution in <a href=""https://redirect.github.com/google/osv-scanner-action/pull/42"">google/osv-scanner-action#42</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/google/osv-scanner-action/compare/v1.8.4...v1.8.5"">https://github.com/google/osv-scanner-action/compare/v1.8.4...v1.8.5</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/google/osv-scanner-action/commit/f0e6719deb666cd19a0b56bc56d01161bd848b4f""><code>f0e6719</code></a> Merge pull request <a href=""https://redirect.github.com/google/osv-scanner-action/issues/42"">#42</a> from google/update-to-v1.8.5</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/b2d64235572a61311979c49d9f483037e8ec59ce""><code>b2d6423</code></a> Update unified workflow example to point to v1.8.5 reusable workflows</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/7c52d44abe9736f8a11bac47f6baadad7b3389f5""><code>7c52d44</code></a> Update reusable workflows to point to v1.8.5 actions</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/c8774f9a566b87da6d60dc699730b268382bcd4e""><code>c8774f9</code></a> Update actions to use v1.8.5 osv-scanner image</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/6777cfabcf8b8e42d6e8bb80b6312016fbf2ad59""><code>6777cfa</code></a> Merge pull request <a href=""https://redirect.github.com/google/osv-scanner-action/issues/41"">#41</a> from google/force-checkout</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/5624e70eae69b85ece43d7d0fd0eb8b8d9185c60""><code>5624e70</code></a> Use force checkout</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/75f230ec19d246026449d558f7971b0b65e30a19""><code>75f230e</code></a> Merge pull request <a href=""https://redirect.github.com/google/osv-scanner-action/issues/34"">#34</a> from renovate-bot/renovate/workflows</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/69f000a81f620a62000595b6df05ef15cdc08b51""><code>69f000a</code></a> chore(deps): update workflows</li>
<li>See full diff in <a href=""https://github.com/google/osv-scanner-action/compare/v1.8.4...v1.8.5"">compare view</a></li>
</ul>
</details>
<br />

Updates `peter-evans/create-pull-request` from 6.1.0 to 7.0.5
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/peter-evans/create-pull-request/releases"">peter-evans/create-pull-request's releases</a>.</em></p>
<blockquote>
<h2>Create Pull Request v7.0.5</h2>
<p> Fixes an issue with commit signing to allow it to support symlinks</p>
<h2>What's Changed</h2>
<ul>
<li>fix: support symlinks when commit signing by <a href=""https://github.com/peter-evans""><code>@peter-evans</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3359"">peter-evans/create-pull-request#3359</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/peter-evans/create-pull-request/compare/v7.0.4...v7.0.5"">https://github.com/peter-evans/create-pull-request/compare/v7.0.4...v7.0.5</a></p>
<h2>Create Pull Request v7.0.4</h2>
<p> Fixes an issue with commit signing to allow it to support submodules</p>
<h2>What's Changed</h2>
<ul>
<li>docs: correct suggestion for bot setup by <a href=""https://github.com/henryiii""><code>@henryiii</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3342"">peter-evans/create-pull-request#3342</a></li>
<li>build(deps-dev): bump <code>@types/jest</code> from 29.5.12 to 29.5.13 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3343"">peter-evans/create-pull-request#3343</a></li>
<li>build(deps-dev): bump eslint from 8.57.0 to 8.57.1 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3344"">peter-evans/create-pull-request#3344</a></li>
<li>fix: support submodules when commit signing by <a href=""https://github.com/peter-evans""><code>@peter-evans</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3354"">peter-evans/create-pull-request#3354</a></li>
</ul>
<h2>New Contributors</h2>
<ul>
<li><a href=""https://github.com/henryiii""><code>@henryiii</code></a> made their first contribution in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3342"">peter-evans/create-pull-request#3342</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/peter-evans/create-pull-request/compare/v7.0.3...v7.0.4"">https://github.com/peter-evans/create-pull-request/compare/v7.0.3...v7.0.4</a></p>
<h2>Create Pull Request v7.0.3</h2>
<p> Fixes an issue with commit signing where commit SHAs have variable lengths when abbreviated.</p>
<h2>What's Changed</h2>
<ul>
<li>fix: disable abbreviated commit shas in diff by <a href=""https://github.com/peter-evans""><code>@peter-evans</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3337"">peter-evans/create-pull-request#3337</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/peter-evans/create-pull-request/compare/v7.0.2...v7.0.3"">https://github.com/peter-evans/create-pull-request/compare/v7.0.2...v7.0.3</a></p>
<h2>Create Pull Request v7.0.2</h2>
<p> Fixes an issue with commit signing when a change was detected as being a rename or copy.</p>
<h2>What's Changed</h2>
<ul>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.48 to 18.19.50 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3320"">peter-evans/create-pull-request#3320</a></li>
<li>build(deps-dev): bump typescript from 5.5.4 to 5.6.2 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3319"">peter-evans/create-pull-request#3319</a></li>
<li>fix: disable diff detection for renames and copies by <a href=""https://github.com/peter-evans""><code>@peter-evans</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3330"">peter-evans/create-pull-request#3330</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/peter-evans/create-pull-request/compare/v7.0.1...v7.0.2"">https://github.com/peter-evans/create-pull-request/compare/v7.0.1...v7.0.2</a></p>
<h2>Create Pull Request v7.0.1</h2>
<p> Fixes <a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3311"">an issue</a> affecting one particular use case where the action fails on <code>diff --stat</code> with <code>fatal: ambiguous argument</code>.</p>
<h2>What's Changed</h2>
<ul>
<li>build(deps): bump peter-evans/create-pull-request from 6 to 7 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3283"">peter-evans/create-pull-request#3283</a></li>
<li>build(deps-dev): bump <code>@types/node</code> from 18.19.46 to 18.19.48 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3288"">peter-evans/create-pull-request#3288</a></li>
<li>build(deps-dev): bump <code>@typescript-eslint/parser</code> from 7.17.0 to 7.18.0 by <a href=""https://github.com/dependabot""><code>@dependabot</code></a> in <a href=""https://redirect.github.com/peter-evans/create-pull-request/pull/3289"">peter-evans/create-pull-request#3289</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/5e914681df9dc83aa4e4905692ca88beb2f9e91f""><code>5e91468</code></a> fix: support symlinks when commit signing (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3359"">#3359</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/2f38cd26bfebe301a5ee90bdd6550a69dc3ef23f""><code>2f38cd2</code></a> fix: support submodules when commit signing (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3354"">#3354</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/7a8aeac749996aed943101d8e7dfb0cecc06197e""><code>7a8aeac</code></a> build(deps-dev): bump eslint from 8.57.0 to 8.57.1 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3344"">#3344</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/d39d596a7720fc2c61c9aa5503097fb553431b5e""><code>d39d596</code></a> build(deps-dev): bump <code>@types/jest</code> from 29.5.12 to 29.5.13 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3343"">#3343</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/f6f978fd3dc86c443f758f603d22dc554762c832""><code>f6f978f</code></a> docs: correct suggestion for bot setup (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3342"">#3342</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/6cd32fd93684475c31847837f87bb135d40a2b79""><code>6cd32fd</code></a> fix: disable abbreviated commit shas in diff (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3337"">#3337</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/d121e62763d8cc35b5fb1710e887d6e69a52d3a4""><code>d121e62</code></a> fix: disable diff detection for renames and copies (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3330"">#3330</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/f4d66f4d5a5a7e65a185463192800c32d296ac6d""><code>f4d66f4</code></a> build(deps-dev): bump typescript from 5.5.4 to 5.6.2 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3319"">#3319</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/488c869d17c8a5cb8a2f0a09471ed82c1d2a084f""><code>488c869</code></a> build(deps-dev): bump <code>@types/node</code> from 18.19.48 to 18.19.50 (<a href=""https://redirect.github.com/peter-evans/create-pull-request/issues/3320"">#3320</a>)</li>
<li><a href=""https://github.com/peter-evans/create-pull-request/commit/5354f85616108575685a73a0ddd2f67c26a441c3""><code>5354f85</code></a> docs: update readme</li>
<li>Additional commits viewable in <a href=""https://github.com/peter-evans/create-pull-request/compare/c5a7806660adbe173f04e3e038b0ccdcd758773c...5e914681df9dc83aa4e4905692ca88beb2f9e91f"">compare view</a></li>
</ul>
</details>
<br />

Updates `github/codeql-action` from 3.26.6 to 3.26.10
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p>
<blockquote>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>[UNRELEASED]</h2>
<p>No user facing changes.</p>
<h2>3.26.10 - 30 Sep 2024</h2>
<ul>
<li>We are rolling out a feature in September/October 2024 that sets up CodeQL using a bundle compressed with <a href=""http://facebook.github.io/zstd/"">Zstandard</a>. Our aim is to improve the performance of setting up CodeQL. <a href=""https://redirect.github.com/github/codeql-action/pull/2502"">#2502</a></li>
</ul>
<h2>3.26.9 - 24 Sep 2024</h2>
<p>No user facing changes.</p>
<h2>3.26.8 - 19 Sep 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.19.0. <a href=""https://redirect.github.com/github/codeql-action/pull/2483"">#2483</a></li>
</ul>
<h2>3.26.7 - 13 Sep 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.18.4. <a href=""https://redirect.github.com/github/codeql-action/pull/2471"">#2471</a></li>
</ul>
<h2>3.26.6 - 29 Aug 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.18.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2449"">#2449</a></li>
</ul>
<h2>3.26.5 - 23 Aug 2024</h2>
<ul>
<li>Fix an issue where the <code>csrutil</code> system call used for telemetry would fail on MacOS ARM machines with System Integrity Protection disabled. <a href=""https://redirect.github.com/github/codeql-action/pull/2441"">#2441</a></li>
</ul>
<h2>3.26.4 - 21 Aug 2024</h2>
<ul>
<li><em>Deprecation:</em> The <code>add-snippets</code> input on the <code>analyze</code> Action is deprecated and will be removed in the first release in August 2025. <a href=""https://redirect.github.com/github/codeql-action/pull/2436"">#2436</a></li>
<li>Fix an issue where the disk usage system call used for telemetry would fail on MacOS ARM machines with System Integrity Protection disabled, and then surface a warning. The system call is now disabled for these machines. <a href=""https://redirect.github.com/github/codeql-action/pull/2434"">#2434</a></li>
</ul>
<h2>3.26.3 - 19 Aug 2024</h2>
<ul>
<li>Fix an issue where the CodeQL Action could not write diagnostic messages on Windows. This issue did not impact analysis quality. <a href=""https://redirect.github.com/github/codeql-action/pull/2430"">#2430</a></li>
</ul>
<h2>3.26.2 - 14 Aug 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.18.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2417"">#2417</a></li>
</ul>
<h2>3.26.1 - 13 Aug 2024</h2>
<p>No user facing changes.</p>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/github/codeql-action/commit/e2b3eafc8d227b0241d48be5f425d47c2d750a13""><code>e2b3eaf</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2507"">#2507</a> from github/update-v3.26.10-2617ff2d3</li>
<li><a href=""https://github.com/github/codeql-action/commit/7dbbf6d5424ee9117470bd89a28b9b992c935ff4""><code>7dbbf6d</code></a> Update changelog for v3.26.10</li>
<li><a href=""https://github.com/github/codeql-action/commit/2617ff2d3f2bf8dd95abadcd289352a4023a4758""><code>2617ff2</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2502"">#2502</a> from github/henrymercer/zstd-experiment</li>
<li><a href=""https://github.com/github/codeql-action/commit/46e0c78da9edf293aeab3d4d62cf1a7b7534c6a0""><code>46e0c78</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2504"">#2504</a> from github/mergeback/v3.26.9-to-main-461ef6c7</li>
<li><a href=""https://github.com/github/codeql-action/commit/da7be78a1ea4e90acbaa595fcc5606082dba4591""><code>da7be78</code></a> Update checked-in dependencies</li>
<li><a href=""https://github.com/github/codeql-action/commit/ae1c6a2b12389a4d40a3383d49e14518da35a78e""><code>ae1c6a2</code></a> Update changelog and version after v3.26.9</li>
<li><a href=""https://github.com/github/codeql-action/commit/461ef6c76dfe95d5c364de2f431ddbd31a417628""><code>461ef6c</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2503"">#2503</a> from github/update-v3.26.9-f861efb2b</li>
<li><a href=""https://github.com/github/codeql-action/commit/00b1146c45021691af6c1c3c45e04d65d3c3f1e8""><code>00b1146</code></a> Update changelog for v3.26.9</li>
<li><a href=""https://github.com/github/codeql-action/commit/f861efb2b37e018668a6943ba7b408a7083627cc""><code>f861efb</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2498"">#2498</a> from github/dependabot/npm_and_yarn/npm-9874b37b58</li>
<li><a href=""https://github.com/github/codeql-action/commit/6b2f7e7c28404627554332e4fe1880c5be10639c""><code>6b2f7e7</code></a> Run PR checks using JS only</li>
<li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/4dd16135b69a43b6c8efb853346f8437d92d3c93...e2b3eafc8d227b0241d48be5f425d47c2d750a13"">compare view</a></li>
</ul>
</details>
<br />

Updates `docker/build-push-action` from 6.7.0 to 6.9.0
<details>
<summary>Release notes</summary>
<p><em>Sourced from <a href=""https://github.com/docker/build-push-action/releases"">docker/build-push-action's releases</a>.</em></p>
<blockquote>
<h2>v6.9.0</h2>
<ul>
<li>Bump <code>@docker/actions-toolkit</code> from 0.38.0 to 0.39.0 in <a href=""https://redirect.github.com/docker/build-push-action/pull/1234"">docker/build-push-action#1234</a></li>
<li>Bump path-to-regexp from 6.2.2 to 6.3.0 in <a href=""https://redirect.github.com/docker/build-push-action/pull/1232"">docker/build-push-action#1232</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/build-push-action/compare/v6.8.0...v6.9.0"">https://github.com/docker/build-push-action/compare/v6.8.0...v6.9.0</a></p>
<h2>v6.8.0</h2>
<ul>
<li>Bump <code>@docker/actions-toolkit</code> from 0.37.1 to 0.38.0 in <a href=""https://redirect.github.com/docker/build-push-action/pull/1230"">docker/build-push-action#1230</a></li>
</ul>
<p><strong>Full Changelog</strong>: <a href=""https://github.com/docker/build-push-action/compare/v6.7.0...v6.8.0"">https://github.com/docker/build-push-action/compare/v6.7.0...v6.8.0</a></p>
</blockquote>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/docker/build-push-action/commit/4f58ea79222b3b9dc2c8bbdd6debcef730109a75""><code>4f58ea7</code></a> Merge pull request <a href=""https://redirect.github.com/docker/build-push-action/issues/1234"">#1234</a> from docker/dependabot/npm_and_yarn/docker/actions-t...</li>
<li><a href=""https://github.com/docker/build-push-action/commit/49b5ea61c60477d214908bb6e23ce05c074ef04e""><code>49b5ea6</code></a> chore: update generated content</li>
<li><a href=""https://github.com/docker/build-push-action/commit/13c9fddd72db0ce3cd9d87eb53e0480d2a32a77b""><code>13c9fdd</code></a> chore(deps): Bump <code>@docker/actions-toolkit</code> from 0.38.0 to 0.39.0</li>
<li><a href=""https://github.com/docker/build-push-action/commit/e44afff3590e1d4f93b6adc72376512edb012a7c""><code>e44afff</code></a> Merge pull request <a href=""https://redirect.github.com/docker/build-push-action/issues/1232"">#1232</a> from docker/dependabot/npm_and_yarn/path-to-regexp-6...</li>
<li><a href=""https://github.com/docker/build-push-action/commit/67ebad331f4ca45e39184b280dbacb11eb3beae0""><code>67ebad3</code></a> chore(deps): Bump path-to-regexp from 6.2.2 to 6.3.0</li>
<li><a href=""https://github.com/docker/build-push-action/commit/32945a339266b759abcbdc89316275140b0fc960""><code>32945a3</code></a> Merge pull request <a href=""https://redirect.github.com/docker/build-push-action/issues/1230"">#1230</a> from docker/dependabot/npm_and_yarn/docker/actions-t...</li>
<li><a href=""https://github.com/docker/build-push-action/commit/e0fe9cf0f26132beab7b62929bd647eef9e7df31""><code>e0fe9cf</code></a> chore: update generated content</li>
<li><a href=""https://github.com/docker/build-push-action/commit/8f1ff6bf9a836299c21b10f942be49efb52a832c""><code>8f1ff6b</code></a> chore(deps): Bump <code>@docker/actions-toolkit</code> from 0.37.1 to 0.38.0</li>
<li>See full diff in <a href=""https://github.com/docker/build-push-action/compare/5cd11c3a4ced054e52742c5fd54dca954e0edd85...4f58ea79222b3b9dc2c8bbdd6debcef730109a75"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore <dependency name> major version` will close this group update PR and stop Dependabot creating any more for the specific dependency's major version (unless you unignore this specific dependency's major version or upgrade to it yourself)
- `@dependabot ignore <dependency name> minor version` will close this group update PR and stop Dependabot creating any more for the specific dependency's minor version (unless you unignore this specific dependency's minor version or upgrade to it yourself)
- `@dependabot ignore <dependency name>` will close this group update PR and stop Dependabot creating any more for the specific dependency (unless you unignore this specific dependency or upgrade to it yourself)
- `@dependabot unignore <dependency name>` will remove all of the ignore conditions of the specified dependency
- `@dependabot unignore <dependency name> <ignore condition>` will remove the ignore condition of the specified dependency and ignore conditions


</details>",dependabot[bot],2024-10-01 08:13:42+00:00,['gbaned'],2024-10-09 07:47:06+00:00,2024-10-09 07:47:05+00:00,https://github.com/tensorflow/tensorflow/pull/76867,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small'), ('dependencies', 'Pull requests that update a dependency file'), ('github_actions', 'Pull requests that update GitHub Actions code')]",[],
2558453711,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 07:51:01+00:00,[],2024-10-01 16:53:10+00:00,,https://github.com/tensorflow/tensorflow/pull/76866,[],[],
2558434316,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 07:40:54+00:00,[],2024-10-01 07:40:54+00:00,,https://github.com/tensorflow/tensorflow/pull/76865,[],[],
2558433289,pull_request,closed,,PR #17636: [NVIDIA GPU] Enhance concurrency handling in cross-rank address sharing,"PR #17636: [NVIDIA GPU] Enhance concurrency handling in cross-rank address sharing

Imported from GitHub PR https://github.com/openxla/xla/pull/17636

This is a followup PR to https://github.com/openxla/xla/pull/15144. A distributed cache is maintained when device addresses are shared across ranks. There are two issues withe the existing implementation:

1. The cache is not guarded by mutex;
2. The cache initialization process have redundant access.

These issues can cause race condition or dead lock when the progress on different ranks are very close. Consequently we need to introduce below enhancements:

1. Guard the cache with mutex;
2. Shard the initialization process by rank, so that each rank only handle a piece of the cache and should not have overlapping access in theory.

Copybara import of the project:

--
a6472fc75fd0411bd8e65f27082e21e9a946ab17 by Terry Sun <tesun@nvidia.com>:

enhance concurrency handling

--
356ab824b95d66c793e361882e95d70689759ffd by Terry Sun <tesun@nvidia.com>:

lock mutex

--
29ebb2de64711bf4b4a08cf1593317228b56f825 by Terry Sun <tesun@nvidia.com>:

bring back test

--
91b911f0aaac0e590636a82956b464436e94ef9f by Terry Sun <tesun@nvidia.com>:

better lock granularity

--
cc1d93a5f1032a205473961b2c2d3e14bee3a9c6 by Terry Sun <tesun@nvidia.com>:

guard all accesses

Merging this change closes #17636

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17636 from terryysun:terryysun/sync_fix cc1d93a5f1032a205473961b2c2d3e14bee3a9c6
",copybara-service[bot],2024-10-01 07:40:21+00:00,[],2024-10-01 20:01:24+00:00,2024-10-01 20:01:24+00:00,https://github.com/tensorflow/tensorflow/pull/76864,[],[],
2558395711,pull_request,closed,,PR #17440: Inject desired pattern for handling Transpose for fp8 gemm rewrite,"PR #17440: Inject desired pattern for handling Transpose for fp8 gemm rewrite

Imported from GitHub PR https://github.com/openxla/xla/pull/17440

Related to https://github.com/openxla/xla/issues/17276 and https://github.com/openxla/xla/pull/16975. 
This PR updates the GemmRewriter to handle the transpose of non-descending layouts directly, eliminating the need for the layout_normalization pass to correct this error-prone pattern post-rewrite. The desired transformation is now injected into GemmRewriter, ensuring the problematic layout is handled internally. This PR transforms the following error-prone pattern, where the transpose of a non-descending layout is the issue:
```
a = f8e4m3fn[x,y]{0,1} xxx
transpose.0 = f8e4m3fn[y,x]{0,1} transpose(a), dimensions=(1,0)
custom-call(a,...)
```
to 
```
a = f8e4m3fn[x,y]{0,1} xxx
bt = f8e4m3fn[y,x]{1,0} bitcast(a)
transpose.1 = f8e4m3fn[x,y]{1,0} transpose(bt), dimensions=(1,0)
bt.1= f8e4m3fn[y,x]{0,1} bitcast(transpose.1)
custom-call(bt.1,...)
```
Copybara import of the project:

--
237c03240da3dce736d92c8273dc1f9d3be53af5 by shuw <shuw@nvidia.com>:

Improve TransposeMatrix

--
508cd6928bbc20c1d87818eed4ee6190c6c9f691 by Shu Wang <shuw@nvidia.com>:

Fix bug of permutation.
--
c55e8a9f64c8dac69907ccebce3b8109ddeb2c48 by shuw <shuw@nvidia.com>:

clang format

--
ad0a4ba8054092dd79608865a823c1d432f81b21 by Shu Wang <shuw@nvidia.com>:

Add unittest.
--
1d45b4d64347c64a9483fd26caf7d8598818b855 by Shu Wang <shuw@nvidia.com>:

Remove uncessary space.
--
78378455e70e439e71da078c3099732a14292d7d by Shu Wang <shuw@nvidia.com>:

Update unittest.

--
b479c2177672a0010ffba1630efdaec5ca4cee26 by shuw <shuw@nvidia.com>:

Improve TransposeMatrix

--
b63318487153a8668b9f95574b054b0129194c0c by Shu Wang <shuw@nvidia.com>:

Update unittest shape and BUILD file.

Merging this change closes #17440

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17440 from wenscarl:fp8_regulate_transpose b63318487153a8668b9f95574b054b0129194c0c
",copybara-service[bot],2024-10-01 07:20:50+00:00,[],2024-10-02 19:48:04+00:00,2024-10-02 19:48:03+00:00,https://github.com/tensorflow/tensorflow/pull/76863,[],[],
2558390497,pull_request,closed,,Integrate LLVM at llvm/llvm-project@ac2a2816e3fe,"Integrate LLVM at llvm/llvm-project@ac2a2816e3fe

Updates LLVM usage to match
[ac2a2816e3fe](https://github.com/llvm/llvm-project/commit/ac2a2816e3fe)
",copybara-service[bot],2024-10-01 07:18:04+00:00,[],2024-10-01 13:05:50+00:00,2024-10-01 13:05:48+00:00,https://github.com/tensorflow/tensorflow/pull/76862,[],[],
2558337345,pull_request,closed,,PR #17544: [ROCm] Pass AMDGPU_TARGETS to crosstool wrapper,"PR #17544: [ROCm] Pass AMDGPU_TARGETS to crosstool wrapper

Imported from GitHub PR https://github.com/openxla/xla/pull/17544

Passing amdgpu targets to crosstool wrapper which calls hipcc can restrict the kernels generated to specific set of supported amdgpu architectures.
Copybara import of the project:

--
aba828b02a32aeca576086e8e41aa8b6f70e4f39 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Pass AMDGPU_TARGETS to crosstool wrapper

Passing amdgpu targets to crosstool wrapper which calls hipcc can
restrict the kernels generated to specific set of supported amdgpu
architectures.

Merging this change closes #17544

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17544 from ROCm:ci_pass_arch_to_crosstool_20240924 aba828b02a32aeca576086e8e41aa8b6f70e4f39
",copybara-service[bot],2024-10-01 06:47:50+00:00,[],2024-10-01 10:00:35+00:00,2024-10-01 10:00:34+00:00,https://github.com/tensorflow/tensorflow/pull/76861,[],[],
2558245211,pull_request,closed,,[xla:gpu] Disable Conditions in cuda graphs by default,"[xla:gpu] Disable Conditions in cuda graphs by default

Reverts e081db68a13da5cb86b6bb14e5856866b45321f5
",copybara-service[bot],2024-10-01 05:47:15+00:00,[],2024-10-01 17:02:21+00:00,2024-10-01 17:02:20+00:00,https://github.com/tensorflow/tensorflow/pull/76860,[],[],
2558169535,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:46:40+00:00,[],2024-10-01 04:46:40+00:00,,https://github.com/tensorflow/tensorflow/pull/76859,[],[],
2558167659,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:45:12+00:00,[],2024-10-01 04:45:12+00:00,,https://github.com/tensorflow/tensorflow/pull/76858,[],[],
2558166877,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:44:28+00:00,[],2024-10-01 05:28:31+00:00,,https://github.com/tensorflow/tensorflow/pull/76857,[],[],
2558163082,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:40:54+00:00,[],2024-10-01 04:40:54+00:00,,https://github.com/tensorflow/tensorflow/pull/76856,[],[],
2558157813,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:35:43+00:00,[],2024-10-01 04:35:43+00:00,,https://github.com/tensorflow/tensorflow/pull/76855,[],[],
2558157805,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:35:42+00:00,[],2024-10-01 04:35:42+00:00,,https://github.com/tensorflow/tensorflow/pull/76854,[],[],
2558157433,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:35:20+00:00,[],2024-10-01 04:35:20+00:00,,https://github.com/tensorflow/tensorflow/pull/76853,[],[],
2558154100,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:32:17+00:00,[],2024-10-01 04:32:17+00:00,,https://github.com/tensorflow/tensorflow/pull/76852,[],[],
2558153944,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:32:07+00:00,[],2024-10-01 04:32:07+00:00,,https://github.com/tensorflow/tensorflow/pull/76851,[],[],
2558152662,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:30:52+00:00,[],2024-10-01 04:30:52+00:00,,https://github.com/tensorflow/tensorflow/pull/76850,[],[],
2558150937,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:29:55+00:00,[],2024-10-01 04:29:55+00:00,,https://github.com/tensorflow/tensorflow/pull/76849,[],[],
2558150865,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:29:50+00:00,[],2024-10-02 06:24:08+00:00,2024-10-02 06:24:07+00:00,https://github.com/tensorflow/tensorflow/pull/76848,[],[],
2558145219,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:24:25+00:00,[],2024-10-01 04:24:25+00:00,,https://github.com/tensorflow/tensorflow/pull/76847,[],[],
2558145112,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:24:18+00:00,[],2024-10-01 04:24:18+00:00,,https://github.com/tensorflow/tensorflow/pull/76846,[],[],
2558144710,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:23:59+00:00,[],2024-10-01 04:23:59+00:00,,https://github.com/tensorflow/tensorflow/pull/76845,[],[],
2558135710,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 04:15:10+00:00,[],2024-10-01 04:15:10+00:00,,https://github.com/tensorflow/tensorflow/pull/76844,[],[],
2558080959,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-10-01 03:19:44+00:00,[],2024-10-01 04:46:19+00:00,2024-10-01 04:46:18+00:00,https://github.com/tensorflow/tensorflow/pull/76843,[],[],
2558020768,pull_request,open,,Delete jax.lib.xla_client.execute_with_python_values.,"Delete jax.lib.xla_client.execute_with_python_values.

Nothing under jax.lib.xla_client is public, so there's no deprecation period required.
",copybara-service[bot],2024-10-01 02:19:04+00:00,[],2024-10-01 02:19:04+00:00,,https://github.com/tensorflow/tensorflow/pull/76842,[],[],
2557918224,pull_request,closed,,[XLA:Python] Improve the error message for the case where the previous permissive None treedef behavior is encountered.,"[XLA:Python] Improve the error message for the case where the previous permissive None treedef behavior is encountered.
",copybara-service[bot],2024-10-01 00:30:36+00:00,[],2024-10-01 01:45:50+00:00,2024-10-01 01:45:49+00:00,https://github.com/tensorflow/tensorflow/pull/76841,[],[],
2557912811,pull_request,closed,,Remove no_prod_deps* config_settings.,"Remove no_prod_deps* config_settings.
",copybara-service[bot],2024-10-01 00:25:21+00:00,[],2024-10-01 20:51:46+00:00,2024-10-01 20:51:45+00:00,https://github.com/tensorflow/tensorflow/pull/76840,[],[],
2557910152,pull_request,closed,,[XLA:SPMD] Fix ReshapeSharding for dimensions of size 1 and >1 partitions.,"[XLA:SPMD] Fix ReshapeSharding for dimensions of size 1 and >1 partitions.

If there is a source dimension satisfying the following conditions, we replicate the source sharding along this dimension since the source sharding cannot be propagated along this dimension.
1. its size is 1
2. its partitions is greater than 1
3. there is no corresponding target dimension

An example is shown below. Please refer to the added examples in hlo_sharding_util_test.cc.
```
input shape: [1,2,16]
input sharding: [3,2,2]<=[12]
output shape: [2,16]

output sharding before this cl: [2,2,3]<=[12] last_tile_dim_replicate
output sharding with this cl: [2,2,3]<=[3,2,2]T(1,2,0) last_tile_dim_replicate
```
",copybara-service[bot],2024-10-01 00:22:43+00:00,[],2024-10-02 18:15:22+00:00,2024-10-02 18:15:22+00:00,https://github.com/tensorflow/tensorflow/pull/76839,[],[],
2557891707,pull_request,open,,[XLA:MSA] Added flags to enable/disable async copy and async slice replacements in memory space assignment. Both features are enabled by default.,"[XLA:MSA] Added flags to enable/disable async copy and async slice replacements in memory space assignment. Both features are enabled by default.
",copybara-service[bot],2024-10-01 00:04:32+00:00,[],2024-10-16 20:53:52+00:00,,https://github.com/tensorflow/tensorflow/pull/76838,[],[],
2557870766,pull_request,closed,,Add pattern to match GELU with tf.Erfc implementation.,"Add pattern to match GELU with tf.Erfc implementation.
",copybara-service[bot],2024-09-30 23:47:16+00:00,['arfaian'],2024-10-01 00:17:54+00:00,2024-10-01 00:17:54+00:00,https://github.com/tensorflow/tensorflow/pull/76837,[],[],
2557863400,pull_request,open,,Testing CI after force submit,"Testing CI after force submit
",copybara-service[bot],2024-09-30 23:42:49+00:00,['ddunl'],2024-09-30 23:42:50+00:00,,https://github.com/tensorflow/tensorflow/pull/76836,[],[],
2557853466,pull_request,closed,,Better description of C++ treatment of the non-overridden overloaded functions.,"Better description of C++ treatment of the non-overridden overloaded functions.
Added explicit includes.
",copybara-service[bot],2024-09-30 23:36:47+00:00,[],2024-10-03 18:51:24+00:00,2024-10-03 18:51:23+00:00,https://github.com/tensorflow/tensorflow/pull/76835,[],[],
2557852343,pull_request,open,,Internal visibility change.,"Internal visibility change.
",copybara-service[bot],2024-09-30 23:36:27+00:00,[],2024-09-30 23:36:27+00:00,,https://github.com/tensorflow/tensorflow/pull/76834,[],[],
2557773901,pull_request,closed,,Rename cuda_libdevice_path to cuda_root_path,"Rename cuda_libdevice_path to cuda_root_path
",copybara-service[bot],2024-09-30 22:42:57+00:00,[],2024-10-01 00:04:43+00:00,2024-10-01 00:04:42+00:00,https://github.com/tensorflow/tensorflow/pull/76833,[],[],
2557734140,pull_request,open,,Add odml.gather composite lowering pattern to StableHLO dialect.,"Add odml.gather composite lowering pattern to StableHLO dialect.

lowers to TFL gather
",copybara-service[bot],2024-09-30 22:06:14+00:00,['turbotoribio'],2024-09-30 22:06:16+00:00,,https://github.com/tensorflow/tensorflow/pull/76832,[],[],
2557698731,pull_request,closed,,aarch64: set compute library openmp runtime to off by default,"since the official wheel binary is using Eigen thread pool runtime, there is no dependency on OpenMP. However, having openmp ON by default in compute library bazel config causing an unnecessary dependency on `libgomp/libomp`  for aarch64 linux wheel. This PR is to remove the dependency.",snadampal,2024-09-30 21:47:29+00:00,['gbaned'],2024-10-27 00:26:40+00:00,2024-10-27 00:26:39+00:00,https://github.com/tensorflow/tensorflow/pull/76831,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small')]","[{'comment_id': 2391376222, 'issue_id': 2557698731, 'author': 'mihaimaruseac', 'body': 'There have been no changes since my approval 2 days ago. This is pending on internal review.', 'created_at': datetime.datetime(2024, 10, 3, 13, 6, 16, tzinfo=datetime.timezone.utc)}, {'comment_id': 2391386727, 'issue_id': 2557698731, 'author': 'snadampal', 'body': ""Hi @mihaimaruseac, thanks for the review, approval and also the note!\r\n\r\nbtw, The CI build failure on AMD ROCm is not related to the PR, so, i'm not looking into it."", 'created_at': datetime.datetime(2024, 10, 3, 13, 11, 14, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413354601, 'issue_id': 2557698731, 'author': 'keerthanakadiri', 'body': 'Hi @mihaimaruseac , Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 15, 9, 20, 51, tzinfo=datetime.timezone.utc)}, {'comment_id': 2413616850, 'issue_id': 2557698731, 'author': 'mihaimaruseac', 'body': '> There have been no changes since my approval 2 days ago. This is pending on internal review.\r\n\r\nThis is still true. Please check status of PR before sending automated messages.', 'created_at': datetime.datetime(2024, 10, 15, 11, 22, 8, tzinfo=datetime.timezone.utc)}, {'comment_id': 2422529992, 'issue_id': 2557698731, 'author': 'snadampal', 'body': 'please let me know how I can reproduce the internal build error: not finding the openmp symbols.', 'created_at': datetime.datetime(2024, 10, 18, 13, 51, 59, tzinfo=datetime.timezone.utc)}]","mihaimaruseac on (2024-10-03 13:06:16 UTC): There have been no changes since my approval 2 days ago. This is pending on internal review.

snadampal (Issue Creator) on (2024-10-03 13:11:14 UTC): Hi @mihaimaruseac, thanks for the review, approval and also the note!

btw, The CI build failure on AMD ROCm is not related to the PR, so, i'm not looking into it.

keerthanakadiri on (2024-10-15 09:20:51 UTC): Hi @mihaimaruseac , Can you please review this PR? Thank you !

mihaimaruseac on (2024-10-15 11:22:08 UTC): This is still true. Please check status of PR before sending automated messages.

snadampal (Issue Creator) on (2024-10-18 13:51:59 UTC): please let me know how I can reproduce the internal build error: not finding the openmp symbols.

"
2557695258,pull_request,closed,,Reverts 1b240fae66605d39e14d4459450664c0ac20e97f,"Reverts 1b240fae66605d39e14d4459450664c0ac20e97f
",copybara-service[bot],2024-09-30 21:45:40+00:00,[],2024-09-30 23:18:16+00:00,2024-09-30 23:18:15+00:00,https://github.com/tensorflow/tensorflow/pull/76830,[],[],
2557642556,pull_request,closed,,Add a backward compatibility shim for PJRT layouts.,"Add a backward compatibility shim for PJRT layouts.
",copybara-service[bot],2024-09-30 21:08:56+00:00,[],2024-10-01 16:03:54+00:00,2024-10-01 16:03:53+00:00,https://github.com/tensorflow/tensorflow/pull/76829,[],[],
2557607779,pull_request,closed,,Try to debug weird tag issue,"Try to debug weird tag issue
",copybara-service[bot],2024-09-30 20:46:51+00:00,['ddunl'],2024-09-30 21:39:34+00:00,2024-09-30 21:39:33+00:00,https://github.com/tensorflow/tensorflow/pull/76828,[],[],
2557573857,pull_request,open,,[XLA:GPU] Improve error message for unsupported dot algorithms.,"[XLA:GPU] Improve error message for unsupported dot algorithms.

The current error message can be a bit confusing because it will report that an algorithm is ""unsupported on the current device"" when the real problem is the input or output storage type. This change updates the error message to include a comment about the storage types.
",copybara-service[bot],2024-09-30 20:25:32+00:00,[],2024-10-01 14:04:15+00:00,,https://github.com/tensorflow/tensorflow/pull/76827,[],[],
2557555370,pull_request,closed,,[StableHLO] Fix updated indices_are_sorted and handle case of batching dim size overflowing indices integer type.,"[StableHLO] Fix updated indices_are_sorted and handle case of batching dim size overflowing indices integer type.
",copybara-service[bot],2024-09-30 20:13:53+00:00,[],2024-09-30 22:05:18+00:00,2024-09-30 22:05:18+00:00,https://github.com/tensorflow/tensorflow/pull/76825,[],[],
2557550912,pull_request,open,,[HLO Componentization] Create hlo/builder sub-component (Phase II).,"[HLO Componentization] Create hlo/builder sub-component (Phase II).

This CL takes care of
1. Migrating external projects dependencies from  xla/client --> xla/hlo/builder

Phase I takes care of
1. Migrating xla/translate --> xla/hlo/translate
2. Setting up build aliases in xla/translate ensuring external dependencies are still satisfied.
",copybara-service[bot],2024-09-30 20:11:08+00:00,['sdasgup3'],2024-09-30 21:54:26+00:00,,https://github.com/tensorflow/tensorflow/pull/76824,[],[],
2557540034,pull_request,closed,,Remove shape_util.cc from PrimitiveType LINT.ThenChange.,"Remove shape_util.cc from PrimitiveType LINT.ThenChange.

You do not have to modify shape_util.cc when modifying PrimitiveType as of https://github.com/openxla/xla/commit/9965b5122949af3b8da01f78062a4256b0e26d04 (cl/572704974).
",copybara-service[bot],2024-09-30 20:04:32+00:00,['reedwm'],2024-10-01 20:19:06+00:00,2024-10-01 20:19:05+00:00,https://github.com/tensorflow/tensorflow/pull/76823,[],[],
2557512265,pull_request,closed,,[XLA:Python] Fix crash introduced by https://github.com/openxla/xla/pull/10150,"[XLA:Python] Fix crash introduced by https://github.com/openxla/xla/pull/10150

If a non-weakreferenceable object is passed, remove the entry again, otherwise we leave a garbage entry in the map.

(The original code did double lookup for reasons that I had missed, but this is better.)
",copybara-service[bot],2024-09-30 19:47:18+00:00,[],2024-09-30 20:37:21+00:00,2024-09-30 20:37:20+00:00,https://github.com/tensorflow/tensorflow/pull/76822,[],[],
2557486318,pull_request,closed,,PR #16585: Add support for float8_e4m3 and float8_e3m4 types,"PR #16585: Add support for float8_e4m3 and float8_e3m4 types

Imported from GitHub PR https://github.com/openxla/xla/pull/16585

This PR adds f8E4M3 and f8E3M4 types support to XLA (mainly to cpu_compiler).

### `f8E4M3` type follows IEEE 754 convention.

```c
f8E4M3 (IEEE 754)
- Exponent bias: 7
- Maximum stored exponent value: 14 (binary 1110)
- Maximum unbiased exponent value: 14 - 7 = 7
- Minimum stored exponent value: 1 (binary 0001)
- Minimum unbiased exponent value: 1  7 = 6
- Precision specifies the total number of bits used for the significand (mantisa), 
    including implicit leading integer bit = 3 + 1 = 4
- Follows IEEE 754 conventions for representation of special values
- Has Positive and Negative zero
- Has Positive and Negative infinity
- Has NaNs

Additional details:
- Max exp (unbiased): 7
- Min exp (unbiased): -6
- Infinities (+/-): S.1111.000
- Zeros (+/-): S.0000.000
- NaNs: S.1111.{001, 010, 011, 100, 101, 110, 111}
- Max normal number: S.1110.111 = +/-2^(7) x (1 + 0.875) = +/-240
- Min normal number: S.0001.000 = +/-2^(-6)
- Max subnormal number: S.0000.111 = +/-2^(-6) x 0.875 = +/-2^(-9) x 7
- Min subnormal number: S.0000.001 = +/-2^(-6) x 0.125 = +/-2^(-9)
```

### `f8E3M4` type  follows IEEE 754 convention

```c
f8E3M4 (IEEE 754)
- Exponent bias: 3
- Maximum stored exponent value: 6 (binary 110)
- Maximum unbiased exponent value: 6 - 3 = 3
- Minimum stored exponent value: 1 (binary 001)
- Minimum unbiased exponent value: 1  3 = 2
- Precision specifies the total number of bits used for the significand (mantissa), 
    including implicit leading integer bit = 4 + 1 = 5
- Follows IEEE 754 conventions for representation of special values
- Has Positive and Negative zero
- Has Positive and Negative infinity
- Has NaNs

Additional details:
- Max exp (unbiased): 3
- Min exp (unbiased): -2
- Infinities (+/-): S.111.0000
- Zeros (+/-): S.000.0000
- NaNs: S.111.{0,1} except S.111.0000
- Max normal number: S.110.1111 = +/-2^(6-3) x (1 + 15/16) = +/-2^3 x 31 x 2^(-4) = +/-15.5
- Min normal number: S.001.0000 = +/-2^(1-3) x (1 + 0) = +/-2^(-2)
- Max subnormal number: S.000.1111 = +/-2^(-2) x 15/16 = +/-2^(-2) x 15 x 2^(-4) = +/-15 x 2^(-6)
- Min subnormal number: S.000.0001 = +/-2^(-2) x 1/16 =  +/-2^(-2) x 2^(-4) = +/-2^(-6)
```

### Testing:
```
bazel test \
//xla:array2d_test \
//xla:fp_util_test \
//xla:literal_comparison_test \
//xla:literal_test \
//xla/mlir/utils:type_util_test \
//xla:primitive_util_test \
//xla/python/ifrt:dtype_test \
//xla/python:xla_client_test \
//xla/service:elemental_ir_emitter_test \
//xla/service:float_normalization_test \
//xla/service/gpu/tests:float_conversions_test \
//xla/tests:array_elementwise_ops_test \
//xla/tests:constants_test \
//xla/tests:convert_test \
//xla/tests:float8_test \
//xla:util_test

bazel test \
//xla/hlo/translate/hlo_to_mhlo/tests:import.hlo.test \
//xla/hlo/translate/mhlo_to_hlo/tests:export.mlir.test \
//xla/mlir_hlo/tests:Dialect/mhlo/hlo-legalize-to-stablehlo.mlir.test \
//xla/mlir_hlo/tests:Dialect/mhlo/ops.mlir.test \
//xla/mlir_hlo/tests:Dialect/mhlo/stablehlo-legalize-to-hlo.mlir.test
```

### Related PRs:
- LLVM [PR-97179](https://github.com/llvm/llvm-project/pull/97179) [APFloat] Add support for f8E4M3 IEEE 754 type (Merged)
- LLVM [PR-97118](https://github.com/llvm/llvm-project/pull/97118) [MLIR] Add f8E4M3 IEEE 754 type (Merged)
- LLVM [PR-99698](https://github.com/llvm/llvm-project/pull/99698) [APFloat] Add support for f8E3M4 IEEE 754 type (Merged)
-  LLVM [PR-101230](https://github.com/llvm/llvm-project/pull/101230) [MLIR] Add f8E3M4 IEEE 754 type (Merged)
- StableHLO [PR-2486](https://github.com/openxla/stablehlo/pull/2486) [RFC] Add f8E4M3 and f8E3M4 types support (Merged)
- StableHLO [PR-2482](https://github.com/openxla/stablehlo/pull/2482) Add f8E4M3 and f8E3M4 types support (Merged)
- ml_dtypes [PR-161](https://github.com/jax-ml/ml_dtypes/pull/161) Add float8_e4m3 (Merged)
- ml_dtypes [PR-171](https://github.com/jax-ml/ml_dtypes/pull/171/) Add float8_e3m4 (Merged)
- XLA [PR-17075](https://github.com/openxla/xla/pull/17075) [TSL] Bump ml_dtypes. Add float8_e4m3, float8_e3m4 (Approved)
- XLA [PR-3200](https://github.com/openxla/xla/pull/3200) Add support for float8_e4m3fnuz and float8_e5m2fnuz (Template)
- JAX [PR-23585](https://github.com/google/jax/pull/23585) Add float8_e4m3 type support (in Review)
Copybara import of the project:

--
ec1c723027012a816d7e17f268c5f034863696e6 by Alexander Pivovarov <pivovaa@amazon.com>:

Add support for float8_e4m3 and float8_e3m4 types

Merging this change closes #16585

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16585 from apivovarov:float8_e4m3 ec1c723027012a816d7e17f268c5f034863696e6
",copybara-service[bot],2024-09-30 19:31:49+00:00,[],2024-10-02 20:15:15+00:00,2024-10-02 20:15:15+00:00,https://github.com/tensorflow/tensorflow/pull/76821,[],[],
2557483077,pull_request,closed,,PR #16520: [ROCM] ResetStream function for GemmAlgorithmPicker (BlasSupport interface),"PR #16520: [ROCM] ResetStream function for GemmAlgorithmPicker (BlasSupport interface)

Imported from GitHub PR https://github.com/openxla/xla/pull/16520

Here I added **ResetStream** function which sets the underlying stream for cublas/rocblas libraries to default stream 0.

This is useful for GemmAlgorithmPicker which uses a temporary stream object for autotuning. In rocblas, **rocblas_set_stream** function is **persistent**, meaning that once the stream value is set, it will be used in all subsequent computations until new stream value is set. 

In case of GemmAlgorithmPicker, we leave a **destroyed** stream object set into the math library. This does not produce any error behaviour but merely just a warning on ROCM side: ""Stream Capture Check Failed"".

With this new ResetStream function, one can reset the stream value in GemmAlgorithmPicker destructor. Potentially, it can also be useful in other places where temporary stream value is used.

Besides, I have also made some small code restructure for GemmAlgorithmPicker

@xla-rotation: could you have a look please? 

Copybara import of the project:

--
2bd0cf22c50b6724a7facd2471800dc31d1eb39d by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

set stream to null at the end of rocm_blas gemm function call

--
436d073c727ede53e562acd33ce622d3d4a67d74 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

fixing buildbreaks

--
9347c71f2e691808beee8925a9b5e7a792198b25 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

added test for reset_stream

--
bb009b08edcecc8234db2e80ae34dfbe5d7c8513 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

changed IsMainStreamSet interface

Merging this change closes #16520

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16520 from ROCm:ci_blas_reset_stream bb009b08edcecc8234db2e80ae34dfbe5d7c8513
",copybara-service[bot],2024-09-30 19:29:56+00:00,[],2024-10-01 20:09:29+00:00,2024-10-01 20:09:28+00:00,https://github.com/tensorflow/tensorflow/pull/76820,[],[],
2557474516,pull_request,open,,[XLA:GPU] Fix the derivation for the number of warps for tiled HLO computations.,"[XLA:GPU] Fix the derivation for the number of warps for tiled HLO computations.

The number of warps used to process a computation determines how many
registers we are able to use concurrently. Therefore, looking at the largest
(padded) tile size makes sense, since it determines the minimum number of
elements that must be live concurrently.

Previously, the logic erroneously only looked at the output tile sizes.

This approach is not perfect, and may be further improved by e.g. doing a
live range analysis on the tiles of the computation.
",copybara-service[bot],2024-09-30 19:24:47+00:00,[],2024-09-30 19:24:47+00:00,,https://github.com/tensorflow/tensorflow/pull/76819,[],[],
2557433888,pull_request,open,,PR #15577: [PJRT:GPU] Add setting for mocked number of hosts per slice,"PR #15577: [PJRT:GPU] Add setting for mocked number of hosts per slice

Imported from GitHub PR https://github.com/openxla/xla/pull/15577

With the existing `enable_mock_nccl` setting it is impossible to warm up compilation cache when there are multiple processes per node. This is because the cache key includes topology and GPU topology contains information about number of slices and number of hosts per slice. The current mocking of topologies always sets num_hosts_per_slice to 1. However, if you have multiple GPUs on a node and run a process-per-GPU then num_hosts_per_slice must be set to the number of GPUs.

This patch allows setting num_hosts_per_slice explicitly when creating the GPU client.
Copybara import of the project:

--
b88208eb908942660bc74764558297eecb684813 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Add setting for number of hosts per slice

--
0e3200a556e3bd2599cf2fbfeb9ce24e39df8906 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Specify topology as ""slice x hosts_per_slice""

--
237308db034c94de61e869ec394f98a54dd12669 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Change topology description to include #devices-per-host

--
813c234abda25274e3bd18a22a20e529e3e33a13 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Add default value to BuildDistributedDevices new parameter

Merging this change closes #15577

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/15577 from jaro-sevcik:mock-num-hosts-per-slice 813c234abda25274e3bd18a22a20e529e3e33a13
",copybara-service[bot],2024-09-30 19:00:52+00:00,[],2024-10-03 22:23:11+00:00,,https://github.com/tensorflow/tensorflow/pull/76818,[],[],
2557431051,pull_request,open,,copy the legalize tf passes under lite/stablehlo,"copy the legalize tf passes under lite/stablehlo

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17737 from PragmaTwice:fix-typo 17575b22ef2fa43d9409c2b29ea408e3fc958155
",copybara-service[bot],2024-09-30 18:59:17+00:00,[],2024-09-30 18:59:17+00:00,,https://github.com/tensorflow/tensorflow/pull/76817,[],[],
2557423571,pull_request,open,,PR #17704: [jax.distributed] Allow enabling grpc channel compression,"PR #17704: [jax.distributed] Allow enabling grpc channel compression

Imported from GitHub PR https://github.com/openxla/xla/pull/17704

Allows passing an additional boolean argument `use_compression` via `xla_extension.get_distributed_runtime_client(...)` that controls whether compression is enabled on the gRPC channels created for each distributed runtime client.

Motivation: XLA sends O(mesh) [device topologies](https://github.com/openxla/xla/blob/9fb4f21c3542c10b6a5bd98144801bbeec10b489/xla/pjrt/distributed/protocol.proto#L84) through its centralized coordination service and we have reason to believe that this becomes a bottleneck at large scale. Compression of the underlying gRPC communication is currently implicitly disabled, and might give us a cheap avenue to scale a bit further with the centralized KV store design.

One small note: I refrained from adding `use_compression` to `DistributedRuntimeClient::Options` because the new flag is only relevant during channel creation in `distributed.cc`, but not within `DistributedRuntimeClient`. If we added `use_compression` to Options then the `GetDistributedRuntimeClient(channel, options)` defined in `client.cc` would seem to allow controlling compression, but it's really ignored. Let me know if you'd rather go that way.

Corresponding JAX PR: https://github.com/jax-ml/jax/pull/23969
Copybara import of the project:

--
ab6d053eb0e2ea1c2153a55e59eed83cd3d027c9 by Georg Stefan Schmid <gschmid@nvidia.com>:

[jax.distributed] Allow enabling grpc channel compression

Merging this change closes #17704

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17704 from gspschmid:gschmid/dist-compression ab6d053eb0e2ea1c2153a55e59eed83cd3d027c9
",copybara-service[bot],2024-09-30 18:54:35+00:00,[],2024-10-03 22:25:50+00:00,,https://github.com/tensorflow/tensorflow/pull/76816,[],[],
2557349604,pull_request,open,,internal changes (to be reverted),"internal changes (to be reverted)
",copybara-service[bot],2024-09-30 18:13:36+00:00,[],2024-10-01 01:28:22+00:00,,https://github.com/tensorflow/tensorflow/pull/76815,[],[],
2557316862,pull_request,closed,,Allow callers to tell IFRT whether to populate `ExecuteResult::status` or not,"Allow callers to tell IFRT whether to populate `ExecuteResult::status` or not

When `xla::ifrt::ExecuteOptions::fill_status` is false, the IFRT implementation does not populate `ExecuteResult::status`, whihc may be more efficient in some IFRT implementations. If `fill_status` is true, the implementation tries to fulfill the promise as soon as execution is complete.

The default value is set to false because most IFRT users today don't use `ExecuteResult::status`. Existing code that queries `ExecuteResult::status` has been updated to explicitly set `fill_status` to true.
",copybara-service[bot],2024-09-30 17:54:22+00:00,[],2024-10-01 20:43:05+00:00,2024-10-01 20:43:04+00:00,https://github.com/tensorflow/tensorflow/pull/76814,[],[],
2557315737,pull_request,closed,,Preserve HLO shardings on calls and non-entry functions.,"Preserve HLO shardings on calls and non-entry functions.

XLA doesn't inline call instructions and their functions if the call instruction has `backend_config`. As such in Shardy we do the same. GSPMD propagation also adds shardings on the call instruction and function inputs/outputs.

However, when given this module:
```mlir
module @jit_f attributes {mhlo.cross_program_prefetches = [], mhlo.input_output_alias = [], mhlo.is_dynamic = true, mhlo.num_partitions = 4 : i32, mhlo.use_auto_spmd_partitioning = false} {
  func.func @main(%arg0: tensor<8x2xi32> {mhlo.sharding = ""{devices=[2,2]<=[4]}""} loc(""x"")) -> (tensor<8x2xi32> {mhlo.sharding = ""{devices=[2,2]<=[4]}""}) {
    %0 = call @called_computation(%arg0) {mhlo.frontend_attributes = {backend_config = ""{\22flag_configs\22:[],\22scoped_memory_configs\22:[],\22device_type\22:\22DEVICE_TYPE_HOST\22,\22used_scoped_memory_configs\22:[]}""}, mhlo.sharding = ""{devices=[2,2]<=[4]}""} : (tensor<8x2xi32>) -> tensor<8x2xi32> loc(#loc33)
    %1 = mhlo.custom_call @MoveToHost(%0) {backend_config = """", mhlo.sharding = ""{devices=[2,2]<=[4]}""} : (tensor<8x2xi32>) -> tensor<8x2xi32> loc(#loc12)
    return %1 : tensor<8x2xi32> loc(#loc)
  } loc(#loc)
  func.func private @called_computation(%arg0: tensor<8x2xi32> {mhlo.sharding = ""{devices=[2,2]<=[4]}""} loc(""param_0"")) -> (tensor<8x2xi32> {mhlo.sharding = ""{devices=[2,2]<=[4]}""}) {
    %0 = mhlo.multiply %arg0, %arg0 {mhlo.frontend_attributes = {_xla_compute_type = ""host""}, mhlo.sharding = ""{devices=[2,2]<=[4]}""} : tensor<8x2xi32> loc(#loc33)
    return %0 : tensor<8x2xi32>
  }
}
```

HLO conversion removes the call instruction and `@called_computation` shardings. This PR preserves them.
",copybara-service[bot],2024-09-30 17:53:44+00:00,[],2024-10-09 15:03:12+00:00,2024-10-09 15:03:11+00:00,https://github.com/tensorflow/tensorflow/pull/76813,[],[],
2557281593,pull_request,open,,Copy and rework flatbuffer_conversions.h into compiler,"Copy and rework flatbuffer_conversions.h into compiler

Reverts d84b856d969201974a8bd1c5a93f75fbd08ea465
",copybara-service[bot],2024-09-30 17:36:01+00:00,[],2024-10-14 15:51:46+00:00,,https://github.com/tensorflow/tensorflow/pull/76812,[],[],
2557277237,pull_request,closed,,[xla:cpu] Add a flag `xla_cpu_max_isa` to limit the features that LLVM will codegen.,"[xla:cpu] Add a flag `xla_cpu_max_isa` to limit the features that LLVM will codegen.

The flag doesn't do anything in this PR. Implementation is in a separate PR (#17722).
",copybara-service[bot],2024-09-30 17:33:42+00:00,['penpornk'],2024-10-01 19:07:59+00:00,2024-10-01 19:07:58+00:00,https://github.com/tensorflow/tensorflow/pull/76811,[],[],
2557255518,pull_request,closed,,Remove XLA_BACKEND_SUPPORTS_BFLOAT16 macro. This macro is set for all devices so it can be cleaned up.,"Remove XLA_BACKEND_SUPPORTS_BFLOAT16 macro. This macro is set for all devices so it can be cleaned up.
",copybara-service[bot],2024-09-30 17:22:26+00:00,[],2024-09-30 21:49:08+00:00,2024-09-30 21:49:07+00:00,https://github.com/tensorflow/tensorflow/pull/76810,[],[],
2557205211,pull_request,closed,,PR #17737: [XLA:GPU] Rename `uint32_count` to `uint8_count` in `GPUDriver::AsynchronousMemsetUint8`,"PR #17737: [XLA:GPU] Rename `uint32_count` to `uint8_count` in `GPUDriver::AsynchronousMemsetUint8`

Imported from GitHub PR https://github.com/openxla/xla/pull/17737

In `GpuDriver::AsynchronousMemsetUint8`, the count should be in bytes, instead of in uint32.
Copybara import of the project:

--
17575b22ef2fa43d9409c2b29ea408e3fc958155 by PragmaTwice <twice@apache.org>:

[XLA:GPU] Rename uint32_count to uint8_count in GPUDriver::AsynchronousMemsetUint8

Merging this change closes #17737

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17737 from PragmaTwice:fix-typo 17575b22ef2fa43d9409c2b29ea408e3fc958155
",copybara-service[bot],2024-09-30 17:02:15+00:00,[],2024-09-30 18:55:24+00:00,2024-09-30 18:55:24+00:00,https://github.com/tensorflow/tensorflow/pull/76809,[],[],
2557200658,pull_request,closed,,Get the initial value for `useNewBackend` from the server.,"Get the initial value for `useNewBackend` from the server.
",copybara-service[bot],2024-09-30 17:00:17+00:00,[],2024-09-30 18:44:33+00:00,2024-09-30 18:44:32+00:00,https://github.com/tensorflow/tensorflow/pull/76808,[],[],
2557180012,pull_request,closed,,[XLA:GPU] Fix the derivation for the number of warps for tiled HLO computations.,"[XLA:GPU] Fix the derivation for the number of warps for tiled HLO computations.

The number of warps used to process a computation determines how many
registers we are able to use concurrently. Therefore, looking at the largest
(padded) tile size makes sense, since it determines the minimum number of
elements that must be live concurrently.

Previously, the logic erroneously only looked at the output tile sizes.

This approach is not perfect, and may be further improved by e.g. doing a
live range analysis on the tiles of the computation.
",copybara-service[bot],2024-09-30 16:48:32+00:00,[],2024-09-30 19:29:48+00:00,2024-09-30 19:29:47+00:00,https://github.com/tensorflow/tensorflow/pull/76807,[],[],
2557105203,pull_request,closed,,[XLA:GPU][IndexAnalysis] Move RTVars folding logic to indexing_analysis.,"[XLA:GPU][IndexAnalysis] Move RTVars folding logic to indexing_analysis.

RTVars now don't depend on HloInstruction*.
",copybara-service[bot],2024-09-30 16:11:08+00:00,['pifon2a'],2024-10-01 21:00:36+00:00,2024-10-01 21:00:36+00:00,https://github.com/tensorflow/tensorflow/pull/76806,[],[],
2557096483,pull_request,closed,,Updates GenerateScatterShardingFromOperands() to avoid hash sets (whose iteration order is nondeterministic).,"Updates GenerateScatterShardingFromOperands() to avoid hash sets (whose iteration order is nondeterministic).
",copybara-service[bot],2024-09-30 16:07:03+00:00,[],2024-09-30 17:38:02+00:00,2024-09-30 17:38:01+00:00,https://github.com/tensorflow/tensorflow/pull/76805,[],[],
2557031052,pull_request,closed,,[XLA:GPU] Disable cublas for BF16_BF6_F32 on Hopper because it uses the TF32_TF32_F32 kernel instead. ,"[XLA:GPU] Disable cublas for BF16_BF6_F32 on Hopper because it uses the TF32_TF32_F32 kernel instead. 

We have to keep the precision guarantees when dot has the explicit algorithm property set as BF16_BF16_F32.
",copybara-service[bot],2024-09-30 15:37:08+00:00,[],2024-10-01 16:33:00+00:00,2024-10-01 16:32:59+00:00,https://github.com/tensorflow/tensorflow/pull/76804,[],[],
2557023292,pull_request,closed,,[XLA:GPU] Add sub-byte normalization after TransposeDimensionGrouper,"[XLA:GPU] Add sub-byte normalization after TransposeDimensionGrouper

TransposeDimensionGrouper inserts bitcasts, and XLA requires subbyte types (int4 in this case) to have explicit bit witdth.
",copybara-service[bot],2024-09-30 15:33:56+00:00,[],2024-09-30 17:26:03+00:00,2024-09-30 17:26:02+00:00,https://github.com/tensorflow/tensorflow/pull/76803,[],[],
2556937554,pull_request,closed,,Set the output tensor byte size in reshape to the input tensor byte size.,"Set the output tensor byte size in reshape to the input tensor byte size.

Reshape doesn't alter it's data, and when it is prepared, we know it's inputs
have a correct shape/byte size (because dynamicaly shaped tensors stop the
prepare cycle and force an eval one before restarting a prepare cycle).

This allows the ArenaPlanner to match the dynamic Reshape input and output
tensors and reuse the input tensor data for the output tensor.
",copybara-service[bot],2024-09-30 14:57:48+00:00,['qukhan'],2024-09-30 21:06:54+00:00,2024-09-30 21:06:53+00:00,https://github.com/tensorflow/tensorflow/pull/76802,[],[],
2556861833,pull_request,closed,,[XLA:GPU][IndexAnalysis] Move RTVars folding tests to indexing_analysis_test.,"[XLA:GPU][IndexAnalysis] Move RTVars folding tests to indexing_analysis_test.

Next step will be moving the folding to indexing_analysis.cc and removing `hlo` and `map` fields from RTVar struct.
",copybara-service[bot],2024-09-30 14:28:27+00:00,['pifon2a'],2024-09-30 16:21:26+00:00,2024-09-30 16:21:24+00:00,https://github.com/tensorflow/tensorflow/pull/76801,[],[],
2556778934,pull_request,closed,,Enable expand dims in the xnnpack delegate,"Enable expand dims in the xnnpack delegate
",copybara-service[bot],2024-09-30 13:59:21+00:00,['alankelly'],2024-10-02 17:20:38+00:00,2024-10-02 17:20:37+00:00,https://github.com/tensorflow/tensorflow/pull/76800,[],[],
2556772404,pull_request,closed,,[tsl] Add functions to check if a CPU is x86/aarch64.,"[tsl] Add functions to check if a CPU is x86/aarch64.
",copybara-service[bot],2024-09-30 13:57:52+00:00,['penpornk'],2024-09-30 15:38:14+00:00,2024-09-30 15:38:13+00:00,https://github.com/tensorflow/tensorflow/pull/76799,[],[],
2556665645,pull_request,open,,Add a missing include,"Add a missing include
",copybara-service[bot],2024-09-30 13:20:30+00:00,[],2024-09-30 13:20:30+00:00,,https://github.com/tensorflow/tensorflow/pull/76798,[],[],
2556657600,pull_request,open,,Add more elementwise ops with bf16 support on Hopper.,"Add more elementwise ops with bf16 support on Hopper.

There are a few more elementwise ops where we don't need to convert to f32 when
running on Hopper.
",copybara-service[bot],2024-09-30 13:18:09+00:00,['akuegel'],2024-09-30 13:18:10+00:00,,https://github.com/tensorflow/tensorflow/pull/76797,[],[],
2556504439,pull_request,closed,,Integrate Triton up to [6fa4f504](https://github.com/openai/triton/commits/6fa4f504d61e48f7cea454ce0c1f6169907d5aaa),"Integrate Triton up to [6fa4f504](https://github.com/openai/triton/commits/6fa4f504d61e48f7cea454ce0c1f6169907d5aaa)
",copybara-service[bot],2024-09-30 12:27:55+00:00,[],2024-10-02 09:46:31+00:00,2024-10-02 09:46:30+00:00,https://github.com/tensorflow/tensorflow/pull/76796,[],[],
2556338586,pull_request,closed,,Dynamic update slice optimizations:,"Dynamic update slice optimizations:
If the update tensor is the entirety of the output, then simply copy it and return.

Replace the per element index calculation with a recursive function which memcpys the contiguous dimension.
",copybara-service[bot],2024-09-30 11:17:08+00:00,['alankelly'],2024-09-30 13:20:54+00:00,2024-09-30 13:20:53+00:00,https://github.com/tensorflow/tensorflow/pull/76795,[],[],
2556239011,pull_request,open,,Integrate LLVM at llvm/llvm-project@ac2a2816e3fe,"Integrate LLVM at llvm/llvm-project@ac2a2816e3fe

Updates LLVM usage to match
[ac2a2816e3fe](https://github.com/llvm/llvm-project/commit/ac2a2816e3fe)
",copybara-service[bot],2024-09-30 10:35:54+00:00,[],2024-10-01 06:32:09+00:00,,https://github.com/tensorflow/tensorflow/pull/76793,[],[],
2556150545,pull_request,closed,,Add QoS/Preemption options to MtkNeuronSettings,"Add QoS/Preemption options to MtkNeuronSettings
",copybara-service[bot],2024-09-30 09:56:56+00:00,[],2024-10-18 03:13:32+00:00,2024-10-18 03:13:31+00:00,https://github.com/tensorflow/tensorflow/pull/76792,[],[],
2555918779,pull_request,closed,,Move CreateDeviceDescription to CudaExecutor and RocmExecutor and add tests,"Move CreateDeviceDescription to CudaExecutor and RocmExecutor and add tests

The function is only being called from backend-specific code (from `{cuda|rocm}_executor.cc` and `{cuda|rocm}_platform.cc`, so there is no need
for it to be present in `GpuExecutor`.

I also had to complete the comparison operators for `CudaComputeCapability` and
added tests for that.
",copybara-service[bot],2024-09-30 08:20:31+00:00,[],2024-09-30 12:40:09+00:00,2024-09-30 12:40:08+00:00,https://github.com/tensorflow/tensorflow/pull/76791,[],[],
2555810204,pull_request,open,,Reverts 86e1d9fcbc2d4437c6c418308e9c5dd27c48b38d,"Reverts 86e1d9fcbc2d4437c6c418308e9c5dd27c48b38d
",copybara-service[bot],2024-09-30 07:28:06+00:00,[],2024-09-30 07:28:06+00:00,,https://github.com/tensorflow/tensorflow/pull/76790,[],[],
2555701624,pull_request,closed,,PR #17719: Allow compare/select on int4 data,"PR #17719: Allow compare/select on int4 data

Imported from GitHub PR https://github.com/openxla/xla/pull/17719

A simple HLO with kCompare and kSelect opcodes doesn't work for int4 types.
This PR fixes the issue.
Copybara import of the project:

--
467bb68c4d2a1d1776c7254666a93bba90156bf1 by Sergey Kozub <skozub@nvidia.com>:

Allow compare/select on int4 data

Merging this change closes #17719

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17719 from openxla:skozub/int4_select 467bb68c4d2a1d1776c7254666a93bba90156bf1
",copybara-service[bot],2024-09-30 06:39:41+00:00,[],2024-09-30 17:46:02+00:00,2024-09-30 17:46:01+00:00,https://github.com/tensorflow/tensorflow/pull/76789,[],[],
2555700492,pull_request,closed,,Remove cuda_only_cc_library,"Remove cuda_only_cc_library

Since now we can exclude targets from building using tags, we won't need the `cuda_only_cc_library` rule anymore.

This also required me to remove some wrongly added dependencies, notably I found several targets depending on cublas_plugin, even though those targets were not CUDA specific and shouldn't directly depend on CUDA-specific targets.

I also found out that the `tsl_gpu_library` macro is not handling its `cuda_deps` attribute correctly. It was adding those dependencies both for ROCm and for CUDA. So this change is fixing that as well.
",copybara-service[bot],2024-09-30 06:39:01+00:00,[],2024-09-30 09:18:53+00:00,2024-09-30 09:18:52+00:00,https://github.com/tensorflow/tensorflow/pull/76788,[],[],
2555526352,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 04:43:51+00:00,[],2024-09-30 04:43:51+00:00,,https://github.com/tensorflow/tensorflow/pull/76787,[],[],
2555477855,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 04:03:09+00:00,[],2024-09-30 04:03:09+00:00,,https://github.com/tensorflow/tensorflow/pull/76786,[],[],
2555477687,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 04:03:00+00:00,[],2024-09-30 04:03:00+00:00,,https://github.com/tensorflow/tensorflow/pull/76785,[],[],
2555475430,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 04:01:02+00:00,[],2024-09-30 04:01:02+00:00,,https://github.com/tensorflow/tensorflow/pull/76784,[],[],
2555467927,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 03:53:31+00:00,[],2024-10-01 13:41:19+00:00,,https://github.com/tensorflow/tensorflow/pull/76783,[],[],
2555467561,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 03:53:07+00:00,[],2024-10-01 09:29:46+00:00,2024-10-01 09:29:45+00:00,https://github.com/tensorflow/tensorflow/pull/76782,[],[],
2555467029,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 03:52:33+00:00,[],2024-09-30 03:52:33+00:00,,https://github.com/tensorflow/tensorflow/pull/76781,[],[],
2555466123,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 03:51:32+00:00,[],2024-09-30 03:51:32+00:00,,https://github.com/tensorflow/tensorflow/pull/76780,[],[],
2555465172,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 03:50:23+00:00,[],2024-10-01 07:56:01+00:00,2024-10-01 07:56:00+00:00,https://github.com/tensorflow/tensorflow/pull/76779,[],[],
2555464870,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 03:50:01+00:00,[],2024-09-30 03:50:01+00:00,,https://github.com/tensorflow/tensorflow/pull/76778,[],[],
2555464795,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 03:49:56+00:00,[],2024-09-30 03:49:56+00:00,,https://github.com/tensorflow/tensorflow/pull/76777,[],[],
2555463997,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 03:49:00+00:00,[],2024-09-30 03:49:00+00:00,,https://github.com/tensorflow/tensorflow/pull/76776,[],[],
2555460401,pull_request,open,,Add explicit includes to fix Kokoro compile issues.,"Add explicit includes to fix Kokoro compile issues.
",copybara-service[bot],2024-09-30 03:44:54+00:00,[],2024-09-30 03:44:54+00:00,,https://github.com/tensorflow/tensorflow/pull/76775,[],[],
2555377175,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 02:17:10+00:00,[],2024-09-30 02:17:10+00:00,,https://github.com/tensorflow/tensorflow/pull/76774,[],[],
2555362100,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-09-30 01:59:46+00:00,[],2024-09-30 01:59:46+00:00,,https://github.com/tensorflow/tensorflow/pull/76773,[],[],
