id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2736927192,pull_request,closed,,Add missing default for `xla_gpu_triton_gemm_disable_reduced_precision_reduction`,"Add missing default for `xla_gpu_triton_gemm_disable_reduced_precision_reduction`
",copybara-service[bot],2024-12-12 21:36:53+00:00,['frgossen'],2024-12-17 20:09:30+00:00,2024-12-17 20:09:29+00:00,https://github.com/tensorflow/tensorflow/pull/82861,[],[],
2736912284,pull_request,closed,,Update the compiler plugin api to partition at the level of subgraph rather than model. This allows associating selected ops with their parent subgraph.,"Update the compiler plugin api to partition at the level of subgraph rather than model. This allows associating selected ops with their parent subgraph.
",copybara-service[bot],2024-12-12 21:27:43+00:00,['LukeBoyer'],2024-12-13 05:57:40+00:00,2024-12-13 05:57:40+00:00,https://github.com/tensorflow/tensorflow/pull/82860,[],[],
2736911763,pull_request,closed,,Add dynamic_arg_layouts to C++ cache and add a test in JAX which checks for cache miss if layouts of inputs arguments are different to the same jitted function.,"Add dynamic_arg_layouts to C++ cache and add a test in JAX which checks for cache miss if layouts of inputs arguments are different to the same jitted function.
",copybara-service[bot],2024-12-12 21:27:19+00:00,['yashk2810'],2024-12-13 03:03:38+00:00,2024-12-13 03:03:38+00:00,https://github.com/tensorflow/tensorflow/pull/82859,[],[],
2736898877,pull_request,open,,Remove CHECK macros from tsl/platform/default/logging.h,"Remove CHECK macros from tsl/platform/default/logging.h
",copybara-service[bot],2024-12-12 21:19:04+00:00,[],2025-01-16 09:54:18+00:00,,https://github.com/tensorflow/tensorflow/pull/82858,[],[],
2736898643,pull_request,closed,,[XLA:Python] Mark from_python and from_cpp methods of nanobind typecasters as noexcept.,"[XLA:Python] Mark from_python and from_cpp methods of nanobind typecasters as noexcept.

This is technically a requirement for typecasters (https://nanobind.readthedocs.io/en/latest/porting.html#type-casters).
",copybara-service[bot],2024-12-12 21:18:55+00:00,[],2024-12-13 02:33:18+00:00,2024-12-13 02:33:18+00:00,https://github.com/tensorflow/tensorflow/pull/82857,[],[],
2736863369,pull_request,closed,,Avoid redundant copies of `std::vector<DeviceMemoryTransfer>`,"Avoid redundant copies of `std::vector<DeviceMemoryTransfer>`
",copybara-service[bot],2024-12-12 20:54:45+00:00,['cliveverghese'],2024-12-16 19:32:51+00:00,2024-12-16 19:32:50+00:00,https://github.com/tensorflow/tensorflow/pull/82856,[],[],
2736821731,pull_request,open,,Add the ATL library - temporary fix for internal CI.,"Add the ATL library - temporary fix for internal CI.
",copybara-service[bot],2024-12-12 20:28:47+00:00,['belitskiy'],2024-12-12 20:28:48+00:00,,https://github.com/tensorflow/tensorflow/pull/82855,[],[],
2736809765,pull_request,closed,,Add unit tests for model load/serialize with multi subgraph.,"Add unit tests for model load/serialize with multi subgraph.
",copybara-service[bot],2024-12-12 20:21:19+00:00,['LukeBoyer'],2024-12-13 01:54:53+00:00,2024-12-13 01:54:52+00:00,https://github.com/tensorflow/tensorflow/pull/82854,[],[],
2736737712,pull_request,closed,,Migrate StableHLO Python extension to nanobind.,"Migrate StableHLO Python extension to nanobind.

I'm working towards moving the MLIR Python core code to use nanobind instead of pybind11:
* https://github.com/llvm/llvm-project/pull/117922, which was merged recently, allows downstream Python dialect extensions to be defined using either pybind11 or nanobind.
* https://github.com/llvm/llvm-project/pull/118583 is a PR in review that ports the Python core code to use nanobind instead of pybind11.

This PR migrates StableHLO and related dialects to use nanobind rather than pybind11, with the goal of migrating JAX away from pybind11.
",copybara-service[bot],2024-12-12 19:40:40+00:00,[],2024-12-18 15:12:52+00:00,2024-12-18 15:12:51+00:00,https://github.com/tensorflow/tensorflow/pull/82853,[],[],
2736719078,pull_request,open,,Integrate LLVM at llvm/llvm-project@03cbe42627c7,"Integrate LLVM at llvm/llvm-project@03cbe42627c7

Updates LLVM usage to match
[03cbe42627c7](https://github.com/llvm/llvm-project/commit/03cbe42627c7)
",copybara-service[bot],2024-12-12 19:30:12+00:00,[],2024-12-12 19:30:12+00:00,,https://github.com/tensorflow/tensorflow/pull/82852,[],[],
2736683350,pull_request,closed,,Fix range analysis bug.,"Fix range analysis bug.

The way we multiply operand ranges with constant is wrong because step was not multiplied when the operand is constant.
",copybara-service[bot],2024-12-12 19:09:05+00:00,[],2024-12-13 03:46:40+00:00,2024-12-13 03:46:39+00:00,https://github.com/tensorflow/tensorflow/pull/82851,[],[],
2736669398,pull_request,closed,,Update TensorBufferScopedLock to use LiteRtTensorBuffer,"Update TensorBufferScopedLock to use LiteRtTensorBuffer

So we don't need to create temporal TensorBuffer objects.
",copybara-service[bot],2024-12-12 19:00:45+00:00,['terryheo'],2024-12-13 19:40:50+00:00,2024-12-13 19:40:49+00:00,https://github.com/tensorflow/tensorflow/pull/82850,[],[],
2736597874,pull_request,closed,,Enable pywrap rules for LinuxCPU builds,"Enable pywrap rules for LinuxCPU builds
",copybara-service[bot],2024-12-12 18:19:22+00:00,['vam-google'],2024-12-17 19:06:45+00:00,2024-12-17 19:06:44+00:00,https://github.com/tensorflow/tensorflow/pull/82849,[],[],
2736547182,pull_request,closed,,[XLA:CPU] Improve F8E4M3 and F8E3M4 accuracy,"[XLA:CPU] Improve F8E4M3 and F8E3M4 accuracy

Related to https://github.com/openxla/xla/issues/17324
",copybara-service[bot],2024-12-12 17:52:46+00:00,[],2024-12-23 21:10:16+00:00,2024-12-23 21:10:15+00:00,https://github.com/tensorflow/tensorflow/pull/82848,[],"[{'comment_id': 2539624925, 'issue_id': 2736547182, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82848/checks?check_run_id=34333848889) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 12, 17, 52, 52, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-12 17:52:52 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82848/checks?check_run_id=34333848889) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2736497478,pull_request,closed,,[XLA:GPU] Force cuDNN convolutions to be assigned a `NHWC` layout from Hopper.,"[XLA:GPU] Force cuDNN convolutions to be assigned a `NHWC` layout from Hopper.

This is the best way to use convolutions on tensor cores, according to
[NVIDIA's documentation](https://docs.nvidia.com/deeplearning/performance/dl-performance-convolutional/index.html#tensor-layout).

Extending that to pre-Hopper GPUs is left for a future change. We also filter
out a few cases that are simply not supported by cuDNN.
",copybara-service[bot],2024-12-12 17:27:14+00:00,[],2024-12-17 12:22:43+00:00,2024-12-17 12:22:41+00:00,https://github.com/tensorflow/tensorflow/pull/82847,[],[],
2736497264,pull_request,closed,,[XLA::CPU] Update `ElementalKernelEmitter` to take HLO instruction instead of shapes.,"[XLA::CPU] Update `ElementalKernelEmitter` to take HLO instruction instead of shapes.
",copybara-service[bot],2024-12-12 17:27:08+00:00,[],2024-12-16 12:19:22+00:00,2024-12-16 12:19:21+00:00,https://github.com/tensorflow/tensorflow/pull/82846,[],[],
2736434857,pull_request,closed,,Fix 02 broken links in bert_nl_classifier.md,"Hi, Team
I found 02 broken documentation links for [TensorFlow Lite Model Maker for text Classfication](https://www.tensorflow.org/lite/models/modify/model_maker/text_classification) and [MobileBert](https://www.tensorflow.org/lite/models/modify/model_maker/text_classification) hyperlinks in this [Integrate BERT natural language classifier ](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/inference_with_metadata/task_library/bert_nl_classifier.md)file so I have updated those links to functional link. Please review and merge this change as appropriate.

Thank you for your consideration.",gaikwadrahul8,2024-12-12 16:58:13+00:00,['gbaned'],2024-12-16 06:29:28+00:00,2024-12-16 06:29:28+00:00,https://github.com/tensorflow/tensorflow/pull/82845,"[('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2736432448,pull_request,closed,,PR #20109: Create a workflow to run CPU benchmarks,"PR #20109: Create a workflow to run CPU benchmarks

Imported from GitHub PR https://github.com/openxla/xla/pull/20109

- Create a workflow to run OpenXLA CPU/GPU/TPU benchmarks to measure performance improvements and regression. 

Copybara import of the project:

--
944a401992e46242e40af211d1e0eb07180dbbf4 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Create benchmarks.yml
--
5a31afcfefe05b569b97cb943b66d9f3e882aab8 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
551e23791be102e3f105bc407c71e5f3722f50a9 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
abbc701662100c6b96338f07259408b81b46c0b3 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
712c9b866b8f25a4da8c12ef576421b971bf2011 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
255a8fff366814e900755b18c591ff6d051f23e9 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
9a3bb7d7131c817a2b06ab521a195804511a8ee7 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
cf95a041a544197ca6f65f1a2443fe0ed7f161c6 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
da77242e674b1957ea364385676bcf1139461049 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
b08d632543ee921642bd703f25f80dae7645b44d by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update benchmarks.yml
--
e6fc10f8e53c89eef3427d4d35d015982f39df6b by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update and rename benchmarks.yml to cpu_benchmarks.yml
--
4349b2e49f67a9e71ad704f56c38056bd5d7eea2 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml
--
bcce7a7e2e604af4f718a6abff98e3e6c937c6a5 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml
--
ee5b591e30f87dedccb06e627a3957756084c8a2 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml
--
3ad84596053f0669cbdaa5f9cd02a50b965a25f2 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml
--
cd9d339ae0256eb704bd6f53f346f140d112349b by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml
--
4c30d819b4373c981080301974d1ac54db23ccc6 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml
--
7e22bae1a5cde532d1c4473277271c2c35542ec6 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml
--
eed90264df299bed261c31b82d598232e296536a by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml
--
03da4b7361f08814e44ef5955a4b241787d03bb2 by Julia Guo <153684546+juliagmt-google@users.noreply.github.com>:

Update cpu_benchmarks.yml

Merging this change closes #20109

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20109 from juliagmt-google:main 03da4b7361f08814e44ef5955a4b241787d03bb2
",copybara-service[bot],2024-12-12 16:57:09+00:00,[],2024-12-13 18:42:40+00:00,2024-12-13 18:42:39+00:00,https://github.com/tensorflow/tensorflow/pull/82844,[],[],
2736396708,pull_request,closed,,[XLA:GPU] Rely on LLVM parser rather than objcopy to load fatbin in tests ,"[XLA:GPU] Rely on LLVM parser rather than objcopy to load fatbin in tests 

To avoid relying on `objcopy` from toolchains
",copybara-service[bot],2024-12-12 16:41:42+00:00,[],2025-01-07 10:45:06+00:00,2025-01-07 10:45:04+00:00,https://github.com/tensorflow/tensorflow/pull/82843,[],[],
2736354735,pull_request,closed,,[XLA:GPU] Readability and performance nits.,"[XLA:GPU] Readability and performance nits.
",copybara-service[bot],2024-12-12 16:22:59+00:00,[],2024-12-13 11:40:08+00:00,2024-12-13 11:40:06+00:00,https://github.com/tensorflow/tensorflow/pull/82842,[],[],
2736253624,pull_request,closed,,Fix 02 broken links in audio_classifier.md,"Hi, Team
I found 02 broken documentation links for [TensorFlow Lite Model Maker for Audio Classification](https://www.tensorflow.org/lite/api_docs/python/tflite_model_maker/audio_classifier) and [AudioRecord](https://github.com/tensorflow/tensorflow/blob/master/lite/api_docs/python/tflite_support/task/audio/AudioRecord) hyperlinks in this [Integrate audio classifiers](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/inference_with_metadata/task_library/audio_classifier.md) file so I have updated those links to functional links. Please review and merge this change as appropriate.

Thank you for your consideration.",gaikwadrahul8,2024-12-12 15:39:37+00:00,['gbaned'],2024-12-16 06:42:36+00:00,2024-12-16 06:42:35+00:00,https://github.com/tensorflow/tensorflow/pull/82841,"[('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2736201257,pull_request,closed,,#sdy add option to avoid escaping attribute when adding to frontend attrs.,"#sdy add option to avoid escaping attribute when adding to frontend attrs.
",copybara-service[bot],2024-12-12 15:18:00+00:00,[],2024-12-12 16:45:54+00:00,2024-12-12 16:45:53+00:00,https://github.com/tensorflow/tensorflow/pull/82840,[],[],
2735978031,pull_request,closed,,[XLA:GPU][Emitters] Move gpu/fusions/ir to backends/gpu/codegen/ir,"[XLA:GPU][Emitters] Move gpu/fusions/ir to backends/gpu/codegen/ir
",copybara-service[bot],2024-12-12 13:50:02+00:00,['metaflow'],2024-12-12 14:52:51+00:00,2024-12-12 14:52:50+00:00,https://github.com/tensorflow/tensorflow/pull/82839,[],[],
2735866920,pull_request,closed,,"Remove stale TODO, ""nomsan"" has been removed already.","Remove stale TODO, ""nomsan"" has been removed already.
",copybara-service[bot],2024-12-12 13:12:37+00:00,[],2024-12-12 15:50:08+00:00,2024-12-12 15:50:07+00:00,https://github.com/tensorflow/tensorflow/pull/82836,[],[],
2735788873,pull_request,closed,,PR #20463: Updated multiple typo's,"PR #20463: Updated multiple typo's

Imported from GitHub PR https://github.com/openxla/xla/pull/20463


Copybara import of the project:

--
60f1cd1010df96d827f64684abd82a0f7b144c99 by nallave <116003489+nallave@users.noreply.github.com>:

Update type_id_registry.h
--
8da0c89a2fbe592b67af565ca01721646769be5b by nallave <116003489+nallave@users.noreply.github.com>:

Commit

Merging this change closes #20463

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20463 from nallave:patch-1 8da0c89a2fbe592b67af565ca01721646769be5b
",copybara-service[bot],2024-12-12 12:39:05+00:00,[],2024-12-12 14:28:59+00:00,2024-12-12 14:28:57+00:00,https://github.com/tensorflow/tensorflow/pull/82835,[],[],
2735724121,pull_request,closed,,[XLA:GPU][Emitters] Move gpu/fusions/transforms to backends/gpu/codegen/transforms,"[XLA:GPU][Emitters] Move gpu/fusions/transforms to backends/gpu/codegen/transforms
",copybara-service[bot],2024-12-12 12:10:05+00:00,['metaflow'],2024-12-12 13:56:05+00:00,2024-12-12 13:56:04+00:00,https://github.com/tensorflow/tensorflow/pull/82834,[],[],
2735668243,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 11:46:22+00:00,[],2024-12-13 05:05:12+00:00,2024-12-13 05:05:04+00:00,https://github.com/tensorflow/tensorflow/pull/82833,[],[],
2735568844,pull_request,closed,,[XLA:CPU] Move kernel prototype properties inside of KernelApiIrBuilder,"[XLA:CPU] Move kernel prototype properties inside of KernelApiIrBuilder
",copybara-service[bot],2024-12-12 10:59:39+00:00,[],2024-12-16 10:43:24+00:00,2024-12-16 10:43:23+00:00,https://github.com/tensorflow/tensorflow/pull/82831,[],[],
2735538520,pull_request,closed,,[XLA:CPU] Add shape method python binding to Literal,"[XLA:CPU] Add shape method python binding to Literal
",copybara-service[bot],2024-12-12 10:47:03+00:00,[],2024-12-13 13:48:53+00:00,2024-12-13 13:48:53+00:00,https://github.com/tensorflow/tensorflow/pull/82830,[],[],
2735511266,pull_request,closed,,Integrate LLVM at llvm/llvm-project@0876c11ceeb0,"Integrate LLVM at llvm/llvm-project@0876c11ceeb0

Updates LLVM usage to match
[0876c11ceeb0](https://github.com/llvm/llvm-project/commit/0876c11ceeb0)
",copybara-service[bot],2024-12-12 10:35:10+00:00,[],2024-12-12 16:23:07+00:00,2024-12-12 16:23:06+00:00,https://github.com/tensorflow/tensorflow/pull/82829,[],[],
2735444974,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 10:07:24+00:00,[],2024-12-16 00:03:37+00:00,2024-12-16 00:03:36+00:00,https://github.com/tensorflow/tensorflow/pull/82828,[],[],
2735440632,pull_request,closed,,[XLA:GPU] Rollback introduction of `EmitterLocOpBuilder`.,"[XLA:GPU] Rollback introduction of `EmitterLocOpBuilder`.

Reverts 65b974a49ff3dd57e2a980638d517b5787e51249
",copybara-service[bot],2024-12-12 10:05:28+00:00,[],2024-12-12 11:06:21+00:00,2024-12-12 11:06:20+00:00,https://github.com/tensorflow/tensorflow/pull/82827,[],[],
2735387374,pull_request,open,,Transfer pre-allocated subgraphs into model. Pop metadata from the model's map.,"Transfer pre-allocated subgraphs into model. Pop metadata from the model's map.
",copybara-service[bot],2024-12-12 09:42:26+00:00,[],2024-12-13 07:46:32+00:00,,https://github.com/tensorflow/tensorflow/pull/82826,[],[],
2735258323,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19099 from Intel-tensorflow:akhil/conv_fusions_3_d 643bf016dbddd644ce71d10efe3c02d212c2888e
",copybara-service[bot],2024-12-12 08:49:48+00:00,[],2024-12-12 12:25:39+00:00,,https://github.com/tensorflow/tensorflow/pull/82825,[],[],
2735204846,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:29:14+00:00,[],2024-12-12 12:16:13+00:00,,https://github.com/tensorflow/tensorflow/pull/82824,[],[],
2735197673,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:25:30+00:00,[],2024-12-14 10:54:16+00:00,2024-12-14 10:54:16+00:00,https://github.com/tensorflow/tensorflow/pull/82823,[],[],
2735192799,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:23:33+00:00,[],2024-12-14 06:00:26+00:00,2024-12-14 06:00:25+00:00,https://github.com/tensorflow/tensorflow/pull/82822,[],[],
2735191747,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:23:09+00:00,[],2024-12-12 08:23:09+00:00,,https://github.com/tensorflow/tensorflow/pull/82821,[],[],
2735185932,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:20:51+00:00,[],2024-12-17 08:07:48+00:00,,https://github.com/tensorflow/tensorflow/pull/82820,[],[],
2735184577,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:20:16+00:00,[],2024-12-12 08:20:16+00:00,,https://github.com/tensorflow/tensorflow/pull/82819,[],[],
2735181362,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:19:01+00:00,[],2024-12-12 08:19:01+00:00,,https://github.com/tensorflow/tensorflow/pull/82818,[],[],
2735169983,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:13:42+00:00,[],2024-12-12 08:13:42+00:00,,https://github.com/tensorflow/tensorflow/pull/82817,[],[],
2735164969,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:11:13+00:00,[],2024-12-12 13:06:20+00:00,2024-12-12 13:06:19+00:00,https://github.com/tensorflow/tensorflow/pull/82816,[],[],
2735162155,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:09:59+00:00,[],2024-12-13 06:09:10+00:00,2024-12-13 06:09:10+00:00,https://github.com/tensorflow/tensorflow/pull/82815,[],[],
2735154147,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:06:43+00:00,[],2024-12-12 08:53:16+00:00,,https://github.com/tensorflow/tensorflow/pull/82814,[],[],
2735154131,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:06:43+00:00,[],2024-12-12 08:06:43+00:00,,https://github.com/tensorflow/tensorflow/pull/82813,[],[],
2735153493,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:06:21+00:00,[],2024-12-13 09:42:28+00:00,2024-12-13 09:42:27+00:00,https://github.com/tensorflow/tensorflow/pull/82812,[],[],
2735148964,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 08:04:35+00:00,[],2024-12-12 08:04:35+00:00,,https://github.com/tensorflow/tensorflow/pull/82811,[],[],
2735123889,pull_request,closed,,Fix build failure in nvjitlink_impl.cc,"Fix build failure in nvjitlink_impl.cc

nvjitlink_impl.cc doesn't build on clang 18 and moving the structured binding out of the TF_ASSIGN_OR_RETURN fixes the issue.
",copybara-service[bot],2024-12-12 07:50:44+00:00,[],2024-12-12 09:49:41+00:00,2024-12-12 09:49:41+00:00,https://github.com/tensorflow/tensorflow/pull/82810,[],[],
2735117546,pull_request,closed,,Include missing headers,"Include missing headers
",copybara-service[bot],2024-12-12 07:46:58+00:00,[],2024-12-12 15:16:28+00:00,2024-12-12 15:16:28+00:00,https://github.com/tensorflow/tensorflow/pull/82809,[],[],
2735116031,pull_request,closed,,Add new `ml-build-rbe` container to the configurations of RBE used with remote config.,"Add new `ml-build-rbe` container to the configurations of RBE used with remote config.
Update .bazelrc file to use the new RBE config.
",copybara-service[bot],2024-12-12 07:46:24+00:00,['quoctruong'],2024-12-13 22:43:52+00:00,2024-12-13 22:43:51+00:00,https://github.com/tensorflow/tensorflow/pull/82808,[],[],
2735071236,pull_request,closed,,Fix a bug with the build of Docker Container for RBE,"Fix a bug with the build of Docker Container for RBE
",copybara-service[bot],2024-12-12 07:21:42+00:00,['quoctruong'],2024-12-12 18:53:26+00:00,2024-12-12 18:53:25+00:00,https://github.com/tensorflow/tensorflow/pull/82807,[],[],
2735061939,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 07:16:07+00:00,[],2024-12-12 13:18:50+00:00,,https://github.com/tensorflow/tensorflow/pull/82806,[],[],
2734989432,pull_request,closed,,Make CompiledMemoryStats::ToProto() const.,"Make CompiledMemoryStats::ToProto() const.
",copybara-service[bot],2024-12-12 06:30:46+00:00,['swachhandl'],2024-12-12 21:22:15+00:00,2024-12-12 21:22:15+00:00,https://github.com/tensorflow/tensorflow/pull/82805,[],[],
2734985426,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 06:28:20+00:00,[],2024-12-14 05:08:12+00:00,2024-12-14 05:08:12+00:00,https://github.com/tensorflow/tensorflow/pull/82804,[],[],
2734934148,pull_request,closed,,Migrate some TSL code over to ABSL equivalents,"Migrate some TSL code over to ABSL equivalents

No functional change is intended.
",copybara-service[bot],2024-12-12 05:58:03+00:00,['majnemer'],2024-12-13 23:17:05+00:00,2024-12-13 23:17:05+00:00,https://github.com/tensorflow/tensorflow/pull/82803,[],[],
2734871917,pull_request,closed,,Add conversion from std::any to LiteRtAny,"Add conversion from std::any to LiteRtAny
",copybara-service[bot],2024-12-12 05:30:45+00:00,[],2024-12-13 02:47:37+00:00,2024-12-13 02:47:36+00:00,https://github.com/tensorflow/tensorflow/pull/82802,[],[],
2734753553,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-12 04:25:21+00:00,[],2024-12-12 07:01:29+00:00,,https://github.com/tensorflow/tensorflow/pull/82801,[],[],
2734676506,pull_request,closed,,[XLA:Python] Fix some old nanobind-transition TODOs.,"[XLA:Python] Fix some old nanobind-transition TODOs.

Also remove two prototypes for functions that no longer exist.

No functional changes intended.
",copybara-service[bot],2024-12-12 03:40:20+00:00,[],2024-12-12 04:11:38+00:00,2024-12-12 04:11:37+00:00,https://github.com/tensorflow/tensorflow/pull/82800,[],[],
2734674660,pull_request,closed,,Add model_flops calculations to device_op_metrics.,"Add model_flops calculations to device_op_metrics.
",copybara-service[bot],2024-12-12 03:39:37+00:00,[],2024-12-13 02:08:20+00:00,2024-12-13 02:08:20+00:00,https://github.com/tensorflow/tensorflow/pull/82799,[],[],
2734669279,pull_request,closed,,fix to export symbol correctly on shared library for windows ( fix to bug ),"When compiling on Windows platform without bazel, msys etc.. 
The target in tensorflow/lite/CMakeLists.txt file has a flag with PUBLIC keyword for it's compiler definition.
Since the PUBLIC keyword it affect to tensorflow/lite/c/CMakeLists.txt compile definition.

The default definition for first one is to make STATIC library.
The default definition for second one is to make SHARED library and flags that modify the definitions are not same.

So even if the flag is set in the tensorflow/lite/c/CMakeLists.txt to make SHARED library, still the flag in tensorflow/lite/CMakeLists.txt files still remain to make STATIC library setting the definition named TFL_STATIC_LIBRARY_BUILD.
This definition is inherit to the tensorflow/lite/c library. So the tensorflowlite_c.dll has no proper symbols on windows platform.

This can be fixed modify keyword not to inherit definitions to other library. Or modify condition statement in c_api_types.h file.
You can see more specific infomation in my error history page.
Please visit the next url : https://github.com/kwoncy2020/kwoncy2020/tree/main/error_history/2024_dec_002_using_dll_library_msvc_in_vscode_solve_export_symbol_problem_when_consecutively_linking",kwoncy2020,2024-12-12 03:36:36+00:00,['gbaned'],2025-01-06 17:53:39+00:00,2025-01-06 17:53:39+00:00,https://github.com/tensorflow/tensorflow/pull/82798,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]","[{'comment_id': 2537737062, 'issue_id': 2734669279, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82798/checks?check_run_id=34294705623) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 12, 3, 36, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2542625324, 'issue_id': 2734669279, 'author': 'kwoncy2020', 'body': ""I didn't know about CLA. Sorry for my late afreement. I passed CLA."", 'created_at': datetime.datetime(2024, 12, 14, 1, 33, 40, tzinfo=datetime.timezone.utc)}, {'comment_id': 2543978979, 'issue_id': 2734669279, 'author': 'kwoncy2020', 'body': ""Yes. When I try to build the shared library from wsl using cross compile, there's a error requiring standard c++20.\r\nAnd When I try it also on Windows host,  I meet the same error.  I attached the error image below.\r\n![10_build_error_tflite_c_for_win_on_windows_problem2](https://github.com/user-attachments/assets/f0418ae6-5de8-4aa8-8aa3-bc535b793488)\r\n\r\n\r\nYou can see more detail on my error history : https://github.com/kwoncy2020/kwoncy2020/tree/main/error_history/2024_dec_001_cross_build_tflite_c_for_windows_with_WSL2"", 'created_at': datetime.datetime(2024, 12, 15, 17, 54, 28, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-12 03:36:40 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82798/checks?check_run_id=34294705623) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

kwoncy2020 (Issue Creator) on (2024-12-14 01:33:40 UTC): I didn't know about CLA. Sorry for my late afreement. I passed CLA.

kwoncy2020 (Issue Creator) on (2024-12-15 17:54:28 UTC): Yes. When I try to build the shared library from wsl using cross compile, there's a error requiring standard c++20.
And When I try it also on Windows host,  I meet the same error.  I attached the error image below.
![10_build_error_tflite_c_for_win_on_windows_problem2](https://github.com/user-attachments/assets/f0418ae6-5de8-4aa8-8aa3-bc535b793488)


You can see more detail on my error history : https://github.com/kwoncy2020/kwoncy2020/tree/main/error_history/2024_dec_001_cross_build_tflite_c_for_windows_with_WSL2

"
2734656134,pull_request,closed,,Redo the internal model api.,"Redo the internal model api.

*ir_allocator* : Wrap the structures needed for storing pointer stable ir 

*model* : Replace naked structs with getters/setters and proper classes.

- Store subgraph reference in signature directly. Indices to subgraphs are not stable but pointers are.

- Generic mechanism to store the misc buffers for the capi within internal model classes (dims/qparams)

- Don't leak anything from tflite schema outside of `detail` namespace

*model_graph* : Pull complicated graph structure operations from `algo` here

*graph_validation* : Move the disparate graph structure validation functions here
",copybara-service[bot],2024-12-12 03:28:53+00:00,['LukeBoyer'],2024-12-12 22:47:05+00:00,2024-12-12 22:47:05+00:00,https://github.com/tensorflow/tensorflow/pull/82797,[],[],
2734578571,pull_request,closed,,Add HardwareType combining to CombineRunEnvironment.,"Add HardwareType combining to CombineRunEnvironment.
",copybara-service[bot],2024-12-12 02:45:44+00:00,[],2024-12-13 02:57:18+00:00,2024-12-13 02:57:17+00:00,https://github.com/tensorflow/tensorflow/pull/82796,[],[],
2734539139,pull_request,closed,,"Update the comparator so that it can induce a strict weak ordering, otherwise it will causes an assertion error at runtime.","Update the comparator so that it can induce a strict weak ordering, otherwise it will causes an assertion error at runtime.
",copybara-service[bot],2024-12-12 02:22:46+00:00,[],2024-12-14 00:58:34+00:00,2024-12-14 00:58:34+00:00,https://github.com/tensorflow/tensorflow/pull/82795,[],[],
2734438737,pull_request,closed,,"Swap output format of ""MatchTrivialLoopRange"" to better align with Range usage.","Swap output format of ""MatchTrivialLoopRange"" to better align with Range usage.
",copybara-service[bot],2024-12-12 01:26:38+00:00,[],2024-12-14 00:08:42+00:00,2024-12-14 00:08:41+00:00,https://github.com/tensorflow/tensorflow/pull/82794,[],[],
2734346440,pull_request,open,,Reverts 3522d78a0b48ba1ac42275ad32c7209db1319406,"Reverts 3522d78a0b48ba1ac42275ad32c7209db1319406
",copybara-service[bot],2024-12-12 00:27:17+00:00,[],2024-12-12 00:27:17+00:00,,https://github.com/tensorflow/tensorflow/pull/82793,[],[],
2734344812,pull_request,closed,,Add fused children to HloInstructionWrapper to show nested children of fused ops in op_profile page,"Add fused children to HloInstructionWrapper to show nested children of fused ops in op_profile page
",copybara-service[bot],2024-12-12 00:26:15+00:00,['zzzaries'],2024-12-14 00:36:06+00:00,2024-12-14 00:36:05+00:00,https://github.com/tensorflow/tensorflow/pull/82792,[],[],
2734329691,pull_request,closed,,Internal change only,"Internal change only
",copybara-service[bot],2024-12-12 00:18:01+00:00,[],2025-01-06 22:45:01+00:00,2025-01-06 22:45:00+00:00,https://github.com/tensorflow/tensorflow/pull/82791,[],[],
2734284348,pull_request,closed,,Add public visibility for tensorflow/compiler/mlir/lite/core/c:tflite_types.,"Add public visibility for tensorflow/compiler/mlir/lite/core/c:tflite_types.
",copybara-service[bot],2024-12-11 23:53:29+00:00,['junjiang-lab'],2024-12-12 02:23:17+00:00,2024-12-12 02:23:16+00:00,https://github.com/tensorflow/tensorflow/pull/82790,[],[],
2734249847,pull_request,closed,,Configure HloPjRtTestBase with new option structs.,"Configure HloPjRtTestBase with new option structs.

A struct instead of optional parameters make it easier for us to express
different test setups. In most applications we expect the default values to
suffice.
",copybara-service[bot],2024-12-11 23:34:05+00:00,[],2024-12-14 03:32:48+00:00,2024-12-14 03:32:47+00:00,https://github.com/tensorflow/tensorflow/pull/82789,[],[],
2734232157,pull_request,open,,"Add nozapfhahn for opt provider files, to ignore expected mutant testing warnings during submissions","Add nozapfhahn for opt provider files, to ignore expected mutant testing warnings during submissions
",copybara-service[bot],2024-12-11 23:24:17+00:00,[],2024-12-11 23:24:17+00:00,,https://github.com/tensorflow/tensorflow/pull/82788,[],[],
2734206230,pull_request,closed,,Integrate LLVM at llvm/llvm-project@19bc282320ba,"Integrate LLVM at llvm/llvm-project@19bc282320ba

Updates LLVM usage to match
[19bc282320ba](https://github.com/llvm/llvm-project/commit/19bc282320ba)
",copybara-service[bot],2024-12-11 23:03:46+00:00,[],2024-12-12 09:32:04+00:00,2024-12-12 09:32:04+00:00,https://github.com/tensorflow/tensorflow/pull/82787,[],[],
2734204358,pull_request,closed,,[XLA] Use kXlaSchedulingGroupIdAttr string for the scheduling annotations.,"[XLA] Use kXlaSchedulingGroupIdAttr string for the scheduling annotations.
",copybara-service[bot],2024-12-11 23:02:13+00:00,['seherellis'],2024-12-12 01:50:31+00:00,2024-12-12 01:50:31+00:00,https://github.com/tensorflow/tensorflow/pull/82786,[],[],
2734196448,pull_request,closed,,Legalize quantize Op used for re-quantization.,"Legalize quantize Op used for re-quantization.
",copybara-service[bot],2024-12-11 22:57:04+00:00,[],2025-01-25 04:25:44+00:00,2025-01-25 04:25:43+00:00,https://github.com/tensorflow/tensorflow/pull/82785,[],[],
2734182326,pull_request,open,,[XLA:GPU] Schedule send/recv early if pipeline parallelism ops enabled,"[XLA:GPU] Schedule send/recv early if pipeline parallelism ops enabled
",copybara-service[bot],2024-12-11 22:45:10+00:00,['frgossen'],2024-12-11 22:45:12+00:00,,https://github.com/tensorflow/tensorflow/pull/82784,[],[],
2734164434,pull_request,open,,[XLA:GPU] Propagate all profiling failures to `gemm_fusion_autotuner.cc`.,"[XLA:GPU] Propagate all profiling failures to `gemm_fusion_autotuner.cc`.

Currently register allocation failures are converted to `std::nullopt` which are then special cased (either ignored or converted back to internal failures). We remove the intermediate conversion and forward the failure to the callers. This is simpler and semantically equivalent with the added benefit that we don't loose the failure details.
",copybara-service[bot],2024-12-11 22:31:13+00:00,[],2024-12-12 14:46:52+00:00,,https://github.com/tensorflow/tensorflow/pull/82783,[],[],
2734161991,pull_request,closed,,[xla:cpu] Update custom call config WARN to VLOG,"[xla:cpu] Update custom call config WARN to VLOG
",copybara-service[bot],2024-12-11 22:29:21+00:00,[],2024-12-12 21:31:29+00:00,2024-12-12 21:31:28+00:00,https://github.com/tensorflow/tensorflow/pull/82782,[],[],
2734137321,pull_request,closed,,Change default QNN tensor MemType to QNN_TENSORMEMTYPE_RAW.,"Change default QNN tensor MemType to QNN_TENSORMEMTYPE_RAW.
",copybara-service[bot],2024-12-11 22:13:40+00:00,[],2024-12-12 00:46:37+00:00,2024-12-12 00:46:37+00:00,https://github.com/tensorflow/tensorflow/pull/82781,[],[],
2734113092,pull_request,closed,,[xla:cpu] Add missing files from openxla/xla#16438,"[xla:cpu] Add missing files from openxla/xla#16438

Add missing files and changes from a PR adding matmul reordering support to oneDNN for aarch64 CPU:
https://github.com/openxla/xla/pull/16438

Also add a missing indirect convolution patch from a TF PR:
https://github.com/tensorflow/tensorflow/pull/62852
",copybara-service[bot],2024-12-11 21:58:20+00:00,['penpornk'],2024-12-11 23:59:06+00:00,2024-12-11 23:59:06+00:00,https://github.com/tensorflow/tensorflow/pull/82780,[],[],
2734110627,pull_request,closed,,Take per-channel quantization parameters in QC compiler plugin.,"Take per-channel quantization parameters in QC compiler plugin.
",copybara-service[bot],2024-12-11 21:56:36+00:00,[],2024-12-13 03:54:01+00:00,2024-12-13 03:54:01+00:00,https://github.com/tensorflow/tensorflow/pull/82779,[],[],
2734103120,pull_request,closed,,Open source TPU step utils.,"Open source TPU step utils.
",copybara-service[bot],2024-12-11 21:51:55+00:00,[],2024-12-13 04:00:53+00:00,2024-12-13 04:00:52+00:00,https://github.com/tensorflow/tensorflow/pull/82778,[],[],
2734094329,pull_request,closed,,[xla-auto-sharding] Fix potential dangling pointer (reference) bug.,"[xla-auto-sharding] Fix potential dangling pointer (reference) bug.

Note:
- The scaled request object is allocated on the stack when `ScaleRequest` is called, but then it goes out of scope.
- This change should be equally performant due to return value optimization.
",copybara-service[bot],2024-12-11 21:46:53+00:00,[],2024-12-12 00:27:51+00:00,2024-12-12 00:27:51+00:00,https://github.com/tensorflow/tensorflow/pull/82777,[],[],
2734084774,pull_request,closed,,Take per-tensor quantization parameters in QNN IR.,"Take per-tensor quantization parameters in QNN IR.
",copybara-service[bot],2024-12-11 21:41:15+00:00,[],2024-12-13 03:09:42+00:00,2024-12-13 03:09:41+00:00,https://github.com/tensorflow/tensorflow/pull/82776,[],[],
2734073423,pull_request,closed,,PR #19099: [XLA:CPU][oneDNN] Add post-ops for oneDNN Convolutions,"PR #19099: [XLA:CPU][oneDNN] Add post-ops for oneDNN Convolutions

Imported from GitHub PR https://github.com/openxla/xla/pull/19099

This PR adds support for multiple post-ops for oneDNN Convolution and adds tests to verify functionality. New Post-ops supported:

1. Relu
2. Tanh
3. Gelu (Approx.)
4. Gelu (Exact)
5. Relu6
6. Sigmoid
7. Elu
8. Elementwise scalar product
Copybara import of the project:

--
1c343b607e7d1d931bac9601d9301918d2460e6f by Akhil Goel <akhil.goel@intel.com>:

Add post-ops for oneDNN Convolutions

--
643bf016dbddd644ce71d10efe3c02d212c2888e by Akhil Goel <akhil.goel@intel.com>:

Remove auto-merge redefinition

Merging this change closes #19099

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19099 from Intel-tensorflow:akhil/conv_fusions_3_d 643bf016dbddd644ce71d10efe3c02d212c2888e
",copybara-service[bot],2024-12-11 21:33:23+00:00,[],2024-12-12 12:51:06+00:00,2024-12-12 12:51:05+00:00,https://github.com/tensorflow/tensorflow/pull/82775,[],"[{'comment_id': 2537238718, 'issue_id': 2734073423, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82775/checks?check_run_id=34282900670) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 11, 21, 33, 28, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-11 21:33:28 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82775/checks?check_run_id=34282900670) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2734063169,pull_request,closed,,Add action which automatically runs CI for public OpenXLA GitHub org members,"Add action which automatically runs CI for public OpenXLA GitHub org members
",copybara-service[bot],2024-12-11 21:27:20+00:00,['ddunl'],2024-12-16 21:13:38+00:00,2024-12-16 21:13:37+00:00,https://github.com/tensorflow/tensorflow/pull/82774,[],[],
2733970369,pull_request,open,,Migrate `type_name`/`cpp_type_name` to `absl::string_view`.,"Migrate `type_name`/`cpp_type_name` to `absl::string_view`.
",copybara-service[bot],2024-12-11 20:45:35+00:00,[],2024-12-11 20:45:35+00:00,,https://github.com/tensorflow/tensorflow/pull/82773,[],[],
2733960686,pull_request,closed,,[XLA:GPU] Add a nested builder arg to the EmitXlaLoop builder.,"[XLA:GPU] Add a nested builder arg to the EmitXlaLoop builder.
",copybara-service[bot],2024-12-11 20:42:07+00:00,['pifon2a'],2024-12-12 08:44:29+00:00,2024-12-12 08:44:28+00:00,https://github.com/tensorflow/tensorflow/pull/82772,[],[],
2733949247,pull_request,open,,remove non-maintained tensorflow-io-gcs-filesystem dependency from pip_package,"this dependency has been causing a problem for more than a year without a solution, wheels are not built and it seems not very well maintained, if at all. tensorflow only depends on it for some optional purpose 

as seen by it's addition PR it's only enabled with a certain variable: https://github.com/tensorflow/tensorflow/pull/51460

yet community has been trying to find a solution for the problems it has been causing without a direct fix, it might be beneficial to get rid of this dependency for extended belief on tensorflow's multiplatform support and reliability

https://github.com/tensorflow/io/issues/2087
https://github.com/tensorflow/tensorflow/issues/56636
https://github.com/tensorflow/io/issues/1789
https://github.com/tensorflow/io/issues/2093
https://github.com/tensorflow/io/issues/2087
https://discuss.ai.google.dev/t/tensorflow-io-gcs-filesystem-with-windows/32191/3",nazimisik,2024-12-11 20:38:12+00:00,['gbaned'],2025-02-05 17:33:15+00:00,,https://github.com/tensorflow/tensorflow/pull/82771,"[('stat:awaiting response', 'Status  - Awaiting response from author'), ('size:XS', 'CL Change Size: Extra Small')]","[{'comment_id': 2537091956, 'issue_id': 2733949247, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82771/checks?check_run_id=34280386793) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 11, 20, 38, 17, tzinfo=datetime.timezone.utc)}, {'comment_id': 2538101070, 'issue_id': 2733949247, 'author': 'nazimisik', 'body': 'This would be okay if the depended library was correctly maintained but right now it brings lots of problems to real environments and we would at least like to see some plan to remediate this.', 'created_at': datetime.datetime(2024, 12, 12, 8, 10, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2538131571, 'issue_id': 2733949247, 'author': 'nazimisik', 'body': 'same since 2023\r\n\r\nhttps://github.com/tensorflow/io/issues/1789#issuecomment-1491355793', 'created_at': datetime.datetime(2024, 12, 12, 8, 19, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610301241, 'issue_id': 2733949247, 'author': 'Gornoka', 'body': 'Would a less extreme option be considered acceptable @mihaimaruseac.\r\n\r\nI would see the following decent options:\r\n* This dependency could be made an extra (as it is optional and nonexistence is handled), \r\n* get os dependent version requirements, as the `<=0.31.0` for windows, this way the normal install from the docs with pip would not break, tutorials with gcs would continue to work, and UV / poetry would not choke on this and could resolve to the fallback version. If you deem either of these solutions worthwhile i would be happy to create a pr.', 'created_at': datetime.datetime(2025, 1, 23, 16, 24, 24, tzinfo=datetime.timezone.utc)}, {'comment_id': 2610316607, 'issue_id': 2733949247, 'author': 'mihaimaruseac', 'body': 'I think making it an extra would work better.\r\n\r\nThe team is currently preparing for a new release of TF and they might reach a different decision too.', 'created_at': datetime.datetime(2025, 1, 23, 16, 27, 30, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-11 20:38:17 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82771/checks?check_run_id=34280386793) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

nazimisik (Issue Creator) on (2024-12-12 08:10:24 UTC): This would be okay if the depended library was correctly maintained but right now it brings lots of problems to real environments and we would at least like to see some plan to remediate this.

nazimisik (Issue Creator) on (2024-12-12 08:19:43 UTC): same since 2023

https://github.com/tensorflow/io/issues/1789#issuecomment-1491355793

Gornoka on (2025-01-23 16:24:24 UTC): Would a less extreme option be considered acceptable @mihaimaruseac.

I would see the following decent options:
* This dependency could be made an extra (as it is optional and nonexistence is handled), 
* get os dependent version requirements, as the `<=0.31.0` for windows, this way the normal install from the docs with pip would not break, tutorials with gcs would continue to work, and UV / poetry would not choke on this and could resolve to the fallback version. If you deem either of these solutions worthwhile i would be happy to create a pr.

mihaimaruseac on (2025-01-23 16:27:30 UTC): I think making it an extra would work better.

The team is currently preparing for a new release of TF and they might reach a different decision too.

"
2733912528,pull_request,closed,,Use int64_t for thread ids instead of int32_t,"Use int64_t for thread ids instead of int32_t

Apple's XNU kernel uses 64-bit thread ids. It is imprudent to assume that the top 32 bits are clear.
",copybara-service[bot],2024-12-11 20:25:57+00:00,['majnemer'],2024-12-17 08:18:58+00:00,2024-12-17 08:18:55+00:00,https://github.com/tensorflow/tensorflow/pull/82770,[],[],
2733847617,pull_request,closed,,Extend use_parameter_layout_on_device option to `ExecuteReplicated`.,"Extend use_parameter_layout_on_device option to `ExecuteReplicated`.

`ExecuteReplicated` ignored the `use_parameter_layout_on_device` option of the
`HloRunnerPjRt`. If enabled, this flag passes the parameter layout for use with
the on-device buffer. This is something that `HloRunner` does as well, so this
functionality is just replicating the existing behavior for use with PjRt.
",copybara-service[bot],2024-12-11 19:55:13+00:00,[],2024-12-14 03:16:40+00:00,2024-12-14 03:16:39+00:00,https://github.com/tensorflow/tensorflow/pull/82769,[],[],
2733822001,pull_request,open,,Add hermetic PYTHON 3.13 requirements lock file in Tensorflow project.,"Add hermetic PYTHON 3.13 requirements lock file in Tensorflow project.
",copybara-service[bot],2024-12-11 19:40:08+00:00,[],2024-12-11 19:40:08+00:00,,https://github.com/tensorflow/tensorflow/pull/82768,[],[],
2733810632,pull_request,closed,,Fix a bug in TFXlaCallModuleOpToStablehloPass regarding PlatformIndexArg handling,"Fix a bug in TFXlaCallModuleOpToStablehloPass regarding PlatformIndexArg handling

The issue is that the ""PlatformIndexArg"" of a StableHLO module is not always a noop argument as was originally expected. When a StableHLO module contains function calls inside, this ""PlatformIndexArg"" will be propagated along the call graph. Therefore, unconditional removing this arg will remove a still-being-used SSA value and trigger an assertion.

The fix is that instead of removing the arg on the callee function side, we can add a dummy I32 operand on the caller side. After the inlining, this dummy operand will be dead code eliminated and produce the same result as before.
",copybara-service[bot],2024-12-11 19:34:08+00:00,[],2024-12-11 21:55:52+00:00,2024-12-11 21:55:50+00:00,https://github.com/tensorflow/tensorflow/pull/82767,[],[],
2733806337,pull_request,closed,,Allow preserving all tensors with the BUILTIN or AUTO op resolver,"Allow preserving all tensors with the BUILTIN or AUTO op resolver
",copybara-service[bot],2024-12-11 19:31:29+00:00,[],2024-12-12 19:25:01+00:00,2024-12-12 19:24:59+00:00,https://github.com/tensorflow/tensorflow/pull/82766,[],[],
2733793448,pull_request,closed,,Update TensorBuffer handling in CompiledModel::Run() for CPU buffer,"Update TensorBuffer handling in CompiledModel::Run() for CPU buffer

In BufferRegister() method,
- ExternalLiteRtBufferContext::RegisterTensorBuffer() if it's compatible
- Use AHWB for CPU access via CustomAllocation
- When the buffer is incompatible, it fails for now.
",copybara-service[bot],2024-12-11 19:24:31+00:00,['terryheo'],2024-12-13 22:35:49+00:00,2024-12-13 22:35:49+00:00,https://github.com/tensorflow/tensorflow/pull/82765,[],[],
2733687639,pull_request,open,,"public message needed only for shardy change, the change will be separately submitted in cl/703502551 and this message removes","public message needed only for shardy change, the change will be separately submitted in cl/703502551 and this message removes
",copybara-service[bot],2024-12-11 18:27:49+00:00,[],2024-12-11 18:27:49+00:00,,https://github.com/tensorflow/tensorflow/pull/82763,[],[],
2733525452,pull_request,closed,,[XLA] Return the number of overlapping chunks instead of chunks themselves for tracking outstanding prefetches/evictions,"[XLA] Return the number of overlapping chunks instead of chunks themselves for tracking outstanding prefetches/evictions
",copybara-service[bot],2024-12-11 17:09:47+00:00,[],2024-12-13 20:20:11+00:00,2024-12-13 20:20:10+00:00,https://github.com/tensorflow/tensorflow/pull/82762,[],[],
2733507665,pull_request,open,,PR #19649: [ROCm] Implement hermetic rocm dependency,"PR #19649: [ROCm] Implement hermetic rocm dependency

Imported from GitHub PR https://github.com/openxla/xla/pull/19649

This change has as a goal to introduce an external dependency to the rocm library and tools.

Building xla with the hermetic rocm is done by using these env variables:

--repo_env=OS=ubuntu_20.04
--repo_env=ROCM_VERSION=6.2.0

To use only hermetic libs define this flag:
--@local_config_rocm//rocm:use_rocm_hermetic_rpath=True
This flag will make rpaths and configs to look inside the sandbox
If flag is not set then default installation paths are used e.g /opt/rocm


One has to provie OS version and ROCm version to initialize a proper rocm repository.
If these flags are not set then default ROCm installation will be used to build XLA.

depends-on: https://github.com/openxla/xla/pull/19691

Copybara import of the project:

--
cf744eca78f697144e122c6a9d1aa8fc52722b20 by Alexandros Theodoridis <atheodor@amd.com>:

Implement hermetic rocm dependency

--
4f4ad859ec3143fdb04f7792541c61b98c708397 by Alexandros Theodoridis <atheodor@amd.com>:

Add missing dependency

--
8e164f765b45b5e5d118b02695fd6d6e2b0b232d by Alexandros Theodoridis <atheodor@amd.com>:

Add missing dependency and remove so files from data

--
35538f4922b5b28b9debd0ce17bb15b83b5921fc by Alexandros Theodoridis <atheodor@amd.com>:

Rename setting to use_rocm_hermetic_rpath

--
58d140220e9e58572c9a7ae3de2ec1ea189566d3 by Alexandros Theodoridis <atheodor@amd.com>:

Fix build for cuda and cpu

Merging this change closes #19649

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19649 from ROCm:ci_implement_hermetic_rocm_dependency_upstream 58d140220e9e58572c9a7ae3de2ec1ea189566d3
",copybara-service[bot],2024-12-11 17:02:02+00:00,[],2024-12-11 22:30:14+00:00,,https://github.com/tensorflow/tensorflow/pull/82761,[],[],
2733476319,pull_request,closed,,#sdy Add unique module name in Shardy dumps,"#sdy Add unique module name in Shardy dumps

This is important to match the corresponding filenames in HLO dumps and also to avoid overriding Shardy dumps when two modules with the same name are compiled using the same dump dir.
",copybara-service[bot],2024-12-11 16:47:46+00:00,[],2024-12-12 10:13:02+00:00,2024-12-12 10:13:01+00:00,https://github.com/tensorflow/tensorflow/pull/82760,[],[],
2733441813,pull_request,closed,,Make ErrorSpec constructor `constexpr`.,"Make ErrorSpec constructor `constexpr`.
",copybara-service[bot],2024-12-11 16:32:10+00:00,[],2024-12-16 17:52:25+00:00,2024-12-16 17:52:24+00:00,https://github.com/tensorflow/tensorflow/pull/82758,[],[],
2733430427,pull_request,closed,,Support batching dimensions in ConvertGatherOp,"Support batching dimensions in ConvertGatherOp

Adding support for converting `mhlo.gather`s that have `operand_batching_dims`/`start_indices_batching_dims`. To do this, we canonicalize `operand` and `start_indices` by transposing and flattening the batching dimensions into a leading dimension. We additionally add iota indices to index into the operand's flattened batch dimension with `TF::GatherOp`. Finally, we unflatten and transpose the `TF::GatherOp` result back to the original result shape.
",copybara-service[bot],2024-12-11 16:27:15+00:00,[],2024-12-17 05:43:48+00:00,2024-12-17 05:43:47+00:00,https://github.com/tensorflow/tensorflow/pull/82757,[],[],
2733429301,pull_request,open,,Add RemoveTrivialGatherOpIndices pattern,"Add RemoveTrivialGatherOpIndices pattern

If the start indices tensor of an `mhlo::GatherOp` is created by concatenating multiple tensors along the index vector dim, we can remove any tensors that are all zeros and remove the corresponding value in the start index map of the gather. This can help enable further conversion of the gather op via `ConvertGatherOp`.
",copybara-service[bot],2024-12-11 16:26:43+00:00,[],2024-12-11 16:26:43+00:00,,https://github.com/tensorflow/tensorflow/pull/82756,[],[],
2733426700,pull_request,closed,,Support non-collapsed indexed dimensions in ConvertGatherOp,"Support non-collapsed indexed dimensions in ConvertGatherOp

Adding support for converting `mhlo.gather`s where not all the indexed dimensions are collapsed away. This can be done by reshaping the result, though it does require a static shape for now.
",copybara-service[bot],2024-12-11 16:25:44+00:00,[],2024-12-17 05:58:33+00:00,2024-12-17 05:58:32+00:00,https://github.com/tensorflow/tensorflow/pull/82755,[],[],
2733413741,pull_request,closed,,[XLA] Avoid redundant lookup in ConsumeResource,"[XLA] Avoid redundant lookup in ConsumeResource
",copybara-service[bot],2024-12-11 16:20:19+00:00,[],2024-12-11 19:02:57+00:00,2024-12-11 19:02:57+00:00,https://github.com/tensorflow/tensorflow/pull/82754,[],[],
2733328537,pull_request,closed,,[XLA:GPU] Remove restriction on `bitcast`s being a no-op with regards to tiling,"[XLA:GPU] Remove restriction on `bitcast`s being a no-op with regards to tiling
in `SoftmaxRewriterTriton`.

This restriction was necessary before we checked tiling using
`SymbolicTileAnalysis`, but is unnecessary now.
",copybara-service[bot],2024-12-11 15:44:20+00:00,[],2024-12-12 11:41:52+00:00,2024-12-12 11:41:51+00:00,https://github.com/tensorflow/tensorflow/pull/82753,[],[],
2733286474,pull_request,closed,,[XLA:GPU] Always use GpuAsyncTracker.,"[XLA:GPU] Always use GpuAsyncTracker.
",copybara-service[bot],2024-12-11 15:27:47+00:00,[],2024-12-13 14:46:32+00:00,2024-12-13 14:46:32+00:00,https://github.com/tensorflow/tensorflow/pull/82752,[],[],
2733285671,pull_request,closed,,[XLA:GPU] Deprecate diamond chains in `SoftmaxRewriterTriton`.,"[XLA:GPU] Deprecate diamond chains in `SoftmaxRewriterTriton`.

Now that priority fusion is able to fuse into normalization diamonds, it
shouldn't be necessary to match long strings of ops around normalizations.

This is part of a series of simplifications which should minimize the
normalization rewriter.
",copybara-service[bot],2024-12-11 15:27:32+00:00,[],2024-12-12 11:14:42+00:00,2024-12-12 11:14:41+00:00,https://github.com/tensorflow/tensorflow/pull/82751,[],[],
2733280258,pull_request,closed,,[XLA:GPU][NFC] Modularize a little bit gpu_hlo_schedule.cc.,"[XLA:GPU][NFC] Modularize a little bit gpu_hlo_schedule.cc.
",copybara-service[bot],2024-12-11 15:24:35+00:00,[],2024-12-12 13:21:43+00:00,2024-12-12 13:21:42+00:00,https://github.com/tensorflow/tensorflow/pull/82750,[],[],
2733244761,pull_request,closed,,[xla:gpu] `CreateTritonPipeline` no longer depends on internal XLA GPU abstractions,"[xla:gpu] `CreateTritonPipeline` no longer depends on internal XLA GPU abstractions

Both `BlockLevelParameters` and `se::ComputeCapability` were not strictly
necessary. So, I decided to replace them with simpler types, which do not
require JAX to depend on XLA:GPU internals.

Note also that `mlir::PassManager` is now passed by pointer to make it easier
to call into `CreateTritonPipeline` using MLIR C API abstractions, which
generally store pointers to their C++ counterparts.

See google/jax#25196.
",copybara-service[bot],2024-12-11 15:10:26+00:00,['superbobry'],2024-12-11 21:12:52+00:00,2024-12-11 21:12:52+00:00,https://github.com/tensorflow/tensorflow/pull/82749,[],[],
2733230015,pull_request,open,,[ROCM] Add nanoo fp8 data type to cast op,"This is a follow-up work of this PR: https://github.com/tensorflow/tensorflow/pull/77117. It adds the nanoo fp8 support to cast op. 

After this PR, we can trigger fp8 acceleration in the gemm rewriter pass in XLA: https://github.com/openxla/xla/discussions/22

A miminum test case:
```Python
@tf.function(jit_compile=True)
def fp8_matmul(x_fp8, y_fp8, scale_x, scale_y):
    # 1. dequantize x_fp8 and y_fp8 to fp32
    x_fp32_unscaled = tf.cast(x_fp8, tf.float32) * scale_x
    y_fp32_unscaled = tf.cast(y_fp8, tf.float32) * scale_y
    # 2. perform matmul in fp32
    z_fp32_unscaled = tf.matmul(x_fp32_unscaled, y_fp32_unscaled)
    return z_fp32_unscaled
```
And it will be fused into a hipblaslt call.",ScXfjiang,2024-12-11 15:04:34+00:00,['gbaned'],2025-01-16 04:30:51+00:00,,https://github.com/tensorflow/tensorflow/pull/82748,"[('awaiting review', 'Pull request awaiting review'), ('comp:gpu', 'GPU related issues'), ('size:M', 'CL Change Size: Medium'), ('comp:core', 'issues related to core part of tensorflow')]","[{'comment_id': 2562206785, 'issue_id': 2733230015, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 12, 26, 6, 26, 2, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-12-26 06:26:02 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

"
2733088145,pull_request,closed,,[XLA:CPU] Benchmark for grouped strided convolutions,"[XLA:CPU] Benchmark for grouped strided convolutions
",copybara-service[bot],2024-12-11 14:11:07+00:00,[],2024-12-11 15:30:38+00:00,2024-12-11 15:30:38+00:00,https://github.com/tensorflow/tensorflow/pull/82747,[],"[{'comment_id': 2536096594, 'issue_id': 2733088145, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82747/checks?check_run_id=34259105943) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 11, 14, 11, 14, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-11 14:11:14 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82747/checks?check_run_id=34259105943) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2733016873,pull_request,closed,,[XLA GPU] Add additional unit tests for `IsPtxRegisterAllocationError`.,"[XLA GPU] Add additional unit tests for `IsPtxRegisterAllocationError`.
",copybara-service[bot],2024-12-11 13:42:22+00:00,[],2024-12-11 14:45:11+00:00,2024-12-11 14:45:11+00:00,https://github.com/tensorflow/tensorflow/pull/82746,[],[],
2732998871,pull_request,closed,,spam,spam,alisafdar007,2024-12-11 13:34:33+00:00,['gbaned'],2024-12-12 08:08:09+00:00,2024-12-12 08:08:06+00:00,https://github.com/tensorflow/tensorflow/pull/82745,"[('size:M', 'CL Change Size: Medium')]","[{'comment_id': 2536009139, 'issue_id': 2732998871, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82745/checks?check_run_id=34256973678) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 11, 13, 34, 37, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-11 13:34:37 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82745/checks?check_run_id=34256973678) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2732945929,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 13:12:09+00:00,[],2024-12-14 04:54:50+00:00,2024-12-14 04:54:50+00:00,https://github.com/tensorflow/tensorflow/pull/82744,[],[],
2732843889,pull_request,closed,,Fix infinite loop in TopKSplitter,"Fix infinite loop in TopKSplitter

TopK Splitter was not correctly handling the case where the split dimension (n) is equal to the split threshold.

The splitted (new) dimension n is calculated as floor(n / split_threshold) which is equal to n, therefore no split is happening and since the pass is implemented as an HLO graph traversal we end up in an infinite loop that is trying to split the very same TopK instruction over and over again.

The fix skips the rewrite for the cases where n == split_threshold.

I also added a unit test which fails without the fix: http://sponge2/fc872deb-7ecb-4164-b528-2e7f6a4596b9 (fail)
",copybara-service[bot],2024-12-11 12:27:04+00:00,[],2024-12-11 13:54:01+00:00,2024-12-11 13:54:00+00:00,https://github.com/tensorflow/tensorflow/pull/82743,[],[],
2732834158,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 12:22:39+00:00,[],2024-12-12 08:57:35+00:00,,https://github.com/tensorflow/tensorflow/pull/82742,[],[],
2732552297,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 10:45:28+00:00,[],2024-12-12 09:16:17+00:00,,https://github.com/tensorflow/tensorflow/pull/82741,[],[],
2732413001,pull_request,closed,,PR #20313: Fix async wrapper to walk child computations,"PR #20313: Fix async wrapper to walk child computations

Imported from GitHub PR https://github.com/openxla/xla/pull/20313

Async wrapper should walk all the computations of instructions, except fusion instructions (especially while and condition instructions). This patch adds that, along with tests.
Copybara import of the project:

--
1c9ca5ee7c318e266b066b744678d9c2c5b67cbb by Shraiysh Vaishay <svaishay@nvidia.com>:

Fix async wrapper to walk child computations

Async wrapper should walk all the computations of instructions, except
fusion instructions (especially while and condition instructions). This
patch adds that, along with tests.

--
2c09ae1cd770dec066addaf70f68d2efa32b5462 by Shraiysh Vaishay <svaishay@nvidia.com>:

Addressed comments

Merging this change closes #20313

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20313 from shraiysh:async_wrapper 2c09ae1cd770dec066addaf70f68d2efa32b5462
",copybara-service[bot],2024-12-11 09:51:52+00:00,[],2024-12-11 13:12:47+00:00,2024-12-11 13:12:46+00:00,https://github.com/tensorflow/tensorflow/pull/82740,[],[],
2732365719,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 09:32:12+00:00,[],2024-12-12 08:33:39+00:00,,https://github.com/tensorflow/tensorflow/pull/82739,[],[],
2732350975,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19099 from Intel-tensorflow:akhil/conv_fusions_3_d 643bf016dbddd644ce71d10efe3c02d212c2888e
",copybara-service[bot],2024-12-11 09:26:06+00:00,[],2024-12-12 13:38:07+00:00,2024-12-12 13:38:06+00:00,https://github.com/tensorflow/tensorflow/pull/82738,[],[],
2732286297,pull_request,closed,,Integrate LLVM at llvm/llvm-project@eacdbc269e5f,"Integrate LLVM at llvm/llvm-project@eacdbc269e5f

Updates LLVM usage to match
[eacdbc269e5f](https://github.com/llvm/llvm-project/commit/eacdbc269e5f)
",copybara-service[bot],2024-12-11 08:57:09+00:00,[],2024-12-11 14:38:51+00:00,2024-12-11 14:38:51+00:00,https://github.com/tensorflow/tensorflow/pull/82737,[],[],
2732274011,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:51:09+00:00,[],2024-12-12 07:48:31+00:00,,https://github.com/tensorflow/tensorflow/pull/82735,[],[],
2732260970,pull_request,closed,,PR #20334: [nfc] clang-format is failing on unrelated PRs because of this,"PR #20334: [nfc] clang-format is failing on unrelated PRs because of this

Imported from GitHub PR https://github.com/openxla/xla/pull/20334

Formatting.
Copybara import of the project:

--
65921cebb91536e319b2e922f7f27d310de8d114 by Shraiysh Vaishay <svaishay@nvidia.com>:

[nfc] clang-format is failing on unrelated PRs because of this

Formatting.

Merging this change closes #20334

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20334 from shraiysh:nfc_clang_format_fix 65921cebb91536e319b2e922f7f27d310de8d114
",copybara-service[bot],2024-12-11 08:44:46+00:00,[],2024-12-11 10:19:54+00:00,2024-12-11 10:19:53+00:00,https://github.com/tensorflow/tensorflow/pull/82734,[],[],
2732251234,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:39:52+00:00,[],2024-12-12 07:11:35+00:00,,https://github.com/tensorflow/tensorflow/pull/82733,[],[],
2732234064,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:31:28+00:00,[],2024-12-12 10:40:45+00:00,2024-12-12 10:40:44+00:00,https://github.com/tensorflow/tensorflow/pull/82732,[],[],
2732228097,pull_request,closed,,PR #20006: [XLA:GPU] Only allow horizontal loop fusion for default memory space,"PR #20006: [XLA:GPU] Only allow horizontal loop fusion for default memory space

Imported from GitHub PR https://github.com/openxla/xla/pull/20006

Horizontal loop fusion currently breaks weight offloading in JAX if it fuses a host-memory copy and device-memory copy because such a fusion results in a same-space buffer, triggering memory space assertions in JAX.

This PR avoids any horizontal loop fusions for host-memory (even though in practice, some fusions would work even in host space).
Copybara import of the project:

--
6a3b325aae43227b847e1124a85236ab89e6d7e2 by Jaroslav Sevcik <jsevcik@nvidia.com>:

[XLA:GPU] Only allow horizontal loop fusion for default memory space

Merging this change closes #20006

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20006 from jaro-sevcik:jsevcik/horizontal-loop-fusion-default-memory-space-only 6a3b325aae43227b847e1124a85236ab89e6d7e2
",copybara-service[bot],2024-12-11 08:28:32+00:00,[],2024-12-11 09:40:31+00:00,2024-12-11 09:40:30+00:00,https://github.com/tensorflow/tensorflow/pull/82731,[],[],
2732227253,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:28:05+00:00,[],2024-12-11 08:28:05+00:00,,https://github.com/tensorflow/tensorflow/pull/82730,[],[],
2732226343,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:27:34+00:00,[],2024-12-13 10:33:52+00:00,2024-12-13 10:33:51+00:00,https://github.com/tensorflow/tensorflow/pull/82729,[],[],
2732226099,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:27:26+00:00,[],2024-12-12 04:54:09+00:00,,https://github.com/tensorflow/tensorflow/pull/82728,[],[],
2732223055,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:25:49+00:00,[],2024-12-13 13:30:04+00:00,2024-12-13 13:30:03+00:00,https://github.com/tensorflow/tensorflow/pull/82727,[],[],
2732222121,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:25:20+00:00,[],2024-12-13 05:45:37+00:00,2024-12-13 05:45:37+00:00,https://github.com/tensorflow/tensorflow/pull/82726,[],[],
2732218264,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:23:21+00:00,[],2024-12-18 08:51:37+00:00,2024-12-18 08:51:35+00:00,https://github.com/tensorflow/tensorflow/pull/82725,[],[],
2732210335,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 08:20:20+00:00,[],2024-12-12 07:18:41+00:00,2024-12-12 07:18:40+00:00,https://github.com/tensorflow/tensorflow/pull/82724,[],[],
2732141995,pull_request,closed,,Automated Code Change,"Automated Code Change

Reverts 65b974a49ff3dd57e2a980638d517b5787e51249
",copybara-service[bot],2024-12-11 07:57:08+00:00,[],2024-12-12 11:50:54+00:00,2024-12-12 11:50:53+00:00,https://github.com/tensorflow/tensorflow/pull/82723,[],[],
2732117594,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 07:50:09+00:00,[],2024-12-18 06:25:03+00:00,2024-12-18 06:25:03+00:00,https://github.com/tensorflow/tensorflow/pull/82722,[],[],
2732032325,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 07:16:22+00:00,[],2024-12-11 12:02:57+00:00,,https://github.com/tensorflow/tensorflow/pull/82721,[],[],
2731983654,pull_request,closed,,[XLA:GPU] Decrease `VLOG` levels to start logging at level `2` in `softmax_rewriter_triton.cc`.,"[XLA:GPU] Decrease `VLOG` levels to start logging at level `2` in `softmax_rewriter_triton.cc`.
",copybara-service[bot],2024-12-11 06:51:40+00:00,[],2024-12-11 09:52:06+00:00,2024-12-11 09:52:05+00:00,https://github.com/tensorflow/tensorflow/pull/82720,[],[],
2731957782,pull_request,open,,Integrate LLVM at llvm/llvm-project@eacdbc269e5f,"Integrate LLVM at llvm/llvm-project@eacdbc269e5f

Updates LLVM usage to match
[eacdbc269e5f](https://github.com/llvm/llvm-project/commit/eacdbc269e5f)
",copybara-service[bot],2024-12-11 06:36:14+00:00,[],2024-12-11 06:36:14+00:00,,https://github.com/tensorflow/tensorflow/pull/82719,[],[],
2731952993,pull_request,closed,,Remove `python3.12-distutils` (this is deprecated in python3.12).,"Remove `python3.12-distutils` (this is deprecated in python3.12).
",copybara-service[bot],2024-12-11 06:33:01+00:00,['quoctruong'],2024-12-11 20:26:01+00:00,2024-12-11 20:26:00+00:00,https://github.com/tensorflow/tensorflow/pull/82718,[],[],
2731945698,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20214 from shraiysh:ds_fusion 92e120354e04c8b754b5853c79662b96342b44f1
",copybara-service[bot],2024-12-11 06:28:15+00:00,[],2024-12-11 13:09:00+00:00,,https://github.com/tensorflow/tensorflow/pull/82717,[],[],
2731943602,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/81030 from tensorflow:keerthanakadiri-patch-1 b362f96437cb3a5b9a94eac88f958d31066c9db8
",copybara-service[bot],2024-12-11 06:26:53+00:00,[],2024-12-11 11:08:52+00:00,,https://github.com/tensorflow/tensorflow/pull/82716,[],[],
2731936969,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 06:22:08+00:00,[],2024-12-11 08:43:38+00:00,,https://github.com/tensorflow/tensorflow/pull/82715,[],[],
2731922035,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 06:11:03+00:00,[],2024-12-12 10:02:27+00:00,2024-12-12 10:02:27+00:00,https://github.com/tensorflow/tensorflow/pull/82714,[],[],
2731903296,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19099 from Intel-tensorflow:akhil/conv_fusions_3_d 643bf016dbddd644ce71d10efe3c02d212c2888e
",copybara-service[bot],2024-12-11 05:58:22+00:00,[],2024-12-12 13:45:53+00:00,2024-12-12 13:45:52+00:00,https://github.com/tensorflow/tensorflow/pull/82713,[],[],
2731884007,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 05:44:01+00:00,[],2024-12-11 05:44:01+00:00,,https://github.com/tensorflow/tensorflow/pull/82712,[],[],
2731865249,pull_request,closed,,Adds stacktrace logging in dtors of `DynamicDeviceMgr` and `WorkerSession`,"Adds stacktrace logging in dtors of `DynamicDeviceMgr` and `WorkerSession`
",copybara-service[bot],2024-12-11 05:28:50+00:00,['anshumang'],2024-12-11 06:27:34+00:00,2024-12-11 06:27:34+00:00,https://github.com/tensorflow/tensorflow/pull/82711,[],[],
2731775868,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-11 04:17:56+00:00,[],2024-12-12 12:57:57+00:00,2024-12-12 12:57:56+00:00,https://github.com/tensorflow/tensorflow/pull/82710,[],[],
2731756287,pull_request,closed,,Add `LayoutModeToXlaShape` util to header so that users can get xla::Shape with layout without an XlaComputation.,"Add `LayoutModeToXlaShape` util to header so that users can get xla::Shape with layout without an XlaComputation.
",copybara-service[bot],2024-12-11 03:58:29+00:00,[],2024-12-11 05:36:47+00:00,2024-12-11 05:36:47+00:00,https://github.com/tensorflow/tensorflow/pull/82709,[],[],
2731595086,pull_request,closed,,"[XLA:LatencyHidingScheduler] Fix crash with non-standard async ops whose done op does not consume the respective start op and that they might have a reverse data dependency (e.g., `done -> ops -> start`).","[XLA:LatencyHidingScheduler] Fix crash with non-standard async ops whose done op does not consume the respective start op and that they might have a reverse data dependency (e.g., `done -> ops -> start`).

This happens with partial pipeline parallelism where the send-dones and recv-dones of the previous iteration consume the loop parameter gtes and are issued before the sends and recvs of the current iteration. This CL removes the requirements for
- having the done op consume the start op and
- traversing them in the traditional order.
",copybara-service[bot],2024-12-11 01:29:57+00:00,['seherellis'],2024-12-11 05:48:53+00:00,2024-12-11 05:48:52+00:00,https://github.com/tensorflow/tensorflow/pull/82708,[],[],
2731577568,pull_request,closed,,Add B100 to default Nvidia gpu backends,"Add B100 to default Nvidia gpu backends
",copybara-service[bot],2024-12-11 01:13:06+00:00,[],2024-12-11 17:21:18+00:00,2024-12-11 17:21:17+00:00,https://github.com/tensorflow/tensorflow/pull/82707,[],[],
2731521040,pull_request,closed,,Cleanup inconsistent names/comments,"Cleanup inconsistent names/comments
",copybara-service[bot],2024-12-11 00:20:11+00:00,['SandSnip3r'],2024-12-11 01:15:24+00:00,2024-12-11 01:15:23+00:00,https://github.com/tensorflow/tensorflow/pull/82706,[],[],
2731503430,pull_request,closed,,"timespan, xplane_visitor: Support operator<=.","timespan, xplane_visitor: Support operator<=.

Timespan exposes operator< and operator==, while xplane_visitor only supports
operator<. Annoyingly, C++20 is required to synthesize the relational operators
from each other, so we simply implement operator<= on both (and operator== on
XPlaneVisitor for completeness using the logical definition.
",copybara-service[bot],2024-12-11 00:09:25+00:00,[],2024-12-13 23:40:53+00:00,2024-12-13 23:40:52+00:00,https://github.com/tensorflow/tensorflow/pull/82705,[],[],
2731483657,pull_request,closed,,[XLA:GPU] Schedule send/recv early if pipeline parallelism ops enabled,"[XLA:GPU] Schedule send/recv early if pipeline parallelism ops enabled
",copybara-service[bot],2024-12-10 23:54:08+00:00,['frgossen'],2024-12-11 22:41:59+00:00,2024-12-11 22:41:58+00:00,https://github.com/tensorflow/tensorflow/pull/82704,[],[],
2731482011,pull_request,open,,Add has_megacore and has_merged_vmem in XPlane stats.,"Add has_megacore and has_merged_vmem in XPlane stats.
",copybara-service[bot],2024-12-10 23:52:30+00:00,['zzzaries'],2024-12-11 21:40:00+00:00,,https://github.com/tensorflow/tensorflow/pull/82703,[],[],
2731478973,pull_request,closed,,Migrate InputPipelineAnalysis data models to open source.,"Migrate InputPipelineAnalysis data models to open source.
",copybara-service[bot],2024-12-10 23:50:04+00:00,[],2024-12-11 00:11:26+00:00,2024-12-11 00:11:25+00:00,https://github.com/tensorflow/tensorflow/pull/82702,[],[],
2731365361,pull_request,closed,,Add a HLOPrintOption to control printing of the parameter number for parameters.,"Add a HLOPrintOption to control printing of the parameter number for parameters.
",copybara-service[bot],2024-12-10 22:43:22+00:00,[],2025-01-08 21:12:52+00:00,2025-01-08 21:12:52+00:00,https://github.com/tensorflow/tensorflow/pull/82701,[],[],
2731343862,pull_request,closed,,Fix an issue in `PartitionGatherTrivialSlicedOperandDimensions` when handling out-of-bound indices.,"Fix an issue in `PartitionGatherTrivialSlicedOperandDimensions` when handling out-of-bound indices.

A gather operation will clamp the fetched indices such that we always retrieve the corresponding entries in the operand. However, the result of `PartitionGatherTrivialSlicedOperandDimensions` will do not handle these indices. Namely, if the indices is out of bound, we do not retrieve the entries from the operand and the result is 0.

This is a execution bug in SPMD partitioner in both GSPMD and Shardy. The compilation succeeds. This issue does not exist in scatter since scatter does not need to clamp the indices.

This change fixes this issue by clamping the indices at the very beginning of `PartitionGatherTrivialSlicedOperandDimensions`.
",copybara-service[bot],2024-12-10 22:31:20+00:00,[],2024-12-13 01:47:02+00:00,2024-12-13 01:47:01+00:00,https://github.com/tensorflow/tensorflow/pull/82700,[],[],
2731336629,pull_request,closed,,Select QNN graph configuration based on input/output tensor type.,"Select QNN graph configuration based on input/output tensor type.
",copybara-service[bot],2024-12-10 22:27:04+00:00,[],2024-12-11 22:28:46+00:00,2024-12-11 22:28:45+00:00,https://github.com/tensorflow/tensorflow/pull/82699,[],[],
2731322558,pull_request,closed,,Make flatbufferwrapper spit out an unpacked model rather than saving it as a member.,"Make flatbufferwrapper spit out an unpacked model rather than saving it as a member.
",copybara-service[bot],2024-12-10 22:19:19+00:00,['LukeBoyer'],2024-12-11 01:10:07+00:00,2024-12-11 01:10:06+00:00,https://github.com/tensorflow/tensorflow/pull/82698,[],[],
2731315264,pull_request,open,,internal change to check pointer validity before access.,"internal change to check pointer validity before access.
",copybara-service[bot],2024-12-10 22:14:21+00:00,[],2024-12-11 19:54:45+00:00,,https://github.com/tensorflow/tensorflow/pull/82697,[],[],
2731311167,pull_request,closed,,Remove unused ErrorSpec.,"Remove unused ErrorSpec.

`//xla/tests:collective_ops_test_cpu` fails to build on tensorflow/xla/linux/cpu/build_cpu.

```
xla/tests/collective_ops_test.cc:1438:19: error: unused variable 'es' [-Werror,-Wunused-variable]
 1438 |   const ErrorSpec es{1e-5, 1e-5};
      |                   ^~
xla/tests/collective_ops_test.cc:1489:19: error: unused variable 'es' [-Werror,-Wunused-variable]
 1489 |   const ErrorSpec es{1e-5, 1e-5};
      |                   ^~
2 errors generated.
```
",copybara-service[bot],2024-12-10 22:11:34+00:00,[],2024-12-11 01:01:44+00:00,2024-12-11 01:01:44+00:00,https://github.com/tensorflow/tensorflow/pull/82696,[],[],
2731309850,pull_request,closed,,Remove unused ConvertFunctionToMlir & ConvertGraphToMlir. The api's are unreferenced and dead code.,"Remove unused ConvertFunctionToMlir & ConvertGraphToMlir. The api's are unreferenced and dead code.
",copybara-service[bot],2024-12-10 22:10:50+00:00,['rocketas'],2024-12-10 22:40:24+00:00,2024-12-10 22:40:24+00:00,https://github.com/tensorflow/tensorflow/pull/82695,[],[],
2731159456,pull_request,closed,,Add a default error spec field to HloRunnerAgnosticTestBase.,"Add a default error spec field to HloRunnerAgnosticTestBase.

This error spec field is the same as the default used in HloTestBase. We provide
this explicit default so that test writers avoid choosing an arbitrary spec that
is too low.
",copybara-service[bot],2024-12-10 20:47:34+00:00,[],2024-12-11 16:49:37+00:00,2024-12-11 16:49:37+00:00,https://github.com/tensorflow/tensorflow/pull/82694,[],[],
2731126265,pull_request,closed,,[XLA:GPU] Use `absl::Status` payload to more precisely identify register allocation errors.,"[XLA:GPU] Use `absl::Status` payload to more precisely identify register allocation errors.

The logic introduced in cl/580967289 is too generic. Resource exhausted errors are not necessarily register allocation errors (e.g. OOM).
",copybara-service[bot],2024-12-10 20:30:20+00:00,[],2024-12-11 11:43:05+00:00,2024-12-11 11:43:04+00:00,https://github.com/tensorflow/tensorflow/pull/82693,[],[],
2731102812,pull_request,closed,,Use `Device::ToString` instead of `Device::DebugString` inside `BaseDeviceList::ToString()`,"Use `Device::ToString` instead of `Device::DebugString` inside `BaseDeviceList::ToString()`

A large device list will be more compact this way since `ToString()` is expected to be shorter than `DebugString()`.
",copybara-service[bot],2024-12-10 20:17:42+00:00,[],2024-12-11 00:01:18+00:00,2024-12-11 00:01:17+00:00,https://github.com/tensorflow/tensorflow/pull/82692,[],[],
2731085159,pull_request,open,,Revert PR #20025: [NVIDIA GPU] LHS enhancement for collective multi-streaming ,"Revert PR #20025: [NVIDIA GPU] LHS enhancement for collective multi-streaming 

This break the pipeline parallelism benchmark. 

Reverts 2b6064775be63f55cc5cda79102443f839c77428
",copybara-service[bot],2024-12-10 20:10:07+00:00,['frgossen'],2024-12-10 20:10:08+00:00,,https://github.com/tensorflow/tensorflow/pull/82691,[],[],
2731073363,pull_request,closed,,Remove the `test_hlo_pjrt_runner` tag.,"Remove the `test_hlo_pjrt_runner` tag.

There are no remaining uses of this tag, so we're removing it.

Tests that are migrated to work with PjRt should use the
`test_migrated_to_hlo_runner_pjrt` tag to always run with PjRt.
",copybara-service[bot],2024-12-10 20:03:35+00:00,[],2024-12-11 17:36:24+00:00,2024-12-11 17:36:24+00:00,https://github.com/tensorflow/tensorflow/pull/82690,[],[],
2731042967,pull_request,open,,PR #20313: Fix async wrapper to walk child computations,"PR #20313: Fix async wrapper to walk child computations

Imported from GitHub PR https://github.com/openxla/xla/pull/20313

Async wrapper should walk all the computations of instructions, except fusion instructions (especially while and condition instructions). This patch adds that, along with tests.
Copybara import of the project:

--
1c9ca5ee7c318e266b066b744678d9c2c5b67cbb by Shraiysh Vaishay <svaishay@nvidia.com>:

Fix async wrapper to walk child computations

Async wrapper should walk all the computations of instructions, except
fusion instructions (especially while and condition instructions). This
patch adds that, along with tests.

--
2c09ae1cd770dec066addaf70f68d2efa32b5462 by Shraiysh Vaishay <svaishay@nvidia.com>:

Addressed comments

Merging this change closes #20313

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20313 from shraiysh:async_wrapper 2c09ae1cd770dec066addaf70f68d2efa32b5462
",copybara-service[bot],2024-12-10 19:47:09+00:00,[],2024-12-11 09:51:38+00:00,,https://github.com/tensorflow/tensorflow/pull/82689,[],[],
2730976999,pull_request,closed,,[Mosaic] Pad trailing transposes chunks with zeros.,"[Mosaic] Pad trailing transposes chunks with zeros.
",copybara-service[bot],2024-12-10 19:12:03+00:00,[],2024-12-12 02:36:51+00:00,2024-12-12 02:36:50+00:00,https://github.com/tensorflow/tensorflow/pull/82688,[],[],
2730972246,pull_request,closed,,Respect DeviceAssignment in HloRunnerPjRt.,"Respect DeviceAssignment in HloRunnerPjRt.

`DeviceAssignment` maps a (replica, computation) tuple to a physical device
index. We must respect this mapping. Prior to this patch we mapped replicas
directly onto devices with the same index.
",copybara-service[bot],2024-12-10 19:09:13+00:00,[],2024-12-10 22:12:20+00:00,2024-12-10 22:12:20+00:00,https://github.com/tensorflow/tensorflow/pull/82687,[],[],
2730957863,pull_request,closed,,Add result accuracy attribute to ExpOp in StableHlo.,"Add result accuracy attribute to ExpOp in StableHlo.
",copybara-service[bot],2024-12-10 19:01:03+00:00,[],2025-01-25 00:17:11+00:00,2025-01-25 00:17:10+00:00,https://github.com/tensorflow/tensorflow/pull/82686,[],[],
2730930571,pull_request,open,,Integrate LLVM at llvm/llvm-project@0f7b3a9407d2,"Integrate LLVM at llvm/llvm-project@0f7b3a9407d2

Updates LLVM usage to match
[0f7b3a9407d2](https://github.com/llvm/llvm-project/commit/0f7b3a9407d2)
",copybara-service[bot],2024-12-10 18:51:09+00:00,[],2024-12-10 18:51:09+00:00,,https://github.com/tensorflow/tensorflow/pull/82685,[],[],
2730928960,pull_request,closed,,Set implicitTrunc on APInt creation,"Set implicitTrunc on APInt creation

With https://github.com/llvm/llvm-project/commit/3494ee95902cef62f767489802e469c58a13ea04, upstream has stricter checks for ints.
",copybara-service[bot],2024-12-10 18:50:32+00:00,[],2024-12-10 20:36:57+00:00,2024-12-10 20:36:57+00:00,https://github.com/tensorflow/tensorflow/pull/82684,[],[],
2730886131,pull_request,open,,Remove `//tensorflow/tsl/platform/strcat.h`.,"Remove `//tensorflow/tsl/platform/strcat.h`.

Now just a forwarding header.
",copybara-service[bot],2024-12-10 18:28:40+00:00,['majnemer'],2024-12-10 19:55:20+00:00,,https://github.com/tensorflow/tensorflow/pull/82683,[],[],
2730878052,pull_request,closed,,PR #20216: Add pattern for offset as a function of loop iteration (ds fusion),"PR #20216: Add pattern for offset as a function of loop iteration (ds fusion)

Imported from GitHub PR https://github.com/openxla/xla/pull/20216

Improving the pattern being recognized in dynamic slice fusion, to allow offset as a function of loop induction variable. This offset will later be calculated on the host at runtime (the host will keep track of the induction variable).
Copybara import of the project:

--
9ead1a6ffe1482024f5ed72ef031cb7b33657ba8 by Shraiysh Vaishay <svaishay@nvidia.com>:

Add pattern for offset as a function of loop iteration (ds fusion)

Improving the pattern being recognized in dynamic slice fusion, to allow
offset as a function of loop induction variable. This offset will later
be calculated on the host at runtime (the host will keep track of the
induction variable).

--
96371e9cac87081b3159ab2782498b69965dd2e9 by Shraiysh Vaishay <svaishay@nvidia.com>:

Addressed comments

--
a87d45c477eb6490c229c01b0fe7067c1238eb7a by Shraiysh Vaishay <svaishay@nvidia.com>:

Addressed comment

Merging this change closes #20216

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20216 from shraiysh:ds_fusion_2 a87d45c477eb6490c229c01b0fe7067c1238eb7a
",copybara-service[bot],2024-12-10 18:24:14+00:00,[],2024-12-11 10:08:35+00:00,2024-12-11 10:08:34+00:00,https://github.com/tensorflow/tensorflow/pull/82682,[],[],
2730828885,pull_request,closed,,"Remove use of ConvertFunctionToMlir as it is deprecated, this is the only remaining call. Functionality does not change.","Remove use of ConvertFunctionToMlir as it is deprecated, this is the only remaining call. Functionality does not change.
",copybara-service[bot],2024-12-10 18:06:39+00:00,['rocketas'],2024-12-10 19:26:20+00:00,2024-12-10 19:26:18+00:00,https://github.com/tensorflow/tensorflow/pull/82681,[],[],
2730745116,pull_request,closed,,[XLA:GPU] Remove `--xla_gpu_experimental_enable_triton_softmax_priority_fusion`.,"[XLA:GPU] Remove `--xla_gpu_experimental_enable_triton_softmax_priority_fusion`.

The flag is no longer necessary, and can therefore be deleted from the
compiler's API.
",copybara-service[bot],2024-12-10 17:33:50+00:00,[],2024-12-10 20:46:21+00:00,2024-12-10 20:46:21+00:00,https://github.com/tensorflow/tensorflow/pull/82680,[],[],
2730657378,pull_request,open,,Add GL Utils test.,"Add GL Utils test.
",copybara-service[bot],2024-12-10 16:51:25+00:00,[],2025-01-24 17:08:44+00:00,,https://github.com/tensorflow/tensorflow/pull/82679,[],[],
2730647911,pull_request,closed,,[XLA:GPU] Propagate all profiling failures to `gemm_fusion_autotuner.cc`.,"[XLA:GPU] Propagate all profiling failures to `gemm_fusion_autotuner.cc`.

Currently register allocation failures are converted to `std::nullopt` which are then special cased (either ignored or converted back to internal failures). We remove the intermediate conversion and forward the failure to the callers. This is simpler and semantically equivalent with the added benefit that we don't loose the failure details.
",copybara-service[bot],2024-12-10 16:47:31+00:00,[],2024-12-12 14:39:53+00:00,2024-12-12 14:39:52+00:00,https://github.com/tensorflow/tensorflow/pull/82678,[],[],
2730574621,pull_request,closed,,[XLA:CPU] Update ShapeToIrType & PrimitiveTypeToIrType to take a LLVMContext,"[XLA:CPU] Update ShapeToIrType & PrimitiveTypeToIrType to take a LLVMContext
",copybara-service[bot],2024-12-10 16:18:39+00:00,[],2024-12-10 17:59:29+00:00,2024-12-10 17:59:28+00:00,https://github.com/tensorflow/tensorflow/pull/82677,[],[],
2730571697,pull_request,closed,,[XLA:GPU] Guard send/recv schedule manipulation behind xla_gpu_enable_pipelined_p2p flag,"[XLA:GPU] Guard send/recv schedule manipulation behind xla_gpu_enable_pipelined_p2p flag

This was added for pipeline parallelism optimisations and is only used when xla_gpu_enable_pipelined_p2p is enabled.
This scheudle manipulation only ever kicked in when xla_gpu_enable_pipelined_p2p was enabled anyways. Let's make this clear.
",copybara-service[bot],2024-12-10 16:17:16+00:00,['frgossen'],2024-12-10 23:14:57+00:00,2024-12-10 23:14:56+00:00,https://github.com/tensorflow/tensorflow/pull/82676,[],[],
2730567174,pull_request,closed,,[XLA:CPU] Use KernelApiIrBuilder in IrEmitter2,"[XLA:CPU] Use KernelApiIrBuilder in IrEmitter2

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20334 from shraiysh:nfc_clang_format_fix 65921cebb91536e319b2e922f7f27d310de8d114
",copybara-service[bot],2024-12-10 16:15:24+00:00,[],2024-12-11 11:35:13+00:00,2024-12-11 11:35:12+00:00,https://github.com/tensorflow/tensorflow/pull/82675,[],[],
2730565196,pull_request,closed,,[XLA:CPU] Add new KernelApiIrBuilder,"[XLA:CPU] Add new KernelApiIrBuilder
",copybara-service[bot],2024-12-10 16:14:42+00:00,[],2024-12-11 10:42:56+00:00,2024-12-11 10:42:54+00:00,https://github.com/tensorflow/tensorflow/pull/82674,[],[],
2730559897,pull_request,closed,,[XLA:CPU] Implement ElementalKernelEmitter,"[XLA:CPU] Implement ElementalKernelEmitter
",copybara-service[bot],2024-12-10 16:12:24+00:00,[],2024-12-12 10:30:37+00:00,2024-12-12 10:30:36+00:00,https://github.com/tensorflow/tensorflow/pull/82673,[],[],
2730494458,pull_request,closed,,Integrate LLVM at llvm/llvm-project@0f7b3a9407d2,"Integrate LLVM at llvm/llvm-project@0f7b3a9407d2

Updates LLVM usage to match
[0f7b3a9407d2](https://github.com/llvm/llvm-project/commit/0f7b3a9407d2)
",copybara-service[bot],2024-12-10 15:44:45+00:00,[],2024-12-10 18:40:01+00:00,2024-12-10 18:40:01+00:00,https://github.com/tensorflow/tensorflow/pull/82672,[],[],
2730492708,pull_request,closed,,[numpy] Fix test failures under NumPy 2.2.,"[numpy] Fix test failures under NumPy 2.2.
",copybara-service[bot],2024-12-10 15:44:01+00:00,[],2024-12-10 22:50:28+00:00,2024-12-10 22:50:27+00:00,https://github.com/tensorflow/tensorflow/pull/82671,[],[],
2730420318,pull_request,closed,,Add dependencies to third_party/tensorflow/compiler/xla/service/spmd/shardy/sdy_round_trip/ friends group,"Add dependencies to third_party/tensorflow/compiler/xla/service/spmd/shardy/sdy_round_trip/ friends group
",copybara-service[bot],2024-12-10 15:15:52+00:00,[],2024-12-10 15:51:38+00:00,2024-12-10 15:51:37+00:00,https://github.com/tensorflow/tensorflow/pull/82670,[],[],
2730312307,pull_request,closed,,Improve speed and collision/aliasing resistance of Absl::HashOf() on HloModule/HloComputation:,"Improve speed and collision/aliasing resistance of Absl::HashOf() on HloModule/HloComputation:
 * Rather that hashing only opcodes + output/operand shapes (in hlo_instruction.h), build the hash progressively (in hlo_computation.h) walking the instructions in post-order, hashing opcode, shape and other constants (e.g. parameter value, literal value) once per instruction
 * Add wrapper to support Absh::Hash on Literals
 * Add tests covering parameter/literal values, instruction reordering etc.
",copybara-service[bot],2024-12-10 14:39:59+00:00,[],2025-01-08 00:22:10+00:00,2025-01-08 00:22:10+00:00,https://github.com/tensorflow/tensorflow/pull/82668,[],[],
2730133501,pull_request,open,,[XLA:GPU] Fix logging bug.,"[XLA:GPU] Fix logging bug.

Using the output vector size as a proxy for the candidate index is not correct. When `MeasurePerformance` returns `std::nullopt`, the result is not added to the output vector.
",copybara-service[bot],2024-12-10 13:30:24+00:00,[],2024-12-10 13:30:24+00:00,,https://github.com/tensorflow/tensorflow/pull/82667,[],[],
2730066105,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 13:02:21+00:00,[],2024-12-10 13:02:21+00:00,,https://github.com/tensorflow/tensorflow/pull/82666,[],[],
2729992159,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 12:28:56+00:00,[],2024-12-13 04:53:56+00:00,2024-12-13 04:53:54+00:00,https://github.com/tensorflow/tensorflow/pull/82665,[],[],
2729950034,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 12:09:53+00:00,[],2024-12-10 12:09:53+00:00,,https://github.com/tensorflow/tensorflow/pull/82664,[],[],
2729943967,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 12:07:03+00:00,[],2024-12-10 12:07:03+00:00,,https://github.com/tensorflow/tensorflow/pull/82663,[],[],
2729913563,pull_request,closed,,PR #16438: aarch64: implement onednn matmul operator with explicit reorders,"PR #16438: aarch64: implement onednn matmul operator with explicit reorders

Imported from GitHub PR https://github.com/openxla/xla/pull/16438

I have added a new function for aarch64 mainly because the changes are spread all over and keeping it common with the existing one looked very convoluted.


Copybara import of the project:

--
0d9d31909a9bb3ce8a2c78798e3b5f0e9ec2bb1a by Sunita Nadampalli <nadampal@amazon.com>:

Add explicit reorders to onednn matmul operator

For the scenario when weights are not prepacked,
they need to be explicitly reordered for Arm Compute Library
backend on aarch64

--
24797a017c9a882647f9c612f895b705d04a17f5 by Sunita Nadampalli <nadampal@amazon.com>:

onednn acl: add blocked layout format support for matmul weight tensors

--
56cbd6bab3d18c1e13da9c3714c9a8e49d83d9e8 by Sunita Nadampalli <nadampal@amazon.com>:

onednn acl: fx segfault during post op execute

--
26664cf2d2d3c94693760706f6e1292121fdcd97 by Sunita Nadampalli <nadampal@amazon.com>:

onednn acl: add bf16 platform support check

--
a0056ae45e17fceaa82498549162237e365a690c by Sunita Nadampalli <nadampal@amazon.com>:

onednn acl: add sbgemm definition for matmul primitive

Merging this change closes #16438

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16438 from snadampal:aarch64_xla a0056ae45e17fceaa82498549162237e365a690c
",copybara-service[bot],2024-12-10 11:55:00+00:00,[],2024-12-10 12:33:20+00:00,2024-12-10 12:33:19+00:00,https://github.com/tensorflow/tensorflow/pull/82662,[],"[{'comment_id': 2531375315, 'issue_id': 2729913563, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82662/checks?check_run_id=34188917713) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 10, 11, 55, 5, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-10 11:55:05 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82662/checks?check_run_id=34188917713) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2729818949,pull_request,open,,[XLA:GPU] Move calls to `allocation_attr.freed_by_func` into `BFCAllocator::AllocateRawInternal`.,"[XLA:GPU] Move calls to `allocation_attr.freed_by_func` into `BFCAllocator::AllocateRawInternal`.

The logic is duplicated at all call sites.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20025 from terryysun:terryysun/lhs_deadlock_avoidance cf45a819590ec5cd8d48580939fcbe01546172b4
",copybara-service[bot],2024-12-10 11:14:18+00:00,[],2024-12-10 11:14:18+00:00,,https://github.com/tensorflow/tensorflow/pull/82661,[],[],
2729798226,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 11:05:19+00:00,[],2024-12-13 11:08:46+00:00,2024-12-13 11:08:45+00:00,https://github.com/tensorflow/tensorflow/pull/82660,[],[],
2729777923,pull_request,closed,,[XLA:GPU] Disable cutlass dynamic-update-slice rewrite on V100.,"[XLA:GPU] Disable cutlass dynamic-update-slice rewrite on V100.
",copybara-service[bot],2024-12-10 10:57:23+00:00,['pifon2a'],2024-12-10 11:38:08+00:00,2024-12-10 11:38:07+00:00,https://github.com/tensorflow/tensorflow/pull/82659,[],[],
2729768982,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 10:54:54+00:00,[],2024-12-15 23:22:57+00:00,2024-12-15 23:22:57+00:00,https://github.com/tensorflow/tensorflow/pull/82658,[],[],
2729759203,pull_request,closed,,[xla:gpu] Extracted `CreateTritonPipeline` into a separate target,"[xla:gpu] Extracted `CreateTritonPipeline` into a separate target

This will allow us to use it from jaxlib without depending on the whole fusion
emitter. See google/jax#25196.
",copybara-service[bot],2024-12-10 10:50:47+00:00,['superbobry'],2024-12-10 17:44:15+00:00,2024-12-10 17:44:14+00:00,https://github.com/tensorflow/tensorflow/pull/82657,[],[],
2729730365,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 10:40:15+00:00,[],2024-12-10 10:40:15+00:00,,https://github.com/tensorflow/tensorflow/pull/82656,[],[],
2729666312,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 10:15:55+00:00,[],2024-12-10 12:42:43+00:00,2024-12-10 12:42:42+00:00,https://github.com/tensorflow/tensorflow/pull/82655,[],[],
2729664389,pull_request,closed,,Integrate LLVM at llvm/llvm-project@be2df95e9281,"Integrate LLVM at llvm/llvm-project@be2df95e9281

Updates LLVM usage to match
[be2df95e9281](https://github.com/llvm/llvm-project/commit/be2df95e9281)
",copybara-service[bot],2024-12-10 10:15:08+00:00,[],2024-12-10 13:53:10+00:00,2024-12-10 13:53:08+00:00,https://github.com/tensorflow/tensorflow/pull/82654,[],[],
2729659077,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20006 from jaro-sevcik:jsevcik/horizontal-loop-fusion-default-memory-space-only 6a3b325aae43227b847e1124a85236ab89e6d7e2
",copybara-service[bot],2024-12-10 10:12:49+00:00,[],2024-12-11 10:52:09+00:00,2024-12-11 10:52:08+00:00,https://github.com/tensorflow/tensorflow/pull/82653,[],[],
2729649214,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19099 from Intel-tensorflow:akhil/conv_fusions_3_d 643bf016dbddd644ce71d10efe3c02d212c2888e
",copybara-service[bot],2024-12-10 10:09:35+00:00,[],2024-12-12 13:27:02+00:00,2024-12-12 13:27:02+00:00,https://github.com/tensorflow/tensorflow/pull/82652,[],[],
2729640679,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 10:06:46+00:00,[],2024-12-10 10:06:46+00:00,,https://github.com/tensorflow/tensorflow/pull/82651,[],[],
2729632217,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20025 from terryysun:terryysun/lhs_deadlock_avoidance cf45a819590ec5cd8d48580939fcbe01546172b4
",copybara-service[bot],2024-12-10 10:03:36+00:00,[],2024-12-10 11:06:01+00:00,,https://github.com/tensorflow/tensorflow/pull/82650,[],[],
2729627778,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 10:01:45+00:00,[],2024-12-10 10:01:45+00:00,,https://github.com/tensorflow/tensorflow/pull/82649,[],[],
2729624495,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 10:00:20+00:00,[],2024-12-10 10:00:20+00:00,,https://github.com/tensorflow/tensorflow/pull/82648,[],[],
2729621271,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 09:59:09+00:00,[],2024-12-10 09:59:09+00:00,,https://github.com/tensorflow/tensorflow/pull/82647,[],[],
2729619359,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 09:58:24+00:00,[],2024-12-10 09:58:24+00:00,,https://github.com/tensorflow/tensorflow/pull/82646,[],[],
2729618943,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20334 from shraiysh:nfc_clang_format_fix 65921cebb91536e319b2e922f7f27d310de8d114
",copybara-service[bot],2024-12-10 09:58:14+00:00,[],2024-12-11 11:26:24+00:00,2024-12-11 11:26:23+00:00,https://github.com/tensorflow/tensorflow/pull/82645,[],[],
2729602094,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 09:51:33+00:00,[],2024-12-12 08:28:35+00:00,2024-12-12 08:28:35+00:00,https://github.com/tensorflow/tensorflow/pull/82644,[],[],
2729597825,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 09:50:19+00:00,[],2024-12-10 10:38:54+00:00,,https://github.com/tensorflow/tensorflow/pull/82643,[],[],
2729562434,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 09:37:25+00:00,[],2024-12-12 08:08:22+00:00,2024-12-12 08:08:20+00:00,https://github.com/tensorflow/tensorflow/pull/82642,[],[],
2729550748,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 09:33:30+00:00,[],2024-12-10 12:35:56+00:00,,https://github.com/tensorflow/tensorflow/pull/82641,[],[],
2729546585,pull_request,open,,Test Leak Checker (confidential word),"Test Leak Checker (confidential word)
",copybara-service[bot],2024-12-10 09:31:48+00:00,[],2024-12-10 09:31:48+00:00,,https://github.com/tensorflow/tensorflow/pull/82640,[],[],
2729446348,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 08:56:11+00:00,[],2024-12-10 08:56:11+00:00,,https://github.com/tensorflow/tensorflow/pull/82639,[],[],
2729422413,pull_request,closed,,Add debug option for failing the PTX compilation on register spilling,"Add debug option for failing the PTX compilation on register spilling

With this change, it's possible to abort a CUDA kernel compilation if the generated PTX code results in register spilling on the target architecture.

The feature is mainly useful with tools like `run_hlo_module`. Passing the flag `--xla_gpu_fail_ptx_compilation_on_register_spilling` activates this mode.

Note that this has no effect on kernels that go through autotuning (Triton kernels) since autotuning already discards spilling variants of the kernel.
",copybara-service[bot],2024-12-10 08:46:14+00:00,[],2024-12-10 10:46:16+00:00,2024-12-10 10:46:15+00:00,https://github.com/tensorflow/tensorflow/pull/82638,[],[],
2729394311,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 08:32:45+00:00,[],2024-12-10 08:32:45+00:00,,https://github.com/tensorflow/tensorflow/pull/82636,[],[],
2729364459,pull_request,closed,,fix audit wheel compliance issues for pywrap rules,"fix audit wheel compliance issues for pywrap rules
",copybara-service[bot],2024-12-10 08:19:38+00:00,['vam-google'],2024-12-11 06:45:42+00:00,2024-12-11 06:45:42+00:00,https://github.com/tensorflow/tensorflow/pull/82635,[],[],
2729330443,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 08:03:25+00:00,[],2024-12-11 14:31:58+00:00,2024-12-11 14:31:57+00:00,https://github.com/tensorflow/tensorflow/pull/82634,[],[],
2729329257,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 08:02:48+00:00,[],2024-12-11 10:33:24+00:00,2024-12-11 10:33:23+00:00,https://github.com/tensorflow/tensorflow/pull/82633,[],[],
2729328475,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 08:02:21+00:00,[],2024-12-12 07:06:42+00:00,2024-12-12 07:06:42+00:00,https://github.com/tensorflow/tensorflow/pull/82632,[],[],
2729324867,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 08:00:35+00:00,[],2024-12-10 08:00:35+00:00,,https://github.com/tensorflow/tensorflow/pull/82631,[],[],
2729309585,pull_request,closed,,Add MHLO `mhlo.custom_call @ragged_all_to_all` -> HLO RaggedAllToAll pass,"Add MHLO `mhlo.custom_call @ragged_all_to_all` -> HLO RaggedAllToAll pass

The following mlir module
```
module @jit_bind {
  func.func public @main(%arg0: tensor<6xf32>, %arg1: tensor<6xf32>, %arg2: tensor<3xi32>, %arg3: tensor<3xi32>, %arg4: tensor<3xi32>, %arg5: tensor<3xi32>) -> (tensor<6xf32>) {
    %0 = mhlo.custom_call @ragged_all_to_all(%arg0, %arg1, %arg2, %arg3, %arg4, %arg5) {api_version = 4 : i32, backend_config = {replica_groups = dense<[[0, 1, 2]]> : tensor<1x3xi64>}} : (tensor<6xf32>, tensor<6xf32>, tensor<3xi32>, tensor<3xi32>, tensor<3xi32>, tensor<3xi32>) -> tensor<6xf32>
    return %0 : tensor<6xf32>
  }
}
```

translates to
```
HloModule jit_bind, entry_computation_layout={(f32[6]{0}, f32[6]{0}, s32[3]{0}, s32[3]{0}, s32[3]{0}, /*index=5*/s32[3]{0})->f32[6]{0}}

ENTRY %main.8 (Arg_0.1: f32[6], Arg_1.2: f32[6], Arg_2.3: s32[3], Arg_3.4: s32[3], Arg_4.5: s32[3], Arg_5.6: s32[3]) -> f32[6] {
  %Arg_0.1 = f32[6] parameter(0)
  %Arg_1.2 = f32[6] parameter(1)
  %Arg_2.3 = s32[3] parameter(2)
  %Arg_3.4 = s32[3] parameter(3)
  %Arg_4.5 = s32[3] parameter(4)
  %Arg_5.6 = s32[3] parameter(5)
  ROOT %ragged-all-to-all.7 = f32[6] ragged-all-to-all(f32[6] %Arg_0.1, f32[6] %Arg_1.2, s32[3] %Arg_2.3, s32[3] %Arg_3.4, s32[3] %Arg_4.5, /*index=5*/s32[3] %Arg_5.6), replica_groups={{0,1,2}}
}
```
",copybara-service[bot],2024-12-10 07:52:11+00:00,['ghpvnist'],2024-12-10 18:15:30+00:00,2024-12-10 18:15:29+00:00,https://github.com/tensorflow/tensorflow/pull/82630,[],[],
2729292121,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:43:24+00:00,[],2024-12-10 07:43:24+00:00,,https://github.com/tensorflow/tensorflow/pull/82629,[],[],
2729230670,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:17:47+00:00,[],2024-12-10 13:13:54+00:00,2024-12-10 13:13:53+00:00,https://github.com/tensorflow/tensorflow/pull/82628,[],[],
2729229225,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:17:03+00:00,[],2024-12-10 07:17:03+00:00,,https://github.com/tensorflow/tensorflow/pull/82627,[],[],
2729228269,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:16:25+00:00,[],2024-12-10 13:31:15+00:00,2024-12-10 13:31:14+00:00,https://github.com/tensorflow/tensorflow/pull/82626,[],[],
2729228128,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/81030 from tensorflow:keerthanakadiri-patch-1 b362f96437cb3a5b9a94eac88f958d31066c9db8
",copybara-service[bot],2024-12-10 07:16:21+00:00,[],2024-12-11 13:28:52+00:00,2024-12-11 13:28:51+00:00,https://github.com/tensorflow/tensorflow/pull/82625,[],[],
2729227431,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20214 from shraiysh:ds_fusion 92e120354e04c8b754b5853c79662b96342b44f1
",copybara-service[bot],2024-12-10 07:15:54+00:00,[],2024-12-11 14:04:48+00:00,2024-12-11 14:04:47+00:00,https://github.com/tensorflow/tensorflow/pull/82624,[],[],
2729227311,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:15:50+00:00,[],2024-12-10 07:15:50+00:00,,https://github.com/tensorflow/tensorflow/pull/82623,[],[],
2729227057,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:15:41+00:00,[],2024-12-12 06:41:22+00:00,2024-12-12 06:41:21+00:00,https://github.com/tensorflow/tensorflow/pull/82622,[],[],
2729226747,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:15:30+00:00,[],2024-12-12 07:48:44+00:00,,https://github.com/tensorflow/tensorflow/pull/82621,[],[],
2729226046,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:15:06+00:00,[],2024-12-10 07:15:06+00:00,,https://github.com/tensorflow/tensorflow/pull/82620,[],[],
2729225913,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:15:02+00:00,[],2024-12-11 05:23:48+00:00,2024-12-11 05:23:47+00:00,https://github.com/tensorflow/tensorflow/pull/82619,[],[],
2729225208,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:14:36+00:00,[],2024-12-12 10:57:57+00:00,,https://github.com/tensorflow/tensorflow/pull/82618,[],[],
2729224840,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:14:22+00:00,[],2024-12-11 08:29:27+00:00,2024-12-11 08:29:26+00:00,https://github.com/tensorflow/tensorflow/pull/82617,[],[],
2729224770,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:14:20+00:00,[],2024-12-11 05:13:59+00:00,2024-12-11 05:13:58+00:00,https://github.com/tensorflow/tensorflow/pull/82616,[],[],
2729223426,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:13:40+00:00,[],2024-12-12 12:38:44+00:00,2024-12-12 12:38:43+00:00,https://github.com/tensorflow/tensorflow/pull/82615,[],[],
2729223070,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:13:31+00:00,[],2024-12-10 07:13:31+00:00,,https://github.com/tensorflow/tensorflow/pull/82614,[],[],
2729222965,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20334 from shraiysh:nfc_clang_format_fix 65921cebb91536e319b2e922f7f27d310de8d114
",copybara-service[bot],2024-12-10 07:13:27+00:00,[],2024-12-11 12:02:21+00:00,2024-12-11 12:02:20+00:00,https://github.com/tensorflow/tensorflow/pull/82613,[],[],
2729222214,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:13:08+00:00,[],2024-12-11 14:12:00+00:00,2024-12-11 14:11:59+00:00,https://github.com/tensorflow/tensorflow/pull/82612,[],[],
2729221201,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/81030 from tensorflow:keerthanakadiri-patch-1 b362f96437cb3a5b9a94eac88f958d31066c9db8
",copybara-service[bot],2024-12-10 07:12:40+00:00,[],2024-12-11 12:47:31+00:00,2024-12-11 12:47:31+00:00,https://github.com/tensorflow/tensorflow/pull/82611,[],[],
2729220603,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:12:28+00:00,[],2024-12-10 13:02:06+00:00,2024-12-10 13:02:06+00:00,https://github.com/tensorflow/tensorflow/pull/82610,[],[],
2729219812,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:11:56+00:00,[],2024-12-12 08:43:31+00:00,,https://github.com/tensorflow/tensorflow/pull/82609,[],[],
2729219230,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/81030 from tensorflow:keerthanakadiri-patch-1 b362f96437cb3a5b9a94eac88f958d31066c9db8
",copybara-service[bot],2024-12-10 07:11:33+00:00,[],2024-12-11 12:42:07+00:00,2024-12-11 12:42:07+00:00,https://github.com/tensorflow/tensorflow/pull/82608,[],[],
2729219004,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20313 from shraiysh:async_wrapper 2c09ae1cd770dec066addaf70f68d2efa32b5462
",copybara-service[bot],2024-12-10 07:11:26+00:00,[],2024-12-11 13:42:41+00:00,2024-12-11 13:42:40+00:00,https://github.com/tensorflow/tensorflow/pull/82607,[],[],
2729218824,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:11:18+00:00,[],2024-12-12 06:53:58+00:00,2024-12-12 06:53:54+00:00,https://github.com/tensorflow/tensorflow/pull/82606,[],[],
2729218145,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:10:52+00:00,[],2024-12-10 07:10:52+00:00,,https://github.com/tensorflow/tensorflow/pull/82605,[],[],
2729217944,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/81030 from tensorflow:keerthanakadiri-patch-1 b362f96437cb3a5b9a94eac88f958d31066c9db8
",copybara-service[bot],2024-12-10 07:10:44+00:00,[],2024-12-11 12:24:14+00:00,2024-12-11 12:24:13+00:00,https://github.com/tensorflow/tensorflow/pull/82604,[],[],
2729217269,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:10:18+00:00,[],2024-12-12 08:20:47+00:00,2024-12-12 08:20:47+00:00,https://github.com/tensorflow/tensorflow/pull/82603,[],[],
2729217116,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:10:12+00:00,[],2024-12-12 07:59:11+00:00,2024-12-12 07:59:11+00:00,https://github.com/tensorflow/tensorflow/pull/82602,[],[],
2729216413,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:09:45+00:00,[],2024-12-11 09:26:36+00:00,2024-12-11 09:26:36+00:00,https://github.com/tensorflow/tensorflow/pull/82601,[],[],
2729216211,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:09:37+00:00,[],2024-12-12 07:42:31+00:00,,https://github.com/tensorflow/tensorflow/pull/82600,[],[],
2729215936,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:09:25+00:00,[],2024-12-11 12:14:12+00:00,,https://github.com/tensorflow/tensorflow/pull/82599,[],[],
2729215717,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:09:17+00:00,[],2024-12-10 07:09:17+00:00,,https://github.com/tensorflow/tensorflow/pull/82598,[],[],
2729215700,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:09:16+00:00,[],2024-12-12 11:28:40+00:00,2024-12-12 11:28:40+00:00,https://github.com/tensorflow/tensorflow/pull/82597,[],[],
2729215632,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:09:14+00:00,[],2024-12-12 06:19:55+00:00,2024-12-12 06:19:54+00:00,https://github.com/tensorflow/tensorflow/pull/82596,[],[],
2729213036,pull_request,closed,,Replace std::string_view with absl::string_view,"Replace std::string_view with absl::string_view
",copybara-service[bot],2024-12-10 07:07:33+00:00,[],2024-12-10 10:17:18+00:00,2024-12-10 10:17:17+00:00,https://github.com/tensorflow/tensorflow/pull/82595,[],[],
2729212703,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 07:07:19+00:00,[],2024-12-10 07:07:19+00:00,,https://github.com/tensorflow/tensorflow/pull/82594,[],[],
2729197828,pull_request,closed,,Replace std::string_view with absl::string_view,"Replace std::string_view with absl::string_view
",copybara-service[bot],2024-12-10 06:57:41+00:00,[],2024-12-14 08:34:19+00:00,2024-12-14 08:34:17+00:00,https://github.com/tensorflow/tensorflow/pull/82593,[],[],
2729182222,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/82466 from tensorflow:LakshmiKalaKadali-patch-7 ac56327b7f0bf95811abe0d4b5aca3ea3a608dc2
",copybara-service[bot],2024-12-10 06:47:41+00:00,[],2024-12-10 06:47:41+00:00,,https://github.com/tensorflow/tensorflow/pull/82592,[],[],
2729181984,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/82466 from tensorflow:LakshmiKalaKadali-patch-7 ac56327b7f0bf95811abe0d4b5aca3ea3a608dc2
",copybara-service[bot],2024-12-10 06:47:31+00:00,[],2024-12-10 06:47:31+00:00,,https://github.com/tensorflow/tensorflow/pull/82591,[],[],
2729181609,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 06:47:19+00:00,[],2024-12-10 10:03:27+00:00,,https://github.com/tensorflow/tensorflow/pull/82590,[],[],
2729177139,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/82466 from tensorflow:LakshmiKalaKadali-patch-7 ac56327b7f0bf95811abe0d4b5aca3ea3a608dc2
",copybara-service[bot],2024-12-10 06:45:19+00:00,[],2024-12-10 06:45:19+00:00,,https://github.com/tensorflow/tensorflow/pull/82589,[],[],
2729173390,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/82466 from tensorflow:LakshmiKalaKadali-patch-7 ac56327b7f0bf95811abe0d4b5aca3ea3a608dc2
",copybara-service[bot],2024-12-10 06:43:27+00:00,[],2024-12-10 06:43:27+00:00,,https://github.com/tensorflow/tensorflow/pull/82588,[],[],
2729111900,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 06:03:03+00:00,[],2024-12-12 05:50:18+00:00,2024-12-12 05:50:17+00:00,https://github.com/tensorflow/tensorflow/pull/82587,[],[],
2729107745,pull_request,closed,,Replace std::string_view with absl::string_view,"Replace std::string_view with absl::string_view
",copybara-service[bot],2024-12-10 05:59:57+00:00,[],2024-12-10 22:29:41+00:00,2024-12-10 22:29:40+00:00,https://github.com/tensorflow/tensorflow/pull/82586,[],[],
2729073853,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 05:42:52+00:00,[],2024-12-10 05:42:52+00:00,,https://github.com/tensorflow/tensorflow/pull/82585,[],[],
2729059843,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 05:33:58+00:00,[],2024-12-10 05:33:58+00:00,,https://github.com/tensorflow/tensorflow/pull/82584,[],[],
2729025662,pull_request,closed,,Replace std::string_view with absl::string_view,"Replace std::string_view with absl::string_view
",copybara-service[bot],2024-12-10 05:11:59+00:00,[],2024-12-10 07:02:07+00:00,2024-12-10 07:02:06+00:00,https://github.com/tensorflow/tensorflow/pull/82583,[],[],
2729013314,pull_request,closed,,PR #19161: Asymmetrically Replicated Instructions in Replication Analysis,"PR #19161: Asymmetrically Replicated Instructions in Replication Analysis

Imported from GitHub PR https://github.com/openxla/xla/pull/19161

Extends the HLO replication analysis to handle asymmetrically replicated instructions with replica groups covering multiple partitions and replicas.
Copybara import of the project:

--
2142a2275583a1de3e9c73cf4c751b3d06d43b4d by Philipp Hack <phack@nvidia.com>:

Extends the HLO replication analysis to asymmetrically replicated instructions.

--
9b0a98454533b6dc98320963ce88c6f17e8d9fb8 by Philipp Hack <phack@nvidia.com>:

Extends the HLO replication analysis to asymmetrically replicated instructions.

--
22ff34d0d02acf2ad2fad5caacf10a40233e3193 by Philipp Hack <phack@nvidia.com>:

Extends the HLO replication analysis to asymmetrically replicated instructions.

--
337a28a1992dea5ea4d2432f229f56f7409025de by Philipp Hack <phack@nvidia.com>:

Extends the HLO replication analysis to asymmetrically replicated instructions.

--
300c9e52325f65952f93d685c4730b479c3a6fd2 by Philipp Hack <phack@nvidia.com>:

Extends the HLO replication analysis to asymmetrically replicated instructions.

--
3721d68e2b373533d8d114474a53d66543f868c7 by Philipp Hack <phack@nvidia.com>:

Extends the HLO replication analysis to asymmetrically replicated instructions.

Merging this change closes #19161

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19161 from philipphack:u_replication_asymmetric_xla 3721d68e2b373533d8d114474a53d66543f868c7
",copybara-service[bot],2024-12-10 05:01:18+00:00,[],2024-12-11 10:00:22+00:00,2024-12-11 10:00:21+00:00,https://github.com/tensorflow/tensorflow/pull/82582,[],[],
2728999737,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 04:50:57+00:00,[],2024-12-10 04:50:57+00:00,,https://github.com/tensorflow/tensorflow/pull/82581,[],[],
2728988140,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 04:41:31+00:00,[],2024-12-13 07:45:57+00:00,2024-12-13 07:45:56+00:00,https://github.com/tensorflow/tensorflow/pull/82580,[],[],
2728967617,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-10 04:26:47+00:00,[],2024-12-10 04:26:47+00:00,,https://github.com/tensorflow/tensorflow/pull/82579,[],[],
2728951022,pull_request,closed,,Migrate cpu_compiler_test to always use PjRt for its test backend.,"Migrate cpu_compiler_test to always use PjRt for its test backend.
",copybara-service[bot],2024-12-10 04:13:03+00:00,[],2024-12-10 20:13:25+00:00,2024-12-10 20:13:24+00:00,https://github.com/tensorflow/tensorflow/pull/82578,[],[],
2728938035,pull_request,closed,,Migrate broadcast_test to always use PjRt for its test backend.,"Migrate broadcast_test to always use PjRt for its test backend.
",copybara-service[bot],2024-12-10 04:01:31+00:00,[],2024-12-11 17:07:42+00:00,2024-12-11 17:07:42+00:00,https://github.com/tensorflow/tensorflow/pull/82577,[],[],
2728935483,pull_request,closed,,Migrate all_reduce_test to always use PjRt for its test backend.,"Migrate all_reduce_test to always use PjRt for its test backend.
",copybara-service[bot],2024-12-10 03:59:10+00:00,[],2024-12-10 23:08:58+00:00,2024-12-10 23:08:58+00:00,https://github.com/tensorflow/tensorflow/pull/82576,[],[],
2728934280,pull_request,closed,,Migrate copy_test to always use PjRt for its test backend.,"Migrate copy_test to always use PjRt for its test backend.
",copybara-service[bot],2024-12-10 03:57:52+00:00,[],2024-12-10 20:57:01+00:00,2024-12-10 20:57:00+00:00,https://github.com/tensorflow/tensorflow/pull/82575,[],[],
2728738435,pull_request,open,,Enable OpResolver with XNNPACK for quantizer,"Enable OpResolver with XNNPACK for quantizer
",copybara-service[bot],2024-12-10 01:56:48+00:00,[],2024-12-10 18:26:03+00:00,,https://github.com/tensorflow/tensorflow/pull/82573,[],[],
2728709904,pull_request,closed,,Replace std::string_view with absl::string_view,"Replace std::string_view with absl::string_view
",copybara-service[bot],2024-12-10 01:33:51+00:00,[],2024-12-10 18:50:02+00:00,2024-12-10 18:50:01+00:00,https://github.com/tensorflow/tensorflow/pull/82572,[],[],
2728668703,pull_request,open,,[TMP] Set asymmetric_quantize_inputs=true in runtime,"[TMP] Set asymmetric_quantize_inputs=true in runtime
",copybara-service[bot],2024-12-10 01:09:49+00:00,['marialyu'],2024-12-10 01:09:50+00:00,,https://github.com/tensorflow/tensorflow/pull/82571,[],[],
2728661355,pull_request,closed,,Register WhileLoopAllReduceCodeMotion pass to the opt tool,"Register WhileLoopAllReduceCodeMotion pass to the opt tool
",copybara-service[bot],2024-12-10 01:03:07+00:00,[],2024-12-10 02:10:37+00:00,2024-12-10 02:10:36+00:00,https://github.com/tensorflow/tensorflow/pull/82570,[],[],
2728641675,pull_request,open,,Add Shape::FromProto static factory method to replace constructor. ,"Add Shape::FromProto static factory method to replace constructor. 
Swap usage in compiler/xla/**
",copybara-service[bot],2024-12-10 00:46:35+00:00,[],2024-12-10 02:03:13+00:00,,https://github.com/tensorflow/tensorflow/pull/82569,[],[],
2728517972,pull_request,closed,,Migrate gather_operation_test to always use PjRt for its test backend.,"Migrate gather_operation_test to always use PjRt for its test backend.
",copybara-service[bot],2024-12-09 23:27:12+00:00,[],2024-12-10 22:05:11+00:00,2024-12-10 22:05:10+00:00,https://github.com/tensorflow/tensorflow/pull/82568,[],[],
2728503304,pull_request,closed,,Add `test_migrated_to_hlo_runner_pjrt` tag to `xla_test`.,"Add `test_migrated_to_hlo_runner_pjrt` tag to `xla_test`.

This tag will link the required PjRt client registry to the primary `xla_test`
target so that the test can run with PjRt.
",copybara-service[bot],2024-12-09 23:20:36+00:00,[],2024-12-10 16:58:25+00:00,2024-12-10 16:58:24+00:00,https://github.com/tensorflow/tensorflow/pull/82567,[],[],
2728498334,pull_request,closed,,Split ROCm-specific backend calls into their own targets.,"Split ROCm-specific backend calls into their own targets.
",copybara-service[bot],2024-12-09 23:16:48+00:00,[],2024-12-12 01:11:40+00:00,2024-12-12 01:11:40+00:00,https://github.com/tensorflow/tensorflow/pull/82566,[],[],
2728454958,pull_request,closed,,Add an interpreter PjRt client registry for testing.,"Add an interpreter PjRt client registry for testing.
",copybara-service[bot],2024-12-09 22:50:59+00:00,[],2024-12-10 03:14:49+00:00,2024-12-10 03:14:48+00:00,https://github.com/tensorflow/tensorflow/pull/82565,[],[],
2728418177,pull_request,closed,,Simplify `GetGatherScatterOperandPassthroughDims` since offset_dims or inserted_window_dims are sorted in gather/scatter operations.,"Simplify `GetGatherScatterOperandPassthroughDims` since offset_dims or inserted_window_dims are sorted in gather/scatter operations.
",copybara-service[bot],2024-12-09 22:27:03+00:00,[],2024-12-10 16:40:56+00:00,2024-12-10 16:40:54+00:00,https://github.com/tensorflow/tensorflow/pull/82564,[],[],
2728410586,pull_request,open,,Reverts 278f7e5b7209f388e7a61a2f2eab398668606dea,"Reverts 278f7e5b7209f388e7a61a2f2eab398668606dea
",copybara-service[bot],2024-12-09 22:21:53+00:00,['zichuan-wei'],2024-12-09 22:21:54+00:00,,https://github.com/tensorflow/tensorflow/pull/82563,[],[],
2728407289,pull_request,closed,,Copy result_accuracy when deriving new instruction.,"Copy result_accuracy when deriving new instruction.
",copybara-service[bot],2024-12-09 22:19:37+00:00,[],2024-12-20 19:12:35+00:00,2024-12-20 19:12:34+00:00,https://github.com/tensorflow/tensorflow/pull/82562,[],[],
2728375844,pull_request,closed,,Remove a bunch of #if CUDA macro use in xla_compile_lib.,"Remove a bunch of #if CUDA macro use in xla_compile_lib.
",copybara-service[bot],2024-12-09 22:03:46+00:00,[],2024-12-14 01:14:10+00:00,2024-12-14 01:14:10+00:00,https://github.com/tensorflow/tensorflow/pull/82561,[],[],
2728363110,pull_request,closed,,"Create OpStatsToRooflineModel, in preparation of Roofline Model creation","Create OpStatsToRooflineModel, in preparation of Roofline Model creation
",copybara-service[bot],2024-12-09 21:55:44+00:00,['zzzaries'],2024-12-10 01:46:54+00:00,2024-12-10 01:46:53+00:00,https://github.com/tensorflow/tensorflow/pull/82560,[],[],
2728341186,pull_request,open,,Migrate gather_operation_test to always use PjRt for its test backend.,"Migrate gather_operation_test to always use PjRt for its test backend.
",copybara-service[bot],2024-12-09 21:43:03+00:00,[],2024-12-09 22:06:57+00:00,,https://github.com/tensorflow/tensorflow/pull/82559,[],[],
2728338203,pull_request,closed,,[xla-auto-sharding] Add BRKGA heuristic as an XLA auto-sharding option.,"[xla-auto-sharding] Add BRKGA heuristic as an XLA auto-sharding option.
",copybara-service[bot],2024-12-09 21:41:16+00:00,[],2024-12-10 15:37:38+00:00,2024-12-10 15:37:37+00:00,https://github.com/tensorflow/tensorflow/pull/82558,[],[],
2728337457,pull_request,closed,,Remove unneeded #ifdef'ed dependency.,"Remove unneeded #ifdef'ed dependency.
",copybara-service[bot],2024-12-09 21:40:46+00:00,[],2024-12-13 17:17:20+00:00,2024-12-13 17:17:18+00:00,https://github.com/tensorflow/tensorflow/pull/82557,[],[],
2728294366,pull_request,closed,,[XLA] Handle empty leaf nodes in an original value,"[XLA] Handle empty leaf nodes in an original value

Add a warning when parsing an original value with leaf nodes without values. Issue an error for such cases in HloVerifier.
",copybara-service[bot],2024-12-09 21:20:15+00:00,['jcai19'],2025-01-08 01:37:10+00:00,2025-01-08 01:37:09+00:00,https://github.com/tensorflow/tensorflow/pull/82556,[],[],
2728290240,pull_request,open,,Integrate LLVM at llvm/llvm-project@be2df95e9281,"Integrate LLVM at llvm/llvm-project@be2df95e9281

Updates LLVM usage to match
[be2df95e9281](https://github.com/llvm/llvm-project/commit/be2df95e9281)
",copybara-service[bot],2024-12-09 21:17:35+00:00,[],2024-12-09 21:17:35+00:00,,https://github.com/tensorflow/tensorflow/pull/82555,[],[],
2728256842,pull_request,closed,,IFRT proxy: Add profiler spans to all entrypoints at the client.,"IFRT proxy: Add profiler spans to all entrypoints at the client.
",copybara-service[bot],2024-12-09 21:02:51+00:00,[],2024-12-09 23:58:42+00:00,2024-12-09 23:58:41+00:00,https://github.com/tensorflow/tensorflow/pull/82554,[],[],
2728246311,pull_request,closed,,[XLA] Fix latency hiding scheduler when faced with annotated no-op instructions.,"[XLA] Fix latency hiding scheduler when faced with annotated no-op instructions.

Annotated no-op instructions should be placed in the ready set instead of the no-op set. This is because we cannot schedule them as soon as they are available; we should wait for the whole annotation set to be ready.
",copybara-service[bot],2024-12-09 20:57:06+00:00,['seherellis'],2024-12-09 23:39:41+00:00,2024-12-09 23:39:41+00:00,https://github.com/tensorflow/tensorflow/pull/82553,[],[],
