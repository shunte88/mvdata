id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2658492013,pull_request,open,,Integrate LLVM at llvm/llvm-project@627b8f87e2c4,"Integrate LLVM at llvm/llvm-project@627b8f87e2c4

Updates LLVM usage to match
[627b8f87e2c4](https://github.com/llvm/llvm-project/commit/627b8f87e2c4)
",copybara-service[bot],2024-11-14 11:19:04+00:00,[],2024-11-14 11:19:04+00:00,,https://github.com/tensorflow/tensorflow/pull/80028,[],[],
2658471225,pull_request,closed,,[XLA:GPU] Support auto layouts in StreamExecutor PjRT path when using HLO as input,"[XLA:GPU] Support auto layouts in StreamExecutor PjRT path when using HLO as input

For now doing that behind a flag and as a minimal change.

The flag is `xla_pjrt_allow_auto_layout_in_hlo`

For StableHLO path, and non PjRT, and non-StreamExecutor paths, it's already like that by default.
",copybara-service[bot],2024-11-14 11:09:22+00:00,[],2024-11-15 09:06:52+00:00,2024-11-15 09:06:51+00:00,https://github.com/tensorflow/tensorflow/pull/80027,[],[],
2658453834,pull_request,closed,,[XLA:GPU] Add a test to check which algorithms are supported by Triton and BLAS.,"[XLA:GPU] Add a test to check which algorithms are supported by Triton and BLAS.
",copybara-service[bot],2024-11-14 11:01:09+00:00,[],2024-11-14 15:58:50+00:00,2024-11-14 15:58:48+00:00,https://github.com/tensorflow/tensorflow/pull/80026,[],[],
2658383515,pull_request,closed,,Update broken link for KerasNLP repository hyperlink in overview.md,"Hi, Team

I found 01 broken documentation link for [KerasNLP repository](https://github.com/keras-team/keras-nlp/tree/master/keras_nlp/models) hyperlink in [overview.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/examples/auto_complete/overview.md#model-authoring) file

I have updated broken link to functional link to keras_hub as per the new update **(We have consolidated KerasNLP and KerasCV into a new KerasHub package so pointed broken link to KerasHub)** Please review and merge this change as appropriate.

Thank you for your consideration.


",gaikwadrahul8,2024-11-14 10:40:48+00:00,['gbaned'],2024-11-14 19:22:49+00:00,2024-11-14 19:22:48+00:00,https://github.com/tensorflow/tensorflow/pull/80025,"[('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2658353748,pull_request,closed,,Remove restriction to disable tensor cores for 8-bit x F32 dots.,"Remove restriction to disable tensor cores for 8-bit x F32 dots.
",copybara-service[bot],2024-11-14 10:30:37+00:00,[],2024-12-04 18:22:30+00:00,2024-12-04 18:22:29+00:00,https://github.com/tensorflow/tensorflow/pull/80024,[],[],
2658341092,pull_request,closed,,Reverts 285f351d6ced24663332d7aedbfe92c3f63acea8,"Reverts 285f351d6ced24663332d7aedbfe92c3f63acea8
",copybara-service[bot],2024-11-14 10:24:49+00:00,['akuegel'],2024-11-14 11:13:41+00:00,2024-11-14 11:13:40+00:00,https://github.com/tensorflow/tensorflow/pull/80023,[],[],
2658299727,pull_request,closed,,Update 02 broken links in overview.md,"Hi, Team

I found 02 broken documentation links for [TensorFlow Lite Model Maker](https://www.tensorflow.org/lite/models/modify/model_maker/audio_classification) hyperlinks in this [overview.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/examples/audio_classification/overview.md) file so I have updated those links to functional links. Please review and merge this change as appropriate.

Thank you for your consideration.",gaikwadrahul8,2024-11-14 10:07:14+00:00,['gbaned'],2024-11-14 19:13:27+00:00,2024-11-14 19:13:26+00:00,https://github.com/tensorflow/tensorflow/pull/80022,"[('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2658128949,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-14 09:11:43+00:00,[],2024-11-14 21:08:54+00:00,2024-11-14 21:08:53+00:00,https://github.com/tensorflow/tensorflow/pull/80017,[],[],
2658103914,pull_request,closed,,Add missing check that iteration variable has scalar shape.,"Add missing check that iteration variable has scalar shape.

So far, the WhileLoopFusibleSinking pass assumed that the loop iteration
variable returned by the call to GetLoopInductionVarTupleIdx() has a scalar
shape. But with a recent change, this method also detects more complex patterns
for loop induction variables, which can include non-scalar shapes. Add an extra
check so that the assumption in the pass is not broken.
",copybara-service[bot],2024-11-14 08:59:40+00:00,['akuegel'],2024-11-14 10:15:39+00:00,2024-11-14 10:15:38+00:00,https://github.com/tensorflow/tensorflow/pull/80016,[],"[{'comment_id': 2475947859, 'issue_id': 2658103914, 'author': 'akuegel', 'body': 'Closing this in favor of instead ensuring that the assumption holds.', 'created_at': datetime.datetime(2024, 11, 14, 10, 15, 38, tzinfo=datetime.timezone.utc)}]","akuegel (Assginee) on (2024-11-14 10:15:38 UTC): Closing this in favor of instead ensuring that the assumption holds.

"
2658101410,pull_request,open,,PR #18838: [NVIDIA GPU] Support multi-operand collective-permute,"PR #18838: [NVIDIA GPU] Support multi-operand collective-permute

Imported from GitHub PR https://github.com/openxla/xla/pull/18838

For collective-permutes with small message sizes, it is beneficial to combine them into a single collective because
1. it gets rid of some kernel launch overhead, and allows NCCL to do some message fusion;
2. fewer collectives make it easier for LHS to make better decision.

In order to support combining collective-permutes, we need to support multi-operand collective-permute first, a.k.a. the combined collective-permute. This PR extends the existing CP interface by overloading it, so that a CP can have multiple operands.
Copybara import of the project:

--
5e10aba5b8f6ae66d1071a1894a87987b6a5bceb by Terry Sun <tesun@nvidia.com>:

support multi-operand cp

--
170fead3de942f5e14f4936df1d76bf7e5e319d4 by Terry Sun <tesun@nvidia.com>:

minor refactoring

--
0d85070baee3f26075f0b3660c4674d7b414c861 by Terry Sun <tesun@nvidia.com>:

update python interface

--
9812a104822ea479d29fef0531b9e10d5c2a831d by Terry Sun <tesun@nvidia.com>:

polish python interface

--
3a1552cbcd2e26f814373e0e01adbe8eceb3be9f by Terry Sun <tesun@nvidia.com>:

formatting

--
d3657f81ac57dc1de86561b3449d051d178e0f75 by Terry Sun <tesun@nvidia.com>:

formatting

Merging this change closes #18838

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18838 from terryysun:terryysun/grouped_cp d3657f81ac57dc1de86561b3449d051d178e0f75
",copybara-service[bot],2024-11-14 08:58:34+00:00,[],2024-11-14 08:58:34+00:00,,https://github.com/tensorflow/tensorflow/pull/80015,[],[],
2658056591,pull_request,open,,[XLA:CPU] Add benchmarks for 1D strided convolutions,"[XLA:CPU] Add benchmarks for 1D strided convolutions

Currently the transposed convolution is orders of magnitude slower than the regular one. Ideally performance should be similar. Detailed results:
--------------------------------------------------------------------------------------------------
Benchmark                                                        Time             CPU   Iterations
--------------------------------------------------------------------------------------------------
BM_Conv1DStrided/process_time                              2869248 ns     31485808 ns           21
BM_Conv1DTransposedStrided/process_time                  444138484 ns   9397599808 ns            1
BM_Conv1DTransposedStridedNonDefaultLayout/process_time  471396271 ns   9208384080 ns            1
",copybara-service[bot],2024-11-14 08:42:24+00:00,[],2024-11-14 08:42:32+00:00,,https://github.com/tensorflow/tensorflow/pull/80014,[],"[{'comment_id': 2475735576, 'issue_id': 2658056591, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/80014/checks?check_run_id=32972686966) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 11, 14, 8, 42, 30, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-11-14 08:42:30 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/80014/checks?check_run_id=32972686966) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2657985638,pull_request,closed,,Integrate LLVM at llvm/llvm-project@97298853b4de,"Integrate LLVM at llvm/llvm-project@97298853b4de

Updates LLVM usage to match
[97298853b4de](https://github.com/llvm/llvm-project/commit/97298853b4de)
",copybara-service[bot],2024-11-14 08:15:55+00:00,[],2024-11-14 15:19:44+00:00,2024-11-14 15:19:36+00:00,https://github.com/tensorflow/tensorflow/pull/80013,[],[],
2657959611,pull_request,closed,,Remove unused variable (NFC).,"Remove unused variable (NFC).
",copybara-service[bot],2024-11-14 08:01:28+00:00,['akuegel'],2024-11-14 08:44:24+00:00,2024-11-14 08:44:23+00:00,https://github.com/tensorflow/tensorflow/pull/80012,[],[],
2657694883,pull_request,open,,Update clone with new operands to handle ragged all-to-all.,"Update clone with new operands to handle ragged all-to-all.
",copybara-service[bot],2024-11-14 05:56:31+00:00,[],2024-11-14 05:56:31+00:00,,https://github.com/tensorflow/tensorflow/pull/80011,[],[],
2657675388,pull_request,closed,,[IFRT] Add ifrt-translate mlir tool for verifying dialect conversions.,"[IFRT] Add ifrt-translate mlir tool for verifying dialect conversions.

This tool will run MLIR lit IFRT IR serialization and deserialization tests. In order to add support for this tool (and for some other possible cases), this change adds an optional `DeserializeIfrtIRProgramOptions`, which contains a pointer to an existing MLIRContext. If option is not null then the program is deserialized in this context, and the returned `IfrtIRProgram` doesn't own the context. Otherwise, the program is deserialized in a new context that is owned by the returned `IfrtIRProgram`.
",copybara-service[bot],2024-11-14 05:44:26+00:00,[],2024-11-14 18:39:36+00:00,2024-11-14 18:39:35+00:00,https://github.com/tensorflow/tensorflow/pull/80010,[],[],
2657612175,pull_request,closed,,Fix a bug in benchmark_performance_options.cc,"Fix a bug in benchmark_performance_options.cc

The use_gpuv3 option should only be checked when the GPU CL delegate is supported.
",copybara-service[bot],2024-11-14 05:17:51+00:00,[],2024-11-18 06:06:14+00:00,2024-11-18 06:06:13+00:00,https://github.com/tensorflow/tensorflow/pull/80009,[],[],
2657605612,pull_request,open,,"Fold tfl.fill op into binary ops like add, sub, mul and div as they support implicit broadcasting.","Fold tfl.fill op into binary ops like add, sub, mul and div as they support implicit broadcasting.
",copybara-service[bot],2024-11-14 05:11:43+00:00,['vamsimanchala'],2024-11-14 05:36:53+00:00,,https://github.com/tensorflow/tensorflow/pull/80008,[],[],
2657575950,pull_request,closed,,Support trivial batching dimensions in ConvertGatherOp,"Support trivial batching dimensions in ConvertGatherOp

Adding support for converting `mhlo.gather`s that have trivial leading batching dimensions, and return a match failure for cases with non-trivial batching dimensions.
",copybara-service[bot],2024-11-14 04:49:34+00:00,[],2024-11-25 19:06:38+00:00,2024-11-25 19:06:37+00:00,https://github.com/tensorflow/tensorflow/pull/80007,[],[],
2657495293,pull_request,open,,[XLA:Python] Modify DLPack behavior with unit dimensions.,"[XLA:Python] Modify DLPack behavior with unit dimensions.

As discovered in https://github.com/jax-ml/jax/issues/24680, when a PyTorch tensor has a dimension with size `1`, it seems to report the DLPack stride for that dimension as `1`. This means that even when the torch Tensor is formally row-major, the imported array isn't. This shouldn't really matter (the placement of unit dimensions can be arbitrary!), but in practice (since XLA:CPU ignores layouts - that's another issue that is being worked on!) it can be annoying. This change updates the behavior to always produce row-major layouts for unit dimensions wrt to their neighbors.
",copybara-service[bot],2024-11-14 03:59:18+00:00,[],2024-11-25 20:57:53+00:00,,https://github.com/tensorflow/tensorflow/pull/80006,[],[],
2657492674,pull_request,open,,PR #19208: [gpu] Make collective permute decomposer accept no channel ids,"PR #19208: [gpu] Make collective permute decomposer accept no channel ids

Imported from GitHub PR https://github.com/openxla/xla/pull/19208

When no channel ids are present, this patch creates sends and recvs with channel id 0.
Copybara import of the project:

--
73f834bbc51621f5850abf56444662c53d2972d9 by Shraiysh Vaishay <svaishay@nvidia.com>:

[gpu] Make collective permute decomposer accept no channel ids

When no channel ids are present, this patch creates sends and recvs with
channel id 0.

Merging this change closes #19208

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19208 from shraiysh:cp_decomposer_no_channel_id 73f834bbc51621f5850abf56444662c53d2972d9
",copybara-service[bot],2024-11-14 03:57:21+00:00,[],2024-11-19 20:39:19+00:00,,https://github.com/tensorflow/tensorflow/pull/80005,[],[],
2657480528,pull_request,open,,Migrate PrepareTFPass to new TFL::Pass mechanism and. remove the .td definition.,"Migrate PrepareTFPass to new TFL::Pass mechanism and. remove the .td definition.
",copybara-service[bot],2024-11-14 03:48:18+00:00,['vamsimanchala'],2024-11-14 04:24:19+00:00,,https://github.com/tensorflow/tensorflow/pull/80004,[],[],
2657480367,pull_request,closed,,Migrate PushTransposeThroughEwisePass pass to new TFL::Pass mechanism and. remove the .td definition.,"Migrate PushTransposeThroughEwisePass pass to new TFL::Pass mechanism and. remove the .td definition.
",copybara-service[bot],2024-11-14 03:48:11+00:00,['vamsimanchala'],2024-11-14 23:21:01+00:00,2024-11-14 23:20:59+00:00,https://github.com/tensorflow/tensorflow/pull/80003,[],[],
2657474458,pull_request,closed,,Fix the attribute name for odml.upsample_bilinear2d composite op.,"Fix the attribute name for odml.upsample_bilinear2d composite op.

Change existing pytorch composites to unify the upsample-bilinear composites from JAX and PyTorch.
",copybara-service[bot],2024-11-14 03:43:12+00:00,['vamsimanchala'],2024-11-19 15:50:10+00:00,2024-11-19 15:50:09+00:00,https://github.com/tensorflow/tensorflow/pull/80002,[],[],
2657450763,pull_request,closed,,Support bfloat16 in numpy.cc and numpy_utils.cc as NPY_USERDEF,"Support bfloat16 in numpy.cc and numpy_utils.cc as NPY_USERDEF
",copybara-service[bot],2024-11-14 03:39:52+00:00,['jaeyoo'],2024-11-14 19:30:00+00:00,2024-11-14 19:29:59+00:00,https://github.com/tensorflow/tensorflow/pull/80001,[],[],
2657418584,pull_request,closed,,Cleanup to remove only internally referenced MlirModuleToString from header file.,"Cleanup to remove only internally referenced MlirModuleToString from header file.
",copybara-service[bot],2024-11-14 03:12:18+00:00,['rocketas'],2024-11-14 03:23:01+00:00,2024-11-14 03:23:01+00:00,https://github.com/tensorflow/tensorflow/pull/79999,[],[],
2657323552,pull_request,closed,,Add Duplicate() method to TensorBuffer,"Add Duplicate() method to TensorBuffer

Introduce reference counting to underlying TensorBufferT.
When a TensorBuffer is duplicated, the created TensorBuffer with increasing
reference to the underlying LiteRtTensorBuffer.
",copybara-service[bot],2024-11-14 02:17:26+00:00,['terryheo'],2024-11-14 02:49:05+00:00,2024-11-14 02:49:04+00:00,https://github.com/tensorflow/tensorflow/pull/79998,[],[],
2657285498,pull_request,closed,,Add test cases for QC compiler plugin.,"Add test cases for QC compiler plugin.
",copybara-service[bot],2024-11-14 01:50:17+00:00,[],2024-11-19 21:57:36+00:00,2024-11-19 21:57:35+00:00,https://github.com/tensorflow/tensorflow/pull/79997,[],[],
2657216453,pull_request,closed,,Update delegate kernels to sync CPU memory only when it's needed,"Update delegate kernels to sync CPU memory only when it's needed

- When user provides TensorBuffer, use it directly without CPU sync
- Also refactored dispatch_delegate tests to cover both CPU only
  and HW TensorBuffer only cases.
",copybara-service[bot],2024-11-14 00:55:51+00:00,['terryheo'],2024-11-15 00:11:52+00:00,2024-11-15 00:11:51+00:00,https://github.com/tensorflow/tensorflow/pull/79996,[],[],
2657207061,pull_request,closed,,Add accessor to ExternalContext from TfLiteOpaqueContext,"Add accessor to ExternalContext from TfLiteOpaqueContext
",copybara-service[bot],2024-11-14 00:46:41+00:00,['terryheo'],2024-11-14 04:36:33+00:00,2024-11-14 04:36:32+00:00,https://github.com/tensorflow/tensorflow/pull/79995,[],[],
2657151665,pull_request,closed,,Remove dead ShapeContainsToken in HLO verifier,"Remove dead ShapeContainsToken in HLO verifier
",copybara-service[bot],2024-11-13 23:57:09+00:00,['frgossen'],2024-11-20 01:20:29+00:00,2024-11-20 01:20:28+00:00,https://github.com/tensorflow/tensorflow/pull/79994,[],[],
2657146628,pull_request,closed,,Add two simple legalizations and cleanup.,"Add two simple legalizations and cleanup.

 * Add FC Op legalization and test data.
 * Add Select/Select_v2 Op legalization.
 * Mics cleanups.
",copybara-service[bot],2024-11-13 23:53:30+00:00,[],2024-11-19 20:01:08+00:00,2024-11-19 20:01:07+00:00,https://github.com/tensorflow/tensorflow/pull/79993,[],[],
2657141073,pull_request,closed,,Improve QC compiler plugin configurations.,"Improve QC compiler plugin configurations.

* Change default QNN graph config to use HTP FP16 precision backend config, this is required to correctly compile FP32 OPs.
* Create 1-element 1D tensor out of scalar value, QNN OP always use ranked tensor type as input.
",copybara-service[bot],2024-11-13 23:48:37+00:00,[],2024-11-19 19:21:43+00:00,2024-11-19 19:21:43+00:00,https://github.com/tensorflow/tensorflow/pull/79992,[],[],
2657123276,pull_request,closed,,Fix build errors on Mac OS X for LiteRT OSS,"Fix build errors on Mac OS X for LiteRT OSS

The errors were due to use of C++20 constructs
",copybara-service[bot],2024-11-13 23:34:04+00:00,[],2024-11-14 03:57:21+00:00,2024-11-14 03:57:20+00:00,https://github.com/tensorflow/tensorflow/pull/79991,[],[],
2657105781,pull_request,closed,,Account for optional channel ID in send/recv error message,"Account for optional channel ID in send/recv error message
",copybara-service[bot],2024-11-13 23:29:35+00:00,['frgossen'],2024-11-20 09:45:13+00:00,2024-11-20 09:45:12+00:00,https://github.com/tensorflow/tensorflow/pull/79990,[],[],
2657064633,pull_request,closed,,"Move `tsl/platform/{cloud,default,windows}` to `xla/tsl/platform`","Move `tsl/platform/{cloud,default,windows}` to `xla/tsl/platform`
",copybara-service[bot],2024-11-13 23:05:17+00:00,['ddunl'],2024-11-21 02:16:30+00:00,2024-11-21 02:16:29+00:00,https://github.com/tensorflow/tensorflow/pull/79989,[],[],
2657060094,pull_request,closed,,gemm_rewriter_test: Split and optimize to allow passing in coverage mode.,"gemm_rewriter_test: Split and optimize to allow passing in coverage mode.

Collecting coverage data from gemm_rewriter_test results in a significant
slowdown, particularly in the already comparatively slow fp8 test cases.
Splitting up the very large file file into separate tests with subsets of the
test cases helps, as does shrinking the buffers in the largest test case.
",copybara-service[bot],2024-11-13 23:01:40+00:00,[],2024-11-14 20:33:11+00:00,2024-11-14 20:33:09+00:00,https://github.com/tensorflow/tensorflow/pull/79988,[],[],
2656986970,pull_request,closed,,Update Linux ARM64 env to use the new ML build container. This will switch all ARM64 TF jobs to use the new containers.,"Update Linux ARM64 env to use the new ML build container. This will switch all ARM64 TF jobs to use the new containers.
",copybara-service[bot],2024-11-13 22:31:07+00:00,['quoctruong'],2024-11-14 18:15:47+00:00,2024-11-14 18:15:46+00:00,https://github.com/tensorflow/tensorflow/pull/79987,[],[],
2656962808,pull_request,closed,,[IFRT] Use glob for IFRT IR mlir lit tests.,"[IFRT] Use glob for IFRT IR mlir lit tests.
",copybara-service[bot],2024-11-13 22:12:36+00:00,[],2024-11-13 23:54:44+00:00,2024-11-13 23:54:43+00:00,https://github.com/tensorflow/tensorflow/pull/79986,[],[],
2656961416,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@37487a8e,"Integrate StableHLO at openxla/stablehlo@37487a8e
",copybara-service[bot],2024-11-13 22:11:29+00:00,['GleasonK'],2024-11-13 23:47:40+00:00,2024-11-13 23:47:39+00:00,https://github.com/tensorflow/tensorflow/pull/79985,[],[],
2656949755,pull_request,closed,,Both the xla_internal_test_main library and the gunit_main library define the symbol main.,"Both the xla_internal_test_main library and the gunit_main library define the symbol main.
  When using static linking, the causes compilation to fail if the test depends on both libraries
  since a symbol is defined twice. For tests that depend on xla_internal_test_main use the gunit
  library instead of gunit_main.
",copybara-service[bot],2024-11-13 22:02:31+00:00,[],2024-11-15 19:40:46+00:00,2024-11-15 19:40:45+00:00,https://github.com/tensorflow/tensorflow/pull/79983,[],[],
2656818594,pull_request,closed,,[XLA:GPU] Delete some unnecessary asterisks from `SoftmaxRewriterTriton`'s `IsSupportedBroadcastOfParameter`.,"[XLA:GPU] Delete some unnecessary asterisks from `SoftmaxRewriterTriton`'s `IsSupportedBroadcastOfParameter`.

Now that we check explicitly for the ability to tile before fusing, we really
don't need our matcher to be this restricted. This allows us to simplify the
code (further simplifications coming).
",copybara-service[bot],2024-11-13 21:20:23+00:00,[],2024-11-18 18:48:13+00:00,2024-11-18 18:48:12+00:00,https://github.com/tensorflow/tensorflow/pull/79981,[],[],
2656806775,pull_request,closed,,Fix AlgebraicSimplifier so that it does not eliminate host offloading copies.,"Fix AlgebraicSimplifier so that it does not eliminate host offloading copies.
",copybara-service[bot],2024-11-13 21:13:00+00:00,['SandSnip3r'],2024-11-15 05:15:59+00:00,2024-11-15 05:15:58+00:00,https://github.com/tensorflow/tensorflow/pull/79980,[],[],
2656759340,pull_request,closed,,Breaking internal tests,"Breaking internal tests

Reverts 2a9cc1cf24c5ccdb1733e392547faee25fdfb97f
",copybara-service[bot],2024-11-13 20:50:54+00:00,[],2024-11-13 21:46:35+00:00,2024-11-13 21:46:35+00:00,https://github.com/tensorflow/tensorflow/pull/79979,[],[],
2656631308,pull_request,closed,,[IFRT] Initial versioned IFRT (VIFRT) dialect.,"[IFRT] Initial versioned IFRT (VIFRT) dialect.

This dialect will be used to offer backward and forward compatible serialization of IFRT IR programs.
",copybara-service[bot],2024-11-13 19:59:44+00:00,[],2024-11-13 21:57:19+00:00,2024-11-13 21:57:18+00:00,https://github.com/tensorflow/tensorflow/pull/79978,[],[],
2656511326,pull_request,closed,,"Cache the return values of GetMeshDimPermutationOrderInShardingSpec as the function is expensive, and it invoked quite often.","Cache the return values of GetMeshDimPermutationOrderInShardingSpec as the function is expensive, and it invoked quite often.

To avoid having a global/static cache, we instead make the cache as well as the function members of the DeviceMesh class.
",copybara-service[bot],2024-11-13 19:15:02+00:00,[],2024-11-14 00:28:47+00:00,2024-11-14 00:28:46+00:00,https://github.com/tensorflow/tensorflow/pull/79977,[],[],
2656491015,pull_request,closed,,"PR #19272: Revert ""PR #15291: [NVIDIA GPU] Add Bitcast to collective pipeliner a…","PR #19272: Revert ""PR #15291: [NVIDIA GPU] Add Bitcast to collective pipeliner a…

Imported from GitHub PR https://github.com/openxla/xla/pull/19272

This reverts commit 6c65d7a3e3358efef0d6fed4505236b41e5c68e7.

Accepting Bitcast in collective pipeliner was a temporary solution for some workload relying on post-layout collective pipeliner. Recently we saw cases where including Bitcast can break the pattern matcher. Revert this PR since Bitcast will not show up in pre-layout collective pipeliner, which is the default behavior moving forward.
Copybara import of the project:

--
ad05557e7a46dcd44afa16c7a0cdb82e63651c4d by Terry Sun <tesun@nvidia.com>:

Revert ""PR #15291: [NVIDIA GPU] Add Bitcast to collective pipeliner acceptable users""

This reverts commit 6c65d7a3e3358efef0d6fed4505236b41e5c68e7.

Merging this change closes #19272

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19272 from terryysun:terryysun/revert_bitcast_in_cp ad05557e7a46dcd44afa16c7a0cdb82e63651c4d
",copybara-service[bot],2024-11-13 19:02:45+00:00,[],2024-11-13 20:07:33+00:00,2024-11-13 20:07:32+00:00,https://github.com/tensorflow/tensorflow/pull/79976,[],[],
2656490052,pull_request,closed,,Move TFRT common to public XLA:CPU API,"Move TFRT common to public XLA:CPU API
",copybara-service[bot],2024-11-13 19:02:12+00:00,['changm'],2024-11-13 21:34:51+00:00,2024-11-13 21:34:50+00:00,https://github.com/tensorflow/tensorflow/pull/79975,[],[],
2656464263,pull_request,closed,,"Create new TF lite directory and move first file, tf_mlir_translate_cl.cc","Create new TF lite directory and move first file, tf_mlir_translate_cl.cc
",copybara-service[bot],2024-11-13 18:49:18+00:00,['rocketas'],2024-11-13 20:38:37+00:00,2024-11-13 20:38:36+00:00,https://github.com/tensorflow/tensorflow/pull/79974,[],[],
2656355260,pull_request,open,,Integrate LLVM at llvm/llvm-project@97298853b4de,"Integrate LLVM at llvm/llvm-project@97298853b4de

Updates LLVM usage to match
[97298853b4de](https://github.com/llvm/llvm-project/commit/97298853b4de)
",copybara-service[bot],2024-11-13 18:07:42+00:00,[],2024-11-14 01:55:07+00:00,,https://github.com/tensorflow/tensorflow/pull/79973,[],[],
2656340809,pull_request,closed,,1. Consolidate shutdown errors to be `INTERNAL` regardless of barrier failure root cause.,"1. Consolidate shutdown errors to be `INTERNAL` regardless of barrier failure root cause.

Previously, the Shutdown() status returned depends on if it's the first task that invoked the barrier or the last task.

2. Increase RPC buffer time for service-related errors to propagate back. (i.e. don't time out immediately at X seconds, but X+5 seconds so that the service can identify the timeout and return a better error if it's still alive). Waiting 5 more seconds shouldn't be an issue for start/end-of job errors.

This resulted in flaky tests.
",copybara-service[bot],2024-11-13 18:00:06+00:00,[],2024-11-13 21:04:18+00:00,2024-11-13 21:04:17+00:00,https://github.com/tensorflow/tensorflow/pull/79972,[],[],
2656224403,pull_request,closed,,Migrate mlir.cc client to use ConvertGraphToTfExecutor vs ConvertGraphdefToMlir.,"Migrate mlir.cc client to use ConvertGraphToTfExecutor vs ConvertGraphdefToMlir.
",copybara-service[bot],2024-11-13 17:22:13+00:00,['rocketas'],2024-11-13 18:00:21+00:00,2024-11-13 18:00:19+00:00,https://github.com/tensorflow/tensorflow/pull/79971,[],[],
2656216165,pull_request,closed,,Relax the requirement of reusing remap so that it can take multiple inputs as long as each output is mapped from only one input.,"Relax the requirement of reusing remap so that it can take multiple inputs as long as each output is mapped from only one input.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/80025 from tensorflow:gaikwadrahul8-patch-3 92bbf36904c90c0ed0c0a5ae9b18210f7a9e27c0
",copybara-service[bot],2024-11-13 17:18:29+00:00,[],2024-11-14 20:17:56+00:00,2024-11-14 20:17:55+00:00,https://github.com/tensorflow/tensorflow/pull/79970,[],[],
2656183096,pull_request,closed,,Introduce a repository rule `python_wheel_version_suffix_repository` that generates a file with python wheel version suffix information.,"Introduce a repository rule `python_wheel_version_suffix_repository` that generates a file with python wheel version suffix information.

With this rule the version suffix becomes available in Bazel analysis phase. Using this repository rule, we can identify the wheel version suffix in the build rule (e.g. for JAX and Tensorflow build rules).

The version suffix depends on environment variables `_ML_WHEEL_TYPE, _ML_WHEEL_BUILD_DATE, _ML_WHEEL_GIT_HASH, _ML_WHEEL_VERSION_SUFFIX`.

Environment variables combinations for creating different versions suffixes:
  * snapshot builds (default build rule behavior): `--repo-env=ML_WHEEL_TYPE=snapshot`
  * release build: `--repo-env=ML_WHEEL_TYPE=release`
  * nightly build with date as version suffix: `--repo-env=ML_WHEEL_TYPE=nightly --repo-env=ML_WHEEL_BUILD_DATE=<YYYYmmdd>`
  * build with git data as version suffix: `--repo-env=ML_WHEEL_TYPE=custom --repo-env=ML_WHEEL_BUILD_DATE=$(git show -s --format=%as HEAD) --repo-env=ML_WHEEL_GIT_HASH=$(git rev-parse HEAD)`
  * build with git data and additional custom version suffix: `--repo-env=ML_WHEEL_TYPE=custom --repo-env=ML_WHEEL_BUILD_DATE=$(git show -s --format=%as HEAD) --repo-env=ML_WHEEL_GIT_HASH=$(git rev-parse HEAD) --repo-env=ML_WHEEL_VERSION_SUFFIX=-rc1`
",copybara-service[bot],2024-11-13 17:05:35+00:00,[],2025-01-22 17:01:32+00:00,2025-01-22 17:01:30+00:00,https://github.com/tensorflow/tensorflow/pull/79969,[],[],
2656168146,pull_request,closed,,Disable wheel compliance check unless hermetic CC toolchain is ready.,"Disable wheel compliance check unless hermetic CC toolchain is ready.
",copybara-service[bot],2024-11-13 17:00:16+00:00,[],2024-11-13 17:33:39+00:00,2024-11-13 17:33:37+00:00,https://github.com/tensorflow/tensorflow/pull/79968,[],[],
2656168016,pull_request,closed,,Change std::is_pod to std::is_trivially_destructible in flatbuffer_conversions.h,"Change std::is_pod to std::is_trivially_destructible in flatbuffer_conversions.h
",copybara-service[bot],2024-11-13 17:00:12+00:00,[],2024-12-20 20:01:46+00:00,2024-12-20 20:01:45+00:00,https://github.com/tensorflow/tensorflow/pull/79967,[],[],
2656154663,pull_request,open,,"Fix bug where the Python wrapper to ParseArguments() didn't intern the static argnames strings, causing false mismatches when searching for static arguments.","Fix bug where the Python wrapper to ParseArguments() didn't intern the static argnames strings, causing false mismatches when searching for static arguments.

Fixes https://github.com/jax-ml/jax/issues/24857
",copybara-service[bot],2024-11-13 16:55:16+00:00,[],2024-11-13 16:55:16+00:00,,https://github.com/tensorflow/tensorflow/pull/79966,[],[],
2655999591,pull_request,closed,,[XLA:CPU] Add CPU scatter benchmarks,"[XLA:CPU] Add CPU scatter benchmarks
",copybara-service[bot],2024-11-13 16:05:37+00:00,[],2024-11-15 11:47:15+00:00,2024-11-15 11:47:13+00:00,https://github.com/tensorflow/tensorflow/pull/79965,[],[],
2655992145,pull_request,closed,,Migrate search/ml/tools/tf2xla/tf2xla.cc to use ConvertGraphToMlir instead of ConvertGraphdefToMlir.,"Migrate search/ml/tools/tf2xla/tf2xla.cc to use ConvertGraphToMlir instead of ConvertGraphdefToMlir.
",copybara-service[bot],2024-11-13 16:02:25+00:00,['rocketas'],2024-11-13 17:15:56+00:00,2024-11-13 17:15:54+00:00,https://github.com/tensorflow/tensorflow/pull/79964,[],[],
2655983145,pull_request,closed,,two_plus_two_simple_test: Introduce simple test.,"two_plus_two_simple_test: Introduce simple test.

This test had been running internally, but there's no reason for it to, so
let's add it to the OSS test suite.
",copybara-service[bot],2024-11-13 15:59:17+00:00,[],2024-11-13 16:40:35+00:00,2024-11-13 16:40:35+00:00,https://github.com/tensorflow/tensorflow/pull/79963,[],[],
2655983145,pull_request,closed,,two_plus_two_simple_test: Introduce simple test.,"two_plus_two_simple_test: Introduce simple test.

This test had been running internally, but there's no reason for it to, so
let's add it to the OSS test suite.
",copybara-service[bot],2024-11-13 15:59:17+00:00,[],2024-11-13 16:40:35+00:00,2024-11-13 16:40:35+00:00,https://github.com/tensorflow/tensorflow/pull/79963,[],[],
2655980993,pull_request,closed,,[NFC] autotuner_util: Split the Status payload key to its own header.,"[NFC] autotuner_util: Split the Status payload key to its own header.

Doing so allows consumers that don't want the full compiler dependency to not
pull it, and notably means they don't need to depend on CUDA.
",copybara-service[bot],2024-11-13 15:58:28+00:00,[],2024-11-13 20:28:24+00:00,2024-11-13 20:28:24+00:00,https://github.com/tensorflow/tensorflow/pull/79962,[],[],
2655980515,pull_request,closed,,"Fix bug where the Python wrapper to ParseArguments() didn't intern the static argnames strings, causing false mismatches when searching for static arguments.","Fix bug where the Python wrapper to ParseArguments() didn't intern the static argnames strings, causing false mismatches when searching for static arguments.

Fixes https://github.com/jax-ml/jax/issues/24857
",copybara-service[bot],2024-11-13 15:58:16+00:00,[],2024-11-13 16:53:49+00:00,2024-11-13 16:53:48+00:00,https://github.com/tensorflow/tensorflow/pull/79961,[],[],
2655979608,pull_request,closed,,Remove custom PTX compilation pipeline from RedzoneAllocator,"Remove custom PTX compilation pipeline from RedzoneAllocator

We have support for lowering PTX in the runtime, so we can just
use `MultiKernelLoaderSpec` and we get compilation and caching for free.
",copybara-service[bot],2024-11-13 15:57:53+00:00,[],2024-11-20 09:39:55+00:00,2024-11-20 09:39:54+00:00,https://github.com/tensorflow/tensorflow/pull/79960,[],[],
2655978184,pull_request,closed,,Disable memory_checker_test on TAP.,"Disable memory_checker_test on TAP.
",copybara-service[bot],2024-11-13 15:57:20+00:00,['belitskiy'],2024-11-13 17:03:37+00:00,2024-11-13 17:03:35+00:00,https://github.com/tensorflow/tensorflow/pull/79959,[],[],
2655971488,pull_request,closed,,Modernize API for cuda_asm_compiler functions,"Modernize API for cuda_asm_compiler functions

- Replace `int cc_major, int cc_minor` arguments by `CudaComputeCapability`
- Replace `const char* ptx` arguments by `std::string ptx`.
- Remove overload of `CompileGpuAsm` that takes a `StreamExecutor` in favor of the version taking a `CudaComputeCapability`
- Remove the `ActivateContext` call in `LinkGpuAsm` since cuLink* CUDA driver functions don't need an active context
",copybara-service[bot],2024-11-13 15:55:07+00:00,[],2024-11-15 11:23:48+00:00,2024-11-15 11:23:46+00:00,https://github.com/tensorflow/tensorflow/pull/79958,[],[],
2655841517,pull_request,open,,Integrate LLVM at llvm/llvm-project@97298853b4de,"Integrate LLVM at llvm/llvm-project@97298853b4de

Updates LLVM usage to match
[97298853b4de](https://github.com/llvm/llvm-project/commit/97298853b4de)
",copybara-service[bot],2024-11-13 15:15:22+00:00,[],2024-11-13 15:15:22+00:00,,https://github.com/tensorflow/tensorflow/pull/79957,[],[],
2655707329,pull_request,closed,,[Triton] Fix the logic that filters small tile-k configurations that cause issues. Precisely the issues are currently coming from FP8 Matmuls for block_k = 16.,"[Triton] Fix the logic that filters small tile-k configurations that cause issues. Precisely the issues are currently coming from FP8 Matmuls for block_k = 16.
",copybara-service[bot],2024-11-13 14:33:51+00:00,[],2024-11-13 16:21:05+00:00,2024-11-13 16:21:03+00:00,https://github.com/tensorflow/tensorflow/pull/79956,[],[],
2655617175,pull_request,closed,,Update the curl dependency: 8.6.0 -> 8.11.0.,"Due to multiple security vulnerabilities CVE-2024-2004, CVE-2024-2379, CVE-2024-2398, CVE-2024-2466, CVE-2024-6197, CVE-2024-7264, CVE-2024-8096 and CVE-2024-9681",gerwout,2024-11-13 14:00:12+00:00,['gbaned'],2024-11-14 23:20:15+00:00,2024-11-14 23:07:46+00:00,https://github.com/tensorflow/tensorflow/pull/79955,"[('ready to pull', 'PR ready for merge process'), ('size:M', 'CL Change Size: Medium')]","[{'comment_id': 2473710158, 'issue_id': 2655617175, 'author': 'gerwout', 'body': 'Closed PR: https://github.com/tensorflow/tensorflow/pull/79897, created this new PR with master as base as requested', 'created_at': datetime.datetime(2024, 11, 13, 14, 3, 36, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474054066, 'issue_id': 2655617175, 'author': 'gerwout', 'body': '@mihaimaruseac could you tell me why the feedback/copybara check failed? It seems to point to a non public domain, so I am not able to see what is the current problem', 'created_at': datetime.datetime(2024, 11, 13, 16, 7, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474408528, 'issue_id': 2655617175, 'author': 'mihaimaruseac', 'body': 'I think there is an error on XLA ARM builds: https://btx.cloud.google.com/invocations/05f8db5c-2420-41ad-bd86-11f2ec4ef231\r\n\r\nIn general, the process is described in https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md but I think that needs to be updated now that XLA and TFLite and so on have been split to their own repos.', 'created_at': datetime.datetime(2024, 11, 13, 18, 24, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2474410064, 'issue_id': 2655617175, 'author': 'mihaimaruseac', 'body': ""```\r\nERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/curl_sha512_256.h'\r\nERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/cw-out.h'\r\nERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/request.h'\r\nERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/vssh/curl_path.h'\r\nERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/vtls/cipher_suite.h'\r\nERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: 5 input file(s) do not exist\r\n```"", 'created_at': datetime.datetime(2024, 11, 13, 18, 25, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476175039, 'issue_id': 2655617175, 'author': 'gerwout', 'body': ""@mihaimaruseac Thanks for supplying these details, that clarifies what is going wrong. There are currently 4 TSL tests that fail. All of them seem to use libcurl. The current TSL codebase does seem to use the same old vulnerable Curl version (i.e. https://github.com/google/tsl/blob/d08db918df887dd9ed17ad35fe59063f1df4889e/workspace2.bzl#L329). The fix will most likely be that the Curl version for TSL also needs to be upgraded. I am willing to create a PR for TSL as well, but unfortunately (because of the current restructuring) PR's are not accepted for TSL. Tensorflow itself also no longer seems to contain TSL, so I am currently stuck in this catch 22. The fix for TSL will be very similar as this PR, so could you please advice how I can move forward with this one?"", 'created_at': datetime.datetime(2024, 11, 14, 12, 3, 21, tzinfo=datetime.timezone.utc)}, {'comment_id': 2476947164, 'issue_id': 2655617175, 'author': 'mihaimaruseac', 'body': '@MichaelHudgins @jakeharmon8 Is the only way to fix TSL to import this and then patch the imported change? Can you advise here?\r\n\r\n(I think I saw another PR that landed and then had to be reverted because the TSL parts were not changed)', 'created_at': datetime.datetime(2024, 11, 14, 16, 56, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477055150, 'issue_id': 2655617175, 'author': 'MichaelHudgins', 'body': '> @MichaelHudgins @jakeharmon8 Is the only way to fix TSL to import this and then patch the imported change? Can you advise here?\r\n\r\nThat is my understanding of the current state, there is work going on to make this properly updatable from XLA but right now patching the import is the easiest way.', 'created_at': datetime.datetime(2024, 11, 14, 17, 49, 12, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477157872, 'issue_id': 2655617175, 'author': 'mihaimaruseac', 'body': 'Sounds good. Patched this internally and is in the process of submission now', 'created_at': datetime.datetime(2024, 11, 14, 18, 41, 30, tzinfo=datetime.timezone.utc)}, {'comment_id': 2477603310, 'issue_id': 2655617175, 'author': 'mihaimaruseac', 'body': 'Cherry-picking in https://github.com/tensorflow/tensorflow/pull/80068', 'created_at': datetime.datetime(2024, 11, 14, 23, 20, 13, tzinfo=datetime.timezone.utc)}]","gerwout (Issue Creator) on (2024-11-13 14:03:36 UTC): Closed PR: https://github.com/tensorflow/tensorflow/pull/79897, created this new PR with master as base as requested

gerwout (Issue Creator) on (2024-11-13 16:07:54 UTC): @mihaimaruseac could you tell me why the feedback/copybara check failed? It seems to point to a non public domain, so I am not able to see what is the current problem

mihaimaruseac on (2024-11-13 18:24:48 UTC): I think there is an error on XLA ARM builds: https://btx.cloud.google.com/invocations/05f8db5c-2420-41ad-bd86-11f2ec4ef231

In general, the process is described in https://github.com/tensorflow/tensorflow/blob/master/CONTRIBUTING.md but I think that needs to be updated now that XLA and TFLite and so on have been split to their own repos.

mihaimaruseac on (2024-11-13 18:25:21 UTC): ```
ERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/curl_sha512_256.h'
ERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/cw-out.h'
ERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/request.h'
ERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/vssh/curl_path.h'
ERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: missing input file '@curl//:lib/vtls/cipher_suite.h'
ERROR: /root/.cache/bazel/_bazel_root/fe5629ecf2d7463ba41a493eca1bfee8/external/curl/BUILD.bazel:26:11: Middleman _middlemen/@curl_S_S_Ccurl-cc_library-compile failed: 5 input file(s) do not exist
```

gerwout (Issue Creator) on (2024-11-14 12:03:21 UTC): @mihaimaruseac Thanks for supplying these details, that clarifies what is going wrong. There are currently 4 TSL tests that fail. All of them seem to use libcurl. The current TSL codebase does seem to use the same old vulnerable Curl version (i.e. https://github.com/google/tsl/blob/d08db918df887dd9ed17ad35fe59063f1df4889e/workspace2.bzl#L329). The fix will most likely be that the Curl version for TSL also needs to be upgraded. I am willing to create a PR for TSL as well, but unfortunately (because of the current restructuring) PR's are not accepted for TSL. Tensorflow itself also no longer seems to contain TSL, so I am currently stuck in this catch 22. The fix for TSL will be very similar as this PR, so could you please advice how I can move forward with this one?

mihaimaruseac on (2024-11-14 16:56:30 UTC): @MichaelHudgins @jakeharmon8 Is the only way to fix TSL to import this and then patch the imported change? Can you advise here?

(I think I saw another PR that landed and then had to be reverted because the TSL parts were not changed)

MichaelHudgins on (2024-11-14 17:49:12 UTC): That is my understanding of the current state, there is work going on to make this properly updatable from XLA but right now patching the import is the easiest way.

mihaimaruseac on (2024-11-14 18:41:30 UTC): Sounds good. Patched this internally and is in the process of submission now

mihaimaruseac on (2024-11-14 23:20:13 UTC): Cherry-picking in https://github.com/tensorflow/tensorflow/pull/80068

"
2655573387,pull_request,open,,Rollback,"Rollback

Reverts 39a1fb5be63c6bb0a5275d32877a97cd18bc2ee8
",copybara-service[bot],2024-11-13 13:44:03+00:00,[],2024-11-13 13:44:03+00:00,,https://github.com/tensorflow/tensorflow/pull/79954,[],[],
2655529899,pull_request,closed,,[XLA:CPU] Implement new algorithm for 1D strided transposed convolutions.,"[XLA:CPU] Implement new algorithm for 1D strided transposed convolutions.


This algorithm is 50 times faster on the benchmarks, making it closer to the regular convolution (but still 3x slower). Parallelizing the second part of the algorithm (i.e. packing patches) has the potential to get similar perf as the regular convolution.

Results:
name                                                      old cpu/op   new cpu/op   delta
BM_Conv1DStrided/process_time                             28.1ms ± 6%  27.7ms ± 7%     ~     (p=1.000 n=5+5)
BM_Conv1DTransposedStrided/process_time                    8.23s ± 6%   0.03s ± 3%  -99.65%  (p=0.008 n=5+5)
BM_Conv1DTransposedStridedNonDefaultLayout/process_time    7.85s ± 5%   0.03s ± 4%  -99.66%  (p=0.008 n=5+5)

name                                                      old time/op  new time/op  delta
BM_Conv1DStrided/process_time                             2.48ms ± 6%  2.48ms ± 8%     ~     (p=1.000 n=5+5)
BM_Conv1DTransposedStrided/process_time                    371ms ± 5%     7ms ± 4%  -98.18%  (p=0.008 n=5+5)
BM_Conv1DTransposedStridedNonDefaultLayout/process_time    344ms ± 5%     6ms ± 0%  -98.32%  (p=0.016 n=5+4)

Planned improvements of this algorithm:
- support asynchronous execution,
- parallel packing of the patches (second algorithm step),
- support 2D strided transposed convolutions,
- support feature_group_size > 1 (grouped convolution),
- support the case with multiple input channels and output channels at the same time,
- explore input kernel rotation possibilities & perf impact,
",copybara-service[bot],2024-11-13 13:28:15+00:00,[],2024-11-18 18:41:58+00:00,2024-11-18 18:41:56+00:00,https://github.com/tensorflow/tensorflow/pull/79953,[],"[{'comment_id': 2473624774, 'issue_id': 2655529899, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79953/checks?check_run_id=32925459031) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 11, 13, 13, 28, 21, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-11-13 13:28:21 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79953/checks?check_run_id=32925459031) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2655523229,pull_request,closed,,[XLA:GPU] Simplify AutotuneOneConvRunner() parameter.,"[XLA:GPU] Simplify AutotuneOneConvRunner() parameter.

All we care about is the instruction string, not the cache key. Note that in
fact we want the regular output of ToString() including metadata, not the
string output we use for the cache key which excludes metadata.
",copybara-service[bot],2024-11-13 13:26:07+00:00,['akuegel'],2024-11-13 14:24:53+00:00,2024-11-13 14:24:52+00:00,https://github.com/tensorflow/tensorflow/pull/79952,[],[],
2655369924,pull_request,open,,PR #19275: [NVIDIA] Add fixes for supporting determinism expander for high-dimensional scatter operation and a flag to disable it,"PR #19275: [NVIDIA] Add fixes for supporting determinism expander for high-dimensional scatter operation and a flag to disable it

Imported from GitHub PR https://github.com/openxla/xla/pull/19275

This PR is the 2nd step (out of 2) to improve the performance of deterministic scatter. Originally, the scatter op will be expanded to be deterministic in xla/service/ScatterExpander.cc. However, since it took a while-loop-based approach, the performance is extremely poor. We designed and implemented a prefix-scan-based approach to rewrite the scatter operation to be an efficient deterministic scatter. This PR completes the optimization of deterministic scatter operations with non-scalar indices and updates.

The change of this PR is on top of https://github.com/openxla/xla/pull/17886, and has fixed issues reported in the reverted PR https://github.com/openxla/xla/pull/18326. The issue was that the changes in https://github.com/openxla/xla/pull/18326 were not able to handle different kinds of complicated but realistic scatter dimension numbers. Specifically, this PR unifies the implementation of 1D and multi-dimensional scatter operation to make the code easier to maintain, adds multiple tests for various scatter dimension numbers, and thoroughly handles all cases of different kinds of dimension numbers. 

Moreover, this PR also adds an option `xla_gpu_enable_scatter_determinism_expander`, the default value of which is set to be true. This option could make sure that although unlikely, if anything happens with changes in this PR, the user can easily disable  the `scatter_determinism_expander` pass without getting blocked.


Design doc: https://docs.google.com/document/d/1K204VZR3OP0SUDOPsGUYgIIDf2ucTKEC4yQj8XRG2SA/edit

Bugs resolved: https://github.com/jax-ml/jax/issues/17844
Copybara import of the project:

--
b01604490908fbe43685aed7178d0a66602b7a8c by Chenhao Jiang <chenhaoj@nvidia.com>:

PR #18326: [NVIDIA] Complete the optimization of deterministic scatter operations

Imported from GitHub PR https://github.com/openxla/xla/pull/18326

This PR is the 2nd step (out of 2) to improve the performance of deterministic scatter. Originally, the scatter op will be expanded to be deterministic in xla/service/ScatterExpander.cc. However, since it took a while-loop-based approach, the performance is extremely poor. We designed and implemented a prefix-scan-based approach to rewrite the scatter operation to be an efficient deterministic scatter. This PR completes the optimization of deterministic scatter operations with non-scalar indices and updates.

The change of this PR is on top of https://github.com/openxla/xla/pull/17886

Design doc: https://docs.google.com/document/d/1K204VZR3OP0SUDOPsGUYgIIDf2ucTKEC4yQj8XRG2SA/edit

Bugs resolved: https://github.com/jax-ml/jax/issues/17844
Copybara import of the project:

--
de647d44eb28af71e1580b6e8ed9adc751e50f52 by Chenhao Jiang <chenhaoj@nvidia.com>:

Support scatter with non-scalar indices and updates

Merging this change closes #18326

PiperOrigin-RevId: 691023328

--
fbdb066fd38a2fadb4322caaabe8c8d1a9fa77e3 by Chenhao Jiang <chenhaoj@nvidia.com>:

Add the scatter indices to operand space mapping
and change the offset column-wise permutation
based on scatter_dims_to_operand_dims, so that
they can add together correctly.

--
d36c8ac7260c241c4ca6ed7dc16018f8030c0b80 by Chenhao Jiang <chenhaoj@nvidia.com>:

Fix the scatter determinism expander for various dimension numbers

--
678886f97bd133c4ffa2fbf0365e15c808383a6f by Chenhao Jiang <chenhaoj@nvidia.com>:

Add a flag for enabling the scatter_determinism_expander on GPU.

Merging this change closes #19275

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18326 from serach24:chenhao/opt_det_scatter_full de647d44eb28af71e1580b6e8ed9adc751e50f52
",copybara-service[bot],2024-11-13 12:49:21+00:00,[],2024-11-15 19:05:19+00:00,,https://github.com/tensorflow/tensorflow/pull/79951,[],[],
2655309849,pull_request,closed,,[XLA:GPU] Fix bug related to usage of DynamicPadder pass.,"[XLA:GPU] Fix bug related to usage of DynamicPadder pass.

Given that it creates a stable sort op, it needs to run before
StableSortExpander pass.
",copybara-service[bot],2024-11-13 12:22:47+00:00,['akuegel'],2024-11-15 09:55:45+00:00,2024-11-15 09:55:44+00:00,https://github.com/tensorflow/tensorflow/pull/79950,[],[],
2655118747,pull_request,closed,,PR #16901: [XLA:GPU] Fix default device mesh for auto sharding,"PR #16901: [XLA:GPU] Fix default device mesh for auto sharding

Imported from GitHub PR https://github.com/openxla/xla/pull/16901

When the user does not specify the number of GPUs for auto sharding, XLA defaults to using all available GPUs.

The current implementation uses the number of cores (SMs) on the GPU as the default shard count. For example, on an A100, the sharding algorithm will try to shard into 108 devices, which can be confusing for users.

This patch changes the shard count to the number of cards, which has been tested to work correctly on an 8-card A100 machine.
Copybara import of the project:

--
232a62ae2599e6fe76e2e235ea18452195bce799 by Tianyi Liu <i.pear@outlook.com>:

[XLA:GPU] Fix default device mesh for auto sharding

Merging this change closes #16901

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/16901 from i-Pear:try_fix_gpu_cards 232a62ae2599e6fe76e2e235ea18452195bce799
",copybara-service[bot],2024-11-13 11:10:11+00:00,[],2024-11-22 00:47:40+00:00,2024-11-22 00:47:39+00:00,https://github.com/tensorflow/tensorflow/pull/79948,[],[],
2654996821,pull_request,closed,,PR #18248: cuda 12.6.2,"PR #18248: cuda 12.6.2

Imported from GitHub PR https://github.com/openxla/xla/pull/18248


Copybara import of the project:

--
1258a0211e7b09b9e938b6442e115f3436cf985d by Johnny <johnnync13@gmail.com>:

Update cuda_redist_versions.bzl

Merging this change closes #18248

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18248 from johnnynunez:patch-1 1258a0211e7b09b9e938b6442e115f3436cf985d
",copybara-service[bot],2024-11-13 10:36:42+00:00,[],2024-11-14 09:30:15+00:00,2024-11-14 09:30:13+00:00,https://github.com/tensorflow/tensorflow/pull/79947,[],[],
2654985214,pull_request,open,,PR #18838: [NVIDIA GPU] Support multi-operand collective-permute,"PR #18838: [NVIDIA GPU] Support multi-operand collective-permute

Imported from GitHub PR https://github.com/openxla/xla/pull/18838

For collective-permutes with small message sizes, it is beneficial to combine them into a single collective because
1. it gets rid of some kernel launch overhead, and allows NCCL to do some message fusion;
2. fewer collectives make it easier for LHS to make better decision.

In order to support combining collective-permutes, we need to support multi-operand collective-permute first, a.k.a. the combined collective-permute. This PR extends the existing CP interface by overloading it, so that a CP can have multiple operands.
Copybara import of the project:

--
5e10aba5b8f6ae66d1071a1894a87987b6a5bceb by Terry Sun <tesun@nvidia.com>:

support multi-operand cp

--
170fead3de942f5e14f4936df1d76bf7e5e319d4 by Terry Sun <tesun@nvidia.com>:

minor refactoring

--
0d85070baee3f26075f0b3660c4674d7b414c861 by Terry Sun <tesun@nvidia.com>:

update python interface

--
9812a104822ea479d29fef0531b9e10d5c2a831d by Terry Sun <tesun@nvidia.com>:

polish python interface

Merging this change closes #18838

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18838 from terryysun:terryysun/grouped_cp 9812a104822ea479d29fef0531b9e10d5c2a831d
",copybara-service[bot],2024-11-13 10:31:51+00:00,[],2024-11-13 11:53:59+00:00,,https://github.com/tensorflow/tensorflow/pull/79946,[],[],
2654956584,pull_request,closed,,PR #17593: [ROCm] Include clang-19 and clang-20 headers,"PR #17593: [ROCm] Include clang-19 and clang-20 headers

Imported from GitHub PR https://github.com/openxla/xla/pull/17593


Copybara import of the project:

--
4eccb5c93fa60106feaf87b8eb7bbffebaf97fb6 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Include clang-19 and clang-20 headers

Merging this change closes #17593

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/17593 from ROCm:ci_add_clang20_20240925 4eccb5c93fa60106feaf87b8eb7bbffebaf97fb6
",copybara-service[bot],2024-11-13 10:19:37+00:00,[],2024-11-19 10:59:25+00:00,2024-11-19 10:59:24+00:00,https://github.com/tensorflow/tensorflow/pull/79945,[],[],
2654808869,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-13 09:27:19+00:00,[],2024-11-13 09:27:19+00:00,,https://github.com/tensorflow/tensorflow/pull/79944,[],[],
2654807020,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-13 09:26:27+00:00,[],2024-11-13 09:26:27+00:00,,https://github.com/tensorflow/tensorflow/pull/79943,[],[],
2654786429,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-13 09:17:56+00:00,[],2024-11-13 09:17:56+00:00,,https://github.com/tensorflow/tensorflow/pull/79942,[],[],
2654785559,pull_request,closed,,Reverts 1b73252f7705819646c921310499bb85efab2dd3,"Reverts 1b73252f7705819646c921310499bb85efab2dd3
",copybara-service[bot],2024-11-13 09:17:33+00:00,['akuegel'],2024-11-13 11:30:25+00:00,2024-11-13 11:30:24+00:00,https://github.com/tensorflow/tensorflow/pull/79941,[],[],
2654767241,pull_request,closed,,PR #19160: Add support for fusion operations in GetLoopInductionVariableIndex,"PR #19160: Add support for fusion operations in GetLoopInductionVariableIndex

Imported from GitHub PR https://github.com/openxla/xla/pull/19160

After optimizations, while loop analysis was unable to handle the fused operations, primarily for GetLoopInductionVariableIndex and ComputeWhileLoopTripCount. This patch handles only GetloopInductionVariableIdx.

If the GetGTEOperandIndex function fails to find a precise GTE operand, we try to deduce the unique dependence by using the HloExtractor.
Copybara import of the project:

--
b87de101421d7a4b98050379e931507d37bb90ab by Shraiysh Vaishay <svaishay@nvidia.com>:

Add support for fusion operations in GetLoopInductionVariableIndex

After optimizations, while loop analysis was unable to handle the fused
operations, primarily for GetLoopInductionVariableIndex and
ComputeWhileLoopTripCount. This patch handles only
GetloopInductionVariableIdx.

If the GetGTEOperandIndex function fails to find a precise GTE operand,
we try to deduce the unique dependence by using the HloExtractor.

Merging this change closes #19160

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19160 from shraiysh:while_loop_enhancements b87de101421d7a4b98050379e931507d37bb90ab
",copybara-service[bot],2024-11-13 09:09:13+00:00,[],2024-11-13 10:11:27+00:00,2024-11-13 10:11:25+00:00,https://github.com/tensorflow/tensorflow/pull/79940,[],[],
2654749812,pull_request,open,,PR #19026: [NVIDIA GPU] LHS enhancement for multiple collective resources,"PR #19026: [NVIDIA GPU] LHS enhancement for multiple collective resources

Imported from GitHub PR https://github.com/openxla/xla/pull/19026

With https://github.com/openxla/xla/pull/17749, we can let LHS schedule for multiple collective resources. There are some cases that two collectives cannot be overlapped. When two collectives on different stream share at least 2 ranks, they can form cyclic dependency because the execution order of NCCL kernels can be different on each rank. This PR refactored LHS to expose the comparator to backend, and enforced above constraint for GPU backend.
Copybara import of the project:

--
14362ea3ef78d810a5e34c03f4a0e4c44915470c by Terry Sun <tesun@nvidia.com>:

LHS deadlock avoidance

--
e027794972c42ca763578a4b75a0a2a0da9f2ff0 by Terry Sun <tesun@nvidia.com>:

minor fix

--
430db3f7e3fecd5585b79e6dd0c09662a76d9263 by Terry Sun <tesun@nvidia.com>:

address nit

Merging this change closes #19026

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19026 from terryysun:terryysun/overlapping_collectives 430db3f7e3fecd5585b79e6dd0c09662a76d9263
",copybara-service[bot],2024-11-13 09:01:43+00:00,[],2024-11-18 22:45:20+00:00,,https://github.com/tensorflow/tensorflow/pull/79939,[],[],
2654718901,pull_request,open,,StableHLO Reference Interpreter PJRT Plugin,"StableHLO Reference Interpreter PJRT Plugin
",copybara-service[bot],2024-11-13 08:48:38+00:00,['GleasonK'],2024-11-14 09:00:06+00:00,,https://github.com/tensorflow/tensorflow/pull/79938,[],[],
2654600375,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-13 08:04:52+00:00,[],2024-11-13 08:04:52+00:00,,https://github.com/tensorflow/tensorflow/pull/79937,[],[],
2654553873,pull_request,closed,,Avoid unnecessary overhead in HloExtractor (NFC),"Avoid unnecessary overhead in HloExtractor (NFC)

Currently we iterate over all instructions in the old module to find the
instructions which have been cloned. But CloneContext offers direct access to
them, so we should be using that instead.
",copybara-service[bot],2024-11-13 07:44:21+00:00,['akuegel'],2024-11-13 08:47:43+00:00,2024-11-13 08:47:42+00:00,https://github.com/tensorflow/tensorflow/pull/79936,[],[],
2654531864,pull_request,closed,,[XLA] Preserve frontend attributes in async collective creator.,"[XLA] Preserve frontend attributes in async collective creator.
",copybara-service[bot],2024-11-13 07:34:00+00:00,['seherellis'],2024-11-13 21:12:01+00:00,2024-11-13 21:11:59+00:00,https://github.com/tensorflow/tensorflow/pull/79935,[],[],
2654475912,pull_request,closed,,This is to fix the crash on Windows when allocated memory for the model is not aligned.,"This is to fix the crash on Windows when allocated memory for the model is not aligned.
",copybara-service[bot],2024-11-13 07:12:54+00:00,[],2024-11-13 18:29:25+00:00,2024-11-13 18:29:23+00:00,https://github.com/tensorflow/tensorflow/pull/79934,[],[],
2654208578,pull_request,closed,,"Convert DeviceMesh into a class, make its fields private, and add accessors.","Convert DeviceMesh into a class, make its fields private, and add accessors.

This is in preparation for adding a member variable to DeviceMesh to cache the results of GetMeshDimPermutationOrderInShardingSpec.
",copybara-service[bot],2024-11-13 05:14:41+00:00,[],2024-11-13 19:40:00+00:00,2024-11-13 19:39:58+00:00,https://github.com/tensorflow/tensorflow/pull/79933,[],[],
2654097076,pull_request,closed,,Add TraceMeConsumer in work_queue task,"Add TraceMeConsumer in work_queue task
",copybara-service[bot],2024-11-13 04:14:41+00:00,['cliveverghese'],2024-11-13 20:17:00+00:00,2024-11-13 20:16:59+00:00,https://github.com/tensorflow/tensorflow/pull/79932,[],[],
2654087008,pull_request,closed,,Better align Expected to std::expected and add Expected<void> specialization,"Better align Expected to std::expected and add Expected<void> specialization

This CL introduces a separate litert::Error class that has status code and error message. Additional, this CL adds an Expected<void> specialization to return a success status or an error status with an associated error message, similarly to absl::Status.
",copybara-service[bot],2024-11-13 04:09:12+00:00,[],2024-11-14 00:35:04+00:00,2024-11-14 00:35:03+00:00,https://github.com/tensorflow/tensorflow/pull/79931,[],[],
2654016811,pull_request,open,,Make scripts work for everything end2end.,"Make scripts work for everything end2end.

* Add script that wraps apply plugin
* Pull common path variables into file for sharing
* Add root level script that can apply_plugin/invoke/both on arbitrary tflite

Note: this should not effect the standalone usage of run_test_on_android.sh at all
",copybara-service[bot],2024-11-13 03:31:56+00:00,['LukeBoyer'],2024-11-13 18:24:54+00:00,,https://github.com/tensorflow/tensorflow/pull/79928,[],[],
2653895246,pull_request,closed,,PR #19252: [XLA:GPU] Add a work around to the bug that cudaGraphAddKernelNode will segment fault if its argument size > 4KB ,"PR #19252: [XLA:GPU] Add a work around to the bug that cudaGraphAddKernelNode will segment fault if its argument size > 4KB 

Imported from GitHub PR https://github.com/openxla/xla/pull/19252

This PR work around cuda bug with parameter size > 4KB, bug details: 

CUDA has supported parameters to kernels > 4KB (up to 32K) since CTK 12.1. However, if you try to pass a 4KB parameter to a function it segfaults inside of `cudaGraphAddKernelNode`. The problem can be reproduced with the following code:
 ```

#include <stdio.h>
#include <cuda.h>
struct PacketCopyParams {
    uint32_t pkt_size[2000];
};
__global__ void packet_memcpy_kernel(PacketCopyParams params) {
}
int main() {
    cudaKernelNodeParams         kernelNodeParams = {0};
    PacketCopyParams params;
    printf(""Param size is %zu\n"", sizeof(PacketCopyParams));
    void *kernelArgs[1] = {(void *)&params};
    kernelNodeParams.func = (void *)packet_memcpy_kernel;
    kernelNodeParams.gridDim = dim3(1, 1, 1);
    kernelNodeParams.blockDim = dim3(512, 1, 1);
    kernelNodeParams.sharedMemBytes = 0;
    kernelNodeParams.kernelParams = (void **)kernelArgs;
    kernelNodeParams.extra = NULL;
    cudaGraph_t graph;
    cudaGraphNode_t test;
    printf(""cudaGraphCreate: %d\n"", cudaGraphCreate(&graph, 0));
    printf(""cudaGraphAddKernelNode: %d\n"", cudaGraphAddKernelNode(&test, graph, nullptr, 0, &kernelNodeParams));    
}

```
Copybara import of the project:

--
93ca48e6d265622637fbd40605bda35d65b5e437 by Shawn Wang <shawnw@nvidia.com>:

work around cuda bug that cudaGraphAddKernelNode will segment fault if argument size > 4KB

Merging this change closes #19252

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19252 from shawnwang18:shawnw/cuda_graph_kernel_node_fault 93ca48e6d265622637fbd40605bda35d65b5e437
",copybara-service[bot],2024-11-13 02:07:30+00:00,[],2024-11-13 02:43:54+00:00,2024-11-13 02:43:53+00:00,https://github.com/tensorflow/tensorflow/pull/79926,[],[],
2653821868,pull_request,open,,Integrate LLVM at llvm/llvm-project@7b5e285d1609,"Integrate LLVM at llvm/llvm-project@7b5e285d1609

Updates LLVM usage to match
[7b5e285d1609](https://github.com/llvm/llvm-project/commit/7b5e285d1609)
",copybara-service[bot],2024-11-13 01:20:58+00:00,[],2024-11-13 01:20:58+00:00,,https://github.com/tensorflow/tensorflow/pull/79925,[],[],
2653618079,pull_request,closed,,Update profile generation strategy for ProfileInfo fingerprint.,"Update profile generation strategy for ProfileInfo fingerprint.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19272 from terryysun:terryysun/revert_bitcast_in_cp ad05557e7a46dcd44afa16c7a0cdb82e63651c4d
",copybara-service[bot],2024-11-12 23:28:50+00:00,[],2024-11-13 20:54:41+00:00,2024-11-13 20:54:40+00:00,https://github.com/tensorflow/tensorflow/pull/79924,[],[],
2653523207,pull_request,closed,,"Move TrimGraphMemory functionality into cuda_command_buffer.cc, the only file that uses it.","Move TrimGraphMemory functionality into cuda_command_buffer.cc, the only file that uses it.
",copybara-service[bot],2024-11-12 22:42:05+00:00,[],2024-11-13 18:58:13+00:00,2024-11-13 18:58:12+00:00,https://github.com/tensorflow/tensorflow/pull/79922,[],[],
2653522527,pull_request,closed,,Make gpu_executor.h only used by RocmExecutor and CudaExecutor.,"Make gpu_executor.h only used by RocmExecutor and CudaExecutor.
",copybara-service[bot],2024-11-12 22:41:33+00:00,[],2024-11-14 16:15:09+00:00,2024-11-14 16:15:08+00:00,https://github.com/tensorflow/tensorflow/pull/79921,[],[],
2653438777,pull_request,open,,Add is_nchw_op to the pattern of build_interpolate_composite_pass. Change existing pytorch composites to unify the upsample-bilinear composites from JAX and PyTorch.,"Add is_nchw_op to the pattern of build_interpolate_composite_pass. Change existing pytorch composites to unify the upsample-bilinear composites from JAX and PyTorch.
",copybara-service[bot],2024-11-12 22:00:27+00:00,['vamsimanchala'],2024-11-13 20:21:09+00:00,,https://github.com/tensorflow/tensorflow/pull/79919,[],[],
2653417857,pull_request,closed,,Introducing a connection timeout in a ifrt proxy.,"Introducing a connection timeout in a ifrt proxy.
",copybara-service[bot],2024-11-12 21:48:08+00:00,[],2024-11-13 18:50:41+00:00,2024-11-13 18:50:40+00:00,https://github.com/tensorflow/tensorflow/pull/79918,[],[],
2653407051,pull_request,open,,Use `cc_binary` (with `android_filegroup`) rather than `android_jni_library`,"Use `cc_binary` (with `android_filegroup`) rather than `android_jni_library`
for `cc_3p_api_build_test`.

Using `android_jni_library` was doing a link, but wasn't actually linking
in the object files that define the C++ API, because they get put in
a static library and don't get pulled into the `.so` file because they
don't satisfy any of the symbol glob patterns (`Java_*`, etc.) that the
linker is trying to find.  Better to use `cc_binary` so that the object
files that define the C++ API do actually get linked in; that way, the
linker detects if there are any undefined symbols in those object files.

Also, mark the targets generated by the `cc_3p_api_build_test` build macro
with `testonly = True`.
",copybara-service[bot],2024-11-12 21:41:49+00:00,[],2024-11-12 22:49:57+00:00,,https://github.com/tensorflow/tensorflow/pull/79917,[],[],
2653407015,pull_request,closed,,Add explicit read variable in the train graph to trigger xla sharding op for sharded variables.,"Add explicit read variable in the train graph to trigger xla sharding op for sharded variables.
",copybara-service[bot],2024-11-12 21:41:48+00:00,['ishark'],2024-11-13 00:18:50+00:00,2024-11-13 00:18:50+00:00,https://github.com/tensorflow/tensorflow/pull/79916,[],[],
2653391002,pull_request,closed,,[XLA] Ensure infeed/outfeed ordering,"[XLA] Ensure infeed/outfeed ordering

If the user cannot provide a token for infeed/outfeed, assume they are being added to the computation in the correct order. Implicitly reuse the tokens from the previous op to guarantee the user intended ordering.
",copybara-service[bot],2024-11-12 21:33:20+00:00,[],2024-11-15 00:45:41+00:00,2024-11-15 00:45:40+00:00,https://github.com/tensorflow/tensorflow/pull/79915,[],[],
2653357561,pull_request,open,,"PR #19272: Revert ""PR #15291: [NVIDIA GPU] Add Bitcast to collective pipeliner a…","PR #19272: Revert ""PR #15291: [NVIDIA GPU] Add Bitcast to collective pipeliner a…

Imported from GitHub PR https://github.com/openxla/xla/pull/19272

This reverts commit 6c65d7a3e3358efef0d6fed4505236b41e5c68e7.

Accepting Bitcast in collective pipeliner was a temporary solution for some workload relying on post-layout collective pipeliner. Recently we saw cases where including Bitcast can break the pattern matcher. Revert this PR since Bitcast will not show up in pre-layout collective pipeliner, which is the default behavior moving forward.
Copybara import of the project:

--
ad05557e7a46dcd44afa16c7a0cdb82e63651c4d by Terry Sun <tesun@nvidia.com>:

Revert ""PR #15291: [NVIDIA GPU] Add Bitcast to collective pipeliner acceptable users""

This reverts commit 6c65d7a3e3358efef0d6fed4505236b41e5c68e7.

Merging this change closes #19272

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19272 from terryysun:terryysun/revert_bitcast_in_cp ad05557e7a46dcd44afa16c7a0cdb82e63651c4d
",copybara-service[bot],2024-11-12 21:24:18+00:00,[],2024-11-13 03:55:04+00:00,,https://github.com/tensorflow/tensorflow/pull/79914,[],[],
2653340217,pull_request,closed,,Remove op_resolver.cc from `tflite_internal_cc_3p_api_deps_src` filegroup target.,"Remove op_resolver.cc from `tflite_internal_cc_3p_api_deps_src` filegroup target.

This is currently not needed there, and causes problems because it has dependencies
on other files that are not included in that filegroup, e.g. `schema_utils.cc`
(which in turn would pull in `compatibility_macros.h`).
",copybara-service[bot],2024-11-12 21:13:42+00:00,[],2024-11-13 02:18:01+00:00,2024-11-13 02:18:00+00:00,https://github.com/tensorflow/tensorflow/pull/79913,[],[],
2653296343,pull_request,closed,,Change how `go_library` load is exported,"Change how `go_library` load is exported
",copybara-service[bot],2024-11-12 20:47:28+00:00,['ddunl'],2024-11-13 00:31:26+00:00,2024-11-13 00:31:25+00:00,https://github.com/tensorflow/tensorflow/pull/79912,[],[],
2653292981,pull_request,closed,,Fix the build script since we removed the TF and JAX tags and will only have one image for both TF and JAX.,"Fix the build script since we removed the TF and JAX tags and will only have one image for both TF and JAX.
",copybara-service[bot],2024-11-12 20:45:44+00:00,['quoctruong'],2024-11-13 01:22:32+00:00,2024-11-13 01:22:31+00:00,https://github.com/tensorflow/tensorflow/pull/79911,[],[],
2653280974,pull_request,open,,PR #19160: Add support for fusion operations in GetLoopInductionVariableIndex,"PR #19160: Add support for fusion operations in GetLoopInductionVariableIndex

Imported from GitHub PR https://github.com/openxla/xla/pull/19160

After optimizations, while loop analysis was unable to handle the fused operations, primarily for GetLoopInductionVariableIndex and ComputeWhileLoopTripCount. This patch handles only GetloopInductionVariableIdx.

If the GetGTEOperandIndex function fails to find a precise GTE operand, we try to deduce the unique dependence by using the HloExtractor.
Copybara import of the project:

--
b87de101421d7a4b98050379e931507d37bb90ab by Shraiysh Vaishay <svaishay@nvidia.com>:

Add support for fusion operations in GetLoopInductionVariableIndex

After optimizations, while loop analysis was unable to handle the fused
operations, primarily for GetLoopInductionVariableIndex and
ComputeWhileLoopTripCount. This patch handles only
GetloopInductionVariableIdx.

If the GetGTEOperandIndex function fails to find a precise GTE operand,
we try to deduce the unique dependence by using the HloExtractor.

Merging this change closes #19160

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19160 from shraiysh:while_loop_enhancements b87de101421d7a4b98050379e931507d37bb90ab
",copybara-service[bot],2024-11-12 20:39:10+00:00,[],2024-11-12 20:39:10+00:00,,https://github.com/tensorflow/tensorflow/pull/79910,[],[],
2653217099,pull_request,open,,Move BatchedGatherScatterNormalizer from pre-SPMD for pose-SPMD.,"Move BatchedGatherScatterNormalizer from pre-SPMD for pose-SPMD.
",copybara-service[bot],2024-11-12 20:12:38+00:00,['bixia1'],2024-11-12 21:08:59+00:00,,https://github.com/tensorflow/tensorflow/pull/79909,[],[],
2653207600,pull_request,closed,,Move layout changing and dtype changing copies out of host memory space',"Move layout changing and dtype changing copies out of host memory space'
",copybara-service[bot],2024-11-12 20:06:50+00:00,['SandSnip3r'],2024-11-15 01:54:09+00:00,2024-11-15 01:54:08+00:00,https://github.com/tensorflow/tensorflow/pull/79908,[],[],
2653163248,pull_request,closed,,More thorough propagation of host linear layout. Currently linear layout on host,"More thorough propagation of host linear layout. Currently linear layout on host
can only originate from entry computation. Propagation only goes strickly down/up.
More needs to be done later if such layout can original from host compute itself.
Removed the temporary pattern match solution.
",copybara-service[bot],2024-11-12 19:46:49+00:00,[],2024-12-05 05:34:16+00:00,2024-12-05 05:34:15+00:00,https://github.com/tensorflow/tensorflow/pull/79907,[],[],
2653127887,pull_request,open,,Integrate LLVM at llvm/llvm-project@0e936e375e61,"Integrate LLVM at llvm/llvm-project@0e936e375e61

Updates LLVM usage to match
[0e936e375e61](https://github.com/llvm/llvm-project/commit/0e936e375e61)
",copybara-service[bot],2024-11-12 19:28:04+00:00,[],2024-11-12 19:28:04+00:00,,https://github.com/tensorflow/tensorflow/pull/79906,[],[],
2653066135,pull_request,closed,,Rename a flag,"Rename a flag
",copybara-service[bot],2024-11-12 19:02:08+00:00,[],2024-11-12 20:25:28+00:00,2024-11-12 20:25:25+00:00,https://github.com/tensorflow/tensorflow/pull/79905,[],[],
2653046727,pull_request,open,,Integrate LLVM at llvm/llvm-project@0d2ef7af1956,"Integrate LLVM at llvm/llvm-project@0d2ef7af1956

Updates LLVM usage to match
[0d2ef7af1956](https://github.com/llvm/llvm-project/commit/0d2ef7af1956)
",copybara-service[bot],2024-11-12 18:52:37+00:00,[],2024-11-12 18:52:37+00:00,,https://github.com/tensorflow/tensorflow/pull/79904,[],[],
2653038603,pull_request,closed,,Move split_into_island_per_op_pass to tf2xla/transform directory for bridge ownership. Test file with 3 base tests is added.,"Move split_into_island_per_op_pass to tf2xla/transform directory for bridge ownership. Test file with 3 base tests is added.

Initial design desired to remove this pass but failing tests seem to imply it is required so moving to bridge directory.
",copybara-service[bot],2024-11-12 18:48:37+00:00,['rocketas'],2024-11-12 19:15:02+00:00,2024-11-12 19:15:01+00:00,https://github.com/tensorflow/tensorflow/pull/79903,[],[],
2652979719,pull_request,open,,Upgrade protobuf to 28.4,"Upgrade protobuf to 28.4
",copybara-service[bot],2024-11-12 18:25:53+00:00,[],2024-11-12 18:25:53+00:00,,https://github.com/tensorflow/tensorflow/pull/79902,[],[],
2652971220,pull_request,closed,,tests: Move simple numeric tests to OSS.,"tests: Move simple numeric tests to OSS.
",copybara-service[bot],2024-11-12 18:20:44+00:00,[],2024-11-12 21:17:12+00:00,2024-11-12 21:17:12+00:00,https://github.com/tensorflow/tensorflow/pull/79901,[],[],
2652899972,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-12 17:44:07+00:00,[],2024-12-02 20:54:03+00:00,2024-12-02 20:54:02+00:00,https://github.com/tensorflow/tensorflow/pull/79900,[],[],
2652897271,pull_request,open,,Move down_cast from the tensorflow to the tsl namespace,"Move down_cast from the tensorflow to the tsl namespace

No functionality changes are intended
",copybara-service[bot],2024-11-12 17:42:44+00:00,['majnemer'],2024-11-20 19:42:52+00:00,,https://github.com/tensorflow/tensorflow/pull/79899,[],[],
2652819539,pull_request,open,,Canonicalize division by a constant to multiplication by the reciprocal of that constant.,"Canonicalize division by a constant to multiplication by the reciprocal of that constant.

Floating point division are more expensive and prune to have worse precision than multiplication.
",copybara-service[bot],2024-11-12 17:11:26+00:00,['sirakiin'],2024-11-12 17:11:27+00:00,,https://github.com/tensorflow/tensorflow/pull/79898,[],[],
2652779466,pull_request,closed,,Curl upgrade patch 8.6.0 -> 8.11.0,"The current curl version 8.6.0 that is used by Tensorflow has many known security vulnerabilities.
This PR upgraded the curl dependency to version 8.11.0 that is not affected by known vulnerabilities.",gerwout,2024-11-12 16:54:55+00:00,['gbaned'],2024-11-13 14:02:43+00:00,2024-11-13 14:02:42+00:00,https://github.com/tensorflow/tensorflow/pull/79897,"[('size:L', 'CL Change Size: Large')]","[{'comment_id': 2471077066, 'issue_id': 2652779466, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79897/checks?check_run_id=32876540229) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 11, 12, 16, 55, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2473707874, 'issue_id': 2652779466, 'author': 'gerwout', 'body': 'created a new pr, that was easier than fixing this one', 'created_at': datetime.datetime(2024, 11, 13, 14, 2, 42, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-11-12 16:55:04 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79897/checks?check_run_id=32876540229) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

gerwout (Issue Creator) on (2024-11-13 14:02:42 UTC): created a new pr, that was easier than fixing this one

"
2652765691,pull_request,closed,,Integrate LLVM at llvm/llvm-project@0e936e375e61,"Integrate LLVM at llvm/llvm-project@0e936e375e61

Updates LLVM usage to match
[0e936e375e61](https://github.com/llvm/llvm-project/commit/0e936e375e61)
",copybara-service[bot],2024-11-12 16:50:51+00:00,[],2024-11-12 19:23:09+00:00,2024-11-12 19:23:08+00:00,https://github.com/tensorflow/tensorflow/pull/79896,[],[],
2652607845,pull_request,open,,[XLA:GPU][NFC] Remove redundant string conversion.,"[XLA:GPU][NFC] Remove redundant string conversion.
",copybara-service[bot],2024-11-12 15:54:46+00:00,[],2024-11-12 15:54:46+00:00,,https://github.com/tensorflow/tensorflow/pull/79895,[],[],
2652442364,pull_request,open,,This is to fix the crash on Windows when allocated memory for the model is not aligned.,"This is to fix the crash on Windows when allocated memory for the model is not aligned.
",copybara-service[bot],2024-11-12 14:55:32+00:00,[],2024-11-12 14:55:32+00:00,,https://github.com/tensorflow/tensorflow/pull/79894,[],[],
2652437108,pull_request,closed,,[XLA:CPU] Add benchmarks for 1D strided convolutions,"[XLA:CPU] Add benchmarks for 1D strided convolutions

Currently the transposed convolution is orders of magnitude slower than the regular one. Ideally performance should be similar. Detailed results:
--------------------------------------------------------------------------------------------------
Benchmark                                                        Time             CPU   Iterations
--------------------------------------------------------------------------------------------------
BM_Conv1DStrided/process_time                              2869248 ns     31485808 ns           21
BM_Conv1DTransposedStrided/process_time                  444138484 ns   9397599808 ns            1
BM_Conv1DTransposedStridedNonDefaultLayout/process_time  471396271 ns   9208384080 ns            1
",copybara-service[bot],2024-11-12 14:53:45+00:00,[],2024-11-14 08:34:27+00:00,2024-11-14 08:34:26+00:00,https://github.com/tensorflow/tensorflow/pull/79893,[],"[{'comment_id': 2470750719, 'issue_id': 2652437108, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79893/checks?check_run_id=32869136216) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 11, 12, 14, 53, 52, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-11-12 14:53:52 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79893/checks?check_run_id=32869136216) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2652434608,pull_request,open,,Integrate LLVM at llvm/llvm-project@a912c81f6511,"Integrate LLVM at llvm/llvm-project@a912c81f6511

Updates LLVM usage to match
[a912c81f6511](https://github.com/llvm/llvm-project/commit/a912c81f6511)
",copybara-service[bot],2024-11-12 14:52:58+00:00,[],2024-11-12 14:52:58+00:00,,https://github.com/tensorflow/tensorflow/pull/79892,[],[],
2652129017,pull_request,closed,,Fix a bug where an object was being deallocated with a destructor of the wrong type.,"Fix a bug where an object was being deallocated with a destructor of the wrong type.

The `free_with_data` method of `TfLiteOperator` (set by the
`TfLiteOperatorSetFreeWithData` function) deallocates data allocated by the
`init_with_data` method of `TfLiteOperator` (set by `TfLiteOperatorSetInitWithData`).
The run-time type of the `void *buffer` parameter passed to the `free_with_data` method
is determined by the run-time type returned from the `init_with_data` method,
so when we cast `buffer` from `void *`, we need to cast it to the matching type.

This also matches what is done in the corresponding code using non-opaque types in [simple_delegate.cc]( https://github.com/tensorflow/tensorflow/blob/03b1c2be13694357725bf7370dfbf71e62b01a2e/tensorflow/lite/delegates/utils/simple_delegate.cc#L43).
",copybara-service[bot],2024-11-12 13:05:33+00:00,[],2024-11-13 03:10:45+00:00,2024-11-13 03:10:44+00:00,https://github.com/tensorflow/tensorflow/pull/79890,[],[],
2652102964,pull_request,open,,Integrate Triton up to [9732c047](https://github.com/openai/triton/commits/9732c04701bd856daca89bde38bafa4636ca56a8),"Integrate Triton up to [9732c047](https://github.com/openai/triton/commits/9732c04701bd856daca89bde38bafa4636ca56a8)
",copybara-service[bot],2024-11-12 12:55:13+00:00,[],2024-11-15 13:22:03+00:00,,https://github.com/tensorflow/tensorflow/pull/79889,[],[],
2652063742,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-12 12:36:41+00:00,[],2024-11-12 12:49:55+00:00,,https://github.com/tensorflow/tensorflow/pull/79888,[],[],
2652047512,pull_request,closed,,Reverts 161a85bb26fda431fb52554597a23fd422cec02d,"Reverts 161a85bb26fda431fb52554597a23fd422cec02d
",copybara-service[bot],2024-11-12 12:29:05+00:00,[],2024-11-12 14:35:35+00:00,2024-11-12 14:35:33+00:00,https://github.com/tensorflow/tensorflow/pull/79887,[],[],
2651776460,pull_request,closed,,Enable libnvjitlink by default in OSS,"Enable libnvjitlink by default in OSS

The hermetic CUDA change gained us nvjitlink support, so we can now enable if by default. But since there is a memory leak in CUDA SDK 12.4 and below we only enable it by default for later versions. Users will still be able to force-enable it through the flag.

I'm also adding the missing tsl::Flag to DebugOptionsFlag. Without that the debug option couldn't be changed on the command line.
",copybara-service[bot],2024-11-12 10:40:15+00:00,[],2024-11-14 07:47:08+00:00,2024-11-14 07:47:07+00:00,https://github.com/tensorflow/tensorflow/pull/79886,[],[],
2651732233,pull_request,closed,,Disable NVJitLink and LibNvPtxCompiler support under MSAN,"Disable NVJitLink and LibNvPtxCompiler support under MSAN

NVJitLink and LibNvPtxCompiler as precompiled libraries are not compatible with MSan, so we disable their support so that we at least can run some larger tests under MSAN. This is not ideal because it means these tests will take different code paths but the alternative would be not running them at all.
",copybara-service[bot],2024-11-12 10:26:36+00:00,[],2024-11-13 07:39:08+00:00,2024-11-13 07:39:07+00:00,https://github.com/tensorflow/tensorflow/pull/79885,[],[],
2651599678,pull_request,closed,,Add flexible test binary for running arbitrary models on device.,"Add flexible test binary for running arbitrary models on device.

Use `apply_plugin` to generate tflite and `./run_test_on_android.sh invoke_qualcomm_model --model=/path/to/model/on/workstation` to run
",copybara-service[bot],2024-11-12 09:33:27+00:00,['LukeBoyer'],2024-11-13 22:54:38+00:00,2024-11-13 22:54:37+00:00,https://github.com/tensorflow/tensorflow/pull/79883,[],[],
2651555102,pull_request,open,,Integrate LLVM at llvm/llvm-project@1277bea43116,"Integrate LLVM at llvm/llvm-project@1277bea43116

Updates LLVM usage to match
[1277bea43116](https://github.com/llvm/llvm-project/commit/1277bea43116)
",copybara-service[bot],2024-11-12 09:20:42+00:00,[],2024-11-12 09:20:42+00:00,,https://github.com/tensorflow/tensorflow/pull/79876,[],[],
2651542543,pull_request,closed,,Fix missing version case bug in context_binary_info.cc,"Fix missing version case bug in context_binary_info.cc
",copybara-service[bot],2024-11-12 09:15:49+00:00,['LukeBoyer'],2024-11-13 08:03:55+00:00,2024-11-13 08:03:54+00:00,https://github.com/tensorflow/tensorflow/pull/79875,[],[],
2651511320,pull_request,closed,,PR #19237: [GPU] Fix passing of key-value store handle from client to compiler.,"PR #19237: [GPU] Fix passing of key-value store handle from client to compiler.

Imported from GitHub PR https://github.com/openxla/xla/pull/19237


Copybara import of the project:

--
177f911fd4c6af86c25aba2e38ea09767477be03 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Fix passing of key-value store handle from client to compiler.

--
ec2b96ccdf8cd81abdc25f3cff2bdf65df455219 by Ilia Sergachev <isergachev@nvidia.com>:

use allowed_devices instead of CUDA_VISIBLE_DEVICES

--
77ba9fd7b172052269fafd1a1970d58d1d803a59 by Ilia Sergachev <isergachev@nvidia.com>:

skip the added test on pre-Ampere GPUs

Merging this change closes #19237

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19237 from openxla:fix_kv_store 77ba9fd7b172052269fafd1a1970d58d1d803a59
",copybara-service[bot],2024-11-12 09:01:24+00:00,[],2024-11-20 20:37:53+00:00,2024-11-20 20:37:52+00:00,https://github.com/tensorflow/tensorflow/pull/79859,[],[],
2651298359,pull_request,closed,,PR #19194: Add guard for scalar operations when brute-forcing while loop analysis,"PR #19194: Add guard for scalar operations when brute-forcing while loop analysis

Imported from GitHub PR https://github.com/openxla/xla/pull/19194

If `MatchTrivialLoopTripCount`, fails we brute force the while loop with `ComputeWhileLoopTripCount`. In this patch we add a guard to ensure that we only brute-force the while loop when the operation is a scalar operation or a collection of scalar operations (via call, or fusion).
Copybara import of the project:

--
2063a23c31524ff0be338488d7468a67337001c9 by Shraiysh Vaishay <svaishay@nvidia.com>:

Add guard for scalar operations when brute-forcing while loop analysis

If `MatchTrivialLoopTripCount`, fails we brute force the while loop with
`ComputeWhileLoopTripCount`. In this patch we add a guard to ensure that
we only brute-force the while loop when the operation is a scalar
operation or a collection of scalar operations (via call, or fusion).

Merging this change closes #19194

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19194 from shraiysh:scalar_guard_for_while_loop_evaluation 2063a23c31524ff0be338488d7468a67337001c9
",copybara-service[bot],2024-11-12 07:29:45+00:00,[],2024-11-13 03:19:22+00:00,2024-11-13 03:19:21+00:00,https://github.com/tensorflow/tensorflow/pull/79848,[],[],
2651144474,pull_request,closed,,Make aot/runtime work end2end,"Make aot/runtime work end2end

Reconcile the approach to serialiing byte code between aot and dispatch delegate. Remove ""exec_info"" delegate options and read the bytecode offset from metadata in each delegate kernel init step.

Pull some shared delegate test logic into test common. Also add some logic in test common that can append pre-existing npu files to tflite files so we can re-use existing test models.
",copybara-service[bot],2024-11-12 06:06:24+00:00,['LukeBoyer'],2024-11-13 06:50:15+00:00,2024-11-13 06:50:14+00:00,https://github.com/tensorflow/tensorflow/pull/79847,[],[],
2651138073,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-12 06:02:07+00:00,[],2024-11-12 06:02:07+00:00,,https://github.com/tensorflow/tensorflow/pull/79846,[],[],
2651129897,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-12 05:56:43+00:00,[],2024-11-12 05:56:43+00:00,,https://github.com/tensorflow/tensorflow/pull/79845,[],[],
2651121837,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-12 05:52:30+00:00,[],2024-11-12 05:52:30+00:00,,https://github.com/tensorflow/tensorflow/pull/79844,[],[],
2651067594,pull_request,open,,Internal build file change,"Internal build file change
",copybara-service[bot],2024-11-12 05:26:08+00:00,[],2024-11-12 05:26:08+00:00,,https://github.com/tensorflow/tensorflow/pull/79843,[],[],
2651038810,pull_request,closed,,[IFRT] Add passes to convert IFRT IR atom programs to and from VHLO.,"[IFRT] Add passes to convert IFRT IR atom programs to and from VHLO.
",copybara-service[bot],2024-11-12 05:00:13+00:00,[],2024-11-12 19:51:02+00:00,2024-11-12 19:51:01+00:00,https://github.com/tensorflow/tensorflow/pull/79840,[],[],
2650979265,pull_request,closed,,PJRT doc typo fix for website,"PJRT doc typo fix for website
",copybara-service[bot],2024-11-12 04:27:49+00:00,['GleasonK'],2024-11-13 01:48:32+00:00,2024-11-13 01:48:31+00:00,https://github.com/tensorflow/tensorflow/pull/79828,[],[],
2650920544,pull_request,open,,Canonicalize division by a constant to multiplication by the reciprocal of that constant.,"Canonicalize division by a constant to multiplication by the reciprocal of that constant.

Floating point division are more expensive and prune to have worse precision than multiplication.
",copybara-service[bot],2024-11-12 03:36:29+00:00,['sirakiin'],2024-11-12 03:36:29+00:00,,https://github.com/tensorflow/tensorflow/pull/79824,[],[],
2650796495,pull_request,closed,,Remove GpuExecutor::gpu_context method.,"Remove GpuExecutor::gpu_context method.
",copybara-service[bot],2024-11-12 02:03:07+00:00,[],2024-11-13 02:27:43+00:00,2024-11-13 02:27:42+00:00,https://github.com/tensorflow/tensorflow/pull/79823,[],[],
2650748077,pull_request,closed,,PR #19162: [ROCm] Fix grid dimension issue introduced in d8909c9b8,"PR #19162: [ROCm] Fix grid dimension issue introduced in d8909c9b8

Imported from GitHub PR https://github.com/openxla/xla/pull/19162


Copybara import of the project:

--
dd86f21a20d1391cefaf6f74f89abce787bb236a by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Fix grid dimension issue introduced in d8909c9b8

Merging this change closes #19162

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19162 from ROCm:ci_fix_gridy_20241107 dd86f21a20d1391cefaf6f74f89abce787bb236a
",copybara-service[bot],2024-11-12 01:11:43+00:00,[],2024-11-12 03:39:04+00:00,2024-11-12 03:39:03+00:00,https://github.com/tensorflow/tensorflow/pull/79822,[],[],
2650747294,pull_request,closed,,Add test example to add counter lines to tensorboard trace viewer data.,"Add test example to add counter lines to tensorboard trace viewer data.
",copybara-service[bot],2024-11-12 01:10:45+00:00,[],2024-11-12 23:16:03+00:00,2024-11-12 23:16:02+00:00,https://github.com/tensorflow/tensorflow/pull/79821,[],[],
2650743876,pull_request,closed,,PR #19112: [GPU] GEMM fusion: support more broadcasts.,"PR #19112: [GPU] GEMM fusion: support more broadcasts.

Imported from GitHub PR https://github.com/openxla/xla/pull/19112

Support broadcasts involving 1-sized fragments of dimensions like [1,n] -> broadcast -> [1,m,n].
Copybara import of the project:

--
f02445356ed623895ce0c2ac4cf06594f07facf8 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] GEMM fusion analysis: support broadcasts of trivially-sized dimensions.

--
86ba22e4c635717b74ca39e8d1bcc0414f92acdd by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Triton GEMM emitter: support broadcasts of trivially-sized dimensions.

--
2ca1165b9d72e29f241ea29df49fe71879c21fec by Ilia Sergachev <isergachev@nvidia.com>:

address feedback

--
308cf80a053812425fbff6bbdc17e07edac160f6 by Ilia Sergachev <isergachev@nvidia.com>:

add another test

--
8f38c5cd0b50a1d9abc77a6856027fc89de2ec43 by Ilia Sergachev <isergachev@nvidia.com>:

fix tensor pointer advancement

Merging this change closes #19112

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19112 from openxla:gemm_fusion_support_more_broadcasts 8f38c5cd0b50a1d9abc77a6856027fc89de2ec43
",copybara-service[bot],2024-11-12 01:06:45+00:00,[],2024-11-15 04:48:44+00:00,2024-11-15 04:48:43+00:00,https://github.com/tensorflow/tensorflow/pull/79820,[],[],
2650738336,pull_request,closed,,Put P2PSchedulePreparation behind `enable_pipelined_p2p` flag,"Put P2PSchedulePreparation behind `enable_pipelined_p2p` flag

P2PSchedulePreparation assumes channel_ids for send/recv ops, a constraint which we want to relax.
The pass will be removed when the new pipeline parallelism optimisations have landed, so we don't need to invest in generalising it.
",copybara-service[bot],2024-11-12 01:00:23+00:00,['frgossen'],2024-11-28 04:04:45+00:00,2024-11-28 04:04:44+00:00,https://github.com/tensorflow/tensorflow/pull/79819,[],[],
2650731632,pull_request,closed,,"Remove last GpuDriver method, moving it to the appropriate Executor.","Remove last GpuDriver method, moving it to the appropriate Executor.
",copybara-service[bot],2024-11-12 00:52:07+00:00,[],2024-11-13 01:36:10+00:00,2024-11-13 01:36:09+00:00,https://github.com/tensorflow/tensorflow/pull/79818,[],[],
2650725361,pull_request,closed,,Bump up Cast op version op to 7 with bfloat16 runtime kernel support,"Bump up Cast op version op to 7 with bfloat16 runtime kernel support

This CL can resolve the latest bfloat16 TFLite flatbuffers' interpreter executation & quantization. It's required because quantization checks the TFLite float FB validation with interpreter.
",copybara-service[bot],2024-11-12 00:45:32+00:00,[],2024-11-12 01:04:50+00:00,2024-11-12 01:04:49+00:00,https://github.com/tensorflow/tensorflow/pull/79817,[],[],
2650721581,pull_request,closed,,Remove cuda_driver from cuda_plugins_check_deps; it will be deleted.,"Remove cuda_driver from cuda_plugins_check_deps; it will be deleted.
",copybara-service[bot],2024-11-12 00:40:48+00:00,[],2024-11-12 04:53:22+00:00,2024-11-12 04:53:21+00:00,https://github.com/tensorflow/tensorflow/pull/79816,[],[],
2650718441,pull_request,closed,,Propagate shutdown errors before destroying agent.,"Propagate shutdown errors before destroying agent.
Also add a short buffer to the RPC timeouts so that service-related errors may get propagated before the RPC layer times it out.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19162 from ROCm:ci_fix_gridy_20241107 dd86f21a20d1391cefaf6f74f89abce787bb236a
",copybara-service[bot],2024-11-12 00:36:51+00:00,[],2024-11-12 04:18:12+00:00,2024-11-12 04:18:11+00:00,https://github.com/tensorflow/tensorflow/pull/79815,[],[],
2650699993,pull_request,closed,,Fix a bug in _label function to handle targets with @org_tensorflow// prefix.,"Fix a bug in _label function to handle targets with @org_tensorflow// prefix.
",copybara-service[bot],2024-11-12 00:17:34+00:00,['ecalubaquib'],2024-11-12 19:41:43+00:00,2024-11-12 19:41:42+00:00,https://github.com/tensorflow/tensorflow/pull/79814,[],[],
2650668117,pull_request,closed,,Remove unneeded header file inclusion.,"Remove unneeded header file inclusion.
",copybara-service[bot],2024-11-11 23:49:58+00:00,[],2024-11-12 00:18:42+00:00,2024-11-12 00:18:41+00:00,https://github.com/tensorflow/tensorflow/pull/79813,[],[],
2650654857,pull_request,closed,,[IFRT] Add IFRT IR program serialize options and proto to store serialized IFRT IR programs.,"[IFRT] Add IFRT IR program serialize options and proto to store serialized IFRT IR programs.
",copybara-service[bot],2024-11-11 23:39:26+00:00,[],2024-11-12 04:37:39+00:00,2024-11-12 04:37:39+00:00,https://github.com/tensorflow/tensorflow/pull/79812,[],[],
2650622819,pull_request,closed,,Add PJRT_Buffer_CopyRawToHost to PJRT C API.,"Add PJRT_Buffer_CopyRawToHost to PJRT C API.
",copybara-service[bot],2024-11-11 23:25:46+00:00,[],2024-11-15 00:00:31+00:00,2024-11-15 00:00:30+00:00,https://github.com/tensorflow/tensorflow/pull/79811,[],[],
2650605768,pull_request,closed,,Integrate LLVM at llvm/llvm-project@028ea71fdda0,"Integrate LLVM at llvm/llvm-project@028ea71fdda0

Updates LLVM usage to match
[028ea71fdda0](https://github.com/llvm/llvm-project/commit/028ea71fdda0)
",copybara-service[bot],2024-11-11 23:09:11+00:00,[],2024-11-12 05:58:13+00:00,2024-11-12 05:58:13+00:00,https://github.com/tensorflow/tensorflow/pull/79810,[],[],
2650603154,pull_request,closed,,"Simplify MSA's BaseCosts api by removing the BytesPerSecond() method, and instead relying on CostAnalysisOptions that specify the bandwidth.","Simplify MSA's BaseCosts api by removing the BytesPerSecond() method, and instead relying on CostAnalysisOptions that specify the bandwidth.

Also, rename async_copy_bandwidth_bytes_per_second to  default_mem_copy_bandwidth_bytes_per_second.
",copybara-service[bot],2024-11-11 23:06:39+00:00,['sparc1998'],2024-11-15 03:04:42+00:00,2024-11-15 03:04:42+00:00,https://github.com/tensorflow/tensorflow/pull/79809,[],[],
2650588502,pull_request,closed,,Simplify MSA's BaseCosts api by moving GetShapeSize out of BaseCosts.,"Simplify MSA's BaseCosts api by moving GetShapeSize out of BaseCosts.
",copybara-service[bot],2024-11-11 22:54:36+00:00,['sparc1998'],2024-11-13 22:26:07+00:00,2024-11-13 22:26:07+00:00,https://github.com/tensorflow/tensorflow/pull/79808,[],[],
2650563349,pull_request,closed,,Make channel_id optional for send/recv ops. ,"Make channel_id optional for send/recv ops. 

This will not change any current behaviour. 
This is a preparation to enable cross-replica send/recv ops.
",copybara-service[bot],2024-11-11 22:38:46+00:00,['frgossen'],2024-11-28 02:30:16+00:00,2024-11-28 02:30:15+00:00,https://github.com/tensorflow/tensorflow/pull/79807,[],[],
2650534524,pull_request,closed,,lite: schema: add blockwise quantization representation,"lite: schema: add blockwise quantization representation
",copybara-service[bot],2024-11-11 22:31:00+00:00,['zichuan-wei'],2024-11-13 17:45:23+00:00,2024-11-13 17:45:23+00:00,https://github.com/tensorflow/tensorflow/pull/79806,[],[],
2650526540,pull_request,open,,Refactor TF wheel build rule.,"Refactor TF wheel build rule.
",copybara-service[bot],2024-11-11 22:23:48+00:00,[],2024-11-13 18:03:11+00:00,,https://github.com/tensorflow/tensorflow/pull/79805,[],[],
2650384950,pull_request,closed,,[Recoverable] Allow certain tasks to gracefully reconnect without crashing the entire cluster during transient errors (i.e. preemption).,"[Recoverable] Allow certain tasks to gracefully reconnect without crashing the entire cluster during transient errors (i.e. preemption).
",copybara-service[bot],2024-11-11 20:56:46+00:00,[],2024-11-15 18:30:18+00:00,2024-11-15 18:30:16+00:00,https://github.com/tensorflow/tensorflow/pull/79804,[],[],
2650291790,pull_request,closed,,Add hlo_module Megascale stat type.,"Add hlo_module Megascale stat type.
",copybara-service[bot],2024-11-11 20:08:46+00:00,[],2024-11-13 01:58:18+00:00,2024-11-13 01:58:16+00:00,https://github.com/tensorflow/tensorflow/pull/79803,[],[],
2650279366,pull_request,closed,,Move profiler plugin functions to a separate pybind11 module,"Move profiler plugin functions to a separate pybind11 module

Reverts 3a8608bb34d537a91631f7a26b3bcb1fc50d88d3
",copybara-service[bot],2024-11-11 20:01:43+00:00,['cliveverghese'],2024-11-15 02:40:44+00:00,2024-11-15 02:40:43+00:00,https://github.com/tensorflow/tensorflow/pull/79802,[],[],
2650268345,pull_request,closed,,Add more legalization of OPs in QC compiler plugin.,"Add more legalization of OPs in QC compiler plugin.
 * Add Cast Op legalization and test data.
 * Add Softmax Op legalization.
 * Add Sin/Cos Op legalization and test data.
 * Add Transpose Op legalization, modify test to use const perm tensor.
 * Rename UniquePtr to Ptr in all legalization header files.
",copybara-service[bot],2024-11-11 19:57:14+00:00,[],2024-11-13 23:37:06+00:00,2024-11-13 23:37:06+00:00,https://github.com/tensorflow/tensorflow/pull/79801,[],[],
2650243821,pull_request,open,,Update patch lines,"Update patch lines
",copybara-service[bot],2024-11-11 19:47:48+00:00,['rtg0795'],2024-11-11 21:10:49+00:00,,https://github.com/tensorflow/tensorflow/pull/79799,[],[],
2650154568,pull_request,closed,,Move ifrt se_gpu tests to internal,"Move ifrt se_gpu tests to internal
",copybara-service[bot],2024-11-11 19:10:43+00:00,[],2024-11-13 22:15:15+00:00,2024-11-13 22:15:14+00:00,https://github.com/tensorflow/tensorflow/pull/79797,[],[],
2650154221,pull_request,closed,,"Fix duplicate registration error when running python with ""import tensorflow as tf""","Fix duplicate registration error when running python with ""import tensorflow as tf""
",copybara-service[bot],2024-11-11 19:10:28+00:00,['ecalubaquib'],2024-11-25 17:24:48+00:00,2024-11-25 17:24:47+00:00,https://github.com/tensorflow/tensorflow/pull/79796,[],[],
2650116098,pull_request,closed,,Move GpuDriver::GetDeviceCount functionality into the appropriate Platform.,"Move GpuDriver::GetDeviceCount functionality into the appropriate Platform.
",copybara-service[bot],2024-11-11 18:48:05+00:00,[],2024-11-11 23:12:07+00:00,2024-11-11 23:12:06+00:00,https://github.com/tensorflow/tensorflow/pull/79795,[],[],
2650010353,pull_request,closed,,"Add a ToolParam to the XNNPACK TFLite delegate to allow easy enabling of Slinky via the existing ToolParam/BenchmarkParam struct. The net result of this is that anywhere you can currently specify the `--use_xnnpack=true|false` commandline flag, you can now also specify `--xnnpack_slinky=true|false` to control whether XNNPACK is run with Slinky or not. (Note that this flag will be ignored if XNNPACK is built without Slinky.)","Add a ToolParam to the XNNPACK TFLite delegate to allow easy enabling of Slinky via the existing ToolParam/BenchmarkParam struct. The net result of this is that anywhere you can currently specify the `--use_xnnpack=true|false` commandline flag, you can now also specify `--xnnpack_slinky=true|false` to control whether XNNPACK is run with Slinky or not. (Note that this flag will be ignored if XNNPACK is built without Slinky.)
",copybara-service[bot],2024-11-11 17:57:18+00:00,[],2024-11-15 20:49:11+00:00,2024-11-15 20:49:10+00:00,https://github.com/tensorflow/tensorflow/pull/79794,[],[],
2650009511,pull_request,closed,,DynamicUpdateSlice takes float16 type,"DynamicUpdateSlice takes float16 type
",copybara-service[bot],2024-11-11 17:56:52+00:00,['talumbau'],2024-11-13 20:49:50+00:00,2024-11-13 20:49:49+00:00,https://github.com/tensorflow/tensorflow/pull/79793,[],[],
2649995929,pull_request,closed,,Create public entry point for PJRT TPU wrapper and use the C++ PJRT Wrapper by default,"Create public entry point for PJRT TPU wrapper and use the C++ PJRT Wrapper by default
",copybara-service[bot],2024-11-11 17:49:22+00:00,['changm'],2024-11-11 23:52:22+00:00,2024-11-11 23:52:21+00:00,https://github.com/tensorflow/tensorflow/pull/79792,[],[],
2649864904,pull_request,open,,Integrate LLVM at llvm/llvm-project@a7b249e4708d,"Integrate LLVM at llvm/llvm-project@a7b249e4708d

Updates LLVM usage to match
[a7b249e4708d](https://github.com/llvm/llvm-project/commit/a7b249e4708d)
",copybara-service[bot],2024-11-11 16:48:33+00:00,[],2024-11-11 18:53:33+00:00,,https://github.com/tensorflow/tensorflow/pull/79791,[],[],
2649801591,pull_request,closed,,[XLA:GPU] Skip small tile sizes for sparse gemms on Ampere as well. Enable the JAX test again that has been failing.,"[XLA:GPU] Skip small tile sizes for sparse gemms on Ampere as well. Enable the JAX test again that has been failing.
",copybara-service[bot],2024-11-11 16:26:28+00:00,['chsigg'],2024-11-11 17:27:18+00:00,2024-11-11 17:27:17+00:00,https://github.com/tensorflow/tensorflow/pull/79790,[],[],
2649694325,pull_request,open,,Integrate LLVM at llvm/llvm-project@a7b249e4708d,"Integrate LLVM at llvm/llvm-project@a7b249e4708d

Updates LLVM usage to match
[a7b249e4708d](https://github.com/llvm/llvm-project/commit/a7b249e4708d)
",copybara-service[bot],2024-11-11 15:36:44+00:00,[],2024-11-11 16:12:31+00:00,,https://github.com/tensorflow/tensorflow/pull/79789,[],[],
2649628864,pull_request,closed,,[XLA:GPU] Change `assert` to `CHECK` in Triton sparsity extensions.,"[XLA:GPU] Change `assert` to `CHECK` in Triton sparsity extensions.

A JAX test is hitting this after the latest Triton integrate cl/694073628. Disable the test until we get to the bottom of it.
",copybara-service[bot],2024-11-11 15:14:31+00:00,['chsigg'],2024-11-11 16:12:04+00:00,2024-11-11 16:12:03+00:00,https://github.com/tensorflow/tensorflow/pull/79788,[],[],
2649609078,pull_request,closed,,Remove a stale patch.,"Remove a stale patch.
",copybara-service[bot],2024-11-11 15:05:09+00:00,['belitskiy'],2024-11-11 16:29:25+00:00,2024-11-11 16:29:23+00:00,https://github.com/tensorflow/tensorflow/pull/79787,[],[],
2649601247,pull_request,closed,,Update ByteSwapTFLiteModel function for s390x,"Changes are required to address the failure on s390x when using clang which enforces strict checks for s390x. 
The error is related to initialization of a Variable Length Array (VLA), which requires memory allocation at runtime. 
To resolve this, the array has been replaced with a std::vector.


",Nayana-ibm,2024-11-11 15:01:42+00:00,['gbaned'],2024-11-28 06:42:20+00:00,2024-11-28 06:42:20+00:00,https://github.com/tensorflow/tensorflow/pull/79786,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]","[{'comment_id': 2468385934, 'issue_id': 2649601247, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79786/checks?check_run_id=32812871164) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 11, 11, 15, 1, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2485452626, 'issue_id': 2649601247, 'author': 'keerthanakadiri', 'body': 'Hi @Linchenn, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 11, 19, 11, 27, 4, tzinfo=datetime.timezone.utc)}, {'comment_id': 2486429886, 'issue_id': 2649601247, 'author': 'Linchenn', 'body': 'Hi @fergushenderson ,do you happen to have ideas on this PR?', 'created_at': datetime.datetime(2024, 11, 19, 18, 17, 45, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-11-11 15:01:46 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79786/checks?check_run_id=32812871164) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

keerthanakadiri on (2024-11-19 11:27:04 UTC): Hi @Linchenn, Can you please review this PR? Thank you !

Linchenn on (2024-11-19 18:17:45 UTC): Hi @fergushenderson ,do you happen to have ideas on this PR?

"
2649458750,pull_request,closed,,[XLA:GPU] Add the fallback to F32 for dot algorithms bf16_x3 and bf16_x6 and f32 output.,"[XLA:GPU] Add the fallback to F32 for dot algorithms bf16_x3 and bf16_x6 and f32 output.

We do not have the lowering to multiply version of the algorithm at the moment.
The default f32_f32_f32 version is way faster. Let's use it as the fallback now and do the lowering for these algorithms in the follow up cls.
",copybara-service[bot],2024-11-11 14:13:40+00:00,[],2024-11-11 16:49:08+00:00,2024-11-11 16:49:07+00:00,https://github.com/tensorflow/tensorflow/pull/79785,[],[],
2649422975,pull_request,closed,,Update XNNPACK version.,"Update XNNPACK version.
",copybara-service[bot],2024-11-11 13:57:16+00:00,[],2024-11-11 17:01:56+00:00,2024-11-11 17:01:55+00:00,https://github.com/tensorflow/tensorflow/pull/79784,[],[],
2649232672,pull_request,closed,,[Triton] Fix a bug while lowering to LLVM for block_k=16 when the input types involve an 8-bit. This change is porting in this [PR](https://github.com/triton-lang/triton/pull/4768).,"[Triton] Fix a bug while lowering to LLVM for block_k=16 when the input types involve an 8-bit. This change is porting in this [PR](https://github.com/triton-lang/triton/pull/4768).
",copybara-service[bot],2024-11-11 12:42:35+00:00,[],2024-11-11 14:37:40+00:00,2024-11-11 14:37:38+00:00,https://github.com/tensorflow/tensorflow/pull/79783,[],[],
2648872910,pull_request,closed,,Integrate LLVM at llvm/llvm-project@fb4f426c81d7,"Integrate LLVM at llvm/llvm-project@fb4f426c81d7

Updates LLVM usage to match
[fb4f426c81d7](https://github.com/llvm/llvm-project/commit/fb4f426c81d7)
",copybara-service[bot],2024-11-11 10:24:35+00:00,[],2024-11-11 12:15:02+00:00,2024-11-11 12:15:01+00:00,https://github.com/tensorflow/tensorflow/pull/79782,[],[],
2648668625,pull_request,closed,,"The pointer `user` is statically casted to class `HloDynamicSliceInstruction` to invoke virtual calls. According to both the surrounding code and LLVM PGO instrumentation, the actual type is `HloDynamicUpdateSliceInstruction` so update the casted type.","The pointer `user` is statically casted to class `HloDynamicSliceInstruction` to invoke virtual calls. According to both the surrounding code and LLVM PGO instrumentation, the actual type is `HloDynamicUpdateSliceInstruction` so update the casted type.

Note `HloDynamicSliceInstruction` (call it `D1`) and `HloDynamicUpdateSliceInstruction` (call it `D2`) both directly derive from base class `HloDynamicIndexInstruction` (call it `B`). Casting `D2` pointer into `D1` to invoke a virtual interface of `B` can expose undefined behavior, and specifically breaks LLVM whole program de-virtualization (https://groups.google.com/g/llvm-dev/c/6LfIiAo9g68?e=48417069)
",copybara-service[bot],2024-11-11 09:11:04+00:00,[],2024-11-12 00:06:42+00:00,2024-11-12 00:06:42+00:00,https://github.com/tensorflow/tensorflow/pull/79781,[],[],
2648471443,pull_request,closed,,[XLA] Remove ShapeUtil::IsArrayPrimitiveType.,"[XLA] Remove ShapeUtil::IsArrayPrimitiveType.

This function is redundant with Shape::IsArray.
",copybara-service[bot],2024-11-11 07:44:25+00:00,['majnemer'],2024-11-11 16:38:57+00:00,2024-11-11 16:38:57+00:00,https://github.com/tensorflow/tensorflow/pull/79779,[],[],
2648288042,pull_request,closed,,This is to fix the crash on Windows when allocated memory for the model is not aligned.,"This is to fix the crash on Windows when allocated memory for the model is not aligned.
",copybara-service[bot],2024-11-11 06:16:43+00:00,[],2024-11-12 06:09:15+00:00,2024-11-12 06:09:14+00:00,https://github.com/tensorflow/tensorflow/pull/79778,[],[],
2648247113,pull_request,closed,,Update 02 broken links in gpu.md,"Hi, Team

I found 02 broken documentation links for **GPU support for Android** and **GPU support for iOS** the in the following paragraph: **""This document provides an overview of GPUs support in TensorFlow Lite, and some advanced uses for GPU processors. For more specific information about implementing GPU support on specific platforms, see the following guides:

[GPU support for Android](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/android/delegates/gpu)
[GPU support for iOS](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/ios/delegates/gpu) ""**

I have updated those links to functional links. Please review and merge this change as appropriate.

Thank you for your consideration.",gaikwadrahul8,2024-11-11 05:50:33+00:00,['gbaned'],2024-11-23 17:39:17+00:00,2024-11-23 17:39:16+00:00,https://github.com/tensorflow/tensorflow/pull/79777,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2648245356,pull_request,closed,,Warn if tf.lite.interpreter is used instead of ai-edge-litert.interpreter,"Warn if tf.lite.interpreter is used instead of ai-edge-litert.interpreter
",copybara-service[bot],2024-11-11 05:49:18+00:00,['pak-laura'],2024-11-13 19:55:22+00:00,2024-11-13 19:55:21+00:00,https://github.com/tensorflow/tensorflow/pull/79776,[],[],
2648136009,pull_request,closed,,Re-enable FuseInputReshape_BatchMatMulWithFlattenedRhsDims,"Re-enable FuseInputReshape_BatchMatMulWithFlattenedRhsDims

Add a constraint to MoveBinaryOpBeforeReshape to avoid fusing reshape values have multiple users.
",copybara-service[bot],2024-11-11 04:42:08+00:00,['vamsimanchala'],2024-11-12 23:43:11+00:00,2024-11-12 23:43:10+00:00,https://github.com/tensorflow/tensorflow/pull/79775,[],[],
2648021738,pull_request,closed,,Replace LiteRtResult with new litert::Expected inspired from std::expected,"Replace LiteRtResult with new litert::Expected inspired from std::expected
",copybara-service[bot],2024-11-11 03:31:51+00:00,['LukeBoyer'],2024-11-11 22:06:48+00:00,2024-11-11 22:06:47+00:00,https://github.com/tensorflow/tensorflow/pull/79774,[],[],
2647481622,pull_request,open,,Fix propagation of kConditional in dataflow analysis,"Fix propagation of kConditional in dataflow analysis
",copybara-service[bot],2024-11-10 17:56:34+00:00,[],2024-11-10 17:56:34+00:00,,https://github.com/tensorflow/tensorflow/pull/79772,[],[],
2646995404,pull_request,closed,,Fix sign comparison compile error,"Fix sign comparison compile error
",copybara-service[bot],2024-11-10 08:35:34+00:00,[],2024-11-11 08:36:50+00:00,2024-11-11 08:36:48+00:00,https://github.com/tensorflow/tensorflow/pull/79771,[],[],
2646888552,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-10 06:35:25+00:00,[],2024-11-16 06:34:37+00:00,,https://github.com/tensorflow/tensorflow/pull/79770,[],[],
2646888312,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-10 06:34:41+00:00,[],2024-11-10 06:34:41+00:00,,https://github.com/tensorflow/tensorflow/pull/79769,[],[],
2646886349,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-10 06:28:09+00:00,[],2024-11-10 06:28:09+00:00,,https://github.com/tensorflow/tensorflow/pull/79768,[],[],
2646884585,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-10 06:22:15+00:00,[],2024-11-10 06:22:15+00:00,,https://github.com/tensorflow/tensorflow/pull/79767,[],[],
2646884402,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-10 06:21:35+00:00,[],2024-11-10 06:21:35+00:00,,https://github.com/tensorflow/tensorflow/pull/79766,[],[],
2646788966,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-10 04:01:53+00:00,[],2024-11-10 04:01:53+00:00,,https://github.com/tensorflow/tensorflow/pull/79765,[],[],
2646787678,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-10 03:58:47+00:00,[],2024-11-10 03:58:47+00:00,,https://github.com/tensorflow/tensorflow/pull/79764,[],[],
2646669092,pull_request,closed,,Update comments for ProfileInfo fingerprint.,"Update comments for ProfileInfo fingerprint.
",copybara-service[bot],2024-11-09 23:40:21+00:00,[],2024-11-12 15:33:26+00:00,2024-11-12 15:33:19+00:00,https://github.com/tensorflow/tensorflow/pull/79763,[],[],
2646640944,pull_request,closed,,misc cleanup,"misc cleanup

* Replace bespoke bytes span wrapper in compiler plugin with BufferRef.
* Put type alias for InlinedVector in new header litert_detail
* Use InlinedVector for ""dimensions"" in model cc api, and where applicable in compiler_plugin
* Move AssertGet to litert_detail, rename AssertOk
",copybara-service[bot],2024-11-09 23:15:10+00:00,['LukeBoyer'],2024-11-11 17:14:50+00:00,2024-11-11 17:14:49+00:00,https://github.com/tensorflow/tensorflow/pull/79762,[],[],
2646639338,pull_request,open,,"StridedSlices where the begin is all zeros, end is the length of the dim, and stride is all 1s are identities. Rewire the input to be used instead.","StridedSlices where the begin is all zeros, end is the length of the dim, and stride is all 1s are identities. Rewire the input to be used instead.
",copybara-service[bot],2024-11-09 23:08:56+00:00,[],2024-11-10 00:39:56+00:00,,https://github.com/tensorflow/tensorflow/pull/79761,[],[],
2646624951,pull_request,closed,,[XLA] Add tests for depthwise convolutions with batch and outer dimensions.,"[XLA] Add tests for depthwise convolutions with batch and outer dimensions.
",copybara-service[bot],2024-11-09 22:44:27+00:00,['majnemer'],2024-11-11 19:18:37+00:00,2024-11-11 19:18:36+00:00,https://github.com/tensorflow/tensorflow/pull/79760,[],[],
2646529915,pull_request,closed,,Update broken link for create the TFLite op hyperlink in convert_mode…,"Hi, Team

I found a broken documentation link for create the TFLite op hyperlink in the following paragraph: **""Solution: The error occurs as your model has TF ops that don't have a corresponding TFLite implementation. You can resolve this by [using the TF op in the TFLite model](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/guide/ops_select.md) (recommended). If you want to generate a model with TFLite ops only, you can either add a request for the missing TFLite op in [Github issue #21526](https://github.com/tensorflow/tensorflow/issues/21526) (leave a comment if your request hasn’t already been mentioned) or [create the TFLite op](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/guide/ops_custom.md#create_and_register_the_operator) yourself.""** so I have updated this to a functional link. Please review and merge this change as appropriate.

Thank you for your consideration.",gaikwadrahul8,2024-11-09 20:41:49+00:00,['gbaned'],2024-11-10 17:09:55+00:00,2024-11-10 17:09:54+00:00,https://github.com/tensorflow/tensorflow/pull/79759,"[('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2646496113,pull_request,closed,,Update broken link for TensorFlow Lite Task Library hyperlink in metadata.md,"Hi, Team

I found a broken documentation link for **TensorFlow Lite Task Library** hyperlink in the following sentence : **""Note: to create metadata for the popular ML tasks supported in [TensorFlow Lite Task Library](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/inference_with_metadata/task_library/overview), use the high-level API in the [TensorFlow Lite Metadata Writer Library](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models/convert/metadata_writer_tutorial.ipynb).""** I have updated this to a functional link. Please review and merge this change as appropriate.

Thank you for your consideration.",gaikwadrahul8,2024-11-09 20:16:43+00:00,['gbaned'],2024-11-10 16:56:39+00:00,2024-11-10 16:56:39+00:00,https://github.com/tensorflow/tensorflow/pull/79758,"[('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2645969521,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 11:44:31+00:00,[],2024-11-09 11:44:31+00:00,,https://github.com/tensorflow/tensorflow/pull/79755,[],[],
2645960654,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 11:28:08+00:00,[],2024-11-09 11:28:08+00:00,,https://github.com/tensorflow/tensorflow/pull/79754,[],[],
2645957860,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 11:24:20+00:00,[],2024-11-09 11:24:20+00:00,,https://github.com/tensorflow/tensorflow/pull/79753,[],[],
2645957108,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 11:23:56+00:00,[],2024-11-09 11:23:56+00:00,,https://github.com/tensorflow/tensorflow/pull/79752,[],[],
2645927128,pull_request,open,,The change has been integrated from upstream.,"The change has been integrated from upstream.

Reverts b249572edaca3f0a7620c0009d09ee29e0cd8aab
",copybara-service[bot],2024-11-09 10:53:34+00:00,['belitskiy'],2024-11-10 00:36:27+00:00,,https://github.com/tensorflow/tensorflow/pull/79751,[],[],
2645887759,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 10:11:51+00:00,[],2024-11-09 10:11:51+00:00,,https://github.com/tensorflow/tensorflow/pull/79749,[],[],
2645872627,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 09:44:45+00:00,[],2024-11-09 09:44:45+00:00,,https://github.com/tensorflow/tensorflow/pull/79748,[],[],
2645830760,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:55:14+00:00,[],2024-11-09 08:55:14+00:00,,https://github.com/tensorflow/tensorflow/pull/79747,[],[],
2645818799,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:43:04+00:00,[],2024-11-09 08:43:04+00:00,,https://github.com/tensorflow/tensorflow/pull/79746,[],[],
2645818038,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:41:43+00:00,[],2024-11-09 08:41:43+00:00,,https://github.com/tensorflow/tensorflow/pull/79745,[],[],
2645809766,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:36:06+00:00,[],2024-11-09 08:36:06+00:00,,https://github.com/tensorflow/tensorflow/pull/79744,[],[],
2645794567,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:30:58+00:00,[],2024-11-09 08:30:58+00:00,,https://github.com/tensorflow/tensorflow/pull/79743,[],[],
2645794193,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:30:00+00:00,[],2024-11-09 08:30:00+00:00,,https://github.com/tensorflow/tensorflow/pull/79742,[],[],
2645793097,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:26:42+00:00,[],2024-11-09 08:26:42+00:00,,https://github.com/tensorflow/tensorflow/pull/79741,[],[],
2645792615,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:25:11+00:00,[],2024-11-09 08:25:11+00:00,,https://github.com/tensorflow/tensorflow/pull/79740,[],[],
2645791965,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:23:12+00:00,[],2024-11-09 08:23:12+00:00,,https://github.com/tensorflow/tensorflow/pull/79739,[],[],
2645791541,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:22:45+00:00,[],2024-11-09 08:22:45+00:00,,https://github.com/tensorflow/tensorflow/pull/79738,[],[],
2645789673,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:17:43+00:00,[],2024-11-09 08:17:43+00:00,,https://github.com/tensorflow/tensorflow/pull/79737,[],[],
2645783901,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 08:03:27+00:00,[],2024-11-09 08:03:27+00:00,,https://github.com/tensorflow/tensorflow/pull/79735,[],[],
2645777917,pull_request,closed,,Add const to GetCollectiveOpGroupMode parameter,"Add const to GetCollectiveOpGroupMode parameter
",copybara-service[bot],2024-11-09 07:53:06+00:00,[],2024-11-11 21:39:29+00:00,2024-11-11 21:39:28+00:00,https://github.com/tensorflow/tensorflow/pull/79734,[],[],
2645769469,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 07:40:00+00:00,[],2024-11-09 07:40:00+00:00,,https://github.com/tensorflow/tensorflow/pull/79733,[],[],
2645737255,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 07:15:47+00:00,[],2024-11-09 07:15:47+00:00,,https://github.com/tensorflow/tensorflow/pull/79732,[],[],
2645732134,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 07:01:27+00:00,[],2024-11-09 07:01:27+00:00,,https://github.com/tensorflow/tensorflow/pull/79731,[],[],
2645720323,pull_request,closed,,[XLA:FUSION] consider control operands when attempting to find a cycle in,"[XLA:FUSION] consider control operands when attempting to find a cycle in
producer consumer multi-output fusion.

Reverts changelist 693121662
",copybara-service[bot],2024-11-09 06:46:32+00:00,['blakehechtman'],2024-11-12 18:47:35+00:00,2024-11-12 18:47:34+00:00,https://github.com/tensorflow/tensorflow/pull/79730,[],[],
2645687996,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 06:16:36+00:00,[],2024-11-09 06:16:36+00:00,,https://github.com/tensorflow/tensorflow/pull/79729,[],[],
2645673756,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 05:47:40+00:00,[],2024-11-09 05:47:40+00:00,,https://github.com/tensorflow/tensorflow/pull/79728,[],[],
2645672470,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 05:46:04+00:00,[],2024-11-09 05:46:04+00:00,,https://github.com/tensorflow/tensorflow/pull/79727,[],[],
2645626166,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:47:29+00:00,[],2024-11-09 04:47:29+00:00,,https://github.com/tensorflow/tensorflow/pull/79726,[],[],
2645626051,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:47:14+00:00,[],2024-11-09 04:47:14+00:00,,https://github.com/tensorflow/tensorflow/pull/79725,[],[],
2645622411,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:43:38+00:00,[],2024-11-09 04:43:38+00:00,,https://github.com/tensorflow/tensorflow/pull/79724,[],[],
2645621768,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:41:55+00:00,[],2024-11-09 04:41:55+00:00,,https://github.com/tensorflow/tensorflow/pull/79723,[],[],
2645621639,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:41:34+00:00,[],2024-11-09 04:41:34+00:00,,https://github.com/tensorflow/tensorflow/pull/79722,[],[],
2645619021,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:39:03+00:00,[],2024-11-09 04:39:03+00:00,,https://github.com/tensorflow/tensorflow/pull/79721,[],[],
2645610419,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:36:42+00:00,[],2024-11-09 04:36:42+00:00,,https://github.com/tensorflow/tensorflow/pull/79720,[],[],
2645604550,pull_request,closed,,Integrate LLVM at llvm/llvm-project@a749c98b49dc,"Integrate LLVM at llvm/llvm-project@a749c98b49dc

Updates LLVM usage to match
[a749c98b49dc](https://github.com/llvm/llvm-project/commit/a749c98b49dc)
",copybara-service[bot],2024-11-09 04:35:47+00:00,[],2024-11-09 17:31:48+00:00,2024-11-09 17:31:47+00:00,https://github.com/tensorflow/tensorflow/pull/79719,[],[],
2645598675,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:34:22+00:00,[],2024-11-09 04:34:22+00:00,,https://github.com/tensorflow/tensorflow/pull/79718,[],[],
2645597816,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:32:13+00:00,[],2024-11-09 04:32:13+00:00,,https://github.com/tensorflow/tensorflow/pull/79717,[],[],
2645597615,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-09 04:31:36+00:00,[],2024-11-09 04:31:36+00:00,,https://github.com/tensorflow/tensorflow/pull/79716,[],[],
2645580334,pull_request,closed,,fixing the issue-79689,"verting an array of floats to int8 using Numpy does a normal conversion, whereas the tf.cast conversion automatically truncates it to 127 for overflow values, which is what triggers the problem
https://colab.research.google.com/drive/1M0EcrsktHufkVZQomN8Z9eHZ20I35nCl?usp=sharing#scrollTo=wxlPB6R40Wtk",Iceyshell,2024-11-09 03:54:03+00:00,['gbaned'],2024-11-09 13:41:36+00:00,2024-11-09 13:41:34+00:00,https://github.com/tensorflow/tensorflow/pull/79715,"[('size:XS', 'CL Change Size: Extra Small'), ('invalid', 'Hacktoberfest spam PR')]",[],
2645492432,pull_request,closed,,Add documentation for RNN with extension types,Added a file to demonstrate how to make keras.layers.RNN create a model that supports extension types,Iceyshell,2024-11-09 02:19:44+00:00,['gbaned'],2024-11-09 13:41:37+00:00,2024-11-09 13:41:37+00:00,https://github.com/tensorflow/tensorflow/pull/79714,"[('size:M', 'CL Change Size: Medium'), ('invalid', 'Hacktoberfest spam PR')]","[{'comment_id': 2465994829, 'issue_id': 2645492432, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79714/checks?check_run_id=32744035799) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 11, 9, 2, 19, 48, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-11-09 02:19:48 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/79714/checks?check_run_id=32744035799) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2645482090,pull_request,closed,,Replace `bool IsSortOperandShardingMovable` with `std::optional<int64_t> GetFirstFreeDimForSortOperand` in hlo_sharding_util such that the propagation and partitioner can share this util function and use the same criterion.,"Replace `bool IsSortOperandShardingMovable` with `std::optional<int64_t> GetFirstFreeDimForSortOperand` in hlo_sharding_util such that the propagation and partitioner can share this util function and use the same criterion.

cl/694685258 enhances the method to handle sort in the partitioner. We apply the same enhancement to the propagation by sharing the util function.
",copybara-service[bot],2024-11-09 02:09:03+00:00,[],2024-11-12 21:29:26+00:00,2024-11-12 21:29:25+00:00,https://github.com/tensorflow/tensorflow/pull/79713,[],[],
2645465335,pull_request,closed,,Make GPU work with copy=True and device_put since same device pinned_host -> pinned_host copy is possible.,"Make GPU work with copy=True and device_put since same device pinned_host -> pinned_host copy is possible.
",copybara-service[bot],2024-11-09 01:46:27+00:00,['yashk2810'],2024-11-09 02:37:58+00:00,2024-11-09 02:37:58+00:00,https://github.com/tensorflow/tensorflow/pull/79712,[],[],
2645428725,pull_request,closed,,PR #19192: Minor documentation fixes,"PR #19192: Minor documentation fixes

Imported from GitHub PR https://github.com/openxla/xla/pull/19192

This PR:
- updates broken links in the README, and overview and contribution-related docs
- removes mention of the mlperf submission from 2020
- re-formats a couple of code cells (more information inline)


Copybara import of the project:

--
3aea33a924289825016ec9d3e807605938cf86d7 by Pavithra Eswaramoorthy <pavithraes@outlook.com>:

Minor docs updates for releavnce and accuracy

Signed-off-by: Pavithra Eswaramoorthy <pavithraes@outlook.com>

Merging this change closes #19192

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19192 from pavithraes:documentation-updates ad0fb424bc467400fd4d49b46108904844068447
",copybara-service[bot],2024-11-09 00:44:03+00:00,[],2024-11-09 01:07:37+00:00,2024-11-09 01:07:36+00:00,https://github.com/tensorflow/tensorflow/pull/79711,[],[],
2645418535,pull_request,closed,,Initalize quantization.type to fix msan error.,"Initalize quantization.type to fix msan error.
",copybara-service[bot],2024-11-09 00:24:41+00:00,['grantjensen'],2024-11-12 23:30:37+00:00,2024-11-12 23:30:36+00:00,https://github.com/tensorflow/tensorflow/pull/79710,[],[],
2645394679,pull_request,open,,[MPMD-GPU] Make Pathways IFRT client get GPU topology as well.,"[MPMD-GPU] Make Pathways IFRT client get GPU topology as well.
",copybara-service[bot],2024-11-08 23:51:17+00:00,['changhuilin'],2024-11-18 19:02:35+00:00,,https://github.com/tensorflow/tensorflow/pull/79708,[],[],
2645393225,pull_request,open,,[MPMD-GPU] Add `is_subslice_topology` to the IFRT Topology.,"[MPMD-GPU] Add `is_subslice_topology` to the IFRT Topology.

This is to make IFRT Topology fields consistent with `PjRtTopologyDescriptionProto` fields.
",copybara-service[bot],2024-11-08 23:49:43+00:00,['changhuilin'],2024-11-18 19:01:30+00:00,,https://github.com/tensorflow/tensorflow/pull/79707,[],[],
2645311452,pull_request,closed,,Integrate LLVM at llvm/llvm-project@51e8f822f391,"Integrate LLVM at llvm/llvm-project@51e8f822f391

Updates LLVM usage to match
[51e8f822f391](https://github.com/llvm/llvm-project/commit/51e8f822f391)
",copybara-service[bot],2024-11-08 22:40:58+00:00,[],2024-11-09 03:04:18+00:00,2024-11-09 03:04:17+00:00,https://github.com/tensorflow/tensorflow/pull/79706,[],[],
2645262177,pull_request,closed,,Add peak memory bw to XPlane to enable Roofline Analysis and Hlo Stats,"Add peak memory bw to XPlane to enable Roofline Analysis and Hlo Stats
",copybara-service[bot],2024-11-08 22:10:40+00:00,['zzzaries'],2024-11-13 03:35:38+00:00,2024-11-13 03:35:37+00:00,https://github.com/tensorflow/tensorflow/pull/79705,[],[],
2645116896,pull_request,open,,- enable long_name population EnterOpMetadata,"- enable long_name population EnterOpMetadata
- avoid repetitively processing EnterOpMetadata by checking category and provenance in op metric
",copybara-service[bot],2024-11-08 20:40:20+00:00,[],2024-11-08 21:30:59+00:00,,https://github.com/tensorflow/tensorflow/pull/79704,[],[],
2644976432,pull_request,closed,,Move CPU Client Options to public API directory,"Move CPU Client Options to public API directory
",copybara-service[bot],2024-11-08 19:29:58+00:00,['changm'],2024-11-11 18:02:57+00:00,2024-11-11 18:02:56+00:00,https://github.com/tensorflow/tensorflow/pull/79703,[],[],
2644934048,pull_request,open,,Move GPU allocator config to public XLA API,"Move GPU allocator config to public XLA API
",copybara-service[bot],2024-11-08 19:17:51+00:00,['changm'],2024-11-08 19:17:52+00:00,,https://github.com/tensorflow/tensorflow/pull/79702,[],[],
2644925990,pull_request,closed,,Add peak in-use memory tracking to MemoryUsageMonitor,"Add peak in-use memory tracking to MemoryUsageMonitor
",copybara-service[bot],2024-11-08 19:12:25+00:00,[],2024-11-09 01:21:44+00:00,2024-11-09 01:21:44+00:00,https://github.com/tensorflow/tensorflow/pull/79701,[],[],
2644904075,pull_request,open,,Integrate LLVM at llvm/llvm-project@e109c4932105,"Integrate LLVM at llvm/llvm-project@e109c4932105

Updates LLVM usage to match
[e109c4932105](https://github.com/llvm/llvm-project/commit/e109c4932105)
",copybara-service[bot],2024-11-08 18:59:03+00:00,[],2024-11-08 22:22:01+00:00,,https://github.com/tensorflow/tensorflow/pull/79700,[],[],
2644872512,pull_request,closed,,Simplify stream_executor BUILD file after recent changes.,"Simplify stream_executor BUILD file after recent changes.
",copybara-service[bot],2024-11-08 18:47:08+00:00,[],2024-11-11 19:07:44+00:00,2024-11-11 19:07:43+00:00,https://github.com/tensorflow/tensorflow/pull/79699,[],[],
2644774195,pull_request,closed,,PR #19195: [nfc] Use flat_hash_map::insert instead of find and assign.,"PR #19195: [nfc] Use flat_hash_map::insert instead of find and assign.

Imported from GitHub PR https://github.com/openxla/xla/pull/19195

Addressing comment added in #18959
Copybara import of the project:

--
f399d89abd2280a2f00615633ef4306f7ffbd530 by Shraiysh Vaishay <svaishay@nvidia.com>:

[nfc] Use flat_hash_map::insert instead of find and assign.

Addressing comment added in #18959

Merging this change closes #19195

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19195 from shraiysh:nfc-p2p-fix f399d89abd2280a2f00615633ef4306f7ffbd530
",copybara-service[bot],2024-11-08 18:02:25+00:00,[],2024-11-08 20:56:53+00:00,2024-11-08 20:56:53+00:00,https://github.com/tensorflow/tensorflow/pull/79698,[],[],
2644685214,pull_request,closed,,"Create subdirectory of XLA docs for PJRT, add C++ API overview docs","Create subdirectory of XLA docs for PJRT, add C++ API overview docs
",copybara-service[bot],2024-11-08 17:30:41+00:00,['GleasonK'],2024-11-12 00:40:32+00:00,2024-11-12 00:40:31+00:00,https://github.com/tensorflow/tensorflow/pull/79697,[],[],
2644311782,pull_request,closed,,Patch out an ambiguous reference to memcpy in LLVM.,"Patch out an ambiguous reference to memcpy in LLVM.

This fixes the Windows presubmit.
",copybara-service[bot],2024-11-08 15:08:27+00:00,['belitskiy'],2024-11-08 16:07:09+00:00,2024-11-08 16:07:09+00:00,https://github.com/tensorflow/tensorflow/pull/79696,[],[],
2644194687,pull_request,closed,,[XLA:GPU] Require packed dot operands to be packed along contracting dimension.,"[XLA:GPU] Require packed dot operands to be packed along contracting dimension.
",copybara-service[bot],2024-11-08 14:26:20+00:00,[],2024-11-29 11:10:07+00:00,2024-11-29 11:10:06+00:00,https://github.com/tensorflow/tensorflow/pull/79694,[],[],
2644035981,pull_request,closed,,Disable a test to work around a numpy bug.,"Disable a test to work around a numpy bug.

See https://github.com/numpy/numpy/issues/27709
",copybara-service[bot],2024-11-08 13:17:09+00:00,[],2024-11-08 14:33:16+00:00,2024-11-08 14:33:14+00:00,https://github.com/tensorflow/tensorflow/pull/79693,[],[],
2644027592,pull_request,open,,No public changes expected: this should be an empty PR.,"No public changes expected: this should be an empty PR.
",copybara-service[bot],2024-11-08 13:13:50+00:00,[],2024-11-13 02:10:17+00:00,,https://github.com/tensorflow/tensorflow/pull/79692,[],[],
2643927235,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 12:35:27+00:00,[],2024-11-08 12:35:27+00:00,,https://github.com/tensorflow/tensorflow/pull/79691,[],[],
2643839429,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 11:54:23+00:00,[],2024-11-08 11:54:23+00:00,,https://github.com/tensorflow/tensorflow/pull/79690,[],[],
2643697570,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 11:07:28+00:00,[],2024-11-08 11:07:28+00:00,,https://github.com/tensorflow/tensorflow/pull/79688,[],[],
2643674632,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:56:41+00:00,[],2024-11-08 10:56:41+00:00,,https://github.com/tensorflow/tensorflow/pull/79687,[],[],
2643672579,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:55:42+00:00,[],2024-11-08 10:55:42+00:00,,https://github.com/tensorflow/tensorflow/pull/79686,[],[],
2643670108,pull_request,closed,,Integrate LLVM at llvm/llvm-project@f548d39c3c75,"Integrate LLVM at llvm/llvm-project@f548d39c3c75

Updates LLVM usage to match
[f548d39c3c75](https://github.com/llvm/llvm-project/commit/f548d39c3c75)
",copybara-service[bot],2024-11-08 10:54:33+00:00,[],2024-11-08 16:19:55+00:00,2024-11-08 16:19:53+00:00,https://github.com/tensorflow/tensorflow/pull/79685,[],[],
2643665604,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:52:40+00:00,[],2024-11-08 10:52:40+00:00,,https://github.com/tensorflow/tensorflow/pull/79684,[],[],
2643665344,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:52:32+00:00,[],2024-11-08 10:52:32+00:00,,https://github.com/tensorflow/tensorflow/pull/79683,[],[],
2643657616,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:49:16+00:00,[],2024-11-08 10:49:16+00:00,,https://github.com/tensorflow/tensorflow/pull/79682,[],[],
2643656411,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:48:44+00:00,[],2024-11-08 10:48:44+00:00,,https://github.com/tensorflow/tensorflow/pull/79681,[],[],
2643654902,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:48:05+00:00,[],2024-11-08 10:48:05+00:00,,https://github.com/tensorflow/tensorflow/pull/79680,[],[],
2643609859,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:36:44+00:00,[],2024-11-08 10:36:44+00:00,,https://github.com/tensorflow/tensorflow/pull/79679,[],[],
2643580551,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:24:35+00:00,[],2024-11-08 10:24:35+00:00,,https://github.com/tensorflow/tensorflow/pull/79678,[],[],
2643559515,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:14:41+00:00,[],2024-11-08 10:14:41+00:00,,https://github.com/tensorflow/tensorflow/pull/79677,[],[],
2643558644,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:14:13+00:00,[],2024-11-08 10:14:13+00:00,,https://github.com/tensorflow/tensorflow/pull/79676,[],[],
2643556643,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:13:20+00:00,[],2024-11-08 10:13:20+00:00,,https://github.com/tensorflow/tensorflow/pull/79675,[],[],
2643549405,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:10:21+00:00,[],2024-11-08 10:10:21+00:00,,https://github.com/tensorflow/tensorflow/pull/79674,[],[],
2643548960,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:10:08+00:00,[],2024-11-08 10:10:08+00:00,,https://github.com/tensorflow/tensorflow/pull/79673,[],[],
2643547513,pull_request,closed,,_delete graph_tools_,"_delete graph_tools_

Move the ""matchers"" from graph_tools to cc_api under ""litert_model_predicates"", delete the rest of graph_tools. Reimplement the functions to use absl instead of llvm.

_add element_type helpers to cc api_

Add utils for getting byte width and mapping cc native types to lrt types that are constexpr friendly. Add the ability to retrieved integral typed buffers from cc tensor wrappers.
",copybara-service[bot],2024-11-08 10:09:33+00:00,['LukeBoyer'],2024-11-09 02:01:17+00:00,2024-11-09 02:01:16+00:00,https://github.com/tensorflow/tensorflow/pull/79672,[],[],
2643544102,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:07:48+00:00,[],2024-11-08 10:07:48+00:00,,https://github.com/tensorflow/tensorflow/pull/79671,[],[],
2643543157,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:07:21+00:00,[],2024-11-08 10:07:21+00:00,,https://github.com/tensorflow/tensorflow/pull/79670,[],[],
2643542279,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:06:54+00:00,[],2024-11-08 10:06:54+00:00,,https://github.com/tensorflow/tensorflow/pull/79669,[],[],
2643542007,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:06:46+00:00,[],2024-11-08 10:06:46+00:00,,https://github.com/tensorflow/tensorflow/pull/79668,[],[],
2643531139,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 10:01:20+00:00,[],2024-11-08 10:01:20+00:00,,https://github.com/tensorflow/tensorflow/pull/79667,[],[],
2643525606,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 09:59:11+00:00,[],2024-11-08 09:59:11+00:00,,https://github.com/tensorflow/tensorflow/pull/79666,[],[],
2643524221,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 09:58:31+00:00,[],2024-11-08 09:58:31+00:00,,https://github.com/tensorflow/tensorflow/pull/79665,[],[],
2643518366,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 09:56:38+00:00,[],2024-11-08 09:56:38+00:00,,https://github.com/tensorflow/tensorflow/pull/79664,[],[],
2643510991,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 09:53:53+00:00,[],2024-11-08 09:53:53+00:00,,https://github.com/tensorflow/tensorflow/pull/79663,[],[],
2643508218,pull_request,open,,Added suppressions for pytype --none-is-not-bool.,"Added suppressions for pytype --none-is-not-bool.
",copybara-service[bot],2024-11-08 09:52:45+00:00,[],2024-11-08 09:52:45+00:00,,https://github.com/tensorflow/tensorflow/pull/79662,[],[],
2643336903,pull_request,open,,Integrate LLVM at llvm/llvm-project@e109c4932105,"Integrate LLVM at llvm/llvm-project@e109c4932105

Updates LLVM usage to match
[e109c4932105](https://github.com/llvm/llvm-project/commit/e109c4932105)
",copybara-service[bot],2024-11-08 08:47:32+00:00,[],2024-11-08 08:47:32+00:00,,https://github.com/tensorflow/tensorflow/pull/79660,[],[],
2643335748,pull_request,closed,,[XLA:MSA] Add dynamic-slice to async conversion in msa,"[XLA:MSA] Add dynamic-slice to async conversion in msa
",copybara-service[bot],2024-11-08 08:46:57+00:00,[],2025-01-18 01:45:07+00:00,2025-01-18 01:45:06+00:00,https://github.com/tensorflow/tensorflow/pull/79659,[],[],
2643257672,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 08:18:11+00:00,[],2024-11-08 08:18:11+00:00,,https://github.com/tensorflow/tensorflow/pull/79658,[],[],
2643165731,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 07:43:26+00:00,[],2024-11-08 07:43:26+00:00,,https://github.com/tensorflow/tensorflow/pull/79656,[],[],
2643155860,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-11-08 07:38:26+00:00,[],2024-11-08 07:38:26+00:00,,https://github.com/tensorflow/tensorflow/pull/79655,[],[],
