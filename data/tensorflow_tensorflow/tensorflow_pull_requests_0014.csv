id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2728176962,pull_request,closed,,Add StepEvents required for Inference Profiles on GPU.,"Add StepEvents required for Inference Profiles on GPU.
",copybara-service[bot],2024-12-09 20:19:27+00:00,['cliveverghese'],2024-12-09 23:23:41+00:00,2024-12-09 23:23:40+00:00,https://github.com/tensorflow/tensorflow/pull/82552,[],[],
2728167578,pull_request,closed,,"Stop using DISABLED_ON_GPU_ROCM for GPU tests, and instead just use GTEST_SKIP with a runtime check for ROCm.","Stop using DISABLED_ON_GPU_ROCM for GPU tests, and instead just use GTEST_SKIP with a runtime check for ROCm.
",copybara-service[bot],2024-12-09 20:14:29+00:00,[],2024-12-09 21:26:15+00:00,2024-12-09 21:26:15+00:00,https://github.com/tensorflow/tensorflow/pull/82551,[],[],
2728146476,pull_request,closed,,Add a new test base class for a default PjRt test runner w/ SE interpreter.,"Add a new test base class for a default PjRt test runner w/ SE interpreter.
",copybara-service[bot],2024-12-09 20:03:11+00:00,[],2024-12-10 02:34:44+00:00,2024-12-10 02:34:44+00:00,https://github.com/tensorflow/tensorflow/pull/82550,[],[],
2728139351,pull_request,closed,,Replace std::string_view with absl::string_view,"Replace std::string_view with absl::string_view
",copybara-service[bot],2024-12-09 19:59:48+00:00,[],2024-12-10 18:26:05+00:00,2024-12-10 18:26:04+00:00,https://github.com/tensorflow/tensorflow/pull/82549,[],[],
2728116071,pull_request,closed,,[StableHLO] Add shape refinement callback to specify additional patterns.,"[StableHLO] Add shape refinement callback to specify additional patterns.
",copybara-service[bot],2024-12-09 19:51:04+00:00,['GleasonK'],2024-12-13 20:38:42+00:00,2024-12-13 20:38:42+00:00,https://github.com/tensorflow/tensorflow/pull/82548,[],[],
2728113537,pull_request,closed,,Use compute_capability instead of DISABLED_ON_GPU_ROCM to determine whether or not to execute a CUDA-only test.,"Use compute_capability instead of DISABLED_ON_GPU_ROCM to determine whether or not to execute a CUDA-only test.
",copybara-service[bot],2024-12-09 19:49:58+00:00,[],2024-12-10 17:30:12+00:00,2024-12-10 17:30:12+00:00,https://github.com/tensorflow/tensorflow/pull/82547,[],[],
2728039332,pull_request,closed,,Add some comments for copy insertion.,"Add some comments for copy insertion.
",copybara-service[bot],2024-12-09 19:24:41+00:00,[],2024-12-09 20:07:06+00:00,2024-12-09 20:07:06+00:00,https://github.com/tensorflow/tensorflow/pull/82546,[],[],
2728023954,pull_request,closed,,Add RegisterMlirToHloDependentDialects to register required dependent dialects,"Add RegisterMlirToHloDependentDialects to register required dependent dialects
",copybara-service[bot],2024-12-09 19:19:53+00:00,[],2024-12-10 02:18:51+00:00,2024-12-10 02:18:50+00:00,https://github.com/tensorflow/tensorflow/pull/82545,[],[],
2727946422,pull_request,closed,,Disable node fusion when `experimental_preserve_all_tensors` option is enabled.,"Disable node fusion when `experimental_preserve_all_tensors` option is enabled.
",copybara-service[bot],2024-12-09 18:40:40+00:00,[],2024-12-11 02:06:59+00:00,2024-12-11 02:06:58+00:00,https://github.com/tensorflow/tensorflow/pull/82544,[],[],
2727927911,pull_request,closed,,Move legacyfedinput code out of import_model.,"Move legacyfedinput code out of import_model.
",copybara-service[bot],2024-12-09 18:30:21+00:00,['rocketas'],2024-12-09 19:25:50+00:00,2024-12-09 19:25:49+00:00,https://github.com/tensorflow/tensorflow/pull/82543,[],[],
2727926035,pull_request,closed,,[XLA:MSA] Allow cross-program prefetch for buffers that are already pinned to alternate memory.,"[XLA:MSA] Allow cross-program prefetch for buffers that are already pinned to alternate memory.
- Add default memory to memory space assignment options.
- Update tests to check pinned buffers are being cross-program prefetched.
",copybara-service[bot],2024-12-09 18:29:16+00:00,['subhankarshah'],2024-12-13 21:36:05+00:00,2024-12-13 21:36:04+00:00,https://github.com/tensorflow/tensorflow/pull/82542,[],[],
2727917512,pull_request,closed,,Added thread annotations to variable that claimed to not need them.,"Added thread annotations to variable that claimed to not need them.

The `cilent_polling_for_error_` variable previously claimed the following:

> Once set to true, the value will never change back to false, so no mutex is
> needed.

This is not true. Concurrent access to the boolean is a data race and must be
avoided with a mutex. Thankfully, the code was already protecting access to the
variable with a mutex. This CL adds some thread annotations to double check
this.
",copybara-service[bot],2024-12-09 18:24:52+00:00,[],2025-01-21 17:53:52+00:00,2025-01-21 17:53:52+00:00,https://github.com/tensorflow/tensorflow/pull/82541,[],[],
2727917359,pull_request,closed,,Removed unused `GetCoordinationServiceInstance` code.,"Removed unused `GetCoordinationServiceInstance` code.
",copybara-service[bot],2024-12-09 18:24:48+00:00,[],2025-01-21 21:14:40+00:00,2025-01-21 21:14:38+00:00,https://github.com/tensorflow/tensorflow/pull/82540,[],[],
2727825704,pull_request,closed,,[XLA] Add some traceme annotations around XLA:CPU compilation and CPU compiler stack trace logging.,"[XLA] Add some traceme annotations around XLA:CPU compilation and CPU compiler stack trace logging.
",copybara-service[bot],2024-12-09 17:44:07+00:00,[],2024-12-13 21:47:45+00:00,2024-12-13 21:47:44+00:00,https://github.com/tensorflow/tensorflow/pull/82539,[],[],
2727763928,pull_request,closed,,[XLA:GPU] Use absl instead of tensorflow functions/types.,"[XLA:GPU] Use absl instead of tensorflow functions/types.
",copybara-service[bot],2024-12-09 17:22:29+00:00,[],2024-12-10 10:55:50+00:00,2024-12-10 10:55:48+00:00,https://github.com/tensorflow/tensorflow/pull/82538,[],[],
2727735209,pull_request,closed,,Add support for CUDA 12.6.3 and CUDNN 9.5.1/9.6.0.,"Add support for CUDA 12.6.3 and CUDNN 9.5.1/9.6.0.
",copybara-service[bot],2024-12-09 17:08:34+00:00,[],2024-12-09 17:49:39+00:00,2024-12-09 17:49:38+00:00,https://github.com/tensorflow/tensorflow/pull/82537,[],[],
2727660761,pull_request,closed,,[HLO->MHLO] Consolidate non-pipelined async ops into MHLO ops.,"[HLO->MHLO] Consolidate non-pipelined async ops into MHLO ops.
",copybara-service[bot],2024-12-09 16:39:21+00:00,[],2024-12-10 21:57:56+00:00,2024-12-10 21:57:55+00:00,https://github.com/tensorflow/tensorflow/pull/82536,[],[],
2727629898,pull_request,closed,,[XLA:GPU] Simplify `AllocatorRetry::AllocateRaw` control flow.,"[XLA:GPU] Simplify `AllocatorRetry::AllocateRaw` control flow.
",copybara-service[bot],2024-12-09 16:27:15+00:00,[],2025-02-06 10:13:35+00:00,2025-02-06 10:13:35+00:00,https://github.com/tensorflow/tensorflow/pull/82535,[],[],
2727573313,pull_request,closed,,"Clarify deletion timeline of tf.lite.Interpreter in TF 2.19.0 release notes to be TF 2.20, and deprecation notice","Clarify deletion timeline of tf.lite.Interpreter in TF 2.19.0 release notes to be TF 2.20, and deprecation notice
",copybara-service[bot],2024-12-09 16:09:37+00:00,['pak-laura'],2024-12-09 19:03:03+00:00,2024-12-09 19:03:03+00:00,https://github.com/tensorflow/tensorflow/pull/82534,[],[],
2727477664,pull_request,closed,,[numpy] Fix test failures under NumPy 2.2.,"[numpy] Fix test failures under NumPy 2.2.
",copybara-service[bot],2024-12-09 15:39:45+00:00,[],2024-12-09 19:16:15+00:00,2024-12-09 19:16:15+00:00,https://github.com/tensorflow/tensorflow/pull/82533,[],[],
2727465598,pull_request,closed,,[xla:cpu] Add an object pool for efficient xnnpack object pooling,"[xla:cpu] Add an object pool for efficient xnnpack object pooling

Some of the XNNPACK objects are not thread safe (i.e. xnn_runtime) and we need a way to efficiently have a pool of them at run time.

ObjectPool is optimized for fast access on a hot path without any heap allocations (once in steady state with enough objects in the pool).

---------------------------------------------------------
Benchmark               Time             CPU   Iterations
---------------------------------------------------------
BM_GetOrCreate       7.71 ns         7.70 ns     90233273
",copybara-service[bot],2024-12-09 15:36:00+00:00,['ezhulenev'],2024-12-10 17:12:00+00:00,2024-12-10 17:12:00+00:00,https://github.com/tensorflow/tensorflow/pull/82532,[],[],
2727081753,pull_request,closed,,Support dumping unoptimised hlo snapshots with argumnets in pjrt.,"Support dumping unoptimised hlo snapshots with argumnets in pjrt.
",copybara-service[bot],2024-12-09 13:38:13+00:00,[],2024-12-20 12:26:45+00:00,2024-12-20 12:26:44+00:00,https://github.com/tensorflow/tensorflow/pull/82530,[],[],
2727004477,pull_request,closed,,[XLA:GPU] Use `absl::Microseconds` instead of doing duration arithmetic.,"[XLA:GPU] Use `absl::Microseconds` instead of doing duration arithmetic.
",copybara-service[bot],2024-12-09 13:06:53+00:00,[],2024-12-09 14:16:27+00:00,2024-12-09 14:16:26+00:00,https://github.com/tensorflow/tensorflow/pull/82528,[],[],
2726845808,pull_request,closed,,[XLA:CPU] Fix crash due to OOM in XLA's custom convolution algorithm.,"[XLA:CPU] Fix crash due to OOM in XLA's custom convolution algorithm.

Add a threshold for convolution matrix size, if the convolution matrix would exceed the limit, we fallback to generic algorithm instead.
",copybara-service[bot],2024-12-09 12:03:15+00:00,[],2024-12-23 19:09:10+00:00,2024-12-23 19:09:10+00:00,https://github.com/tensorflow/tensorflow/pull/82527,[],"[{'comment_id': 2527730833, 'issue_id': 2726845808, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82527/checks?check_run_id=34126053397) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 9, 12, 3, 22, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-09 12:03:22 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82527/checks?check_run_id=34126053397) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2726791845,pull_request,closed,,"PR #20214: Evaluate simple offset values, if possible","PR #20214: Evaluate simple offset values, if possible

Imported from GitHub PR https://github.com/openxla/xla/pull/20214

With while loop double buffering, a simple add operation gets added to the entry computation. If a dynamic slice fusion operation exists in this case, then we should be able to evaluate this. If the value is a constant, then no extra cost is incurred because of this change.

Also, fixed the type of Offset in DynamicSliceThunk from uint64_t to int64_t. During execution we deal with int64_t, and so, it only makes sense to store it in int64_t too.
Copybara import of the project:

--
58f08a4fe97bad949edb783b79f2a7f1b9657478 by Shraiysh Vaishay <svaishay@nvidia.com>:

Evaluate simple offset values, if possible

With while loop double buffering, a simple add operation gets added to the entry computation. If a dynamic slice fusion operation exists in this case, then we should be able to evaluate this. If the value is a constant, then no extra cost is incurred because of this change.

Also, fixed the type of Offset in DynamicSliceThunk from uint64_t to int64_t. During execution we deal with int64_t, and so, it only makes sense to store it in int64_t too.

--
92e120354e04c8b754b5853c79662b96342b44f1 by Shraiysh Vaishay <svaishay@nvidia.com>:

Fixed build failure

Merging this change closes #20214

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20214 from shraiysh:ds_fusion 92e120354e04c8b754b5853c79662b96342b44f1
",copybara-service[bot],2024-12-09 11:39:01+00:00,[],2024-12-11 13:20:51+00:00,2024-12-11 13:20:50+00:00,https://github.com/tensorflow/tensorflow/pull/82525,[],[],
2726763297,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 11:26:47+00:00,[],2024-12-10 06:19:42+00:00,2024-12-10 06:19:41+00:00,https://github.com/tensorflow/tensorflow/pull/82524,[],[],
2726753887,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 11:22:27+00:00,[],2024-12-09 11:22:27+00:00,,https://github.com/tensorflow/tensorflow/pull/82523,[],[],
2726739183,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 11:15:57+00:00,[],2024-12-09 13:58:20+00:00,2024-12-09 13:58:19+00:00,https://github.com/tensorflow/tensorflow/pull/82522,[],[],
2726737331,pull_request,closed,,Remove extra settings for handling flatbuffer verification on Windows as the crash on Windows is fixed.,"Remove extra settings for handling flatbuffer verification on Windows as the crash on Windows is fixed.
",copybara-service[bot],2024-12-09 11:15:05+00:00,[],2024-12-13 18:21:33+00:00,2024-12-13 18:21:32+00:00,https://github.com/tensorflow/tensorflow/pull/82521,[],[],
2726708686,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 11:03:03+00:00,[],2024-12-09 11:03:03+00:00,,https://github.com/tensorflow/tensorflow/pull/82520,[],[],
2726703245,pull_request,closed,,PR #18989: [AllGatherCSE] Add a pass that CSEs all-gathers on parameters.,"PR #18989: [AllGatherCSE] Add a pass that CSEs all-gathers on parameters.

Imported from GitHub PR https://github.com/openxla/xla/pull/18989

This PR adds a pass that performs common subexpression elimination on all-gathers of parameters. This is especially useful in strategies where you do not want to run all-gathers in the backward pass. 

```
    Before the pass:
    while_loop {
        all-gather.1 = all-gather(param_0)
        some_computation.1 = compute(all-gather.1)
        all-gather.2 = all-gather(param_0)
        some_computation.2 = compute(all-gather.2)
    }

    After the pass:
    while_loop {
        all-gather.0 = all-gather(param_0)
        some_computation.1 = compute(all-gather.0)
        some_computation.2 = compute(all-gather.0)
    }
    ```
Copybara import of the project:

--
c695ce8312d5f0b55b69e8b65df2e4fbd56fc1db by ptoulme-aws <ptoulme@amazon.com>:

[AllGatherCSE] Add a pass that CSEs all-gathers on parameters.

Merging this change closes #18989

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18989 from ptoulme-aws:all_gather_cse c695ce8312d5f0b55b69e8b65df2e4fbd56fc1db
",copybara-service[bot],2024-12-09 11:00:45+00:00,[],2024-12-09 11:34:15+00:00,2024-12-09 11:34:14+00:00,https://github.com/tensorflow/tensorflow/pull/82519,[],[],
2726692130,pull_request,closed,,[xla:gpu] Removed redundant parameter from `CompileTritonToLLVM`,"[xla:gpu] Removed redundant parameter from `CompileTritonToLLVM`
",copybara-service[bot],2024-12-09 10:56:13+00:00,['superbobry'],2024-12-09 17:38:42+00:00,2024-12-09 17:38:40+00:00,https://github.com/tensorflow/tensorflow/pull/82518,[],[],
2726690438,pull_request,open,,PR #18838: [NVIDIA GPU] Support multi-operand collective-permute,"PR #18838: [NVIDIA GPU] Support multi-operand collective-permute

Imported from GitHub PR https://github.com/openxla/xla/pull/18838

For collective-permutes with small message sizes, it is beneficial to combine them into a single collective because
1. it gets rid of some kernel launch overhead, and allows NCCL to do some message fusion;
2. fewer collectives make it easier for LHS to make better decision.

In order to support combining collective-permutes, we need to support multi-operand collective-permute first, a.k.a. the combined collective-permute. This PR extends the existing CP interface by overloading it, so that a CP can have multiple operands.
Copybara import of the project:

--
5e10aba5b8f6ae66d1071a1894a87987b6a5bceb by Terry Sun <tesun@nvidia.com>:

support multi-operand cp

--
170fead3de942f5e14f4936df1d76bf7e5e319d4 by Terry Sun <tesun@nvidia.com>:

minor refactoring

--
0d85070baee3f26075f0b3660c4674d7b414c861 by Terry Sun <tesun@nvidia.com>:

update python interface

--
9812a104822ea479d29fef0531b9e10d5c2a831d by Terry Sun <tesun@nvidia.com>:

polish python interface

--
3a1552cbcd2e26f814373e0e01adbe8eceb3be9f by Terry Sun <tesun@nvidia.com>:

formatting

--
d3657f81ac57dc1de86561b3449d051d178e0f75 by Terry Sun <tesun@nvidia.com>:

formatting

--
9caacb4e84ac3bb580443afc76e048a6e264094a by Terry Sun <tesun@nvidia.com>:

refactor overloading

--
0aff5e0a372af9e4a859b54681acf0501adca096 by Terry Sun <tesun@nvidia.com>:

minor refactor

--
20a0e3d7dd57a7d70cffe20a1b35fb4b4c1e5c8a by Terry Sun <tesun@nvidia.com>:

add parser test

Merging this change closes #18838

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18838 from terryysun:terryysun/grouped_cp a32d5aa1f6d341ba2f18429ec1345757840afda7
",copybara-service[bot],2024-12-09 10:55:27+00:00,[],2024-12-09 13:23:37+00:00,,https://github.com/tensorflow/tensorflow/pull/82517,[],[],
2726650006,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/82466 from tensorflow:LakshmiKalaKadali-patch-7 ac56327b7f0bf95811abe0d4b5aca3ea3a608dc2
",copybara-service[bot],2024-12-09 10:39:09+00:00,[],2024-12-10 07:42:39+00:00,2024-12-10 07:42:38+00:00,https://github.com/tensorflow/tensorflow/pull/82516,[],[],
2726639593,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 10:34:48+00:00,[],2024-12-12 12:26:01+00:00,2024-12-12 12:26:00+00:00,https://github.com/tensorflow/tensorflow/pull/82515,[],[],
2726630221,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 10:30:56+00:00,[],2024-12-09 10:30:56+00:00,,https://github.com/tensorflow/tensorflow/pull/82514,[],[],
2726618435,pull_request,closed,,[xla] Update warnings.bazelrc,"[xla] Update warnings.bazelrc
",copybara-service[bot],2024-12-09 10:26:19+00:00,['penpornk'],2024-12-09 11:09:52+00:00,2024-12-09 11:09:51+00:00,https://github.com/tensorflow/tensorflow/pull/82513,[],[],
2726595425,pull_request,closed,,Internal: add missing dependency on numpy,"Internal: add missing dependency on numpy
",copybara-service[bot],2024-12-09 10:16:21+00:00,[],2024-12-11 12:15:31+00:00,2024-12-11 12:15:30+00:00,https://github.com/tensorflow/tensorflow/pull/82512,[],[],
2726593654,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19099 from Intel-tensorflow:akhil/conv_fusions_3_d 643bf016dbddd644ce71d10efe3c02d212c2888e
",copybara-service[bot],2024-12-09 10:15:41+00:00,[],2024-12-12 13:15:57+00:00,2024-12-12 13:15:55+00:00,https://github.com/tensorflow/tensorflow/pull/82511,[],[],
2726577718,pull_request,closed,,[XLA:GPU] Remove unused `xla_experimental_exec_time_optimization_effort` flag.,"[XLA:GPU] Remove unused `xla_experimental_exec_time_optimization_effort` flag.
",copybara-service[bot],2024-12-09 10:09:11+00:00,[],2024-12-09 18:50:06+00:00,2024-12-09 18:50:04+00:00,https://github.com/tensorflow/tensorflow/pull/82510,[],[],
2726556676,pull_request,closed,,Integrate LLVM at llvm/llvm-project@1d95825d4d16,"Integrate LLVM at llvm/llvm-project@1d95825d4d16

Updates LLVM usage to match
[1d95825d4d16](https://github.com/llvm/llvm-project/commit/1d95825d4d16)
",copybara-service[bot],2024-12-09 10:00:21+00:00,[],2024-12-09 16:16:26+00:00,2024-12-09 16:16:25+00:00,https://github.com/tensorflow/tensorflow/pull/82509,[],[],
2726533791,pull_request,closed,,PR #20294: [cuBLAS] Relax test error margin for int4 dot,"PR #20294: [cuBLAS] Relax test error margin for int4 dot

Imported from GitHub PR https://github.com/openxla/xla/pull/20294

This PR fixes the test failure. Eventually this should be addressed in cuBLAS, as the similar test ""NonstandardLayoutInt4WithManyNonContractingDimsReversedLayout"" passes, so the ""NonstandardLayoutInt4WithManyNonContractingDims"" should pass too.
Copybara import of the project:

--
78b206a2509a1bacd2eef1add02a8f4d90b7701f by Sergey Kozub <skozub@nvidia.com>:

[cuBLAS] Relax test error margin for int4 dot

Merging this change closes #20294

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20294 from openxla:skozub/cublas_int4_test 78b206a2509a1bacd2eef1add02a8f4d90b7701f
",copybara-service[bot],2024-12-09 09:51:21+00:00,[],2024-12-09 10:35:50+00:00,2024-12-09 10:35:50+00:00,https://github.com/tensorflow/tensorflow/pull/82508,[],[],
2726520996,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 09:46:03+00:00,[],2024-12-09 09:46:03+00:00,,https://github.com/tensorflow/tensorflow/pull/82507,[],[],
2726445522,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 09:13:31+00:00,[],2024-12-12 08:52:32+00:00,2024-12-12 08:52:31+00:00,https://github.com/tensorflow/tensorflow/pull/82506,[],[],
2726422071,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20334 from shraiysh:nfc_clang_format_fix 65921cebb91536e319b2e922f7f27d310de8d114
",copybara-service[bot],2024-12-09 09:02:39+00:00,[],2024-12-11 11:51:18+00:00,2024-12-11 11:51:13+00:00,https://github.com/tensorflow/tensorflow/pull/82505,[],[],
2726415591,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 09:00:13+00:00,[],2024-12-10 08:32:11+00:00,2024-12-10 08:32:09+00:00,https://github.com/tensorflow/tensorflow/pull/82504,[],[],
2726402439,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 08:54:28+00:00,[],2024-12-09 09:41:41+00:00,,https://github.com/tensorflow/tensorflow/pull/82503,[],[],
2726366968,pull_request,closed,,Reverts a27025f94345d873bc9e4718b4afc45651ea2db2,"Reverts a27025f94345d873bc9e4718b4afc45651ea2db2
",copybara-service[bot],2024-12-09 08:37:51+00:00,[],2024-12-09 10:44:59+00:00,2024-12-09 10:44:58+00:00,https://github.com/tensorflow/tensorflow/pull/82502,[],[],
2726311444,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 08:11:06+00:00,[],2024-12-10 08:43:16+00:00,2024-12-10 08:43:15+00:00,https://github.com/tensorflow/tensorflow/pull/82501,[],[],
2726302677,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 08:07:09+00:00,[],2024-12-10 06:29:31+00:00,2024-12-10 06:29:30+00:00,https://github.com/tensorflow/tensorflow/pull/82500,[],[],
2726296581,pull_request,open,,"Allow multiple invocations of exchange topologies, as long as the topology is consistent across restarts.","Allow multiple invocations of exchange topologies, as long as the topology is consistent across restarts.
",copybara-service[bot],2024-12-09 08:04:54+00:00,[],2024-12-09 08:21:28+00:00,,https://github.com/tensorflow/tensorflow/pull/82499,[],[],
2726195921,pull_request,closed,,PR #20241: Updated Typo's in multiple documents,"PR #20241: Updated Typo's in multiple documents

Imported from GitHub PR https://github.com/openxla/xla/pull/20241


Copybara import of the project:

--
76475ed985e58991b7490923e508ff3b9f27127d by Kiran Sai Ramineni <106319630+kiransair@users.noreply.github.com>:

Update collective_ops_utils.cc
--
03766ef45aa8653baeaad25f19b1341487ceb5d0 by Kiran Sai Ramineni <106319630+kiransair@users.noreply.github.com>:

Commit

Merging this change closes #20241

Reverts a27025f94345d873bc9e4718b4afc45651ea2db2

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20241 from kiransair:patch-2 03766ef45aa8653baeaad25f19b1341487ceb5d0
",copybara-service[bot],2024-12-09 07:09:30+00:00,[],2024-12-09 11:24:15+00:00,2024-12-09 11:24:14+00:00,https://github.com/tensorflow/tensorflow/pull/82497,[],[],
2726172498,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 06:57:37+00:00,[],2024-12-09 06:57:37+00:00,,https://github.com/tensorflow/tensorflow/pull/82496,[],[],
2726126283,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 06:30:36+00:00,[],2024-12-10 10:28:48+00:00,2024-12-10 10:28:47+00:00,https://github.com/tensorflow/tensorflow/pull/82495,[],[],
2726102020,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 06:16:39+00:00,[],2024-12-09 07:12:10+00:00,,https://github.com/tensorflow/tensorflow/pull/82494,[],[],
2725830820,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 03:05:25+00:00,[],2024-12-10 09:12:21+00:00,2024-12-10 09:12:20+00:00,https://github.com/tensorflow/tensorflow/pull/82493,[],[],
2725823842,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:59:27+00:00,[],2024-12-09 02:59:27+00:00,,https://github.com/tensorflow/tensorflow/pull/82492,[],[],
2725822520,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:58:07+00:00,[],2024-12-09 02:58:07+00:00,,https://github.com/tensorflow/tensorflow/pull/82491,[],[],
2725818817,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:54:34+00:00,[],2024-12-13 06:38:31+00:00,2024-12-13 06:38:30+00:00,https://github.com/tensorflow/tensorflow/pull/82490,[],[],
2725817113,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:53:00+00:00,[],2024-12-09 02:53:00+00:00,,https://github.com/tensorflow/tensorflow/pull/82489,[],[],
2725814296,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:50:21+00:00,[],2024-12-10 08:53:53+00:00,2024-12-10 08:53:52+00:00,https://github.com/tensorflow/tensorflow/pull/82488,[],[],
2725812061,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:48:11+00:00,[],2024-12-09 08:05:21+00:00,,https://github.com/tensorflow/tensorflow/pull/82487,[],[],
2725811114,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:47:19+00:00,[],2024-12-09 02:47:19+00:00,,https://github.com/tensorflow/tensorflow/pull/82486,[],[],
2725808202,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:44:42+00:00,[],2024-12-09 02:44:42+00:00,,https://github.com/tensorflow/tensorflow/pull/82485,[],[],
2725801808,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:39:07+00:00,[],2024-12-09 02:39:07+00:00,,https://github.com/tensorflow/tensorflow/pull/82484,[],[],
2725797488,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 02:35:03+00:00,[],2024-12-09 02:35:03+00:00,,https://github.com/tensorflow/tensorflow/pull/82483,[],[],
2725730119,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-09 01:39:28+00:00,[],2024-12-09 07:04:58+00:00,2024-12-09 07:04:57+00:00,https://github.com/tensorflow/tensorflow/pull/82482,[],[],
2725427981,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 18:02:24+00:00,[],2024-12-08 18:02:24+00:00,,https://github.com/tensorflow/tensorflow/pull/82481,[],[],
2725407452,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:24:31+00:00,[],2024-12-10 05:37:31+00:00,2024-12-10 05:37:30+00:00,https://github.com/tensorflow/tensorflow/pull/82480,[],[],
2725406495,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:22:24+00:00,[],2024-12-08 19:16:20+00:00,2024-12-08 19:16:19+00:00,https://github.com/tensorflow/tensorflow/pull/82479,[],[],
2725398682,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:13:58+00:00,[],2024-12-08 17:13:58+00:00,,https://github.com/tensorflow/tensorflow/pull/82478,[],[],
2725398503,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:13:40+00:00,[],2024-12-12 07:26:47+00:00,2024-12-12 07:26:46+00:00,https://github.com/tensorflow/tensorflow/pull/82477,[],[],
2725398163,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:13:35+00:00,[],2024-12-10 06:03:07+00:00,2024-12-10 06:03:06+00:00,https://github.com/tensorflow/tensorflow/pull/82476,[],[],
2725394190,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:10:00+00:00,[],2024-12-15 16:47:28+00:00,2024-12-15 16:47:27+00:00,https://github.com/tensorflow/tensorflow/pull/82475,[],[],
2725394076,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:09:45+00:00,[],2024-12-10 06:53:35+00:00,2024-12-10 06:53:34+00:00,https://github.com/tensorflow/tensorflow/pull/82474,[],[],
2725393658,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:09:27+00:00,[],2024-12-08 17:09:27+00:00,,https://github.com/tensorflow/tensorflow/pull/82473,[],[],
2725390727,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:07:31+00:00,[],2024-12-08 17:07:31+00:00,,https://github.com/tensorflow/tensorflow/pull/82472,[],[],
2725389047,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:05:58+00:00,[],2024-12-08 17:05:58+00:00,,https://github.com/tensorflow/tensorflow/pull/82471,[],[],
2725386290,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 17:02:53+00:00,[],2024-12-08 17:02:53+00:00,,https://github.com/tensorflow/tensorflow/pull/82470,[],[],
2725383333,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 16:58:46+00:00,[],2024-12-13 05:51:40+00:00,,https://github.com/tensorflow/tensorflow/pull/82469,[],[],
2725379418,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 16:50:45+00:00,[],2024-12-08 21:39:00+00:00,2024-12-08 21:38:59+00:00,https://github.com/tensorflow/tensorflow/pull/82468,[],[],
2725366384,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 16:26:11+00:00,[],2024-12-12 09:13:21+00:00,2024-12-12 09:13:20+00:00,https://github.com/tensorflow/tensorflow/pull/82467,[],[],
2725269586,pull_request,closed,,Example is added to tf.math.truediv function,"Examples are added for the API, tf.math.truediv.",LakshmiKalaKadali,2024-12-08 14:16:34+00:00,['gbaned'],2024-12-10 06:41:08+00:00,2024-12-10 06:41:08+00:00,https://github.com/tensorflow/tensorflow/pull/82466,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('comp:ops', 'OPs related issues'), ('size:S', 'CL Change Size: Small')]",[],
2724910526,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-08 02:27:04+00:00,[],2024-12-08 02:27:04+00:00,,https://github.com/tensorflow/tensorflow/pull/82463,[],[],
2724752440,pull_request,closed,,"Adds a ""SHARDING"" ProfileType to HloModuleProto.","Adds a ""SHARDING"" ProfileType to HloModuleProto.
",copybara-service[bot],2024-12-07 18:07:45+00:00,[],2024-12-13 01:16:39+00:00,2024-12-13 01:16:38+00:00,https://github.com/tensorflow/tensorflow/pull/82462,[],[],
2724561524,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 12:05:11+00:00,[],2024-12-12 11:15:22+00:00,,https://github.com/tensorflow/tensorflow/pull/82460,[],[],
2724517946,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 10:05:25+00:00,[],2024-12-12 07:47:00+00:00,2024-12-12 07:47:00+00:00,https://github.com/tensorflow/tensorflow/pull/82459,[],[],
2724517495,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 10:04:16+00:00,[],2024-12-10 07:13:57+00:00,2024-12-10 07:13:57+00:00,https://github.com/tensorflow/tensorflow/pull/82458,[],[],
2724516885,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 10:02:40+00:00,[],2024-12-08 04:29:15+00:00,2024-12-08 04:29:14+00:00,https://github.com/tensorflow/tensorflow/pull/82457,[],[],
2724510457,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 09:44:49+00:00,[],2024-12-12 12:08:21+00:00,2024-12-12 12:08:20+00:00,https://github.com/tensorflow/tensorflow/pull/82456,[],[],
2724505654,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 09:30:51+00:00,[],2024-12-07 09:30:51+00:00,,https://github.com/tensorflow/tensorflow/pull/82455,[],[],
2724503024,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 09:23:45+00:00,[],2024-12-07 10:04:43+00:00,,https://github.com/tensorflow/tensorflow/pull/82454,[],[],
2724499061,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 09:12:11+00:00,[],2024-12-07 09:12:11+00:00,,https://github.com/tensorflow/tensorflow/pull/82453,[],[],
2724488376,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 08:48:36+00:00,[],2024-12-10 07:31:41+00:00,,https://github.com/tensorflow/tensorflow/pull/82452,[],[],
2724484161,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 08:37:18+00:00,[],2024-12-07 08:37:18+00:00,,https://github.com/tensorflow/tensorflow/pull/82451,[],[],
2724454061,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 07:58:03+00:00,[],2024-12-10 05:26:17+00:00,2024-12-10 05:26:16+00:00,https://github.com/tensorflow/tensorflow/pull/82450,[],[],
2724446461,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 07:39:35+00:00,[],2024-12-07 07:39:35+00:00,,https://github.com/tensorflow/tensorflow/pull/82449,[],[],
2724446179,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 07:38:46+00:00,[],2024-12-12 09:56:02+00:00,2024-12-12 09:56:00+00:00,https://github.com/tensorflow/tensorflow/pull/82448,[],[],
2724445680,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 07:37:51+00:00,[],2024-12-07 07:37:51+00:00,,https://github.com/tensorflow/tensorflow/pull/82447,[],[],
2724444190,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 07:34:03+00:00,[],2024-12-10 12:17:08+00:00,2024-12-10 12:17:06+00:00,https://github.com/tensorflow/tensorflow/pull/82446,[],[],
2724442131,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 07:29:08+00:00,[],2024-12-10 09:46:53+00:00,2024-12-10 09:46:52+00:00,https://github.com/tensorflow/tensorflow/pull/82445,[],[],
2724419628,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 06:42:53+00:00,[],2024-12-07 06:42:53+00:00,,https://github.com/tensorflow/tensorflow/pull/82444,[],[],
2724403223,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 06:08:02+00:00,[],2024-12-07 06:08:02+00:00,,https://github.com/tensorflow/tensorflow/pull/82443,[],[],
2724324030,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-07 04:16:48+00:00,[],2024-12-07 04:16:48+00:00,,https://github.com/tensorflow/tensorflow/pull/82439,[],[],
2724319785,pull_request,closed,,Updating Headers,"Created a PR for new headers so there is more code clarity in reading it. My hope is that these headers break up the long function. Please see this issue for more! 

https://github.com/tensorflow/tensorflow/issues/80282",mrqsmar,2024-12-07 04:07:47+00:00,['gbaned'],2024-12-08 14:24:30+00:00,2024-12-08 14:24:30+00:00,https://github.com/tensorflow/tensorflow/pull/82438,"[('size:S', 'CL Change Size: Small')]","[{'comment_id': 2524857091, 'issue_id': 2724319785, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82438/checks?check_run_id=34065103999) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 7, 4, 7, 51, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-07 04:07:51 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82438/checks?check_run_id=34065103999) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2724252807,pull_request,open,,change usage from constructor to factory method,"change usage from constructor to factory method
",copybara-service[bot],2024-12-07 01:52:36+00:00,[],2024-12-10 00:48:14+00:00,,https://github.com/tensorflow/tensorflow/pull/82437,[],[],
2724247357,pull_request,open,,Add Shape::FromProto static factory method and replace usage.,"Add Shape::FromProto static factory method and replace usage.
",copybara-service[bot],2024-12-07 01:44:27+00:00,[],2024-12-10 00:49:38+00:00,,https://github.com/tensorflow/tensorflow/pull/82436,[],[],
2724169887,pull_request,open,,Remove barely used and unnecessary XlaShape::SetProto,"Remove barely used and unnecessary XlaShape::SetProto
",copybara-service[bot],2024-12-07 00:01:31+00:00,[],2024-12-07 00:01:31+00:00,,https://github.com/tensorflow/tensorflow/pull/82435,[],[],
2724167010,pull_request,closed,,Defensively handle invalid device properties.,"Defensively handle invalid device properties.
",copybara-service[bot],2024-12-06 23:57:46+00:00,[],2024-12-08 07:27:21+00:00,2024-12-08 07:27:20+00:00,https://github.com/tensorflow/tensorflow/pull/82434,[],[],
2724164512,pull_request,closed,,Add inference_latency_chart to tensorboard,"Add inference_latency_chart to tensorboard
",copybara-service[bot],2024-12-06 23:53:18+00:00,['cliveverghese'],2024-12-09 21:51:54+00:00,2024-12-09 21:51:53+00:00,https://github.com/tensorflow/tensorflow/pull/82433,[],[],
2724162812,pull_request,open,,Migrate graphdef_to_tfl_flatbuffer.cc to use ConvertGraphToMlir vs ConvertGraphdefToMlir.,"Migrate graphdef_to_tfl_flatbuffer.cc to use ConvertGraphToMlir vs ConvertGraphdefToMlir.
",copybara-service[bot],2024-12-06 23:50:43+00:00,['rocketas'],2024-12-07 00:44:00+00:00,,https://github.com/tensorflow/tensorflow/pull/82432,[],[],
2724161591,pull_request,open,,Remove barely used function is_static_dimension.,"Remove barely used function is_static_dimension.
",copybara-service[bot],2024-12-06 23:49:14+00:00,[],2024-12-06 23:49:14+00:00,,https://github.com/tensorflow/tensorflow/pull/82431,[],[],
2724124525,pull_request,closed,,Migrate runtime_client from using deprecated ConvertFunctionToMlir. Functionality is unchanged.,"Migrate runtime_client from using deprecated ConvertFunctionToMlir. Functionality is unchanged.
",copybara-service[bot],2024-12-06 23:26:38+00:00,['rocketas'],2024-12-07 00:30:24+00:00,2024-12-07 00:30:23+00:00,https://github.com/tensorflow/tensorflow/pull/82430,[],[],
2724122245,pull_request,closed,,Add ability to disable TargetConfig metadata for se_gpu_pjrt_client.,"Add ability to disable TargetConfig metadata for se_gpu_pjrt_client.
",copybara-service[bot],2024-12-06 23:25:05+00:00,['pschuh'],2024-12-07 00:22:52+00:00,2024-12-07 00:22:51+00:00,https://github.com/tensorflow/tensorflow/pull/82429,[],[],
2724102925,pull_request,closed,,Add LiteRtCompilationOptions to CompiledModel API,"Add LiteRtCompilationOptions to CompiledModel API

- NPU supports with DispatchDelegate is also enabled.
- Updated LiteRtModelT to keep the original buffer information when it's
  loaded from a buffer.
",copybara-service[bot],2024-12-06 23:08:41+00:00,['terryheo'],2024-12-09 18:37:48+00:00,2024-12-09 18:37:46+00:00,https://github.com/tensorflow/tensorflow/pull/82428,[],[],
2724090882,pull_request,closed,,Allow platform-specific relaxation of fusion restrictions on in-place update ops.,"Allow platform-specific relaxation of fusion restrictions on in-place update ops.
",copybara-service[bot],2024-12-06 22:55:16+00:00,[],2024-12-06 23:56:47+00:00,2024-12-06 23:56:47+00:00,https://github.com/tensorflow/tensorflow/pull/82427,[],[],
2724068362,pull_request,closed,,Remove barely used `Shape::Swap` method,"Remove barely used `Shape::Swap` method
",copybara-service[bot],2024-12-06 22:42:29+00:00,[],2024-12-09 10:55:55+00:00,2024-12-09 10:55:54+00:00,https://github.com/tensorflow/tensorflow/pull/82426,[],[],
2724041958,pull_request,open,,Integrate LLVM at llvm/llvm-project@12bdeba76eef,"Integrate LLVM at llvm/llvm-project@12bdeba76eef

Updates LLVM usage to match
[12bdeba76eef](https://github.com/llvm/llvm-project/commit/12bdeba76eef)
",copybara-service[bot],2024-12-06 22:30:40+00:00,[],2024-12-06 22:30:40+00:00,,https://github.com/tensorflow/tensorflow/pull/82425,[],[],
2724010297,pull_request,closed,,[XLA:GPU:ROCm] Restore threads per warp behavior,"[XLA:GPU:ROCm] Restore threads per warp behavior

We previously hard-coded threads-per-warp on ROCm to 32.

Then in https://github.com/openxla/xla/commit/53417984a9baf80ac9b677f13e628867298f8eae I changed ROCm to query the hip runtime for this property.

However, this seems to have broken AMD's CI so I am restoring the old behavior.

This is probably wrong but things are currently broken and reverting back to the prior behavior leaves things less broken.
",copybara-service[bot],2024-12-06 22:07:52+00:00,['majnemer'],2024-12-06 23:31:11+00:00,2024-12-06 23:31:10+00:00,https://github.com/tensorflow/tensorflow/pull/82424,[],[],
2724008893,pull_request,open,,"In progress experimentation for supporting JAX Arrays with variable-width strings (i.e., with dtype = StringDType).","In progress experimentation for supporting JAX Arrays with variable-width strings (i.e., with dtype = StringDType).
",copybara-service[bot],2024-12-06 22:06:38+00:00,[],2024-12-17 17:52:32+00:00,,https://github.com/tensorflow/tensorflow/pull/82423,[],[],
2723985069,pull_request,closed,,Add OverviewInferenceLatency to OverviewPage.,"Add OverviewInferenceLatency to OverviewPage.
",copybara-service[bot],2024-12-06 21:48:59+00:00,['cliveverghese'],2024-12-08 04:18:27+00:00,2024-12-08 04:18:27+00:00,https://github.com/tensorflow/tensorflow/pull/82422,[],[],
2723971859,pull_request,closed,,Add JIT compiler plugin support and test case for QC,"Add JIT compiler plugin support and test case for QC
",copybara-service[bot],2024-12-06 21:38:34+00:00,[],2024-12-07 00:04:05+00:00,2024-12-07 00:04:04+00:00,https://github.com/tensorflow/tensorflow/pull/82421,[],[],
2723957267,pull_request,closed,,Remove UpgradeLegacyGraph wrapper to FunctionalizeControlFlow. Only graph_to_tf_executor uses a nodefilter and the rest are direct calls to FunctionalizeControlFlow. ,"Remove UpgradeLegacyGraph wrapper to FunctionalizeControlFlow. Only graph_to_tf_executor uses a nodefilter and the rest are direct calls to FunctionalizeControlFlow. 

Reduces dependency complexity for futher migrations. UpgradeGraph file will be removed for clearer code ownership.
",copybara-service[bot],2024-12-06 21:26:39+00:00,['rocketas'],2024-12-06 22:56:45+00:00,2024-12-06 22:56:45+00:00,https://github.com/tensorflow/tensorflow/pull/82420,[],[],
2723875047,pull_request,closed,,Handle the case where there are multiple levels of formatting ops between DUS's update,"Handle the case where there are multiple levels of formatting ops between DUS's update
and move-to-host annotation.
",copybara-service[bot],2024-12-06 20:35:05+00:00,[],2024-12-09 19:42:21+00:00,2024-12-09 19:42:20+00:00,https://github.com/tensorflow/tensorflow/pull/82419,[],[],
2723785200,pull_request,open,,Integrate LLVM at llvm/llvm-project@9d2351ab9aff,"Integrate LLVM at llvm/llvm-project@9d2351ab9aff

Updates LLVM usage to match
[9d2351ab9aff](https://github.com/llvm/llvm-project/commit/9d2351ab9aff)
",copybara-service[bot],2024-12-06 19:37:20+00:00,[],2024-12-06 20:54:03+00:00,,https://github.com/tensorflow/tensorflow/pull/82418,[],[],
2723755493,pull_request,closed,,hlo_original_value: Don't blow up when printing empty values.,"hlo_original_value: Don't blow up when printing empty values.

An empty original value is accepted by `ParseOriginalValue` with syntax like
`origin={}`, but converting that value back to a string fails because it
attempts to read a disengaged optional from the `ShapeTree`. Let's ensure the
round-trip works properly.

A fuller fix would be to look at the semantics of whether such values should
be accepted, but the interest of preventing crashes quickly we'll start with
this.
",copybara-service[bot],2024-12-06 19:17:04+00:00,[],2024-12-06 22:42:13+00:00,2024-12-06 22:42:13+00:00,https://github.com/tensorflow/tensorflow/pull/82417,[],[],
2723734360,pull_request,closed,,[XLA:GPU] Implement NcclRaggedAllToAllThunk.,"[XLA:GPU] Implement NcclRaggedAllToAllThunk.

This change add proper implementation of RaggedAllToAll with Nccl. `RaggedAllToAllDecomposer` is now disabled, since it's not needed for integration.

Test coverage is in `collective_ops_e2e_test.cc`.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20214 from shraiysh:ds_fusion 92e120354e04c8b754b5853c79662b96342b44f1
",copybara-service[bot],2024-12-06 19:02:53+00:00,[],2024-12-11 14:25:48+00:00,2024-12-11 14:25:47+00:00,https://github.com/tensorflow/tensorflow/pull/82416,[],[],
2723719008,pull_request,closed,,[xla:cpu] Add xnnpack dependency to xla:cpu runtime,"[xla:cpu] Add xnnpack dependency to xla:cpu runtime
",copybara-service[bot],2024-12-06 18:54:08+00:00,['ezhulenev'],2024-12-07 01:01:30+00:00,2024-12-07 01:01:29+00:00,https://github.com/tensorflow/tensorflow/pull/82415,[],[],
2723699425,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@b3d3cacd,"Integrate StableHLO at openxla/stablehlo@b3d3cacd
",copybara-service[bot],2024-12-06 18:41:12+00:00,[],2024-12-06 20:23:16+00:00,2024-12-06 20:23:15+00:00,https://github.com/tensorflow/tensorflow/pull/82414,[],[],
2723678576,pull_request,closed,,Add a public UpdateEntryComputationLayout method,"Add a public UpdateEntryComputationLayout method
",copybara-service[bot],2024-12-06 18:28:16+00:00,[],2024-12-07 01:07:04+00:00,2024-12-07 01:07:03+00:00,https://github.com/tensorflow/tensorflow/pull/82413,[],[],
2723662834,pull_request,closed,,Add implicit device step tracking.,"Add implicit device step tracking.
",copybara-service[bot],2024-12-06 18:18:39+00:00,[],2024-12-10 21:23:48+00:00,2024-12-10 21:23:47+00:00,https://github.com/tensorflow/tensorflow/pull/82412,[],[],
2723533127,pull_request,closed,,[xla-auto-sharding] Add SolveGreedy() heuristic to make local greedy choices.,"[xla-auto-sharding] Add SolveGreedy() heuristic to make local greedy choices.

Notes:
- Only represent a sharding strategy by the node sharding configs (not the induced edge sharding indices, since they're redundant)
- Add `GetEdgeStrategy()` method for recovering the induced edge sharding strategies
- Factor out logic for computing objective value of a given sharding strategy as `ComputeShardingStrategyCost()`
- Add `SolveGreedy()` heuristic that outputs a sharding based on local greedy decisions for each node
",copybara-service[bot],2024-12-06 17:05:39+00:00,[],2024-12-06 19:51:27+00:00,2024-12-06 19:51:26+00:00,https://github.com/tensorflow/tensorflow/pull/82411,[],[],
2723498155,pull_request,closed,,[XLA] Don't bail when encountering complex loop pipelining patterns,"[XLA] Don't bail when encountering complex loop pipelining patterns
",copybara-service[bot],2024-12-06 16:48:00+00:00,[],2024-12-10 04:27:46+00:00,2024-12-10 04:27:45+00:00,https://github.com/tensorflow/tensorflow/pull/82410,[],[],
2723490040,pull_request,closed,,Remove the use of TENSORFLOW_USE_ROCM from convolution_thunk.cc.,"Remove the use of TENSORFLOW_USE_ROCM from convolution_thunk.cc.
",copybara-service[bot],2024-12-06 16:43:22+00:00,[],2024-12-06 20:49:42+00:00,2024-12-06 20:49:41+00:00,https://github.com/tensorflow/tensorflow/pull/82409,[],[],
2723452183,pull_request,closed,,Improve compilation time by not fusing large constants into LLVM modules for XLA::CPU.,"Improve compilation time by not fusing large constants into LLVM modules for XLA::CPU.
",copybara-service[bot],2024-12-06 16:22:47+00:00,[],2024-12-14 00:23:47+00:00,2024-12-14 00:23:46+00:00,https://github.com/tensorflow/tensorflow/pull/82408,[],[],
2723442958,pull_request,closed,,"Skip inserting into frontend attr if the (key, value) pair already exists and override if key exists","Skip inserting into frontend attr if the (key, value) pair already exists and override if key exists
",copybara-service[bot],2024-12-06 16:18:26+00:00,[],2024-12-12 07:34:38+00:00,2024-12-12 07:34:37+00:00,https://github.com/tensorflow/tensorflow/pull/82407,[],[],
2723442510,pull_request,open,,[XLA:CPU] Expose better parallelism control,"[XLA:CPU] Expose better parallelism control

Add a flag `--xla_cpu_intra_op_parallelism_threads` to control the number of threads used for intra-op parallelism on the CPU backend.
",copybara-service[bot],2024-12-06 16:18:10+00:00,[],2024-12-18 15:48:03+00:00,,https://github.com/tensorflow/tensorflow/pull/82406,[],"[{'comment_id': 2523650875, 'issue_id': 2723442510, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82406/checks?check_run_id=34042556760) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 6, 16, 18, 15, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-06 16:18:15 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82406/checks?check_run_id=34042556760) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2723309974,pull_request,closed,,Allow programatic override of the default values for the gcs file system cache,"Allow programatic override of the default values for the gcs file system cache

Doing this through the constructor also allows the size of the readahead buffer to be changed, which is not possible with the existing API unless we use the long version of the constructor which has 10 parameters. There is also a `ResetFileBlockCache`, but it only modifies the size of the file cache, not the size readahead buffer.

While it is possible to set that with environment variables, those variables are global and would modify the behaviour of all GCS clients. Allowing the override through the constructor would allow more control over how those overrides happen.
",copybara-service[bot],2024-12-06 15:25:12+00:00,[],2024-12-06 17:40:41+00:00,2024-12-06 17:40:40+00:00,https://github.com/tensorflow/tensorflow/pull/82404,[],[],
2723306601,pull_request,open,,#sdy remove `mhlo.tan` `CustomCallOp` from the registry as a StableHLO equivalent now exists.,"#sdy remove `mhlo.tan` `CustomCallOp` from the registry as a StableHLO equivalent now exists.
",copybara-service[bot],2024-12-06 15:23:35+00:00,[],2024-12-06 15:23:35+00:00,,https://github.com/tensorflow/tensorflow/pull/82403,[],[],
2723174009,pull_request,open,,Integrate LLVM at llvm/llvm-project@9d2351ab9aff,"Integrate LLVM at llvm/llvm-project@9d2351ab9aff

Updates LLVM usage to match
[9d2351ab9aff](https://github.com/llvm/llvm-project/commit/9d2351ab9aff)
",copybara-service[bot],2024-12-06 14:19:09+00:00,[],2024-12-06 14:19:09+00:00,,https://github.com/tensorflow/tensorflow/pull/82402,[],[],
2723121129,pull_request,closed,,Fix type stub for register_node to note that to_iterable_with_keys is optional.,"Fix type stub for register_node to note that to_iterable_with_keys is optional.
",copybara-service[bot],2024-12-06 13:55:02+00:00,[],2024-12-06 14:27:01+00:00,2024-12-06 14:27:00+00:00,https://github.com/tensorflow/tensorflow/pull/82401,[],[],
2723092537,pull_request,closed,,"[XLA:Python] Use nanobind::isinstance from upstream nanobind, delete xla::nb_isinstance.","[XLA:Python] Use nanobind::isinstance from upstream nanobind, delete xla::nb_isinstance.

This helper is now part of nanobind 2.4.0.
",copybara-service[bot],2024-12-06 13:42:35+00:00,[],2024-12-09 15:17:48+00:00,2024-12-09 15:17:47+00:00,https://github.com/tensorflow/tensorflow/pull/82400,[],[],
2722974228,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 12:43:46+00:00,[],2024-12-06 12:43:46+00:00,,https://github.com/tensorflow/tensorflow/pull/82399,[],[],
2722849694,pull_request,open,,[XLA:GPU]  Replace usages of `xla_experimental_exec_time_optimization_effort` with `jax_exec_time_optimization_effort`.,"[XLA:GPU]  Replace usages of `xla_experimental_exec_time_optimization_effort` with `jax_exec_time_optimization_effort`.

Also remove now unused `xla_experimental_exec_time_optimization_effort` flag.
",copybara-service[bot],2024-12-06 11:45:11+00:00,[],2024-12-06 11:45:11+00:00,,https://github.com/tensorflow/tensorflow/pull/82398,[],[],
2722800387,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 11:30:27+00:00,[],2024-12-06 11:30:27+00:00,,https://github.com/tensorflow/tensorflow/pull/82397,[],[],
2722749410,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 11:11:21+00:00,[],2024-12-07 09:39:46+00:00,,https://github.com/tensorflow/tensorflow/pull/82396,[],[],
2722746037,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 11:10:03+00:00,[],2024-12-07 06:38:02+00:00,2024-12-07 06:38:01+00:00,https://github.com/tensorflow/tensorflow/pull/82395,[],[],
2722737257,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 11:07:04+00:00,[],2024-12-06 11:07:04+00:00,,https://github.com/tensorflow/tensorflow/pull/82394,[],[],
2722725686,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 11:03:11+00:00,[],2024-12-11 08:43:18+00:00,2024-12-11 08:43:18+00:00,https://github.com/tensorflow/tensorflow/pull/82393,[],[],
2722711392,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 10:57:26+00:00,[],2024-12-11 08:52:54+00:00,2024-12-11 08:52:53+00:00,https://github.com/tensorflow/tensorflow/pull/82392,[],[],
2722709688,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 10:56:41+00:00,[],2024-12-10 10:35:03+00:00,2024-12-10 10:35:02+00:00,https://github.com/tensorflow/tensorflow/pull/82391,[],[],
2722696980,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 10:51:30+00:00,[],2024-12-07 06:56:19+00:00,2024-12-07 06:56:18+00:00,https://github.com/tensorflow/tensorflow/pull/82390,[],[],
2722691296,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 10:49:26+00:00,[],2024-12-11 07:01:59+00:00,2024-12-11 07:01:58+00:00,https://github.com/tensorflow/tensorflow/pull/82389,[],[],
2722690640,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 10:49:14+00:00,[],2024-12-10 09:57:49+00:00,2024-12-10 09:57:48+00:00,https://github.com/tensorflow/tensorflow/pull/82388,[],[],
2722683580,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 10:45:18+00:00,[],2024-12-13 05:16:00+00:00,2024-12-13 05:16:00+00:00,https://github.com/tensorflow/tensorflow/pull/82387,[],[],
2722636192,pull_request,closed,,[xla:ffi] Add num_threads() API to external FFI thread pool,"[xla:ffi] Add num_threads() API to external FFI thread pool
",copybara-service[bot],2024-12-06 10:24:32+00:00,['ezhulenev'],2024-12-06 11:02:11+00:00,2024-12-06 11:02:10+00:00,https://github.com/tensorflow/tensorflow/pull/82386,[],[],
2722475928,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 09:05:56+00:00,[],2024-12-06 09:05:56+00:00,,https://github.com/tensorflow/tensorflow/pull/82384,[],[],
2722451258,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 08:56:46+00:00,[],2024-12-06 08:56:46+00:00,,https://github.com/tensorflow/tensorflow/pull/82383,[],[],
2722433249,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 08:49:25+00:00,[],2024-12-06 08:49:25+00:00,,https://github.com/tensorflow/tensorflow/pull/82382,[],[],
2722379113,pull_request,closed,,Integrate LLVM at llvm/llvm-project@2ccf7ed277df,"Integrate LLVM at llvm/llvm-project@2ccf7ed277df

Updates LLVM usage to match
[2ccf7ed277df](https://github.com/llvm/llvm-project/commit/2ccf7ed277df)
",copybara-service[bot],2024-12-06 08:18:53+00:00,[],2024-12-06 11:53:53+00:00,2024-12-06 11:53:52+00:00,https://github.com/tensorflow/tensorflow/pull/82381,[],[],
2722354180,pull_request,open,,Integrate LLVM at llvm/llvm-project@e6cf5d2863b7,"Integrate LLVM at llvm/llvm-project@e6cf5d2863b7

Updates LLVM usage to match
[e6cf5d2863b7](https://github.com/llvm/llvm-project/commit/e6cf5d2863b7)
",copybara-service[bot],2024-12-06 08:07:35+00:00,[],2024-12-06 10:38:12+00:00,,https://github.com/tensorflow/tensorflow/pull/82380,[],[],
2722343666,pull_request,closed,,Reverts d72c8f988db6072dd00d74cc28d3261eadbfeee7,"Reverts d72c8f988db6072dd00d74cc28d3261eadbfeee7
",copybara-service[bot],2024-12-06 08:03:09+00:00,['akuegel'],2024-12-06 10:11:13+00:00,2024-12-06 10:11:11+00:00,https://github.com/tensorflow/tensorflow/pull/82379,[],[],
2722250094,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 07:19:33+00:00,[],2024-12-06 07:19:33+00:00,,https://github.com/tensorflow/tensorflow/pull/82378,[],[],
2722183068,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 06:33:32+00:00,[],2024-12-06 06:33:32+00:00,,https://github.com/tensorflow/tensorflow/pull/82377,[],[],
2722169758,pull_request,closed,,[hlo-opt] move hwi part of the tool to hlo/tools/ directory,"[hlo-opt] move hwi part of the tool to hlo/tools/ directory
```
xla/
   tools/hlo_opt/ has hardware specific (cpu, gpu) opt providers.
   hlo/tools/hlo_opt/ has hardware independent opt providers. 
   hlo/transforms/tests/ will hold LIT + FileCheck + Hlo-opt tool based pass unit tests
```
",copybara-service[bot],2024-12-06 06:22:56+00:00,[],2024-12-17 01:21:52+00:00,2024-12-17 01:21:51+00:00,https://github.com/tensorflow/tensorflow/pull/82376,[],[],
2722166722,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 06:20:27+00:00,[],2024-12-07 12:31:09+00:00,,https://github.com/tensorflow/tensorflow/pull/82375,[],[],
2722142612,pull_request,closed,,Enable sampling for inference profile and expose them in inference profile tool.,"Enable sampling for inference profile and expose them in inference profile tool.
",copybara-service[bot],2024-12-06 06:00:51+00:00,['cliveverghese'],2024-12-07 07:55:21+00:00,2024-12-07 07:55:20+00:00,https://github.com/tensorflow/tensorflow/pull/82374,[],[],
2722115804,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-06 05:37:38+00:00,[],2024-12-06 05:37:38+00:00,,https://github.com/tensorflow/tensorflow/pull/82373,[],[],
2721930557,pull_request,open,,Reverts ef7a5ee8caca8fbfdc973d2a7e2a3c3a152900b0,"Reverts ef7a5ee8caca8fbfdc973d2a7e2a3c3a152900b0
",copybara-service[bot],2024-12-06 02:58:19+00:00,[],2024-12-06 19:21:31+00:00,,https://github.com/tensorflow/tensorflow/pull/82370,[],[],
2721877303,pull_request,closed,,"[tsl] Deprecate tsl::mutex and tsl::condition_variable, make tsl::Condition an alias of absl::Condition","[tsl] Deprecate tsl::mutex and tsl::condition_variable, make tsl::Condition an alias of absl::Condition

We should just use the absl equivalents throughout the code base.
",copybara-service[bot],2024-12-06 02:10:23+00:00,['majnemer'],2024-12-06 20:38:12+00:00,2024-12-06 20:38:10+00:00,https://github.com/tensorflow/tensorflow/pull/82369,[],[],
2721817108,pull_request,open,,Add signature runner support to drifter.,"Add signature runner support to drifter.
",copybara-service[bot],2024-12-06 01:19:10+00:00,[],2024-12-06 01:58:51+00:00,,https://github.com/tensorflow/tensorflow/pull/82368,[],[],
2721784390,pull_request,closed,,[xla] Add detailed tracing to RendezvousSingle,"[xla] Add detailed tracing to RendezvousSingle

Improve performance observability of rendezvous synchronization.
",copybara-service[bot],2024-12-06 00:53:10+00:00,['ezhulenev'],2024-12-06 01:54:41+00:00,2024-12-06 01:54:41+00:00,https://github.com/tensorflow/tensorflow/pull/82367,[],[],
2721783012,pull_request,closed,,Demote log from ERROR to VLOG(2).,"Demote log from ERROR to VLOG(2).
",copybara-service[bot],2024-12-06 00:52:07+00:00,['SandSnip3r'],2024-12-06 02:28:25+00:00,2024-12-06 02:28:24+00:00,https://github.com/tensorflow/tensorflow/pull/82366,[],[],
2721780405,pull_request,closed,,Update nanobind dependency to v2.4.0.,"Update nanobind dependency to v2.4.0.
",copybara-service[bot],2024-12-06 00:49:48+00:00,[],2024-12-06 03:15:01+00:00,2024-12-06 03:15:00+00:00,https://github.com/tensorflow/tensorflow/pull/82365,[],[],
2721765393,pull_request,closed,,Add per-channel quantization support in LiteRT.,"Add per-channel quantization support in LiteRT.
",copybara-service[bot],2024-12-06 00:36:27+00:00,[],2024-12-10 20:04:45+00:00,2024-12-10 20:04:44+00:00,https://github.com/tensorflow/tensorflow/pull/82364,[],[],
2721758941,pull_request,open,,Add minimal test case to collective pipeliner,"Add minimal test case to collective pipeliner
",copybara-service[bot],2024-12-06 00:32:52+00:00,['frgossen'],2024-12-06 00:32:54+00:00,,https://github.com/tensorflow/tensorflow/pull/82363,[],[],
2721726873,pull_request,closed,,[XLA:LatencyHidingScheduler] Do not allow target-defined resources to have a concurrency limit of 0.,"[XLA:LatencyHidingScheduler] Do not allow target-defined resources to have a concurrency limit of 0.
",copybara-service[bot],2024-12-06 00:08:11+00:00,['seherellis'],2024-12-06 07:17:28+00:00,2024-12-06 07:17:28+00:00,https://github.com/tensorflow/tensorflow/pull/82362,[],[],
2721710343,pull_request,closed,,Re-enable current StableHLO current version attribute in PJRT,"Re-enable current StableHLO current version attribute in PJRT
",copybara-service[bot],2024-12-05 23:59:35+00:00,['GleasonK'],2024-12-06 17:24:15+00:00,2024-12-06 17:24:14+00:00,https://github.com/tensorflow/tensorflow/pull/82360,[],[],
2721657174,pull_request,closed,,Internal changes only,"Internal changes only
",copybara-service[bot],2024-12-05 23:21:41+00:00,[],2024-12-09 21:37:22+00:00,2024-12-09 21:37:20+00:00,https://github.com/tensorflow/tensorflow/pull/82359,[],[],
2721635549,pull_request,closed,,Correct the order of arguments in comment for RaggedAllToAll.,"Correct the order of arguments in comment for RaggedAllToAll.
",copybara-service[bot],2024-12-05 23:08:55+00:00,[],2024-12-06 02:16:26+00:00,2024-12-06 02:16:25+00:00,https://github.com/tensorflow/tensorflow/pull/82358,[],[],
2721611754,pull_request,closed,,Update LiteRT Model API,"Update LiteRT Model API

Align with API naming guide.
- LiteRt[Create|Destory]Modelxxxx
",copybara-service[bot],2024-12-05 22:57:04+00:00,['terryheo'],2024-12-07 03:54:55+00:00,2024-12-07 02:05:01+00:00,https://github.com/tensorflow/tensorflow/pull/82357,[],[],
2721595074,pull_request,open,,Support evaluation in the absence of layouts when possible,"Support evaluation in the absence of layouts when possible

Only bitcast requires the layout to be known when evaluating HLO.
In all other cases, we can evaluate without knowing the layout.
This is needed for collective pipelining where we have to analyse while loops before layouts were assigned.
",copybara-service[bot],2024-12-05 22:45:45+00:00,['frgossen'],2024-12-06 20:30:50+00:00,,https://github.com/tensorflow/tensorflow/pull/82356,[],[],
2721591916,pull_request,closed,,Remove the use of GOOGLE_CUDA and TENSORFLOW_USE_ROCM in buffer_comparator.,"Remove the use of GOOGLE_CUDA and TENSORFLOW_USE_ROCM in buffer_comparator.
",copybara-service[bot],2024-12-05 22:43:28+00:00,[],2024-12-06 18:35:39+00:00,2024-12-06 18:35:37+00:00,https://github.com/tensorflow/tensorflow/pull/82355,[],[],
2721572359,pull_request,closed,,Integrate LLVM at llvm/llvm-project@698d83218565,"Integrate LLVM at llvm/llvm-project@698d83218565

Updates LLVM usage to match
[698d83218565](https://github.com/llvm/llvm-project/commit/698d83218565)
",copybara-service[bot],2024-12-05 22:33:01+00:00,[],2024-12-06 01:29:43+00:00,2024-12-06 01:29:42+00:00,https://github.com/tensorflow/tensorflow/pull/82354,[],[],
2721567626,pull_request,open,,remove use_host_argument_layout and use executable layouts.,"remove use_host_argument_layout and use executable layouts.

Reverts 5c36415e4bafd2ef7ed219fae423d3b79ba017df
",copybara-service[bot],2024-12-05 22:29:59+00:00,[],2024-12-05 22:29:59+00:00,,https://github.com/tensorflow/tensorflow/pull/82353,[],[],
2721564097,pull_request,closed,,"When generating fake arguments for running HLOs via hlo_runner, use argument layouts from the compiled executable, rather than that of the generated host-side literal or a PjRt client specific layout.","When generating fake arguments for running HLOs via hlo_runner, use argument layouts from the compiled executable, rather than that of the generated host-side literal or a PjRt client specific layout.
",copybara-service[bot],2024-12-05 22:28:16+00:00,[],2024-12-10 01:58:46+00:00,2024-12-10 01:58:45+00:00,https://github.com/tensorflow/tensorflow/pull/82352,[],[],
2721563492,pull_request,closed,,Add method for HloRunnerAgnosticTestBase implementations to preprocess modules.,"Add method for HloRunnerAgnosticTestBase implementations to preprocess modules.

This change introduces a new `PreprocessModuleForTestRunner` virtual method with
an empty default implementation. The idea is to invoke this on on a module
intended to be run with the designated test runner, applying a set of default
module transforms for compatibility.

The transforms are specific to the runner being used, so the test base class
implementation is best suited to specifying these transforms (or not specifying
them if not required).
",copybara-service[bot],2024-12-05 22:27:47+00:00,[],2024-12-06 23:49:35+00:00,2024-12-06 23:49:35+00:00,https://github.com/tensorflow/tensorflow/pull/82351,[],[],
2721545073,pull_request,closed,,Add option for `HloRunnerPjRt` to forward parameter layout for on device use.,"Add option for `HloRunnerPjRt` to forward parameter layout for on device use.

I encountered some tests that rely on the on-device layout matching the
parameter layout in the entry computation shape of the module.

#1267 introduced logic to the `HloRunner` which changes the on-device shape to
""favor [the] entry computation shape with some adjustment"". Subsequently, tests
were written against this behavior.

This logic roughly does the following for each parameter:

- The parameter shape is converted using the `device_shape_representation_fn_`.
- For each subshape, if an array:
  - Extract the equivalent subshape from the entry computation shape.
  - If the subshape is static and has tiling info
    - Overwrite the subshape with the equivalent subshape.

It has the effect of attaching the layout info from the ECL, which matters in
many of our tests.

`HloRunnerPjRt` does not appear to have equivalent logic that does this. The
`PjRtClient` API for `BufferFromHostLiteral` lets us optionally override the
on-device layout. This PR allows a user to enable
`use_parameter_layout_on_device` and have the `HloRunnerPjRt` pass the
`parameter_layout` as a `device_layout`.
",copybara-service[bot],2024-12-05 22:15:37+00:00,[],2024-12-07 00:14:59+00:00,2024-12-07 00:14:59+00:00,https://github.com/tensorflow/tensorflow/pull/82350,[],[],
2721499404,pull_request,closed,,[xla-auto-sharding] Generalize multilevel flag to heuristic solver option.,"[xla-auto-sharding] Generalize multilevel flag to heuristic solver option.

Notes:
- Change `multilevel` flag in solve.cc to `heuristic` option flag
- Add call path to `RunHeuristicSolver()` in solve.cc via heuristic flag
- Scale request proto coefficients in the same way we scale the MIP solver input
",copybara-service[bot],2024-12-05 21:47:39+00:00,[],2024-12-06 14:57:54+00:00,2024-12-06 14:57:53+00:00,https://github.com/tensorflow/tensorflow/pull/82348,[],[],
2721415126,pull_request,open,,Integrate LLVM at llvm/llvm-project@c54616ea481a,"Integrate LLVM at llvm/llvm-project@c54616ea481a

Updates LLVM usage to match
[c54616ea481a](https://github.com/llvm/llvm-project/commit/c54616ea481a)
",copybara-service[bot],2024-12-05 21:06:52+00:00,[],2024-12-05 21:06:52+00:00,,https://github.com/tensorflow/tensorflow/pull/82347,[],[],
2721389632,pull_request,closed,,Frontend for Inference Profile.,"Frontend for Inference Profile.
",copybara-service[bot],2024-12-05 20:58:20+00:00,['cliveverghese'],2024-12-07 03:00:12+00:00,2024-12-07 03:00:11+00:00,https://github.com/tensorflow/tensorflow/pull/82346,[],[],
2721376820,pull_request,closed,,"Modifies block_rematerialization_factor to be a float, increasing granularity.","Modifies block_rematerialization_factor to be a float, increasing granularity.
",copybara-service[bot],2024-12-05 20:53:41+00:00,[],2024-12-09 21:46:28+00:00,2024-12-09 21:46:27+00:00,https://github.com/tensorflow/tensorflow/pull/82345,[],[],
2721267326,pull_request,closed,,Exclude more broken tilings from Triton exhaustive autotuning,"Exclude more broken tilings from Triton exhaustive autotuning

It turned out that the previously discovered Triton miscompile for some FP8 and predicate gemm configs also occurs for S8.

So this is excluding these S8 configs as well from exhaustive tiling search during autotuning.
",copybara-service[bot],2024-12-05 19:52:46+00:00,[],2024-12-06 12:04:12+00:00,2024-12-06 12:04:11+00:00,https://github.com/tensorflow/tensorflow/pull/82344,[],[],
2721253225,pull_request,closed,,[xla:gpu] NFC: Replace all users of NcclApi with GpuCollectives,"[xla:gpu] NFC: Replace all users of NcclApi with GpuCollectives

Pass GpuCollectives implementation to XLA via GpuExecutableRunOption.
",copybara-service[bot],2024-12-05 19:43:48+00:00,['ezhulenev'],2024-12-06 03:08:07+00:00,2024-12-06 03:08:06+00:00,https://github.com/tensorflow/tensorflow/pull/82343,[],[],
2721243361,pull_request,open,,Added `jax.experimental.multihost_utils.live_devices` API.,"Added `jax.experimental.multihost_utils.live_devices` API.

This API is intended to enable fault tolerant multi-controller JAX programs.
",copybara-service[bot],2024-12-05 19:37:51+00:00,[],2025-01-22 17:12:24+00:00,,https://github.com/tensorflow/tensorflow/pull/82342,[],[],
2721242368,pull_request,closed,,[xla:collectives] Make NcclApi an alias for GpuCollectives,"[xla:collectives] Make NcclApi an alias for GpuCollectives
",copybara-service[bot],2024-12-05 19:37:14+00:00,['ezhulenev'],2024-12-06 00:55:49+00:00,2024-12-06 00:55:49+00:00,https://github.com/tensorflow/tensorflow/pull/82341,[],[],
2721241549,pull_request,open,,Make the following tensorflow python targets visible publicly for LiteRT,"Make the following tensorflow python targets visible publicly for LiteRT
",copybara-service[bot],2024-12-05 19:36:42+00:00,['ecalubaquib'],2024-12-05 19:36:43+00:00,,https://github.com/tensorflow/tensorflow/pull/82340,[],[],
2721241224,pull_request,closed,,Added `GetAliveTasks` RPC to coordination service.,"Added `GetAliveTasks` RPC to coordination service.

This CL introduces a new `GetAliveTasks` RPC to the multi-controller JAX
coordination service. For a set of tasks `T`, `GetAliveTasks(T)` returns the
subset `A` of healthy tasks in `T`. To avoid hosts from disagreeing on which
tasks are healthy, `GetAliveTasks` has barrier-like semantics. In particular,
`GetAliveTasks` returns `A` only after every task in `A` has called
`GetAliveTasks(T)`. This API is intended to enable fault tolerant training
using multi-controller JAX.

Note that this CL introduces the `GetAliveTasks` API but it is not yet used. In
future CLs, I will pipe the API through to JAX and expose a `jax.alive_devices`
API. I'm separating the CLs to make the code easier to review.

# Implementation Details

`GetAliveTasks` has barrier-like semantics, and the coordination service
already implements barriers. However, the implementation of `GetAliveTasks`
differs from the barrier implementation in a couple of ways.

First, the barrier API expects a unique barrier name. For example, you might
call `barrier(""foo"")` to block on the barrier named ""foo"". For ergonomics,
`GetAliveTasks` does not require barrier names. Instead, the set of tasks
passed to `GetAliveTasks` acts like a name.

Second, the barrier API requires every barrier to have a unique name. It would
be annoying to construct a new name for every single barrier. Instead, the
barrier API allows programmers to repeatedly block on the same barrier.  To
implement this, every barrier has not only a name, but also a counter. For
example, you might request to block on the ""foo.0"" barrier or the ""bar.4""
barrier. Coordination service clients keep track of the latest counter value to
use, incrementing it after every successful barrier. There is also some logic
surrounding how a failed client can recover the latest counter value.

Third, the barrier API allows barrier calls to time out. This means that a
barrier can enter a failed state, and all future entrants to the barrier should
observe this failed state. This introduces some complexity to the API, as
barrier state must be maintained even after the barrier has failed. The
`GetAliveTasks` does not implement timeouts and currently, a barrier cannot
fail. We can augment the API in the future if needed.

However, I would argue that the simpler semantics are sufficient, as there are
other sources of odd failure behavior in existing multi-controller JAX
programs. For example, if some tasks enter a collective and time out, while
other tasks enter the collective later, the program may hang or fail. Thus,
having stronger `GetAliveTasks` semantics increases the complexity of the API
without making multi-controller JAX programs meaningfully more fault tolerant.
",copybara-service[bot],2024-12-05 19:36:29+00:00,[],2024-12-16 23:27:35+00:00,2024-12-16 23:27:35+00:00,https://github.com/tensorflow/tensorflow/pull/82339,[],[],
2721237926,pull_request,open,,Update TF RBE container hashes.,"Update TF RBE container hashes.
",copybara-service[bot],2024-12-05 19:34:18+00:00,[],2024-12-06 00:11:53+00:00,,https://github.com/tensorflow/tensorflow/pull/82338,[],[],
2721210950,pull_request,open,,Internal change only,"Internal change only
",copybara-service[bot],2024-12-05 19:17:22+00:00,[],2024-12-05 19:17:22+00:00,,https://github.com/tensorflow/tensorflow/pull/82337,[],[],
2721169528,pull_request,open,,[XLA:CPU] Enable Convert test for F8E3M4,"[XLA:CPU] Enable Convert test for F8E3M4
",copybara-service[bot],2024-12-05 18:52:20+00:00,[],2024-12-05 18:52:29+00:00,,https://github.com/tensorflow/tensorflow/pull/82336,[],"[{'comment_id': 2521168856, 'issue_id': 2721169528, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82336/checks?check_run_id=33994114784) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 5, 18, 52, 27, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-05 18:52:27 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82336/checks?check_run_id=33994114784) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2721167217,pull_request,open,,[XLA:CPU] Enable Convert test for F8E3M4,"[XLA:CPU] Enable Convert test for F8E3M4
",copybara-service[bot],2024-12-05 18:50:54+00:00,[],2024-12-05 18:51:01+00:00,,https://github.com/tensorflow/tensorflow/pull/82335,[],"[{'comment_id': 2521166438, 'issue_id': 2721167217, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82335/checks?check_run_id=33994044139) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 5, 18, 50, 59, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-05 18:50:59 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82335/checks?check_run_id=33994044139) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2721160758,pull_request,open,,[XLA:CPU] Enable Convert test for F8E3M4,"[XLA:CPU] Enable Convert test for F8E3M4
",copybara-service[bot],2024-12-05 18:48:06+00:00,[],2024-12-05 18:48:13+00:00,,https://github.com/tensorflow/tensorflow/pull/82334,[],"[{'comment_id': 2521161554, 'issue_id': 2721160758, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82334/checks?check_run_id=33993908234) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 5, 18, 48, 12, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-05 18:48:12 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82334/checks?check_run_id=33993908234) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2721101226,pull_request,closed,,Update TFRT dependency to use revision,"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/d02348ca01f8dbe413b11394dd913aa69002a378.
",copybara-service[bot],2024-12-05 18:18:20+00:00,[],2024-12-05 21:52:50+00:00,2024-12-05 21:52:49+00:00,https://github.com/tensorflow/tensorflow/pull/82333,[],[],
2721085996,pull_request,closed,,Integrate LLVM at llvm/llvm-project@fdb90cef75ca,"Integrate LLVM at llvm/llvm-project@fdb90cef75ca

Updates LLVM usage to match
[fdb90cef75ca](https://github.com/llvm/llvm-project/commit/fdb90cef75ca)
",copybara-service[bot],2024-12-05 18:09:10+00:00,[],2024-12-05 20:25:36+00:00,2024-12-05 20:25:36+00:00,https://github.com/tensorflow/tensorflow/pull/82332,[],[],
2721038658,pull_request,closed,,PR #20025: [NVIDIA GPU] LHS enhancement for collective multi-streaming ,"PR #20025: [NVIDIA GPU] LHS enhancement for collective multi-streaming 

Imported from GitHub PR https://github.com/openxla/xla/pull/20025

This PR is a polished version of https://github.com/openxla/xla/pull/19026. Commits are cherry-picked from https://github.com/openxla/xla/pull/19026 except for c1e51c62a0330ed75a81bfb71314e5045c83143f, where we fixed the handling of async collectives.
Copybara import of the project:

--
872b29ab40b7f2436d1bfcc36a2327629ced3860 by Terry Sun <tesun@nvidia.com>:

LHS deadlock avoidance

--
36e3318673bc2deee56514a1a548c859f7673e05 by Terry Sun <tesun@nvidia.com>:

update argument order

--
156ad3dcb685cfd23debab6d5e710267a0fe7dbd by Terry Sun <tesun@nvidia.com>:

polish code style

--
c1e51c62a0330ed75a81bfb71314e5045c83143f by Terry Sun <tesun@nvidia.com>:

fix async collective handling

--
79111443d461be863066acbcafa5f5622103d572 by Terry Sun <tesun@nvidia.com>:

handle non-extendable resources

--
617308115d847525a200f712a7e809ea088ae330 by Terry Sun <tesun@nvidia.com>:

Revert ""handle non-extendable resources""

This reverts commit 79111443d461be863066acbcafa5f5622103d572.

--
3f54e7b960a37b59afed12e6df7bdda1aeebce1a by Terry Sun <tesun@nvidia.com>:

fix rebase issue

--
b88630336eb83b9061055a936696a9eccde2c811 by Terry Sun <tesun@nvidia.com>:

remove redundant header

--
3b5bbc54e075436180df7800844ac5836e8f1a55 by Terry Sun <tesun@nvidia.com>:

consistent util usage and doc string

--
ee300c44bda14ad53b2cb3f49c67aeec6a3c31a9 by Terry Sun <tesun@nvidia.com>:

articulate util usage

--
be22b86f1e69041e2e08cfcc81e990a2743a2cb5 by Terry Sun <tesun@nvidia.com>:

more articulate util usage

--
1affe038dee3edd8ad0563ac3d9047c13a03fcfc by Terry Sun <tesun@nvidia.com>:

use flat_hash_set

--
cf45a819590ec5cd8d48580939fcbe01546172b4 by Terry Sun <tesun@nvidia.com>:

remove redundant build dep

Merging this change closes #20025

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20025 from terryysun:terryysun/lhs_deadlock_avoidance cf45a819590ec5cd8d48580939fcbe01546172b4
",copybara-service[bot],2024-12-05 17:44:34+00:00,[],2024-12-10 11:13:36+00:00,2024-12-10 11:13:36+00:00,https://github.com/tensorflow/tensorflow/pull/82331,[],[],
2721023902,pull_request,closed,,Internal CI/CD change,"Internal CI/CD change
",copybara-service[bot],2024-12-05 17:36:12+00:00,['changm'],2024-12-11 22:18:32+00:00,2024-12-11 22:18:31+00:00,https://github.com/tensorflow/tensorflow/pull/82330,[],[],
2721008365,pull_request,closed,,[xla:gpu] Update custom call config WARN to VLOG,"[xla:gpu] Update custom call config WARN to VLOG
",copybara-service[bot],2024-12-05 17:28:10+00:00,['ezhulenev'],2024-12-05 18:16:24+00:00,2024-12-05 18:16:24+00:00,https://github.com/tensorflow/tensorflow/pull/82329,[],[],
2720968561,pull_request,closed,,[xla:collectives] NFC: Delete unused ScopedPlanAllocator,"[xla:collectives] NFC: Delete unused ScopedPlanAllocator

Latest NCCL fixed performance issues with CUDA graph tracing. Delete workaround that we don't need anymore.
",copybara-service[bot],2024-12-05 17:08:17+00:00,['ezhulenev'],2024-12-05 19:57:57+00:00,2024-12-05 19:57:56+00:00,https://github.com/tensorflow/tensorflow/pull/82327,[],[],
2720952428,pull_request,open,,Additionally add more logging to tfrt_graph_execution_state to help diagnose why,"Additionally add more logging to tfrt_graph_execution_state to help diagnose why
MLIR V1 bridge is not being used.

Reverts eb62b7c27330d5300e616d84b7c52b7bc027f62b
",copybara-service[bot],2024-12-05 17:00:41+00:00,[],2024-12-05 17:00:41+00:00,,https://github.com/tensorflow/tensorflow/pull/82326,[],[],
2720711076,pull_request,closed,,[XLA:CPU] Enable Convert test for F8E3M4,"[XLA:CPU] Enable Convert test for F8E3M4
",copybara-service[bot],2024-12-05 15:25:33+00:00,[],2024-12-05 19:05:26+00:00,2024-12-05 19:05:25+00:00,https://github.com/tensorflow/tensorflow/pull/82323,[],"[{'comment_id': 2520622503, 'issue_id': 2720711076, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82323/checks?check_run_id=33982783333) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 5, 15, 25, 38, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-05 15:25:38 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82323/checks?check_run_id=33982783333) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2720709184,pull_request,closed,,Remove if_oss from B100 references,"Remove if_oss from B100 references
",copybara-service[bot],2024-12-05 15:24:44+00:00,[],2024-12-05 17:42:14+00:00,2024-12-05 17:42:13+00:00,https://github.com/tensorflow/tensorflow/pull/82322,[],[],
2720692417,pull_request,open,,PR #19669: Replace custom free-threading flag by rules_python is_py_freethreaded in Nanobind,"PR #19669: Replace custom free-threading flag by rules_python is_py_freethreaded in Nanobind

Imported from GitHub PR https://github.com/openxla/xla/pull/19669

cc @hawkinsp 
Copybara import of the project:

--
70a8fa88a26285e007ffde950574a019618bcf94 by vfdev-5 <vfdev.5@gmail.com>:

Replace custom free-threading flag by rules_python is_py_freethreaded in Nanobind

Merging this change closes #19669

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19669 from vfdev-5:nanobind-use-rules-python-is_py_freethreaded-flag 70a8fa88a26285e007ffde950574a019618bcf94
",copybara-service[bot],2024-12-05 15:17:46+00:00,[],2024-12-05 15:17:46+00:00,,https://github.com/tensorflow/tensorflow/pull/82321,[],[],
2720683473,pull_request,closed,,PR #19669: Replace custom free-threading flag by rules_python is_py_freethreaded in Nanobind,"PR #19669: Replace custom free-threading flag by rules_python is_py_freethreaded in Nanobind

Imported from GitHub PR https://github.com/openxla/xla/pull/19669

cc @hawkinsp 
Copybara import of the project:

--
70a8fa88a26285e007ffde950574a019618bcf94 by vfdev-5 <vfdev.5@gmail.com>:

Replace custom free-threading flag by rules_python is_py_freethreaded in Nanobind

Merging this change closes #19669

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19669 from vfdev-5:nanobind-use-rules-python-is_py_freethreaded-flag 70a8fa88a26285e007ffde950574a019618bcf94
",copybara-service[bot],2024-12-05 15:14:35+00:00,[],2024-12-06 16:16:44+00:00,2024-12-06 16:16:43+00:00,https://github.com/tensorflow/tensorflow/pull/82320,[],[],
2720668404,pull_request,closed,,Reverts fd9471e7d48e8e86684c847c0e1897c76e737805,"Reverts fd9471e7d48e8e86684c847c0e1897c76e737805
",copybara-service[bot],2024-12-05 15:08:40+00:00,[],2024-12-05 15:47:18+00:00,2024-12-05 15:47:17+00:00,https://github.com/tensorflow/tensorflow/pull/82319,[],[],
2720602250,pull_request,closed,,[xla-auto-sharding] Add SolveRandom() baseline algorithm for a random sharding.,"[xla-auto-sharding] Add SolveRandom() baseline algorithm for a random sharding.

Notes:
- Returns the min-cost sharding strategy from `num_trials` i.i.d. trials.
- Each trial uniformly assigns each node to one of its sharding choices with equal probability, independent of all other node decisions.
- Specify algorithm used in `RunHeuristicSolver()` with a registered string name for now.
",copybara-service[bot],2024-12-05 14:42:00+00:00,[],2024-12-05 16:28:07+00:00,2024-12-05 16:28:05+00:00,https://github.com/tensorflow/tensorflow/pull/82318,[],[],
2720370837,pull_request,open,,Run sparse tests in presubmit,"Run sparse tests in presubmit
",copybara-service[bot],2024-12-05 13:06:23+00:00,[],2024-12-05 14:43:12+00:00,,https://github.com/tensorflow/tensorflow/pull/82315,[],[],
2720342925,pull_request,open,,Update references to JAX's GitHub repo,"Update references to JAX's GitHub repo

JAX has moved from https://github.com/google/jax to https://github.com/jax-ml/jax
",copybara-service[bot],2024-12-05 12:54:16+00:00,['jakeharmon8'],2024-12-05 12:54:17+00:00,,https://github.com/tensorflow/tensorflow/pull/82314,[],[],
2720323565,pull_request,closed,,Integrate LLVM at llvm/llvm-project@dd7a3d4d798e,"Integrate LLVM at llvm/llvm-project@dd7a3d4d798e

Updates LLVM usage to match
[dd7a3d4d798e](https://github.com/llvm/llvm-project/commit/dd7a3d4d798e)
",copybara-service[bot],2024-12-05 12:45:39+00:00,[],2024-12-05 15:09:17+00:00,2024-12-05 15:09:16+00:00,https://github.com/tensorflow/tensorflow/pull/82313,[],[],
2720288366,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 12:30:09+00:00,[],2024-12-05 12:30:09+00:00,,https://github.com/tensorflow/tensorflow/pull/82312,[],[],
2720098322,pull_request,closed,,PR #18616: [XLA:CPU][oneDNN] Refactor code that fuses Add operation with oneDNN primitives,"PR #18616: [XLA:CPU][oneDNN] Refactor code that fuses Add operation with oneDNN primitives

Imported from GitHub PR https://github.com/openxla/xla/pull/18616

This PR refactors the code that fuses add operation to matmul / convolution primitives. It removes usage of macros and separate templatized handlers for matmul and convolution cases.
Copybara import of the project:

--
68bcdf81a47fb0f753d837c034931094c5cd8017 by Akhil Goel <akhil.goel@intel.com>:

Refactor Add Handler

--
462890bb75f2fcea3fdc5966bfa7a2b8f94b255a by Akhil Goel <akhil.goel@intel.com>:

Address review comments

Merging this change closes #18616

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/18616 from Intel-tensorflow:akhil/conv_fusions_3_c 7e1082d1f5029bc53d7ad55e27e1ab5630a736a1
",copybara-service[bot],2024-12-05 11:06:13+00:00,[],2024-12-05 12:08:45+00:00,2024-12-05 12:08:43+00:00,https://github.com/tensorflow/tensorflow/pull/82311,[],"[{'comment_id': 2519996028, 'issue_id': 2720098322, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82311/checks?check_run_id=33968575771) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 5, 11, 6, 19, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-05 11:06:19 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82311/checks?check_run_id=33968575771) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2720091651,pull_request,closed,,[XLA:GPU] Extend atomic_rmw to support vector updates.,"[XLA:GPU] Extend atomic_rmw to support vector updates.
",copybara-service[bot],2024-12-05 11:03:11+00:00,['pifon2a'],2024-12-05 14:41:40+00:00,2024-12-05 14:41:39+00:00,https://github.com/tensorflow/tensorflow/pull/82310,[],[],
2720061434,pull_request,closed,,[XLA:GPU] Make VLOG explanation in SortRewriter more helpful.,"[XLA:GPU] Make VLOG explanation in SortRewriter more helpful.

Add the dtypes for which a CUB kernel is unavailable to the log output.
",copybara-service[bot],2024-12-05 10:49:42+00:00,['thomasjoerg'],2024-12-05 12:46:24+00:00,2024-12-05 12:46:23+00:00,https://github.com/tensorflow/tensorflow/pull/82309,[],[],
2720043055,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 10:41:34+00:00,[],2024-12-06 10:44:59+00:00,2024-12-06 10:44:58+00:00,https://github.com/tensorflow/tensorflow/pull/82308,[],[],
2720036370,pull_request,open,,[XLA:CPU] Implement 2D custom algorithm for strided transposed convolutions.,"[XLA:CPU] Implement 2D custom algorithm for strided transposed convolutions.


This extends the custom algorithm to cover 2D cases. Benchmarks show about 50 times better performance than the generic algorithm, detailed results:

name                                      old cpu/op   new cpu/op   delta
BM_Conv2DStrided/process_time             35.2ms  9%  34.3ms  6%     ~     (p=0.690 n=5+5)
BM_Conv2DTransposedStrided/process_time    8.25s  8%   0.03s  3%  -99.62%  (p=0.008 n=5+5)

name                                      old time/op  new time/op  delta
BM_Conv2DStrided/process_time             3.06ms 19%  2.88ms  6%     ~     (p=0.421 n=5+5)
BM_Conv2DTransposedStrided/process_time    415ms 12%     9ms  4%  -97.93%  (p=0.008 n=5+5)

Planned improvements of this algorithm:
- support feature_group_size > 1 (grouped convolution),
- parallel packing of the patches (second algorithm step),
- support the case with multiple input channels and output channels at the same time,
- explore input kernel rotation possibilities & perf impact,

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19913 from ROCm:fix_exp_log_lowering 3fa4914f90458a0285deb8801c5689421f945fe4
",copybara-service[bot],2024-12-05 10:38:35+00:00,[],2024-12-05 10:38:42+00:00,,https://github.com/tensorflow/tensorflow/pull/82307,[],"[{'comment_id': 2519932070, 'issue_id': 2720036370, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82307/checks?check_run_id=33967177427) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 12, 5, 10, 38, 41, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-12-05 10:38:41 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/82307/checks?check_run_id=33967177427) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2720032411,pull_request,closed,,Reland of PR #19571. Fix test FunctionalHloRunnerTest.ShardedAutotuningWorks,"Reland of PR #19571. Fix test FunctionalHloRunnerTest.ShardedAutotuningWorks

Reverts fe29bc62f24e2f68908b8c19642c9766bb49793d
",copybara-service[bot],2024-12-05 10:36:46+00:00,[],2024-12-09 14:57:48+00:00,2024-12-09 14:57:47+00:00,https://github.com/tensorflow/tensorflow/pull/82306,[],[],
2720029687,pull_request,closed,,[XLA:CPU] Add a Python extension for KernelRunner.,"[XLA:CPU] Add a Python extension for KernelRunner.
",copybara-service[bot],2024-12-05 10:35:40+00:00,[],2024-12-09 15:57:36+00:00,2024-12-09 15:57:35+00:00,https://github.com/tensorflow/tensorflow/pull/82305,[],[],
2719959406,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 10:12:09+00:00,[],2024-12-07 10:37:24+00:00,2024-12-07 10:37:23+00:00,https://github.com/tensorflow/tensorflow/pull/82304,[],[],
2719954611,pull_request,closed,,Fix an initialization order bug in se_gpu_pjrt_compiler.,"Fix an initialization order bug in se_gpu_pjrt_compiler.

`xla::Compiler` manages instances of `Compiler` that are registered statically.

`StreamExecutorGpuClient` used to get its `Compiler` instance during static initialization which might fail if the `Compiler` instance gets registered later.

As a fix we will get the needed `Compiler` instance during every compilation call.
",copybara-service[bot],2024-12-05 10:10:02+00:00,[],2024-12-05 14:14:49+00:00,2024-12-05 14:14:48+00:00,https://github.com/tensorflow/tensorflow/pull/82303,[],[],
2719944209,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 10:05:38+00:00,[],2024-12-09 13:14:58+00:00,2024-12-09 13:14:57+00:00,https://github.com/tensorflow/tensorflow/pull/82302,[],[],
2719930243,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 10:00:01+00:00,[],2024-12-06 06:23:54+00:00,2024-12-06 06:23:54+00:00,https://github.com/tensorflow/tensorflow/pull/82300,[],[],
2719916366,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19913 from ROCm:fix_exp_log_lowering 3fa4914f90458a0285deb8801c5689421f945fe4
",copybara-service[bot],2024-12-05 09:54:12+00:00,[],2024-12-05 12:00:19+00:00,2024-12-05 12:00:18+00:00,https://github.com/tensorflow/tensorflow/pull/82299,[],[],
2719911866,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 09:52:22+00:00,[],2024-12-05 09:52:22+00:00,,https://github.com/tensorflow/tensorflow/pull/82298,[],[],
2719908550,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 09:51:24+00:00,[],2024-12-05 09:51:24+00:00,,https://github.com/tensorflow/tensorflow/pull/82297,[],[],
2719907053,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 09:50:45+00:00,[],2024-12-06 04:50:02+00:00,2024-12-06 04:50:02+00:00,https://github.com/tensorflow/tensorflow/pull/82296,[],[],
2719906661,pull_request,closed,,Reverts f13c44149dba9518dc7f93b85342bcf72e5580fd,"Reverts f13c44149dba9518dc7f93b85342bcf72e5580fd
",copybara-service[bot],2024-12-05 09:50:34+00:00,['thomasjoerg'],2024-12-05 10:24:13+00:00,2024-12-05 10:24:11+00:00,https://github.com/tensorflow/tensorflow/pull/82295,[],[],
2719900899,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20153 from philipphack:u_fp8_rewriter_collectives_xla e2efa84143fe30c5c6b25132831a62707c2a8f75
",copybara-service[bot],2024-12-05 09:47:56+00:00,[],2024-12-05 12:26:56+00:00,2024-12-05 12:26:55+00:00,https://github.com/tensorflow/tensorflow/pull/82294,[],[],
2719896114,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 09:46:14+00:00,[],2024-12-05 13:15:35+00:00,2024-12-05 13:15:34+00:00,https://github.com/tensorflow/tensorflow/pull/82293,[],[],
2719893474,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 09:45:18+00:00,[],2024-12-06 05:32:41+00:00,2024-12-06 05:32:40+00:00,https://github.com/tensorflow/tensorflow/pull/82292,[],[],
2719890080,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19913 from ROCm:fix_exp_log_lowering 3fa4914f90458a0285deb8801c5689421f945fe4
",copybara-service[bot],2024-12-05 09:43:50+00:00,[],2024-12-05 11:41:45+00:00,2024-12-05 11:41:45+00:00,https://github.com/tensorflow/tensorflow/pull/82291,[],[],
2719888978,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 09:43:20+00:00,[],2024-12-06 10:35:09+00:00,2024-12-06 10:35:08+00:00,https://github.com/tensorflow/tensorflow/pull/82290,[],[],
2719876115,pull_request,closed,,Fix typos in documentation strings,"Hi, Team
I observed few typos in the documentation strings and I have fixed those typos so please do the needful. Thank you.

",Venkat6871,2024-12-05 09:38:05+00:00,['gbaned'],2024-12-06 18:17:20+00:00,2024-12-06 18:17:19+00:00,https://github.com/tensorflow/tensorflow/pull/82288,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small')]",[],
2719874007,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 09:37:09+00:00,[],2024-12-10 07:57:49+00:00,2024-12-10 07:57:48+00:00,https://github.com/tensorflow/tensorflow/pull/82287,[],[],
2719860570,pull_request,closed,,Update tensor_util_test.py for testBfloat16,"Currently the test for bfloat16 checks proto value by default in little endian.
Added support for s390x (big endian) as well.",Nayana-ibm,2024-12-05 09:31:11+00:00,['gbaned'],2024-12-09 10:14:58+00:00,2024-12-09 10:14:58+00:00,https://github.com/tensorflow/tensorflow/pull/82286,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small')]",[],
2719800352,pull_request,closed,,PR #19913: [ROCm] Do not use fast approximation for exp and log,"PR #19913: [ROCm] Do not use fast approximation for exp and log

Imported from GitHub PR https://github.com/openxla/xla/pull/19913

Error started occurring from this commit for exp https://github.com/openxla/xla/commit/6e9eefeec077f49c2b22bfeee8da537ed8517b22 (originally introduced here https://github.com/openxla/xla/commit/9b19353a30821fb990afa456a2a5e7fae71e9afc#diff-61ab646c9c3b8b0fc5ed1e9a62f535e9df5843adddd071250343f3bec48eacb6) and from this one https://github.com/openxla/xla/commit/53d533845f3c97d08a49e3d8589ec98c745ac09e for log.

Trying to compile following MLIR code:
```
HloModule module

ENTRY main {
      p0 = bf16[4] parameter(0)
      ROOT exp = bf16[4] exp(p0)
}
```
would result in:
```
UNKNOWN: <unknown>:0: error: loc(callsite(""wrapped_exponential"" at ""wrapped_exponential"")): failed to legalize operation 'math.exp'
<unknown>:0: note: loc(""wrapped_exponential""): called from
<unknown>:0: note: loc(callsite(""wrapped_exponential"" at ""wrapped_exponential"")): see current operation: %7 = ""math.exp""(%6) <{fastmath = #arith.fastmath<afn>}> : (bf16) -> bf16
```


Copybara import of the project:

--
616c10b5308cb827c593a89455fea4b772d6e870 by Milica Makevic <Milica.Makevic@amd.com>:

Do not use fast approximation for exp and log for ROCm

--
3fa4914f90458a0285deb8801c5689421f945fe4 by Milica Makevic <Milica.Makevic@amd.com>:

Add unit test for log and exp lowering on ROCm

Merging this change closes #19913

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19913 from ROCm:fix_exp_log_lowering 3fa4914f90458a0285deb8801c5689421f945fe4
",copybara-service[bot],2024-12-05 09:04:33+00:00,[],2024-12-05 11:03:56+00:00,2024-12-05 11:03:56+00:00,https://github.com/tensorflow/tensorflow/pull/82285,[],[],
2719696185,pull_request,closed,,Integrate LLVM at llvm/llvm-project@71ac1eb50955,"Integrate LLVM at llvm/llvm-project@71ac1eb50955

Updates LLVM usage to match
[71ac1eb50955](https://github.com/llvm/llvm-project/commit/71ac1eb50955)
",copybara-service[bot],2024-12-05 08:16:20+00:00,[],2024-12-05 11:31:53+00:00,2024-12-05 11:31:52+00:00,https://github.com/tensorflow/tensorflow/pull/82284,[],[],
2719693723,pull_request,closed,,Regenerate stubs with Mypy 1.13.0,"Regenerate stubs with Mypy 1.13.0
",copybara-service[bot],2024-12-05 08:15:01+00:00,[],2024-12-17 13:28:05+00:00,2024-12-17 13:28:02+00:00,https://github.com/tensorflow/tensorflow/pull/82283,[],[],
2719683283,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 08:09:50+00:00,[],2024-12-05 10:45:43+00:00,2024-12-05 10:45:42+00:00,https://github.com/tensorflow/tensorflow/pull/82282,[],[],
2719633176,pull_request,closed,,Adding dumping functionality for HloUnoptimizedSnapshot.,"Adding dumping functionality for HloUnoptimizedSnapshot.
",copybara-service[bot],2024-12-05 07:42:44+00:00,[],2024-12-05 13:27:28+00:00,2024-12-05 13:27:26+00:00,https://github.com/tensorflow/tensorflow/pull/82280,[],[],
2719601044,pull_request,closed,,Integrate Triton up to [a69ebfaa](https://github.com/openai/triton/commits/a69ebfaa0832281eabca71ee73f643b28dc034ec),"Integrate Triton up to [a69ebfaa](https://github.com/openai/triton/commits/a69ebfaa0832281eabca71ee73f643b28dc034ec)
",copybara-service[bot],2024-12-05 07:30:41+00:00,['gflegar'],2024-12-06 07:59:43+00:00,2024-12-06 07:59:43+00:00,https://github.com/tensorflow/tensorflow/pull/82279,[],[],
2719575445,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 07:20:11+00:00,[],2024-12-05 08:45:40+00:00,,https://github.com/tensorflow/tensorflow/pull/82278,[],[],
2719504604,pull_request,closed,,Create shim targets for most commonly used TSL headers in preparation for updating users,"Create shim targets for most commonly used TSL headers in preparation for updating users
",copybara-service[bot],2024-12-05 06:49:01+00:00,['ddunl'],2024-12-18 22:29:29+00:00,2024-12-18 22:29:28+00:00,https://github.com/tensorflow/tensorflow/pull/82277,[],[],
2719448340,pull_request,closed,,Introduce shape splitting into MSA.,"Introduce shape splitting into MSA.
",copybara-service[bot],2024-12-05 06:17:44+00:00,[],2025-01-17 08:54:33+00:00,2025-01-17 08:54:32+00:00,https://github.com/tensorflow/tensorflow/pull/82275,[],[],
2719404373,pull_request,open,,Add InferenceStats to Gviz conversion.,"Add InferenceStats to Gviz conversion.
",copybara-service[bot],2024-12-05 05:49:06+00:00,['cliveverghese'],2024-12-05 06:19:52+00:00,,https://github.com/tensorflow/tensorflow/pull/82274,[],[],
2719372527,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 05:23:23+00:00,[],2024-12-05 05:23:23+00:00,,https://github.com/tensorflow/tensorflow/pull/82273,[],[],
2719359390,pull_request,closed,,Map split dimensions for bitcast positions.,"Map split dimensions for bitcast positions.
",copybara-service[bot],2024-12-05 05:17:36+00:00,[],2025-01-24 21:23:11+00:00,2025-01-24 21:23:10+00:00,https://github.com/tensorflow/tensorflow/pull/82272,[],[],
2719331486,pull_request,closed,,[xla:collectives] NFC: Move AllReduce into Collectives API,"[xla:collectives] NFC: Move AllReduce into Collectives API
",copybara-service[bot],2024-12-05 05:04:34+00:00,['ezhulenev'],2024-12-05 08:29:00+00:00,2024-12-05 08:28:59+00:00,https://github.com/tensorflow/tensorflow/pull/82271,[],[],
2719293573,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-12-05 04:36:19+00:00,[],2024-12-05 06:32:55+00:00,2024-12-05 06:32:54+00:00,https://github.com/tensorflow/tensorflow/pull/82270,[],[],
2719232801,pull_request,closed,,"Add a helper function for ""applying"" plugin end 2 end.","Add a helper function for ""applying"" plugin end 2 end.
",copybara-service[bot],2024-12-05 03:39:52+00:00,['LukeBoyer'],2024-12-05 04:46:43+00:00,2024-12-05 04:46:42+00:00,https://github.com/tensorflow/tensorflow/pull/82269,[],[],
2719194301,pull_request,closed,,Add public API to load model from file or buffer,"Add public API to load model from file or buffer
",copybara-service[bot],2024-12-05 02:59:53+00:00,[],2024-12-05 17:09:01+00:00,2024-12-05 17:09:00+00:00,https://github.com/tensorflow/tensorflow/pull/82268,[],[],
2719185666,pull_request,closed,,[XLA:GPU] add execution tests for NCCL group with partially pipelined send/recv instructions,"[XLA:GPU] add execution tests for NCCL group with partially pipelined send/recv instructions
",copybara-service[bot],2024-12-05 02:51:22+00:00,[],2024-12-13 02:27:06+00:00,2024-12-13 02:27:05+00:00,https://github.com/tensorflow/tensorflow/pull/82267,[],[],
2719155006,pull_request,closed,,[xla:collectives] NFC: Move Group calls to GpuCollectives,"[xla:collectives] NFC: Move Group calls to GpuCollectives
",copybara-service[bot],2024-12-05 02:20:18+00:00,['ezhulenev'],2024-12-05 03:04:52+00:00,2024-12-05 03:04:51+00:00,https://github.com/tensorflow/tensorflow/pull/82266,[],[],
2719132840,pull_request,closed,,Fix wheel creation logic when pywrap rules are used,"Fix wheel creation logic when pywrap rules are used
",copybara-service[bot],2024-12-05 01:56:08+00:00,['vam-google'],2024-12-05 05:22:11+00:00,2024-12-05 05:22:10+00:00,https://github.com/tensorflow/tensorflow/pull/82265,[],[],
2719131575,pull_request,closed,,Add an interface to MSA to allow post allocation transformation on hlo module.,"Add an interface to MSA to allow post allocation transformation on hlo module.

The transformation is provided as a lambda to MSA. It applies to all instructions inside non-fusion computations that are not converted to async and their inputs are not in alternate memory:
1) Is allowed to mark a set of instruction for removal
2) Is allowed to change existing instructions of the graph
3) Is NOT allowed to add new instructions to the graph
(note: It is up to the transformation to make sure that changes to the graph are semantics-preserving.)

The lambda then returns a struct containing the set of to be deleted instructions and a map of old HloUse to new HloUse. This map is used to fix the allocation sequence in MSA after the transformation runs.
",copybara-service[bot],2024-12-05 01:54:41+00:00,[],2025-01-07 04:15:45+00:00,2025-01-07 04:15:44+00:00,https://github.com/tensorflow/tensorflow/pull/82264,[],[],
2719086562,pull_request,closed,,Avoid using getCurrentVersion when re-serializing XlaCallModule ops,"Avoid using getCurrentVersion when re-serializing XlaCallModule ops
",copybara-service[bot],2024-12-05 01:04:14+00:00,['GleasonK'],2024-12-05 18:58:55+00:00,2024-12-05 18:58:54+00:00,https://github.com/tensorflow/tensorflow/pull/82263,[],[],
2719082875,pull_request,closed,,Only return the valid part of PCI Bus ID when constructing the C++ string.,"Only return the valid part of PCI Bus ID when constructing the C++ string.

This avoids having two null termination characters in the returned string when PCI Bus ID is shorter than kBufferSize (which is almost always the case).
",copybara-service[bot],2024-12-05 00:59:48+00:00,[],2024-12-05 22:11:43+00:00,2024-12-05 22:11:43+00:00,https://github.com/tensorflow/tensorflow/pull/82262,[],[],
2719082219,pull_request,closed,,"Change XlaCallModuleLoader to take module string by reference, avoid string copies when possible.","Change XlaCallModuleLoader to take module string by reference, avoid string copies when possible.
",copybara-service[bot],2024-12-05 00:59:00+00:00,['GleasonK'],2024-12-05 17:58:03+00:00,2024-12-05 17:58:01+00:00,https://github.com/tensorflow/tensorflow/pull/82261,[],[],
2719080249,pull_request,closed,,IFRT Proxy: Make `Executable::Delete()` and most `::Execute` async.,"IFRT Proxy: Make `Executable::Delete()` and most `::Execute` async.

The first `Execute()` is synchronous; we cache the output spec and use it for subsequent executes.

I believe `executable_test.cc` (and several other tests in the codebase, including the server-side `ifrt_backend_test.cc`) can be rewritten to be more readable with less boilerplate related to gMock. This CL does not make the situation worse, but I may send in separate CLs for other refactoring.
",copybara-service[bot],2024-12-05 00:56:51+00:00,[],2024-12-05 20:10:29+00:00,2024-12-05 20:10:27+00:00,https://github.com/tensorflow/tensorflow/pull/82260,[],[],
2719062548,pull_request,open,,Remove obsolete TODOs and the ones associated with closed bug  in platforms/xla/*,"Remove obsolete TODOs and the ones associated with closed bug  in platforms/xla/*
",copybara-service[bot],2024-12-05 00:37:10+00:00,[],2024-12-05 00:37:10+00:00,,https://github.com/tensorflow/tensorflow/pull/82259,[],[],
2719060170,pull_request,closed,,Remove TENSORFLOW_USE_ROCM #ifdefs in command_buffer_thunk_test.cc.,"Remove TENSORFLOW_USE_ROCM #ifdefs in command_buffer_thunk_test.cc.
",copybara-service[bot],2024-12-05 00:34:30+00:00,[],2024-12-05 23:52:11+00:00,2024-12-05 23:52:10+00:00,https://github.com/tensorflow/tensorflow/pull/82258,[],[],
2719055358,pull_request,open,,[XLA:GPU:Rocm] Fix wavefront size on gfx10+,"[XLA:GPU:Rocm] Fix wavefront size on gfx10+

Newer GPUs compile to wave32 by default but `hipDeviceAttributeWarpSize` will return 64 causing mismatches between the GPU's execution mode and our compiled code.

Let's make sure that our warp size matches what the HW is actually using.
",copybara-service[bot],2024-12-05 00:29:16+00:00,['majnemer'],2024-12-05 00:29:18+00:00,,https://github.com/tensorflow/tensorflow/pull/82257,[],[],
2719050852,pull_request,open,,PR #19699: Explicit stream annotation: Set ExecutionStreamId based on frontend attribute,"PR #19699: Explicit stream annotation: Set ExecutionStreamId based on frontend attribute

Imported from GitHub PR https://github.com/openxla/xla/pull/19699

This PR picks up the stream annotation frontend attribute on async methods and assigns the matching ExecutionStreamId.

This PR is another part of breaking up PR #17982.
Copybara import of the project:

--
dc175b4bc8265d65d35c5703464f606baeadf98e by chaserileyroberts <chaser@nvidia.com>:

Explicit streams are picked up in stream assignment.

Merging this change closes #19699

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/19699 from chaserileyroberts:chase/runtime_explicit_streams dc175b4bc8265d65d35c5703464f606baeadf98e
",copybara-service[bot],2024-12-05 00:24:36+00:00,[],2024-12-05 13:24:05+00:00,,https://github.com/tensorflow/tensorflow/pull/82256,[],[],
2719041161,pull_request,closed,,Remove obsolete TODOs and the ones associated with closed bug  in third_party/tensorflow/compiler/*,"Remove obsolete TODOs and the ones associated with closed bug  in third_party/tensorflow/compiler/*
",copybara-service[bot],2024-12-05 00:15:02+00:00,[],2024-12-06 00:16:54+00:00,2024-12-06 00:16:53+00:00,https://github.com/tensorflow/tensorflow/pull/82255,[],[],
2719035645,pull_request,closed,,Cleanup. Use the unified `GatherScatterDims` for operand pass-through dims in gather/scatter instructions.,"Cleanup. Use the unified `GatherScatterDims` for operand pass-through dims in gather/scatter instructions.

No behavior change.
",copybara-service[bot],2024-12-05 00:09:58+00:00,[],2024-12-05 08:36:37+00:00,2024-12-05 08:36:35+00:00,https://github.com/tensorflow/tensorflow/pull/82254,[],[],
2719033410,pull_request,open,,Remove creation of libcuda.so symlink for the stub libcuda.so.1.,"Remove creation of libcuda.so symlink for the stub libcuda.so.1.
",copybara-service[bot],2024-12-05 00:07:36+00:00,[],2024-12-05 22:42:14+00:00,,https://github.com/tensorflow/tensorflow/pull/82253,[],[],
2719025631,pull_request,closed,,Remove #if TENSORFLOW_USE_ROCM from gpu_executable.cc.,"Remove #if TENSORFLOW_USE_ROCM from gpu_executable.cc.

Reverts 5c36415e4bafd2ef7ed219fae423d3b79ba017df
",copybara-service[bot],2024-12-05 00:00:20+00:00,[],2024-12-05 23:05:19+00:00,2024-12-05 23:05:19+00:00,https://github.com/tensorflow/tensorflow/pull/82252,[],[],
2719018771,pull_request,closed,,Delete HloUnaryInstruction used in CreateUnary. Instead make result_accuracy a Rare field in HloInstruction and optionally set the field in CreateUnary.,"Delete HloUnaryInstruction used in CreateUnary. Instead make result_accuracy a Rare field in HloInstruction and optionally set the field in CreateUnary.
",copybara-service[bot],2024-12-04 23:53:53+00:00,[],2024-12-07 02:16:32+00:00,2024-12-07 02:16:31+00:00,https://github.com/tensorflow/tensorflow/pull/82251,[],[],
2718966711,pull_request,closed,,Correct test for force snappy compression.,"Correct test for force snappy compression.
",copybara-service[bot],2024-12-04 23:12:05+00:00,[],2024-12-06 00:03:35+00:00,2024-12-06 00:03:34+00:00,https://github.com/tensorflow/tensorflow/pull/82250,[],[],
2718955816,pull_request,closed,,Integrate LLVM at llvm/llvm-project@ce0f11325e0c,"Integrate LLVM at llvm/llvm-project@ce0f11325e0c

Updates LLVM usage to match
[ce0f11325e0c](https://github.com/llvm/llvm-project/commit/ce0f11325e0c)
",copybara-service[bot],2024-12-04 23:02:57+00:00,[],2024-12-05 05:44:57+00:00,2024-12-05 05:44:56+00:00,https://github.com/tensorflow/tensorflow/pull/82249,[],[],
2718945667,pull_request,closed,,Remove #if GOOGLE_CUDA from matmul_utils.cc.,"Remove #if GOOGLE_CUDA from matmul_utils.cc.
",copybara-service[bot],2024-12-04 22:54:40+00:00,[],2024-12-05 22:03:41+00:00,2024-12-05 22:03:39+00:00,https://github.com/tensorflow/tensorflow/pull/82248,[],[],
2718942648,pull_request,closed,,Create Hlo Stats Tool,"Create Hlo Stats Tool
",copybara-service[bot],2024-12-04 22:52:06+00:00,['zzzaries'],2024-12-05 02:14:17+00:00,2024-12-05 02:14:16+00:00,https://github.com/tensorflow/tensorflow/pull/82247,[],[],
2718904569,pull_request,closed,,"Replace usage of `absl::InlinedVector<int64_t, 1>` with `DimensionVector` for gather/scatter dimensions in hlo_sharding_util.","Replace usage of `absl::InlinedVector<int64_t, 1>` with `DimensionVector` for gather/scatter dimensions in hlo_sharding_util.
",copybara-service[bot],2024-12-04 22:21:53+00:00,[],2024-12-05 05:09:48+00:00,2024-12-05 05:09:47+00:00,https://github.com/tensorflow/tensorflow/pull/82246,[],[],
2718892895,pull_request,closed,,[xla:collectives] NFC: Move Config and DeviceRank from NcclApi to Collectives API,"[xla:collectives] NFC: Move Config and DeviceRank from NcclApi to Collectives API
",copybara-service[bot],2024-12-04 22:14:09+00:00,['ezhulenev'],2024-12-05 01:43:39+00:00,2024-12-05 01:43:32+00:00,https://github.com/tensorflow/tensorflow/pull/82245,[],[],
2718891408,pull_request,closed,,[xla:collectives] NFC: Move all NCCL collectives to Collectives API,"[xla:collectives] NFC: Move all NCCL collectives to Collectives API
",copybara-service[bot],2024-12-04 22:13:00+00:00,['ezhulenev'],2024-12-05 09:35:46+00:00,2024-12-05 09:35:46+00:00,https://github.com/tensorflow/tensorflow/pull/82244,[],[],
2718888211,pull_request,closed,,"Added interface ""MatchTrivialLoopRange"" to while_loop_analysis to get the range for the induction variable of a loop.","Added interface ""MatchTrivialLoopRange"" to while_loop_analysis to get the range for the induction variable of a loop.
",copybara-service[bot],2024-12-04 22:11:02+00:00,[],2024-12-06 02:41:19+00:00,2024-12-06 02:41:19+00:00,https://github.com/tensorflow/tensorflow/pull/82243,[],[],
2718884019,pull_request,open,,Add Less Op legalization and test data.,"Add Less Op legalization and test data.

Reverts 1c27e02524eda1031728b0a0c00fbf3c9be93248
",copybara-service[bot],2024-12-04 22:08:04+00:00,[],2024-12-04 22:08:04+00:00,,https://github.com/tensorflow/tensorflow/pull/82242,[],[],
2718866632,pull_request,closed,,PR #20153: Delete Exchange of Collectives and Dequantization in GEMM Rewriter,"PR #20153: Delete Exchange of Collectives and Dequantization in GEMM Rewriter

Imported from GitHub PR https://github.com/openxla/xla/pull/20153

Removes collectives from the set of ops that can be exchanged with dequantization in the GEMM rewriter.
Copybara import of the project:

--
e2efa84143fe30c5c6b25132831a62707c2a8f75 by Philipp Hack <phack@nvidia.com>:

Removes collectives from the set of ops exchanged with dequantization in the GEMM rewriter.

Merging this change closes #20153

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/20153 from philipphack:u_fp8_rewriter_collectives_xla e2efa84143fe30c5c6b25132831a62707c2a8f75
",copybara-service[bot],2024-12-04 21:55:53+00:00,[],2024-12-05 11:48:08+00:00,2024-12-05 11:48:07+00:00,https://github.com/tensorflow/tensorflow/pull/82241,[],[],
2718856951,pull_request,closed,,Add CPU specific passes for hlo-opt tool.,"Add CPU specific passes for hlo-opt tool.
",copybara-service[bot],2024-12-04 21:49:35+00:00,[],2024-12-09 21:09:41+00:00,2024-12-09 21:09:40+00:00,https://github.com/tensorflow/tensorflow/pull/82240,[],[],
2718807225,pull_request,closed,,Add support for Pad operation in Hhost_offload_utils::GetPredecessors().,"Add support for Pad operation in Hhost_offload_utils::GetPredecessors().
",copybara-service[bot],2024-12-04 21:18:46+00:00,[],2024-12-05 14:31:41+00:00,2024-12-05 14:31:40+00:00,https://github.com/tensorflow/tensorflow/pull/82239,[],[],
2718803642,pull_request,closed,,Add support for bitcasts that add a degenerate majormost dimension when HostOffloadLegalize moves copies out of host-memory-only offloading.,"Add support for bitcasts that add a degenerate majormost dimension when HostOffloadLegalize moves copies out of host-memory-only offloading.
",copybara-service[bot],2024-12-04 21:16:17+00:00,[],2024-12-05 10:32:02+00:00,2024-12-05 10:32:01+00:00,https://github.com/tensorflow/tensorflow/pull/82238,[],[],
2718801591,pull_request,closed,,Fix wrong index when inserting a copy from host to a call's parameter,"Fix wrong index when inserting a copy from host to a call's parameter
",copybara-service[bot],2024-12-04 21:15:02+00:00,[],2025-01-13 21:37:28+00:00,2025-01-13 21:37:27+00:00,https://github.com/tensorflow/tensorflow/pull/82237,[],[],
2718784867,pull_request,closed,,Reverts 5c36415e4bafd2ef7ed219fae423d3b79ba017df,"Reverts 5c36415e4bafd2ef7ed219fae423d3b79ba017df
",copybara-service[bot],2024-12-04 21:05:03+00:00,[],2024-12-05 22:25:07+00:00,2024-12-05 22:25:06+00:00,https://github.com/tensorflow/tensorflow/pull/82236,[],[],
2718761865,pull_request,closed,,[XLA:GPU][Emitters] Create `xla_ops` dialect for the platform-independent ops.,"[XLA:GPU][Emitters] Create `xla_ops` dialect for the platform-independent ops.
",copybara-service[bot],2024-12-04 20:50:52+00:00,['pifon2a'],2024-12-05 13:51:25+00:00,2024-12-05 13:51:25+00:00,https://github.com/tensorflow/tensorflow/pull/82235,[],[],
2718750057,pull_request,closed,,Fix some *_main deps to only appear on xla_test targets.,"Fix some *_main deps to only appear on xla_test targets.
",copybara-service[bot],2024-12-04 20:43:40+00:00,[],2024-12-04 23:37:10+00:00,2024-12-04 23:37:09+00:00,https://github.com/tensorflow/tensorflow/pull/82234,[],[],
2718729099,pull_request,closed,,[xla:collectives] Move NCCL buffer registration to base Communicator Api,"[xla:collectives] Move NCCL buffer registration to base Communicator Api
",copybara-service[bot],2024-12-04 20:30:32+00:00,['ezhulenev'],2024-12-05 06:03:07+00:00,2024-12-05 06:03:07+00:00,https://github.com/tensorflow/tensorflow/pull/82233,[],[],
2718714956,pull_request,closed,,[FuncGraph] Micro-optimize `as_default()` method.,"[FuncGraph] Micro-optimize `as_default()` method.

Profiling shows that `FuncGraph.as_default()` takes approximately 60us per call, much of which is in reevaluating the `@tf_contextlib.contextmanager` decorator on the local function. We can hoist this out to a top-level function. and pass captures explicitly, to ensure we pay this cost only once.
",copybara-service[bot],2024-12-04 20:22:26+00:00,[],2024-12-06 23:39:13+00:00,2024-12-06 23:39:13+00:00,https://github.com/tensorflow/tensorflow/pull/82232,[],[],
2718709080,pull_request,closed,,Reverts 1c27e02524eda1031728b0a0c00fbf3c9be93248,"Reverts 1c27e02524eda1031728b0a0c00fbf3c9be93248
",copybara-service[bot],2024-12-04 20:19:07+00:00,[],2024-12-04 22:13:22+00:00,2024-12-04 22:13:21+00:00,https://github.com/tensorflow/tensorflow/pull/82231,[],[],
2718685411,pull_request,closed,,[xla-auto-sharding] Add call path for non-MIP heuristic solvers.,"[xla-auto-sharding] Add call path for non-MIP heuristic solvers.

Notes:
- Add public `RunHeuristicSolver()` executor function.
- Add `SolveTrivial()` baseline that assigns all nodes to their first sharding strategy. If infeasible (e.g., violated the peak-memory constraint), output a negative cost encoding the violation code.
",copybara-service[bot],2024-12-04 20:05:55+00:00,[],2024-12-04 21:29:46+00:00,2024-12-04 21:29:44+00:00,https://github.com/tensorflow/tensorflow/pull/82230,[],[],
2718680159,pull_request,closed,,[XLA:GPU] Fix ASAN test failure in layout_assignment_test.,"[XLA:GPU] Fix ASAN test failure in layout_assignment_test.

The temporary DeviceDescription created by GetDeviceDescription() was going out of scope too early.  This was causing ASAN failures.
",copybara-service[bot],2024-12-04 20:02:59+00:00,['majnemer'],2024-12-04 21:10:51+00:00,2024-12-04 21:10:49+00:00,https://github.com/tensorflow/tensorflow/pull/82229,[],[],
2718677941,pull_request,closed,,Add function to convert Multi XSpace to InferenceStats.,"Add function to convert Multi XSpace to InferenceStats.
",copybara-service[bot],2024-12-04 20:01:45+00:00,['cliveverghese'],2024-12-05 08:19:46+00:00,2024-12-05 08:19:46+00:00,https://github.com/tensorflow/tensorflow/pull/82228,[],[],
