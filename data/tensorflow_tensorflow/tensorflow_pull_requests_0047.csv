id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2395002972,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:34:45+00:00,[],2024-07-10 14:24:26+00:00,2024-07-10 14:24:25+00:00,https://github.com/tensorflow/tensorflow/pull/71003,[],[],
2395002770,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:34:40+00:00,[],2024-07-10 05:24:25+00:00,,https://github.com/tensorflow/tensorflow/pull/71002,[],[],
2395001807,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:34:14+00:00,[],2024-07-08 08:34:14+00:00,,https://github.com/tensorflow/tensorflow/pull/71001,[],[],
2394999118,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:32:53+00:00,[],2024-07-10 04:06:23+00:00,2024-07-10 04:06:22+00:00,https://github.com/tensorflow/tensorflow/pull/71000,[],[],
2394998411,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:32:30+00:00,[],2024-07-12 10:10:04+00:00,2024-07-12 10:10:03+00:00,https://github.com/tensorflow/tensorflow/pull/70999,[],[],
2394997242,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:31:52+00:00,[],2024-07-10 08:46:43+00:00,2024-07-10 08:46:41+00:00,https://github.com/tensorflow/tensorflow/pull/70998,[],[],
2394996452,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:31:27+00:00,[],2024-07-09 04:19:54+00:00,2024-07-09 04:19:53+00:00,https://github.com/tensorflow/tensorflow/pull/70997,[],[],
2394996101,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:31:17+00:00,[],2024-07-10 04:25:29+00:00,2024-07-10 04:25:28+00:00,https://github.com/tensorflow/tensorflow/pull/70996,[],[],
2394995690,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:31:03+00:00,[],2024-07-09 07:30:33+00:00,2024-07-09 07:30:32+00:00,https://github.com/tensorflow/tensorflow/pull/70995,[],[],
2394995264,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:30:50+00:00,[],2024-07-08 08:30:50+00:00,,https://github.com/tensorflow/tensorflow/pull/70994,[],[],
2394992040,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14478 from apivovarov:negative_zero 70add58707b9f773c14b08c9143e1ca5b34fc4c5
",copybara-service[bot],2024-07-08 08:29:15+00:00,[],2024-07-08 11:15:58+00:00,,https://github.com/tensorflow/tensorflow/pull/70993,[],[],
2394989055,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:27:42+00:00,[],2024-07-09 08:43:30+00:00,,https://github.com/tensorflow/tensorflow/pull/70992,[],[],
2394987903,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:27:08+00:00,[],2024-07-08 08:27:08+00:00,,https://github.com/tensorflow/tensorflow/pull/70991,[],[],
2394985247,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:25:58+00:00,[],2024-07-08 08:25:58+00:00,,https://github.com/tensorflow/tensorflow/pull/70990,[],[],
2394982472,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:24:50+00:00,[],2024-07-08 09:26:00+00:00,,https://github.com/tensorflow/tensorflow/pull/70989,[],[],
2394977779,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:22:46+00:00,[],2024-07-10 07:25:39+00:00,2024-07-10 07:25:39+00:00,https://github.com/tensorflow/tensorflow/pull/70988,[],[],
2394975115,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:21:32+00:00,[],2024-07-08 09:03:03+00:00,,https://github.com/tensorflow/tensorflow/pull/70987,[],[],
2394972064,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:20:10+00:00,[],2024-07-08 08:20:10+00:00,,https://github.com/tensorflow/tensorflow/pull/70986,[],[],
2394971749,pull_request,open,,Compile to PTX with Libnvptxcompiler if available,"Compile to PTX with Libnvptxcompiler if available

This enables library compilation via libnvptxcompiler by default - for all builds that support it.

libnvptxcompiler is the library version of ptxas and can replace all the usages of ptxas.
",copybara-service[bot],2024-07-08 08:20:00+00:00,[],2024-07-08 08:20:00+00:00,,https://github.com/tensorflow/tensorflow/pull/70985,[],[],
2394965564,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:17:12+00:00,[],2024-07-08 09:01:55+00:00,,https://github.com/tensorflow/tensorflow/pull/70984,[],[],
2394964018,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:16:25+00:00,[],2024-07-08 08:16:25+00:00,,https://github.com/tensorflow/tensorflow/pull/70983,[],[],
2394960667,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:15:01+00:00,[],2024-07-08 08:57:27+00:00,,https://github.com/tensorflow/tensorflow/pull/70982,[],[],
2394956518,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:13:15+00:00,[],2024-07-08 08:13:15+00:00,,https://github.com/tensorflow/tensorflow/pull/70981,[],[],
2394949150,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:09:50+00:00,[],2024-07-08 08:59:52+00:00,,https://github.com/tensorflow/tensorflow/pull/70980,[],[],
2394945920,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:08:24+00:00,[],2024-07-08 10:23:23+00:00,2024-07-08 10:23:22+00:00,https://github.com/tensorflow/tensorflow/pull/70979,[],[],
2394939388,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 08:05:14+00:00,[],2024-07-09 06:13:05+00:00,2024-07-09 06:13:04+00:00,https://github.com/tensorflow/tensorflow/pull/70978,[],[],
2394932063,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14477 from apivovarov:cpu_hlo_runner_main a0d2129bfe74f2f9133f9e1c6b04e06cea6d0e5d
",copybara-service[bot],2024-07-08 08:01:37+00:00,[],2024-07-08 10:15:56+00:00,2024-07-08 10:15:55+00:00,https://github.com/tensorflow/tensorflow/pull/70977,[],[],
2394900964,pull_request,closed,,PR #14477: Allow to build multihost_hlo_runner for CPU backend,"PR #14477: Allow to build multihost_hlo_runner for CPU backend

Imported from GitHub PR https://github.com/openxla/xla/pull/14477

Currently, Bazel skips building `multihost_hlo_runner:hlo_runner_main` on CPU because the target is tagged with `tf_gpu_tests_tags`.

This tag should only be applied to the dedicated `hlo_runner_main_gpu` target.

The regular `hlo_runner_main` works fine on CPU (when `--xla_force_host_platform_device_count=N` is used)

@bchetioui @ddunl @beckerhe Can you have a look?
Copybara import of the project:

--
a0d2129bfe74f2f9133f9e1c6b04e06cea6d0e5d by Alexander Pivovarov <pivovaa@amazon.com>:

Allow to build multihost_hlo_runner for CPU backend

Merging this change closes #14477

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14477 from apivovarov:cpu_hlo_runner_main a0d2129bfe74f2f9133f9e1c6b04e06cea6d0e5d
",copybara-service[bot],2024-07-08 07:46:04+00:00,[],2024-07-08 08:51:13+00:00,2024-07-08 08:51:12+00:00,https://github.com/tensorflow/tensorflow/pull/70976,[],[],
2394870972,pull_request,closed,,Add direct legalizations for binary bitwise ops. Mark tfl bitwise/logical binary ops as broadcastable.,"Add direct legalizations for binary bitwise ops. Mark tfl bitwise/logical binary ops as broadcastable.
",copybara-service[bot],2024-07-08 07:31:04+00:00,['LukeBoyer'],2024-08-16 09:14:15+00:00,2024-08-16 09:05:04+00:00,https://github.com/tensorflow/tensorflow/pull/70975,[],[],
2394843712,pull_request,open,,Add FuseBroadcastIntoFollowingBinary pass to tfl-optimize,"Add FuseBroadcastIntoFollowingBinary pass to tfl-optimize
",copybara-service[bot],2024-07-08 07:17:08+00:00,[],2024-07-08 07:17:08+00:00,,https://github.com/tensorflow/tensorflow/pull/70974,[],[],
2394755505,pull_request,closed,,PR #14478: IsNonNegative(constant(-0.0)) should be false,"PR #14478: IsNonNegative(constant(-0.0)) should be false

Imported from GitHub PR https://github.com/openxla/xla/pull/14478

Currently `AlgebraicSimplifierVisitor::IsNonNegative` returns true for `Constant(-0.0)`.

Why it is a problem.

Particular optimization patterns should only be applied when IsNonNegative is true.
e.g.
```
y = sqrt(x) * sqrt(x)
can be simplified to 
y = x , when x >=0
```
```
if x is -0.0 the results are different:
sqrt(-0.0) = -0.0 =>
y = sqrt(-0.0) * sqrt(-0.0) = 0.0

After simplification - different result
y = x = -0.0

if later we have smth like 1/y - the results will be completely different +inf and -inf
```

Another example
```
y = power(x, 0.5) can be simplified to y = sqrt(x)
but
power(-0.0, 0.5) = 0.0
sqrt(-0.0) = -0.0
```
Results are different too.

in C++ `0.0` is equal to `-0.0`.
Simple check for non-negativity `x >= 0.0` returns True for `-0.0`

To distinguish between `-0.0` and `0.0` we can use `std::signbit`.

Adrian, what you think? @akuegel 
Copybara import of the project:

--
70add58707b9f773c14b08c9143e1ca5b34fc4c5 by Alexander Pivovarov <pivovaa@amazon.com>:

IsNonNegative(constant(-0.0)) should be false

Merging this change closes #14478

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14478 from apivovarov:negative_zero 70add58707b9f773c14b08c9143e1ca5b34fc4c5
",copybara-service[bot],2024-07-08 06:27:38+00:00,[],2024-07-08 11:08:57+00:00,2024-07-08 11:08:57+00:00,https://github.com/tensorflow/tensorflow/pull/70973,[],"[{'comment_id': 2213132850, 'issue_id': 2394755505, 'author': 'review-notebook-app[bot]', 'body': 'Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/70973""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> \n\n See visual diffs & provide feedback on Jupyter Notebooks. \n\n---\n\n <i>Powered by <a href=\'https://www.reviewnb.com/?utm_source=gh\'>ReviewNB</a></i>', 'created_at': datetime.datetime(2024, 7, 8, 6, 27, 44, tzinfo=datetime.timezone.utc)}]","review-notebook-app[bot] on (2024-07-08 06:27:44 UTC): Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/tensorflow/tensorflow/pull/70973""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 See visual diffs & provide feedback on Jupyter Notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>

"
2394731937,pull_request,closed,,Revert: Fix 3 DeadCode findings:,"Revert: Fix 3 DeadCode findings:
* DelayKernelIsSupported appears to be dead and not tested.
* LaunchDelayKernel appears to be dead and not tested.
* UnsupportedGpuFeature appears to be dead and not tested.

Reverts 26efe10962df174862e0f4e426932b8e5e2a63b5
",copybara-service[bot],2024-07-08 06:14:35+00:00,['akuegel'],2024-07-08 07:35:11+00:00,2024-07-08 07:35:10+00:00,https://github.com/tensorflow/tensorflow/pull/70972,[],[],
2394727743,pull_request,open,,Add mlir test cases for broadcasting binary bitwise ops.,"Add mlir test cases for broadcasting binary bitwise ops.
",copybara-service[bot],2024-07-08 06:12:21+00:00,['LukeBoyer'],2024-07-08 06:12:22+00:00,,https://github.com/tensorflow/tensorflow/pull/70971,[],[],
2394682612,pull_request,open,,Add flax based source model registry. Allow for selective import of registries for speed.,"Add flax based source model registry. Allow for selective import of registries for speed.

Also:
* Add tag parameter to jax build source
* Rename filter arg to match other files
",copybara-service[bot],2024-07-08 05:40:39+00:00,['LukeBoyer'],2024-07-08 05:40:40+00:00,,https://github.com/tensorflow/tensorflow/pull/70970,[],[],
2394648962,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 05:13:03+00:00,[],2024-07-08 05:13:03+00:00,,https://github.com/tensorflow/tensorflow/pull/70969,[],[],
2394638883,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-08 05:04:44+00:00,[],2024-07-08 05:04:44+00:00,,https://github.com/tensorflow/tensorflow/pull/70968,[],[],
2394502107,pull_request,closed,,Use absl::bit_width and absl::countr_one to compute the number of binary digits and the position of the rightmost zero bit in a number.,"Use absl::bit_width and absl::countr_one to compute the number of binary digits and the position of the rightmost zero bit in a number.

This avoids round tripping through floating point types and is a bit easier to understand.
",copybara-service[bot],2024-07-08 03:10:14+00:00,['majnemer'],2024-07-09 02:39:55+00:00,2024-07-09 02:31:06+00:00,https://github.com/tensorflow/tensorflow/pull/70967,[],"[{'comment_id': 2216291944, 'issue_id': 2394502107, 'author': 'Thedollbaby2024', 'body': '> Use absl::bit_width and absl::countr_one to compute the number of binary digits and the position of the rightmost zero bit in a number.\r\n> \r\n> This avoids round tripping through floating point types and is a bit easier to understand.\r\n\r\n[apex_api.pdf](https://github.com/user-attachments/files/16136397/apex_api.pdf)\r\n\r\n#70905', 'created_at': datetime.datetime(2024, 7, 9, 2, 39, 54, tzinfo=datetime.timezone.utc)}]","Thedollbaby2024 on (2024-07-09 02:39:54 UTC): [apex_api.pdf](https://github.com/user-attachments/files/16136397/apex_api.pdf)

#70905

"
2394251870,pull_request,closed,,Make stablehlo tests private,"Make stablehlo tests private
",copybara-service[bot],2024-07-07 22:39:29+00:00,['LukeBoyer'],2024-07-09 02:16:49+00:00,2024-07-09 02:16:49+00:00,https://github.com/tensorflow/tensorflow/pull/70965,[],[],
2394251335,pull_request,open,,"Add ""base_convert_flags"" arg to convert.py","Add ""base_convert_flags"" arg to convert.py
",copybara-service[bot],2024-07-07 22:37:44+00:00,['LukeBoyer'],2024-07-08 05:40:14+00:00,,https://github.com/tensorflow/tensorflow/pull/70964,[],[],
2394198874,pull_request,closed,,[xla:cpu] Optimize for launching host kernel once,"[xla:cpu] Optimize for launching host kernel once

name                                     old cpu/op   new cpu/op   delta
BM_SelectAndScatterF32/128/process_time   702µs ± 1%   608µs ± 4%  -13.39%
BM_SelectAndScatterF32/256/process_time  2.74ms ± 2%  2.34ms ± 2%  -14.66%
BM_SelectAndScatterF32/512/process_time  11.2ms ± 3%   9.6ms ± 3%  -14.42%
",copybara-service[bot],2024-07-07 20:07:20+00:00,['ezhulenev'],2024-07-08 07:41:48+00:00,2024-07-08 07:41:47+00:00,https://github.com/tensorflow/tensorflow/pull/70963,[],[],
2394149876,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-07 17:42:43+00:00,[],2024-07-07 17:42:43+00:00,,https://github.com/tensorflow/tensorflow/pull/70962,[],[],
2394147828,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-07 17:36:51+00:00,[],2024-07-07 17:36:51+00:00,,https://github.com/tensorflow/tensorflow/pull/70961,[],[],
2394069137,pull_request,closed,,fix: remove distutils leftovers,"Context: https://github.com/tensorflow/tensorflow/issues/58073
Applied patch: https://gitlab.archlinux.org/archlinux/packaging/packages/tensorflow/-/blob/fff04b07ca2bc6758f81505cc396c91f7466c08a/tensorflow-2.16.1-python-distutils-removal.patch

Credits to @loqs",drupol,2024-07-07 14:01:56+00:00,['gbaned'],2024-07-09 06:54:25+00:00,2024-07-09 06:52:33+00:00,https://github.com/tensorflow/tensorflow/pull/70959,"[('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small'), ('prtype:bugfix', 'PR to fix a bug')]","[{'comment_id': 2212461139, 'issue_id': 2394069137, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70959/checks?check_run_id=27131104153) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 7, 14, 2, tzinfo=datetime.timezone.utc)}, {'comment_id': 2212465670, 'issue_id': 2394069137, 'author': 'mihaimaruseac', 'body': 'The lint error is not from this change, so it should not be blocking.', 'created_at': datetime.datetime(2024, 7, 7, 14, 15, 44, tzinfo=datetime.timezone.utc)}, {'comment_id': 2212608071, 'issue_id': 2394069137, 'author': 'mihaimaruseac', 'body': ""If I read the status correctly, there's nothing blocking. I cannot also approve internally, so we need to wait until ~tomorrow. After the internal approval there will be a few more CI jobs before merging. Sorry for the delay and thank you for the PR"", 'created_at': datetime.datetime(2024, 7, 7, 23, 8, 31, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-07 14:02:00 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70959/checks?check_run_id=27131104153) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

mihaimaruseac on (2024-07-07 14:15:44 UTC): The lint error is not from this change, so it should not be blocking.

mihaimaruseac on (2024-07-07 23:08:31 UTC): If I read the status correctly, there's nothing blocking. I cannot also approve internally, so we need to wait until ~tomorrow. After the internal approval there will be a few more CI jobs before merging. Sorry for the delay and thank you for the PR

"
2393958822,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-07 08:53:06+00:00,[],2024-07-07 08:53:06+00:00,,https://github.com/tensorflow/tensorflow/pull/70957,[],[],
2393945174,pull_request,open,,Add more test cases for stablehlo.convolution_2d.,"Add more test cases for stablehlo.convolution_2d.

* nhwc_hwio_nhwc
* nchw_oihw_nchw
* nhwc_ohwi_nhwc

Also tweak how the filter is used in build_mlir_registry
",copybara-service[bot],2024-07-07 08:12:09+00:00,['LukeBoyer'],2024-07-08 05:46:55+00:00,,https://github.com/tensorflow/tensorflow/pull/70956,[],[],
2393942554,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-07 08:04:48+00:00,[],2024-07-07 08:04:48+00:00,,https://github.com/tensorflow/tensorflow/pull/70955,[],[],
2393942346,pull_request,closed,,Add helper classes to parse conv attrs into cc types. Add legalizations for most basic mhlo.convolution cases.,"Add helper classes to parse conv attrs into cc types. Add legalizations for most basic mhlo.convolution cases.

Also remove some of the earlier submitted tests that are redundant.
",copybara-service[bot],2024-07-07 08:04:12+00:00,['LukeBoyer'],2024-07-16 17:41:49+00:00,2024-07-16 17:41:48+00:00,https://github.com/tensorflow/tensorflow/pull/70954,[],[],
2393903767,pull_request,closed,,[xla:cpu] KernelThunk: move VLOG out of a hot path,"[xla:cpu] KernelThunk: move VLOG out of a hot path

name                                     old cpu/op   new cpu/op   delta
BM_SelectAndScatterF32/128/process_time   767µs ± 5%   706µs ± 1%  -8.00%
BM_SelectAndScatterF32/256/process_time  2.96ms ± 4%  2.74ms ± 1%  -7.68%
BM_SelectAndScatterF32/512/process_time  11.9ms ± 1%  11.2ms ± 2%  -5.91%
",copybara-service[bot],2024-07-07 05:43:46+00:00,['ezhulenev'],2024-07-08 07:22:20+00:00,2024-07-08 07:22:19+00:00,https://github.com/tensorflow/tensorflow/pull/70953,[],[],
2393882293,pull_request,closed,,Add tests with CHECK-NOT for future mhlo.convolution -> tfl legalizations.,"Add tests with CHECK-NOT for future mhlo.convolution -> tfl legalizations.
",copybara-service[bot],2024-07-07 04:03:34+00:00,['LukeBoyer'],2024-07-12 23:59:38+00:00,2024-07-12 23:59:37+00:00,https://github.com/tensorflow/tensorflow/pull/70952,[],[],
2393833180,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-07 01:35:21+00:00,[],2024-07-07 01:35:21+00:00,,https://github.com/tensorflow/tensorflow/pull/70951,[],[],
2393802046,pull_request,closed,,[xla:cpu] Do not check buffer slices in optimized builds,"[xla:cpu] Do not check buffer slices in optimized builds

Overheads of checking buffer slices add up, and incorrect buffer slice is a serious compiler bug that should be discovered in debug builds.

name                                     old cpu/op   new cpu/op   delta
BM_SelectAndScatterF32/128/process_time   965µs ± 1%   806µs ±20%     ~     
BM_SelectAndScatterF32/256/process_time  3.79ms ± 2%  2.93ms ± 0%  -22.64%  
BM_SelectAndScatterF32/512/process_time  15.5ms ± 2%  12.0ms ± 2%  -22.50%
",copybara-service[bot],2024-07-07 00:43:12+00:00,['ezhulenev'],2024-07-08 06:06:33+00:00,2024-07-08 06:06:32+00:00,https://github.com/tensorflow/tensorflow/pull/70950,[],[],
2393791964,pull_request,closed,,Add a pass to unfreeze mutable global tensors and restore them as `arith.ConstOp`->`tf.VarHandleOp` -> `tf.AssignVariableOp` in the session_initializer.,"Add a pass to unfreeze mutable global tensors and restore them as `arith.ConstOp`->`tf.VarHandleOp` -> `tf.AssignVariableOp` in the session_initializer.

This pass is added to the TFLite converter to support mutable global tensors in TFLite. The pass is added after the `OptimizeGlobalTensorsPass` and `FreezeGlobalTensorsPass` passes. The pass first finds all the mutable global tensors in the module. Then, it creates a new `tf.VarHandleOp` for each mutable global tensor and assigns the const op's value to the `tf.VarHandleOp`. Finally, it removes the references to the mutable global tensors from the module.
",copybara-service[bot],2024-07-07 00:08:55+00:00,['vamsimanchala'],2024-07-19 17:16:56+00:00,2024-07-19 17:16:55+00:00,https://github.com/tensorflow/tensorflow/pull/70949,[],[],
2393753036,pull_request,closed,,Move gelu matching to a standard pattern match and legalization that is applied  before chlo->shlo lowering. Delete old file.,"Move gelu matching to a standard pattern match and legalization that is applied  before chlo->shlo lowering. Delete old file.
",copybara-service[bot],2024-07-06 22:12:53+00:00,['LukeBoyer'],2024-07-09 21:27:51+00:00,2024-07-09 21:27:50+00:00,https://github.com/tensorflow/tensorflow/pull/70948,[],[],
2393596075,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 15:11:43+00:00,[],2024-07-06 15:11:43+00:00,,https://github.com/tensorflow/tensorflow/pull/70946,[],[],
2393576340,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 14:10:49+00:00,[],2024-07-06 20:51:38+00:00,2024-07-06 20:51:37+00:00,https://github.com/tensorflow/tensorflow/pull/70945,[],[],
2393573091,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 14:01:35+00:00,[],2024-07-08 07:13:57+00:00,2024-07-08 07:13:57+00:00,https://github.com/tensorflow/tensorflow/pull/70944,[],[],
2393572456,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:59:45+00:00,[],2024-07-06 13:59:45+00:00,,https://github.com/tensorflow/tensorflow/pull/70943,[],[],
2393571916,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:58:08+00:00,[],2024-07-06 20:32:13+00:00,2024-07-06 20:32:12+00:00,https://github.com/tensorflow/tensorflow/pull/70942,[],[],
2393567948,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:45:04+00:00,[],2024-07-06 13:45:04+00:00,,https://github.com/tensorflow/tensorflow/pull/70941,[],[],
2393566923,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:41:39+00:00,[],2024-07-06 13:41:39+00:00,,https://github.com/tensorflow/tensorflow/pull/70940,[],[],
2393565873,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:38:10+00:00,[],2024-07-06 21:08:58+00:00,2024-07-06 21:08:58+00:00,https://github.com/tensorflow/tensorflow/pull/70939,[],[],
2393565843,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:38:06+00:00,[],2024-07-06 13:38:06+00:00,,https://github.com/tensorflow/tensorflow/pull/70938,[],[],
2393565751,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:37:45+00:00,[],2024-07-06 13:37:45+00:00,,https://github.com/tensorflow/tensorflow/pull/70937,[],[],
2393564807,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:34:42+00:00,[],2024-07-06 13:34:42+00:00,,https://github.com/tensorflow/tensorflow/pull/70936,[],[],
2393564289,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:33:04+00:00,[],2024-07-06 13:33:04+00:00,,https://github.com/tensorflow/tensorflow/pull/70935,[],[],
2393564190,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:32:47+00:00,[],2024-07-06 13:32:47+00:00,,https://github.com/tensorflow/tensorflow/pull/70934,[],[],
2393564124,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:32:34+00:00,[],2024-07-06 13:32:34+00:00,,https://github.com/tensorflow/tensorflow/pull/70933,[],[],
2393564109,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:32:31+00:00,[],2024-07-06 13:32:31+00:00,,https://github.com/tensorflow/tensorflow/pull/70932,[],[],
2393564044,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:32:18+00:00,[],2024-07-06 13:32:18+00:00,,https://github.com/tensorflow/tensorflow/pull/70931,[],[],
2393564035,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:32:17+00:00,[],2024-07-06 21:14:54+00:00,2024-07-06 21:14:54+00:00,https://github.com/tensorflow/tensorflow/pull/70930,[],[],
2393563733,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:31:20+00:00,[],2024-07-06 13:31:20+00:00,,https://github.com/tensorflow/tensorflow/pull/70929,[],[],
2393563583,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:30:51+00:00,[],2024-07-06 13:30:51+00:00,,https://github.com/tensorflow/tensorflow/pull/70928,[],[],
2393563142,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:29:27+00:00,[],2024-07-06 21:20:47+00:00,2024-07-06 21:20:47+00:00,https://github.com/tensorflow/tensorflow/pull/70927,[],[],
2393562752,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:28:05+00:00,[],2024-07-06 13:28:05+00:00,,https://github.com/tensorflow/tensorflow/pull/70926,[],[],
2393562645,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:27:44+00:00,[],2024-07-06 13:27:44+00:00,,https://github.com/tensorflow/tensorflow/pull/70925,[],[],
2393562526,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:27:20+00:00,[],2024-07-06 13:27:20+00:00,,https://github.com/tensorflow/tensorflow/pull/70924,[],[],
2393562336,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:26:45+00:00,[],2024-07-06 13:26:45+00:00,,https://github.com/tensorflow/tensorflow/pull/70923,[],[],
2393562294,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:26:36+00:00,[],2024-07-06 13:26:36+00:00,,https://github.com/tensorflow/tensorflow/pull/70922,[],[],
2393562061,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:25:49+00:00,[],2024-07-06 13:25:49+00:00,,https://github.com/tensorflow/tensorflow/pull/70921,[],[],
2393560925,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:21:58+00:00,[],2024-07-06 13:21:58+00:00,,https://github.com/tensorflow/tensorflow/pull/70920,[],[],
2393560167,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:19:35+00:00,[],2024-07-06 13:19:35+00:00,,https://github.com/tensorflow/tensorflow/pull/70919,[],[],
2393559896,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:18:41+00:00,[],2024-07-06 13:18:41+00:00,,https://github.com/tensorflow/tensorflow/pull/70918,[],[],
2393559470,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:17:12+00:00,[],2024-07-06 13:17:12+00:00,,https://github.com/tensorflow/tensorflow/pull/70917,[],[],
2393559207,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:16:22+00:00,[],2024-07-06 13:16:22+00:00,,https://github.com/tensorflow/tensorflow/pull/70916,[],[],
2393558599,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:14:24+00:00,[],2024-07-06 13:14:24+00:00,,https://github.com/tensorflow/tensorflow/pull/70915,[],[],
2393558263,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:13:21+00:00,[],2024-07-06 13:13:21+00:00,,https://github.com/tensorflow/tensorflow/pull/70914,[],[],
2393557990,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:12:27+00:00,[],2024-07-06 13:12:27+00:00,,https://github.com/tensorflow/tensorflow/pull/70913,[],[],
2393554014,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 13:00:01+00:00,[],2024-07-06 13:00:01+00:00,,https://github.com/tensorflow/tensorflow/pull/70912,[],[],
2393553850,pull_request,closed,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/67557 from apach301:fix-error-message bcfe43848ca21c701a76c050fd1d244e95c95d70
",copybara-service[bot],2024-07-06 12:59:33+00:00,[],2024-07-08 08:25:28+00:00,2024-07-08 08:25:27+00:00,https://github.com/tensorflow/tensorflow/pull/70911,[],[],
2393550583,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 12:48:36+00:00,[],2024-07-06 12:48:36+00:00,,https://github.com/tensorflow/tensorflow/pull/70910,[],[],
2393549729,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/64660 from tensorflow:LakshmiKalaKadali-patch-5 5736065e258d9a6e2e0046782ea538cee2bc77c6
",copybara-service[bot],2024-07-06 12:45:45+00:00,[],2024-07-08 06:20:28+00:00,,https://github.com/tensorflow/tensorflow/pull/70909,[],[],
2393549602,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-06 12:45:18+00:00,[],2024-07-06 12:45:18+00:00,,https://github.com/tensorflow/tensorflow/pull/70908,[],[],
2393447170,pull_request,closed,,Add direct legalizations for binary elementwise.,"Add direct legalizations for binary elementwise.
",copybara-service[bot],2024-07-06 07:07:14+00:00,['LukeBoyer'],2024-08-16 11:41:08+00:00,2024-08-16 11:41:07+00:00,https://github.com/tensorflow/tensorflow/pull/70907,[],[],
2393336633,pull_request,closed,,Bump certifi from 2024.6.2 to 2024.7.4,"Bumps [certifi](https://github.com/certifi/python-certifi) from 2024.6.2 to 2024.7.4.
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/certifi/python-certifi/commit/bd8153872e9c6fc98f4023df9c2deaffea2fa463""><code>bd81538</code></a> 2024.07.04 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/295"">#295</a>)</li>
<li><a href=""https://github.com/certifi/python-certifi/commit/06a2cbf21f345563dde6c28b60e29d57e9b210b3""><code>06a2cbf</code></a> Bump peter-evans/create-pull-request from 6.0.5 to 6.1.0 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/294"">#294</a>)</li>
<li><a href=""https://github.com/certifi/python-certifi/commit/13bba02b72bac97c432c277158bc04b4d2a6bc23""><code>13bba02</code></a> Bump actions/checkout from 4.1.6 to 4.1.7 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/293"">#293</a>)</li>
<li><a href=""https://github.com/certifi/python-certifi/commit/e8abcd0e62b334c164b95d49fcabdc9ecbca0554""><code>e8abcd0</code></a> Bump pypa/gh-action-pypi-publish from 1.8.14 to 1.9.0 (<a href=""https://redirect.github.com/certifi/python-certifi/issues/292"">#292</a>)</li>
<li>See full diff in <a href=""https://github.com/certifi/python-certifi/compare/2024.06.02...2024.07.04"">compare view</a></li>
</ul>
</details>
<br />


[![Dependabot compatibility score](https://dependabot-badges.githubapp.com/badges/compatibility_score?dependency-name=certifi&package-manager=pip&previous-version=2024.6.2&new-version=2024.7.4)](https://docs.github.com/en/github/managing-security-vulnerabilities/about-dependabot-security-updates#about-compatibility-scores)

Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore this major version` will close this PR and stop Dependabot creating any more for this major version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this minor version` will close this PR and stop Dependabot creating any more for this minor version (unless you reopen the PR or upgrade to it yourself)
- `@dependabot ignore this dependency` will close this PR and stop Dependabot creating any more for this dependency (unless you reopen the PR or upgrade to it yourself)
You can disable automated security fix PRs for this repo from the [Security Alerts page](https://github.com/tensorflow/tensorflow/network/alerts).

</details>",dependabot[bot],2024-07-06 02:19:41+00:00,['gbaned'],2024-07-17 07:31:40+00:00,2024-07-17 07:31:39+00:00,https://github.com/tensorflow/tensorflow/pull/70906,"[('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small'), ('dependencies', 'Pull requests that update a dependency file'), ('python', 'Pull requests that update Python code')]","[{'comment_id': 2223441594, 'issue_id': 2393336633, 'author': 'mihaimaruseac', 'body': '@dependabot rebase', 'created_at': datetime.datetime(2024, 7, 11, 17, 2, 42, tzinfo=datetime.timezone.utc)}]","mihaimaruseac on (2024-07-11 17:02:42 UTC): @dependabot rebase

"
2393265214,pull_request,closed,,Add pass stub for chlo->tfl.,"Add pass stub for chlo->tfl.

There are cases where we need to do some legalization before chlo gets decomposed. Gelu requires matching on chlo.erf op and is one such case. This pass can be used in the future to directly lower chlo or house pre-chlo decomp patterns.

Gelu is added to this pass in child CL.
",copybara-service[bot],2024-07-06 00:28:57+00:00,['LukeBoyer'],2024-07-09 03:16:58+00:00,2024-07-09 03:16:57+00:00,https://github.com/tensorflow/tensorflow/pull/70905,[],[],
2393263264,pull_request,open,,Fix api compatibility test for logging to include the use_call_stack argument.,"Fix api compatibility test for logging to include the use_call_stack argument.
",copybara-service[bot],2024-07-06 00:26:25+00:00,[],2024-07-07 20:41:20+00:00,,https://github.com/tensorflow/tensorflow/pull/70904,[],[],
2393207919,pull_request,closed,,"Re-style scatter library, move definition to cc from h, explicitly template with used ops.","Re-style scatter library, move definition to cc from h, explicitly template with used ops.

Trying to make all the lowering libraries in this folder have the same style/organization.
",copybara-service[bot],2024-07-05 22:41:39+00:00,['LukeBoyer'],2024-07-09 03:08:53+00:00,2024-07-09 03:08:53+00:00,https://github.com/tensorflow/tensorflow/pull/70903,[],[],
2393042404,pull_request,closed,,[xla:gpu] Switch ThunkExecutor and HostKernel Task to std::function,"[xla:gpu] Switch ThunkExecutor and HostKernel Task to std::function

We always use Eigen ThreadPool to launch HostKernel and ThunkExecutor tasks, and absl::AnyInvocable only adds overheads because it requires conversion to copyable tasl.

name                                     old cpu/op   new cpu/op   delta
BM_AsyncThunkExecutor/1/process_time     8.85µs ± 5%  8.86µs ± 6%    ~     
BM_AsyncThunkExecutor/16/process_time    88.7µs ±11%  86.3µs ± 9%  -2.72%  
BM_AsyncThunkExecutor/64/process_time     156µs ±10%   155µs ± 7%    ~     
BM_AsyncThunkExecutor/128/process_time    207µs ± 9%   203µs ± 9%  -2.02%  
BM_AsyncThunkExecutor/256/process_time    330µs ±12%   319µs ±12%  -3.44%  
BM_AsyncThunkExecutor/512/process_time    530µs ± 9%   513µs ±11%  -3.22%
",copybara-service[bot],2024-07-05 19:17:52+00:00,['ezhulenev'],2024-07-05 21:30:44+00:00,2024-07-05 21:30:44+00:00,https://github.com/tensorflow/tensorflow/pull/70902,[],[],
2392934968,pull_request,closed,,Internal change only.,"Internal change only.
",copybara-service[bot],2024-07-05 17:22:10+00:00,[],2024-07-08 20:57:20+00:00,2024-07-08 20:57:19+00:00,https://github.com/tensorflow/tensorflow/pull/70900,[],[],
2392862982,pull_request,closed,,[tsl:concurrency] NFC: Add a test for recursive ownership of AsyncValue and State,"[tsl:concurrency] NFC: Add a test for recursive ownership of AsyncValue and State
",copybara-service[bot],2024-07-05 16:12:00+00:00,['ezhulenev'],2024-07-05 16:40:11+00:00,2024-07-05 16:40:10+00:00,https://github.com/tensorflow/tensorflow/pull/70898,[],[],
2392818958,pull_request,closed,,[XLA:GPU] Add num_blocks to TiledHloComputation.,"[XLA:GPU] Add num_blocks to TiledHloComputation.

The original plan was to use `block_id_to_tile_offsets_indexing` to get this information, but turned out that it's too expensive to compute IndexingMap for each tiled instruction. This is a step to minimize the places where we compute the indexing.

The only case when number of blocks per tile is different is if the have a concat in the fusion. This case would have been supported by ``block_id_to_tile_offsets_indexing`, but now we need a new plan. Since `SymbolicTileAnalysis` also doesn't support `concat` yet, it's not an immediate issue.
",copybara-service[bot],2024-07-05 15:37:24+00:00,[],2024-07-08 13:45:46+00:00,2024-07-08 13:45:46+00:00,https://github.com/tensorflow/tensorflow/pull/70897,[],[],
2392786022,pull_request,closed,,[XLA:GPU][NFC] Refactor code to reduce `SoftmaxRewriterTriton::FindAllFusibleDiamondChains`'s complexity.,"[XLA:GPU][NFC] Refactor code to reduce `SoftmaxRewriterTriton::FindAllFusibleDiamondChains`'s complexity.
",copybara-service[bot],2024-07-05 15:13:28+00:00,[],2024-07-11 10:20:28+00:00,2024-07-11 10:20:27+00:00,https://github.com/tensorflow/tensorflow/pull/70896,[],[],
2392719694,pull_request,closed,,"[XLA:GPU] Make `SoftmaxRewriterTriton` use the new `IsTritonSupportedInstruction`, as opposed to the one in `legacy_triton::`.","[XLA:GPU] Make `SoftmaxRewriterTriton` use the new `IsTritonSupportedInstruction`, as opposed to the one in `legacy_triton::`.

Notably, the old function conflated support with ""support enabled by running
`FloatNormalization`"". Therefore, this change appears to impact what can be
fused end-to-end, but that should not be the case provided `FloatNormalization`
is run appropriately.

Since I had to fix the tests in this direction, I took the opportunity to
edit tests in order to remain relevant, and to delete the ones that no longer
seemed useful. All in all, the tests now focus on the properties of the matcher
itself, instead of also testing Triton support which now has its own
disentangled logic. (Except for a couple of dedicated tests that ensure that
Triton support is indeed taken into account when deciding to fuse a diamond.)
",copybara-service[bot],2024-07-05 14:30:42+00:00,[],2024-07-10 16:09:37+00:00,2024-07-10 16:09:36+00:00,https://github.com/tensorflow/tensorflow/pull/70895,[],[],
2392572198,pull_request,closed,,[XLA:CPU] Add runtime check if `set-dimension-size` was rewritten.,"[XLA:CPU] Add runtime check if `set-dimension-size` was rewritten.

In the current runtime, `set-dimension-size` op emitting is not supported by design, normally it is rewritten by `DynamicPadder` HLO pass and never reaches the emit phase. This CL adds a runtime check if this op was actually rewritten and returns an explicit message if it wasn't (instead of cryptic message that kSetDimensionSize opcode was not handled in elemental IR emitter).

Also added unit tests, covering existing and new functionality: `set_dimension_size_test.cc`.

Can't turn these tests for new runtime at this moment, because `set-dimension-size` op is rewritten as `SliceToDynamic` custom call (which is not supported yet).
",copybara-service[bot],2024-07-05 13:02:47+00:00,[],2024-07-10 16:46:40+00:00,2024-07-10 16:46:39+00:00,https://github.com/tensorflow/tensorflow/pull/70894,[],"[{'comment_id': 2210841398, 'issue_id': 2392572198, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70894/checks?check_run_id=27085166992) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 5, 13, 2, 52, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-05 13:02:52 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70894/checks?check_run_id=27085166992) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2392549117,pull_request,closed,,[XLA:GPU] Remove redundant constraints.,"[XLA:GPU] Remove redundant constraints.

We get a lot of the same constraint from each symbolic tile, but we never deduplicate that. That makes constraint expressions to be very long and evaluation takes too much time.
",copybara-service[bot],2024-07-05 12:49:03+00:00,[],2024-07-05 21:01:13+00:00,2024-07-05 21:01:12+00:00,https://github.com/tensorflow/tensorflow/pull/70893,[],[],
2392473430,pull_request,closed,,[XLA:GPU][NFC] Add a pretty printer for parametrized test names in `SoftmaxRewriterTritonTest`.,"[XLA:GPU][NFC] Add a pretty printer for parametrized test names in `SoftmaxRewriterTritonTest`.
",copybara-service[bot],2024-07-05 12:03:10+00:00,[],2024-07-05 12:38:44+00:00,2024-07-05 12:38:44+00:00,https://github.com/tensorflow/tensorflow/pull/70892,[],[],
2392471547,pull_request,closed,,[XLA:GPU][MLIR-based emitters] Add support for `atomic_rmw fadd` for bf16 for hopper.,"[XLA:GPU][MLIR-based emitters] Add support for `atomic_rmw fadd` for bf16 for hopper.
",copybara-service[bot],2024-07-05 12:01:59+00:00,['pifon2a'],2024-07-05 13:42:12+00:00,2024-07-05 13:42:12+00:00,https://github.com/tensorflow/tensorflow/pull/70891,[],[],
2392460224,pull_request,closed,,Remove some designated initializers.,"Remove some designated initializers.
",copybara-service[bot],2024-07-05 11:54:49+00:00,[],2024-07-05 13:10:49+00:00,2024-07-05 13:10:48+00:00,https://github.com/tensorflow/tensorflow/pull/70890,[],[],
2392347140,pull_request,open,,Clean up `xnnpack_delegate.(cc|h)`.,"Clean up `xnnpack_delegate.(cc|h)`.
",copybara-service[bot],2024-07-05 10:40:36+00:00,[],2024-07-05 12:11:56+00:00,,https://github.com/tensorflow/tensorflow/pull/70889,[],[],
2392297585,pull_request,closed,,[XLA:GPU] Replace TF_RET_CHECK with a readable status message.,"[XLA:GPU] Replace TF_RET_CHECK with a readable status message.
",copybara-service[bot],2024-07-05 10:10:32+00:00,[],2024-07-05 11:46:24+00:00,2024-07-05 11:46:24+00:00,https://github.com/tensorflow/tensorflow/pull/70888,[],[],
2392284658,pull_request,closed,,[XLA:CPU] Refactor `ExecuteState` into the `thunk.h` file.,"[XLA:CPU] Refactor `ExecuteState` into the `thunk.h` file.

It is now a protected member of a `Thunk` class.
",copybara-service[bot],2024-07-05 10:03:00+00:00,[],2024-07-09 16:03:04+00:00,2024-07-09 16:03:04+00:00,https://github.com/tensorflow/tensorflow/pull/70887,[],"[{'comment_id': 2210587867, 'issue_id': 2392284658, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70887/checks?check_run_id=27078656462) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 5, 10, 3, 6, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-05 10:03:06 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70887/checks?check_run_id=27078656462) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2392216587,pull_request,closed,,[XLA:GPU][NFC] Add logging to `IsTritonSupportedInstruction` for debuggability.,"[XLA:GPU][NFC] Add logging to `IsTritonSupportedInstruction` for debuggability.
",copybara-service[bot],2024-07-05 09:23:42+00:00,[],2024-07-05 10:29:08+00:00,2024-07-05 10:29:07+00:00,https://github.com/tensorflow/tensorflow/pull/70886,[],[],
2392057063,pull_request,closed,,Add all-gather opcode coverage to triton_support_test.,"Add all-gather opcode coverage to triton_support_test.
",copybara-service[bot],2024-07-05 07:52:51+00:00,[],2024-07-05 12:33:17+00:00,2024-07-05 12:33:17+00:00,https://github.com/tensorflow/tensorflow/pull/70885,[],[],
2392041801,pull_request,closed,,Remove guards from gpu_lt_matmul_thunk target (NFC).,"Remove guards from gpu_lt_matmul_thunk target (NFC).

Those should not be necessary.
",copybara-service[bot],2024-07-05 07:44:36+00:00,['akuegel'],2024-07-05 08:32:50+00:00,2024-07-05 08:32:49+00:00,https://github.com/tensorflow/tensorflow/pull/70884,[],[],
2391899467,pull_request,closed,,Add guards to make sure dynamic_slice_fusion_test is only built on GPU.,"Add guards to make sure dynamic_slice_fusion_test is only built on GPU.
",copybara-service[bot],2024-07-05 06:13:03+00:00,['akuegel'],2024-07-05 06:57:57+00:00,2024-07-05 06:57:57+00:00,https://github.com/tensorflow/tensorflow/pull/70882,[],[],
2391822950,pull_request,closed,,Only use the kernel threadpool if it is enabled,"Only use the kernel threadpool if it is enabled
",copybara-service[bot],2024-07-05 05:12:05+00:00,['alankelly'],2024-07-05 07:20:10+00:00,2024-07-05 07:20:09+00:00,https://github.com/tensorflow/tensorflow/pull/70881,[],[],
2391593776,pull_request,closed,,[stream_executor:host] Optimize HostKernel async launch,"[stream_executor:host] Optimize HostKernel async launch

Skip HostKernelExecuteState reference counting by moving ownership to execute event.

name                                       old cpu/op   new cpu/op   delta
BM_HostKernelAsyncLaunch/1/process_time    11.7ns ± 2%  11.2ns ± 5%   -3.99%  
BM_HostKernelAsyncLaunch/4/process_time    27.6µs ± 8%  26.5µs ± 6%   -3.95%  
BM_HostKernelAsyncLaunch/8/process_time    64.7µs ± 5%  61.4µs ± 6%   -5.05%  
BM_HostKernelAsyncLaunch/16/process_time    149µs ± 4%   141µs ± 7%   -5.16%  
BM_HostKernelAsyncLaunch/32/process_time    266µs ± 4%   248µs ± 5%   -6.79%  
BM_HostKernelAsyncLaunch/64/process_time    329µs ± 4%   286µs ± 5%  -12.86%  

name                                       old time/op          new time/op          delta
BM_HostKernelAsyncLaunch/1/process_time    11.7ns ± 1%          11.2ns ± 2%   -4.48%
BM_HostKernelAsyncLaunch/4/process_time    6.51µs ± 7%          6.23µs ± 5%   -4.30%
BM_HostKernelAsyncLaunch/8/process_time    15.4µs ± 7%          14.5µs ±10%   -5.97%
BM_HostKernelAsyncLaunch/16/process_time   23.9µs ± 4%          22.7µs ± 7%   -4.87%
BM_HostKernelAsyncLaunch/32/process_time   30.4µs ± 6%          28.6µs ± 5%   -5.98%
BM_HostKernelAsyncLaunch/64/process_time   32.5µs ± 4%          29.3µs ± 4%   -9.86%
",copybara-service[bot],2024-07-05 00:57:39+00:00,['ezhulenev'],2024-07-05 17:44:11+00:00,2024-07-05 17:44:10+00:00,https://github.com/tensorflow/tensorflow/pull/70880,[],[],
2391434446,pull_request,closed,,Add util functions for scaling the recorded costs.,"Add util functions for scaling the recorded costs.
",copybara-service[bot],2024-07-04 20:31:22+00:00,[],2024-07-05 06:10:19+00:00,2024-07-05 06:10:18+00:00,https://github.com/tensorflow/tensorflow/pull/70879,[],[],
2391407309,pull_request,closed,,[xla:cpu] Use recursive work splitting to launch thunk executor tasks,"[xla:cpu] Use recursive work splitting to launch thunk executor tasks

+ use explicit capture list in lambdas to avoid accidental captures
+ fix discovered asan error that was not reported before adding explicit captures

Benchmarks:

name                                     old cpu/op   new cpu/op   delta
BM_AsyncThunkExecutor/1/process_time     10.3µs ±30%   9.2µs ± 6%     ~     
BM_AsyncThunkExecutor/16/process_time     107µs ±18%    93µs ± 7%  -12.61%  
BM_AsyncThunkExecutor/64/process_time     165µs ±17%   163µs ± 7%     ~     
BM_AsyncThunkExecutor/128/process_time    233µs ±15%   216µs ± 6%   -7.65%  
BM_AsyncThunkExecutor/258/process_time    334µs ±13%   340µs ± 6%     ~     
BM_AsyncThunkExecutor/512/process_time    546µs ±11%   544µs ± 8%     ~     

name                                     old time/op          new time/op          delta
BM_AsyncThunkExecutor/1/process_time     2.61µs ±18%          2.58µs ± 4%     ~
BM_AsyncThunkExecutor/16/process_time    23.7µs ±24%          20.0µs ± 6%  -15.60%
BM_AsyncThunkExecutor/64/process_time    31.5µs ±22%          30.6µs ± 7%     ~   
BM_AsyncThunkExecutor/128/process_time   41.4µs ±20%          36.6µs ± 7%  -11.63%
BM_AsyncThunkExecutor/258/process_time   54.2µs ±16%          53.4µs ± 6%     ~   
BM_AsyncThunkExecutor/512/process_time   81.9µs ±13%          79.3µs ± 7%     ~   

Benchmarks are not super representative of real XLA models, we often have a situation when one HLO operation (thunk, node) ""unblocks"" ~100+ of other operations (thunks, nodes), and launching them sequentially can be a bottleneck.
",copybara-service[bot],2024-07-04 20:00:46+00:00,['ezhulenev'],2024-07-04 22:20:52+00:00,2024-07-04 22:20:52+00:00,https://github.com/tensorflow/tensorflow/pull/70878,[],[],
2391379356,pull_request,open,,Reorder methods in RequestCost.,"Reorder methods in RequestCost.
",copybara-service[bot],2024-07-04 19:29:19+00:00,[],2024-07-04 19:29:19+00:00,,https://github.com/tensorflow/tensorflow/pull/70877,[],[],
2391334002,pull_request,closed,,[xla:cpu] Add benchmark for sequential thunk executor,"[xla:cpu] Add benchmark for sequential thunk executor

------------------------------------------------------------------------------------
Benchmark                         Time             CPU   Iterations
------------------------------------------------------------------------------------
BM_SequentialThunkExecutor/64      1833 ns         1835 ns       379797
BM_SyncThunkExecutor/64            2818 ns         2821 ns       245604
BM_AsyncThunkExecutor/64          27003 ns       147296 ns         4736
",copybara-service[bot],2024-07-04 18:42:13+00:00,['ezhulenev'],2024-07-04 21:17:47+00:00,2024-07-04 21:17:47+00:00,https://github.com/tensorflow/tensorflow/pull/70876,[],[],
2391228068,pull_request,closed,,[xla:cpu] Make aliasing metadata deterministic,"[xla:cpu] Make aliasing metadata deterministic

Fix flaky test
",copybara-service[bot],2024-07-04 17:05:30+00:00,['ezhulenev'],2024-07-04 17:46:40+00:00,2024-07-04 17:46:39+00:00,https://github.com/tensorflow/tensorflow/pull/70875,[],[],
2391214233,pull_request,open,,PadThunk implementation in new API,"PadThunk implementation in new API
",copybara-service[bot],2024-07-04 16:53:02+00:00,[],2024-07-04 16:53:09+00:00,,https://github.com/tensorflow/tensorflow/pull/70874,[],"[{'comment_id': 2209346473, 'issue_id': 2391214233, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70874/checks?check_run_id=27055030017) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 4, 16, 53, 8, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-04 16:53:08 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70874/checks?check_run_id=27055030017) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2391037581,pull_request,closed,,[XLA:GPU] Enable fusing of fp8 matmuls through Triton.,"[XLA:GPU] Enable fusing of fp8 matmuls through Triton.

This is a resubmission of https://github.com/openxla/xla/pull/14232

Move cuBLAS fp8 GEMM rewriter after Triton GemmFusion, so that the Triton path has a chance to trigger.
",copybara-service[bot],2024-07-04 14:48:12+00:00,[],2024-07-10 13:51:51+00:00,2024-07-10 13:51:51+00:00,https://github.com/tensorflow/tensorflow/pull/70873,[],[],
2391022993,pull_request,closed,,Avoid building hlo_runner_main.cc twice,"Avoid building hlo_runner_main.cc twice

This change moves the actual build in a shared library target
and creates two binary targets that depend on the shared library
target.

It also makes maintaining the dependencies easier and more explicit.
",copybara-service[bot],2024-07-04 14:39:52+00:00,[],2024-07-05 12:27:56+00:00,2024-07-05 12:27:55+00:00,https://github.com/tensorflow/tensorflow/pull/70872,[],[],
2390926420,pull_request,closed,,[XLA:CPU] Add runtime check if `get-dimension-size` was rewritten.,"[XLA:CPU] Add runtime check if `get-dimension-size` was rewritten.


In the current runtime, `get-dimension-size` op emitting is not supported by design, normally it is rewritten by `DynamicPadder` HLO pass and never reaches the emit phase. This CL adds a runtime check if this op was actually rewritten and returns an explicit message if it wasn't (instead of cryptic message that kGetDimensionSize opcode was not handled in elemental IR emitter).

A relevant test case was added to `get_dimension_size_test.cc`.

Besides the runtime check, this CL also turns on `get_dimension_size` tests for the new runtime. Because this op is rewritten as already supported ops, we get support 'for free' in the new runtime.
",copybara-service[bot],2024-07-04 13:49:29+00:00,[],2024-07-09 15:00:29+00:00,2024-07-09 15:00:28+00:00,https://github.com/tensorflow/tensorflow/pull/70871,[],"[{'comment_id': 2209049182, 'issue_id': 2390926420, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70871/checks?check_run_id=27047900896) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 4, 13, 49, 35, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-04 13:49:35 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70871/checks?check_run_id=27047900896) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2390863209,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-04 13:20:58+00:00,[],2024-07-15 10:08:10+00:00,2024-07-15 10:08:08+00:00,https://github.com/tensorflow/tensorflow/pull/70870,[],[],
2390769655,pull_request,closed,,Fix compile time regression & re-enable MMA_V3,"Fix compile time regression & re-enable MMA_V3
",copybara-service[bot],2024-07-04 12:34:48+00:00,[],2024-07-08 18:59:31+00:00,2024-07-08 18:59:31+00:00,https://github.com/tensorflow/tensorflow/pull/70869,[],[],
2390743987,pull_request,closed,,Remove ifdefs from GPU CUDA malloc async allocator,"Remove ifdefs from GPU CUDA malloc async allocator

For better maintainability this is removing almost all
preprocesor branches from gpu_cudamallocasync_allocator.

It also:
- Removes the header only target
- Replaces usage of `tsl::mutex` by `absl::Mutex`
- Removes `#include cuda.h` from the header
- Removes all the unneeded includes / adds missing includes
- Removes `GTEST_SKIP` instructions from tests - assuming we always built with CUDA > 11.2

Since the header only target does not exist anymore, the header can only be included in build configurations that actually build the allocator. That required some ifdefs in TF's common_runtime.

This change is a prerequisite to splitting the se_gpu_pjrt_client target into subtargets that don't require `if_cuda` or `if_rocm` anymore.
",copybara-service[bot],2024-07-04 12:21:51+00:00,[],2024-07-08 18:40:07+00:00,2024-07-08 18:40:06+00:00,https://github.com/tensorflow/tensorflow/pull/70867,[],[],
2390726911,pull_request,closed,,[XLA:GPU][MLIR-based emitters] Canonicalize more scatters in scatter.hlo.,"[XLA:GPU][MLIR-based emitters] Canonicalize more scatters in scatter.hlo.

Also regenerage CHECKS and put them next to the corresponding tests.
",copybara-service[bot],2024-07-04 12:13:15+00:00,['pifon2a'],2024-07-04 12:59:28+00:00,2024-07-04 12:59:27+00:00,https://github.com/tensorflow/tensorflow/pull/70865,[],[],
2390700337,pull_request,closed,,[XLA:CPU] Fix flaky test.,"[XLA:CPU] Fix flaky test.
",copybara-service[bot],2024-07-04 11:59:07+00:00,[],2024-07-04 12:39:11+00:00,2024-07-04 12:39:10+00:00,https://github.com/tensorflow/tensorflow/pull/70864,[],[],
2390542648,pull_request,closed,,[XLA:GPU] Use dims for tile parameters in SymbolicTile expressions.,"[XLA:GPU] Use dims for tile parameters in SymbolicTile expressions.

We changed dims to symbols in some places, because AffineExpr didn't support some kind of expressions with dims before. Now there is no need to replace.

Changing dims to symbols with `AffineMap::replaceDims` is very expensive operation.
",copybara-service[bot],2024-07-04 10:39:30+00:00,[],2024-07-04 13:51:39+00:00,2024-07-04 13:51:37+00:00,https://github.com/tensorflow/tensorflow/pull/70863,[],[],
2390531988,pull_request,closed,,[XLA:GPU] Run fusion-wrapper pass before scheduling.,"[XLA:GPU] Run fusion-wrapper pass before scheduling.
",copybara-service[bot],2024-07-04 10:33:39+00:00,[],2024-07-05 12:09:20+00:00,2024-07-05 12:09:20+00:00,https://github.com/tensorflow/tensorflow/pull/70862,[],[],
2390466656,pull_request,closed,,Reduction emitter and test cleanups.,"Reduction emitter and test cleanups.

- don't pass builders around unnecessarily
- don't throw away source locations in TestBijection
",copybara-service[bot],2024-07-04 10:00:11+00:00,[],2024-07-05 06:31:19+00:00,2024-07-05 06:31:19+00:00,https://github.com/tensorflow/tensorflow/pull/70861,[],[],
2390445504,pull_request,closed,,PR #13527: [XLA:CPU][oneDNN] Enable mm-bias-add fusion,"PR #13527: [XLA:CPU][oneDNN] Enable mm-bias-add fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/13527

This PR enables matmul followed by bias-add + binary-add fusion and tests. It removes the check that was blocking this fusion.
Copybara import of the project:

--
7b916f2c9ffc9bb703a4650be9be99a1c0cb1696 by Kanvi Khanna <kanvi.khanna@intel.com>:

Enable mm-bias-add fusion

Merging this change closes #13527

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/13527 from Intel-tensorflow:kanvi/mm-bias-add a20e62f760fabe253f5a49d3b31c427c16814a60
",copybara-service[bot],2024-07-04 09:49:56+00:00,[],2024-07-04 11:10:41+00:00,2024-07-04 11:10:40+00:00,https://github.com/tensorflow/tensorflow/pull/70860,[],[],
2390427531,pull_request,closed,,[XLA:GPU] Move AffineMap evaluator to a separate target.,"[XLA:GPU] Move AffineMap evaluator to a separate target.

This version of evaluator is more efficient than `replaceDimsAndSymbols + simplifyAffineMap`.
",copybara-service[bot],2024-07-04 09:41:36+00:00,[],2024-07-04 11:17:33+00:00,2024-07-04 11:17:31+00:00,https://github.com/tensorflow/tensorflow/pull/70859,[],[],
2390355458,pull_request,closed,,[XLA:GPU][MLIR-based emitters] Rewrite scatters with scalar operands.,"[XLA:GPU][MLIR-based emitters] Rewrite scatters with scalar operands.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/13527 from Intel-tensorflow:kanvi/mm-bias-add a20e62f760fabe253f5a49d3b31c427c16814a60
",copybara-service[bot],2024-07-04 09:12:10+00:00,['pifon2a'],2024-07-04 12:13:15+00:00,2024-07-04 12:13:14+00:00,https://github.com/tensorflow/tensorflow/pull/70858,[],[],
2390355223,pull_request,closed,,Add gpu_runtime dependency to tests that need it.,"Add gpu_runtime dependency to tests that need it.
",copybara-service[bot],2024-07-04 09:12:03+00:00,['akuegel'],2024-07-04 10:36:12+00:00,2024-07-04 10:36:11+00:00,https://github.com/tensorflow/tensorflow/pull/70857,[],[],
2390308089,pull_request,closed,,PR #14328: [PJRT:GPU] Fail on unknown memory space for execution output buffers,"PR #14328: [PJRT:GPU] Fail on unknown memory space for execution output buffers

Imported from GitHub PR https://github.com/openxla/xla/pull/14328

This PR addresses @yliu120 's post-landing comments from https://github.com/openxla/xla/pull/14088:

 1. Error out on unknown memory_space in the output's layout (this requires a bit of plumbing to propagate the error).
 2. Use `memory_space_by_kind_id` in place of `memory_space_by_kind` (this requires some ugly cast, not sure if it's worth it - performance should not matter much here).
 3. Avoid shape copy, pass by reference.
Copybara import of the project:

--
b64a7f97e3cc080f3bba43ceac0f534467f1f2a6 by Jaroslav Sevcik <jsevcik@nvidia.com>:

Address reviewer comments

Merging this change closes #14328

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14328 from jaro-sevcik:clean-up-after-pr-14088 b64a7f97e3cc080f3bba43ceac0f534467f1f2a6
",copybara-service[bot],2024-07-04 08:49:42+00:00,[],2024-07-04 10:11:27+00:00,2024-07-04 10:11:26+00:00,https://github.com/tensorflow/tensorflow/pull/70856,[],[],
2390257124,pull_request,open,,PR #13527: [XLA:CPU][oneDNN] Enable mm-bias-add fusion,"PR #13527: [XLA:CPU][oneDNN] Enable mm-bias-add fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/13527

This PR enables matmul followed by bias-add + binary-add fusion and tests. It removes the check that was blocking this fusion.
Copybara import of the project:

--
7b916f2c9ffc9bb703a4650be9be99a1c0cb1696 by Kanvi Khanna <kanvi.khanna@intel.com>:

Enable mm-bias-add fusion

Merging this change closes #13527

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/13527 from Intel-tensorflow:kanvi/mm-bias-add a20e62f760fabe253f5a49d3b31c427c16814a60
",copybara-service[bot],2024-07-04 08:23:18+00:00,[],2024-07-04 08:23:18+00:00,,https://github.com/tensorflow/tensorflow/pull/70855,[],[],
2390252939,pull_request,closed,,PR #13638: [XLA:CPU][oneDNN] Block broadcasted add after fusion,"PR #13638: [XLA:CPU][oneDNN] Block broadcasted add after fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/13638

oneDNN currently lacks an optimized implementation for broadcasted add across all dimensions. In such cases, oneDNN might choose to execute the primitive using the reference algorithm. Therefore, we block such cases until oneDNN addresses this issue. Additionally, this PR includes a test to ensure that the rewrite does not occur in such scenarios.
Copybara import of the project:

--
2ff90a1fb0c06b883c365482bc1d06acdcf05c7d by Akhil Goel <akhil.goel@intel.com>:

Block broadcasted add after fusion

Merging this change closes #13638

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/13638 from Intel-tensorflow:akhil/block_binadd 593e4be47f2d5182dc117ff706f3d908889b9a8b
",copybara-service[bot],2024-07-04 08:21:08+00:00,[],2024-07-04 09:56:59+00:00,2024-07-04 09:56:58+00:00,https://github.com/tensorflow/tensorflow/pull/70854,[],"[{'comment_id': 2208389208, 'issue_id': 2390252939, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70854/checks?check_run_id=27033579923) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 4, 8, 21, 12, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-04 08:21:12 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70854/checks?check_run_id=27033579923) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2390206886,pull_request,closed,,PR #14342: Fix //xla/service/gpu:ir_emitter_triton_mem_utils_test in OSS,"PR #14342: Fix //xla/service/gpu:ir_emitter_triton_mem_utils_test in OSS

Imported from GitHub PR https://github.com/openxla/xla/pull/14342

Currently the test fails with:

xla/service/gpu/ir_emitter_triton_mem_utils_test.cc:48:10: fatal error: 'third_party/triton/include/triton/Dialect/Triton/IR/Dialect.h' file not found
   48 | #include ""third_party/triton/include/triton/Dialect/Triton/IR/Dialect.h""

Also, using `cc_test` instead of `xla_cc_test` results in linker errors
Copybara import of the project:

--
bdff18bd6948d0249545891a0408f82a4d448fd5 by Sergey Kozub <skozub@nvidia.com>:

Fix //xla/service/gpu:ir_emitter_triton_mem_utils_test in OSS

Merging this change closes #14342

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14342 from openxla:skozub/ir_emitter_triton_mem_utils_test bdff18bd6948d0249545891a0408f82a4d448fd5
",copybara-service[bot],2024-07-04 07:57:47+00:00,[],2024-07-04 10:18:39+00:00,2024-07-04 10:18:38+00:00,https://github.com/tensorflow/tensorflow/pull/70853,[],[],
2390201055,pull_request,closed,,PR #14426: [XLA:CPU][oneDNN] Enable F16 convolutions on supported CPU platforms,"PR #14426: [XLA:CPU][oneDNN] Enable F16 convolutions on supported CPU platforms

Imported from GitHub PR https://github.com/openxla/xla/pull/14426

This PR enables F16 convolutions on supported Intel CPUs.
Copybara import of the project:

--
e575296da1802257b97f09744c184f9bf31258ed by Akhil Goel <akhil.goel@intel.com>:

Enable F16 convolutions

Merging this change closes #14426

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14426 from Intel-tensorflow:akhil/fp16_conv e575296da1802257b97f09744c184f9bf31258ed
",copybara-service[bot],2024-07-04 07:54:31+00:00,[],2024-07-04 10:28:03+00:00,2024-07-04 10:28:03+00:00,https://github.com/tensorflow/tensorflow/pull/70852,[],"[{'comment_id': 2208341410, 'issue_id': 2390201055, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70852/checks?check_run_id=27032421489) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 4, 7, 54, 36, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-04 07:54:36 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70852/checks?check_run_id=27032421489) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2390189166,pull_request,closed,,Rename sparse-opt to xla-opt,"Rename sparse-opt to xla-opt
",copybara-service[bot],2024-07-04 07:47:53+00:00,[],2024-07-04 09:23:39+00:00,2024-07-04 09:23:38+00:00,https://github.com/tensorflow/tensorflow/pull/70850,[],[],
2390187658,pull_request,closed,,PR #14419: [GPU] Improve compiled kernel caching with new SplitModule mode.,"PR #14419: [GPU] Improve compiled kernel caching with new SplitModule mode.

Imported from GitHub PR https://github.com/openxla/xla/pull/14419

The new RoundRobin mode distributes functions to modules more evenly, therefore there are more single-function cacheable modules. Without this the example in the added test would have only 2 kernels cached.

This needs https://github.com/llvm/llvm-project/commit/c02e8f762a410e55581866c43636efcd6504c1bd to get integrated before it can be submitted.

Copybara import of the project:

--
e91c9a5589881923157692eb9ed08e7e6c096559 by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Improve compiled kernel caching with new SplitModule mode.

The new RoundRobin mode distributes functions to modules more evenly,
therefore there are more single-function cacheable modules.

Merging this change closes #14419

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14419 from openxla:better_kernel_caching e91c9a5589881923157692eb9ed08e7e6c096559
",copybara-service[bot],2024-07-04 07:47:01+00:00,[],2024-07-04 18:17:00+00:00,2024-07-04 18:16:59+00:00,https://github.com/tensorflow/tensorflow/pull/70849,[],[],
2390170137,pull_request,closed,,NFC: Unify shared memory reduction logic.,"NFC: Unify shared memory reduction logic.

All reductions can now emit multiple elements from one thread, if they want to
and it's not limited to the vector symbol. Currently no reduction does this,
but the code is clearer this way anyway.
",copybara-service[bot],2024-07-04 07:37:12+00:00,[],2024-07-04 08:38:03+00:00,2024-07-04 08:38:02+00:00,https://github.com/tensorflow/tensorflow/pull/70848,[],[],
2390143282,pull_request,closed,,Add dependency check rules,"Add dependency check rules

These should prevent backslide. We want to make sure that GPU compiler and CPU
compiler are not linked into targets that don't need them.
",copybara-service[bot],2024-07-04 07:22:42+00:00,['akuegel'],2024-07-04 09:16:06+00:00,2024-07-04 09:16:06+00:00,https://github.com/tensorflow/tensorflow/pull/70847,[],[],
2390107873,pull_request,closed,,[Cleanup] Remove empty unused build target,"[Cleanup] Remove empty unused build target
",copybara-service[bot],2024-07-04 07:03:11+00:00,[],2024-07-04 08:51:22+00:00,2024-07-04 08:51:22+00:00,https://github.com/tensorflow/tensorflow/pull/70846,[],[],
2389991351,pull_request,closed,,Reverts 82d93d8995892c4ddb579e248302cce263888401,"Reverts 82d93d8995892c4ddb579e248302cce263888401
",copybara-service[bot],2024-07-04 05:41:09+00:00,['akuegel'],2024-07-04 07:46:41+00:00,2024-07-04 07:46:41+00:00,https://github.com/tensorflow/tensorflow/pull/70844,[],[],
2389985740,pull_request,closed,,[xla:gpu] Pass Thunk::TaskRunner via ExecuteParams to all thunk executors,"[xla:gpu] Pass Thunk::TaskRunner via ExecuteParams to all thunk executors

+ pass TaskRunner via ExecuteParams so that all thunks, including thunks with nested control flow, execute ThunkExecutor tasks with the same runner
+ remove todos: constructing separate parameters for thunks looks totally reasonable and consistent with gpu backends
",copybara-service[bot],2024-07-04 05:36:44+00:00,['ezhulenev'],2024-07-04 21:00:56+00:00,2024-07-04 21:00:56+00:00,https://github.com/tensorflow/tensorflow/pull/70843,[],[],
2389859562,pull_request,closed,,Add support for local wheel whitelisting and blacklisting,"Add support for local wheel whitelisting and blacklisting

Also fix python version matching logic for wheels which do not require a specific python version.
",copybara-service[bot],2024-07-04 03:28:50+00:00,['vam-google'],2024-07-08 22:23:55+00:00,2024-07-08 22:23:54+00:00,https://github.com/tensorflow/tensorflow/pull/70840,[],[],
2389757899,pull_request,open,,Tighten Eigh tolerances back up by after forcing more accurate computation of sin/cosine factors in the two-sided Jacobi eigensolver.,"Tighten Eigh tolerances back up by after forcing more accurate computation of sin/cosine factors in the two-sided Jacobi eigensolver.
",copybara-service[bot],2024-07-04 01:44:28+00:00,[],2024-07-04 01:44:28+00:00,,https://github.com/tensorflow/tensorflow/pull/70839,[],[],
2389754697,pull_request,closed,,Add a basic test case for circular pipeline collective permute.,"Add a basic test case for circular pipeline collective permute.
",copybara-service[bot],2024-07-04 01:41:33+00:00,[],2024-07-09 01:36:08+00:00,2024-07-09 01:36:07+00:00,https://github.com/tensorflow/tensorflow/pull/70838,[],[],
2389709875,pull_request,closed,,Use reduced_precision_metadata to remove dependency on reduced_precision_support for tf_to_tfl_flatbuffer_helpers.,"Use reduced_precision_metadata to remove dependency on reduced_precision_support for tf_to_tfl_flatbuffer_helpers.
",copybara-service[bot],2024-07-04 00:40:37+00:00,[],2024-07-08 17:35:13+00:00,2024-07-08 17:35:13+00:00,https://github.com/tensorflow/tensorflow/pull/70837,[],[],
2389705826,pull_request,closed,,[xla:gpu] Use crc32 to compute nccl clique id fingerprint,"[xla:gpu] Use crc32 to compute nccl clique id fingerprint

Hash functions do not have to be identical across different processes and it creates confusion. Use stable crc32 algorithm to compute nccl key fingerprint
",copybara-service[bot],2024-07-04 00:34:41+00:00,['ezhulenev'],2024-07-04 01:14:08+00:00,2024-07-04 01:14:07+00:00,https://github.com/tensorflow/tensorflow/pull/70836,[],[],
2389704077,pull_request,open,,Internal change only.,"Internal change only.
",copybara-service[bot],2024-07-04 00:31:54+00:00,[],2024-07-04 00:31:54+00:00,,https://github.com/tensorflow/tensorflow/pull/70835,[],[],
2389693073,pull_request,open,,Make NCCL id logging deterministic,"Make NCCL id logging deterministic
",copybara-service[bot],2024-07-04 00:18:32+00:00,['frgossen'],2024-07-04 00:18:33+00:00,,https://github.com/tensorflow/tensorflow/pull/70834,[],[],
2389648374,pull_request,closed,,Replace python Bazel rule placeholders with `@rules_python`,"Replace python Bazel rule placeholders with `@rules_python`
",copybara-service[bot],2024-07-03 23:18:52+00:00,['ddunl'],2024-07-04 00:53:17+00:00,2024-07-04 00:53:16+00:00,https://github.com/tensorflow/tensorflow/pull/70833,[],[],
2389557099,pull_request,closed,,[xla] NFC: Fix confusing rendezvous timeout error message,"[xla] NFC: Fix confusing rendezvous timeout error message
",copybara-service[bot],2024-07-03 21:53:14+00:00,['ezhulenev'],2024-07-03 22:32:51+00:00,2024-07-03 22:32:50+00:00,https://github.com/tensorflow/tensorflow/pull/70832,[],[],
2389537428,pull_request,closed,,Update Eigen to commit:33d0937c6bdf5ec999939fb17f2a553183d14a74,"Update Eigen to commit:33d0937c6bdf5ec999939fb17f2a553183d14a74
",copybara-service[bot],2024-07-03 21:42:58+00:00,[],2024-07-04 00:27:55+00:00,2024-07-04 00:27:54+00:00,https://github.com/tensorflow/tensorflow/pull/70831,[],[],
2389509903,pull_request,closed,,Remove an unused parameter in MaybeFollowInsStrategyGroup and FollowArrayOrTokenStrategyGroup.,"Remove an unused parameter in MaybeFollowInsStrategyGroup and FollowArrayOrTokenStrategyGroup.
",copybara-service[bot],2024-07-03 21:23:42+00:00,[],2024-07-08 15:39:25+00:00,2024-07-08 15:39:24+00:00,https://github.com/tensorflow/tensorflow/pull/70830,[],[],
2389487605,pull_request,closed,,[xla:gpu] NFC: Improve NCCL clique logging,"[xla:gpu] NFC: Improve NCCL clique logging

To improve debugging experience log what cliques will be acquired for each global device id, we need this to detect when different ranks do not agree on cliques number and their acquisition order.
",copybara-service[bot],2024-07-03 21:08:14+00:00,['ezhulenev'],2024-07-03 21:59:20+00:00,2024-07-03 21:59:20+00:00,https://github.com/tensorflow/tensorflow/pull/70829,[],[],
2389430443,pull_request,closed,,[XLA] Make XLA_LOG_LINES harder to misuse,"[XLA] Make XLA_LOG_LINES harder to misuse

The type of a severity was a plain `int` which meant that log-levels and severities would get confused. Let's be more careful about that by using some type safety.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14699 from shraiysh:fix-circular-repeat 26f12d1e7c504cab0ca876e3685c49b98060b816
",copybara-service[bot],2024-07-03 20:39:11+00:00,['majnemer'],2024-07-11 00:19:23+00:00,2024-07-11 00:19:22+00:00,https://github.com/tensorflow/tensorflow/pull/70828,[],[],
2389403694,pull_request,closed,,#tf-data Turn down `map_fusion` experiment.,"#tf-data Turn down `map_fusion` experiment.
",copybara-service[bot],2024-07-03 20:21:34+00:00,['mpcallanan'],2024-07-04 00:46:34+00:00,2024-07-04 00:46:34+00:00,https://github.com/tensorflow/tensorflow/pull/70826,[],[],
2389350959,pull_request,closed,,Increase the size limit for CUDA wheels.,"Increase the size limit for CUDA wheels.
",copybara-service[bot],2024-07-03 19:54:22+00:00,[],2024-07-03 20:42:32+00:00,2024-07-03 20:42:32+00:00,https://github.com/tensorflow/tensorflow/pull/70824,[],[],
2389340105,pull_request,closed,,move operator_property to mlir lite,"move operator_property to mlir lite
",copybara-service[bot],2024-07-03 19:49:34+00:00,[],2024-07-10 20:31:06+00:00,2024-07-10 20:31:05+00:00,https://github.com/tensorflow/tensorflow/pull/70823,[],[],
2389319880,pull_request,closed,,PR #70765: [oneDNN] Update oneDNN library to v3.5,"PR #70765: [oneDNN] Update oneDNN library to v3.5

Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/70765


Copybara import of the project:

--
97b12896b7e068fb194a40c08812ff26ce0c87cf by Yimei Sun <yimei.sun@intel.com>:

[oneDNN]Update oneDNN library to v3.5

Merging this change closes #70765

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/70765 from Intel-tensorflow:yimei/onednn_v35 97b12896b7e068fb194a40c08812ff26ce0c87cf
",copybara-service[bot],2024-07-03 19:39:05+00:00,[],2024-07-04 16:08:01+00:00,2024-07-04 16:07:59+00:00,https://github.com/tensorflow/tensorflow/pull/70822,[],[],
2389297620,pull_request,open,,Remove experimental XNNPACK to StableHLO converter.,"Remove experimental XNNPACK to StableHLO converter.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/63359 from Notheisz57:Noth_PyInterpreterWrapper_SegFault_Fix 7ad5a7612918285ddca49633d63c462262bd3dc9
",copybara-service[bot],2024-07-03 19:26:20+00:00,[],2024-07-11 18:04:32+00:00,,https://github.com/tensorflow/tensorflow/pull/70821,[],[],
2389293361,pull_request,closed,,[XLA:SPMD] Fix multi-variant Reduce not propagating manual sharding correctly.,"[XLA:SPMD] Fix multi-variant Reduce not propagating manual sharding correctly.
",copybara-service[bot],2024-07-03 19:23:32+00:00,['Tongfei-Guo'],2024-07-04 03:00:01+00:00,2024-07-04 03:00:01+00:00,https://github.com/tensorflow/tensorflow/pull/70820,[],[],
2389270388,pull_request,closed,,[NFC] dump: Add additional unit tests for DumpProtobufToFile and DumpToFile.,"[NFC] dump: Add additional unit tests for DumpProtobufToFile and DumpToFile.

The tests validate that nothing is dumped when dumping is disabled.
",copybara-service[bot],2024-07-03 19:09:24+00:00,[],2024-07-09 05:43:14+00:00,2024-07-09 05:43:13+00:00,https://github.com/tensorflow/tensorflow/pull/70819,[],[],
2389259590,pull_request,closed,,[XLA] Avoid unnecessary literal comparisons in algebraic simplifier,"[XLA] Avoid unnecessary literal comparisons in algebraic simplifier

Creating a literal to compare a scalar is overkill. Let's just handle it directly in AlgSimp.

While we are here, speed-up literal_comparison::{Equal,Near} by avoiding the creation of strings.
",copybara-service[bot],2024-07-03 19:01:48+00:00,['majnemer'],2024-07-04 06:48:28+00:00,2024-07-04 06:48:27+00:00,https://github.com/tensorflow/tensorflow/pull/70818,[],[],
2389227841,pull_request,closed,,Cleanup xla/tests/exhaustive/* C++ files,"Cleanup xla/tests/exhaustive/* C++ files

Follow IWYU, remove uneccesary includes, and ensure the build targets reflect the actual dependencies. Adds ""exhaustive_test_main.cc"" to each xla_test target in anticipation of changes that add CLI args.
",copybara-service[bot],2024-07-03 18:38:42+00:00,[],2024-07-03 19:30:44+00:00,2024-07-03 19:30:43+00:00,https://github.com/tensorflow/tensorflow/pull/70817,[],[],
2389187211,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@1b08c4c0,"Integrate StableHLO at openxla/stablehlo@1b08c4c0
",copybara-service[bot],2024-07-03 18:09:50+00:00,[],2024-07-03 23:53:08+00:00,2024-07-03 23:53:07+00:00,https://github.com/tensorflow/tensorflow/pull/70816,[],[],
2389169632,pull_request,closed,,Implement replicated host buffer transfer in PjRt-IFRT,"Implement replicated host buffer transfer in PjRt-IFRT

This CL extends PjRt-IFRT's `Client::MakeArrayFromHostBuffer` to take a replicated sharding and broadcasts the same host buffers to multiple devices in one IFRT call. This can be used by JAX's `batched_device_put` so that it can create a N-way replicated array in one IFRT call instead of doing N host-to-device copies followed by an array assembly.
",copybara-service[bot],2024-07-03 17:58:33+00:00,[],2024-07-11 19:08:57+00:00,2024-07-11 19:08:56+00:00,https://github.com/tensorflow/tensorflow/pull/70815,[],[],
2389153374,pull_request,closed,,Move definition of `xla_bzl_library` to `xla.bzl`,"Move definition of `xla_bzl_library` to `xla.bzl`
",copybara-service[bot],2024-07-03 17:47:38+00:00,['cliveverghese'],2024-07-03 23:21:41+00:00,2024-07-03 23:21:41+00:00,https://github.com/tensorflow/tensorflow/pull/70814,[],[],
2389142950,pull_request,closed,,[xla:cpu] Add kernel parameter verification to check assigned buffer slices,"[xla:cpu] Add kernel parameter verification to check assigned buffer slices

In preparation for emitting aliasing metadata verify host kernels buffer assignment.
",copybara-service[bot],2024-07-03 17:41:05+00:00,['ezhulenev'],2024-07-03 18:59:51+00:00,2024-07-03 18:59:50+00:00,https://github.com/tensorflow/tensorflow/pull/70813,[],[],
2389142569,pull_request,closed,,[xla:cpu] Add alias scopes and noalias metadata to host kernels,"[xla:cpu] Add alias scopes and noalias metadata to host kernels
",copybara-service[bot],2024-07-03 17:40:46+00:00,['ezhulenev'],2024-07-03 19:50:00+00:00,2024-07-03 19:50:00+00:00,https://github.com/tensorflow/tensorflow/pull/70812,[],[],
2389087474,pull_request,closed,,Add host tracers for GPU Plugin,"Add host tracers for GPU Plugin
",copybara-service[bot],2024-07-03 17:06:13+00:00,['cliveverghese'],2024-07-03 17:56:19+00:00,2024-07-03 17:56:17+00:00,https://github.com/tensorflow/tensorflow/pull/70811,[],[],
2389082261,pull_request,closed,,Clean up shared memory indexing logic.,"Clean up shared memory indexing logic.

Right now, we assume there's a single kind of optional in some cases
vector loop argument. By allowing any number of loops, we can simplify
the code.

Also clean up all the mess around symbol handling:
- don't remove unused symbols. We only did that to make the tests nicer
  to read, but it serves no real purpose.
- make EvaluateEpilogue less weird. Ensure that the epilogue (= output)
  indexing and the shared memory read indexing have the same symbols.
",copybara-service[bot],2024-07-03 17:02:37+00:00,[],2024-07-04 07:09:46+00:00,2024-07-04 07:09:46+00:00,https://github.com/tensorflow/tensorflow/pull/70810,[],[],
2389075429,pull_request,closed,,Remove already resolved TODO.,"Remove already resolved TODO.
",copybara-service[bot],2024-07-03 16:58:09+00:00,[],2024-07-04 08:12:38+00:00,2024-07-04 08:12:38+00:00,https://github.com/tensorflow/tensorflow/pull/70809,[],[],
2389058826,pull_request,closed,,Remove unused dependency on kernel_utils.,"Remove unused dependency on kernel_utils.
",copybara-service[bot],2024-07-03 16:46:50+00:00,[],2024-07-09 00:03:01+00:00,2024-07-09 00:03:01+00:00,https://github.com/tensorflow/tensorflow/pull/70808,[],[],
2388953947,pull_request,closed,,[xla:cpu] Pass buffer allocations for arguments and results when emitting kernel prototype,"[xla:cpu] Pass buffer allocations for arguments and results when emitting kernel prototype

Buffer allocations are needed for deriving LLVM aliasing scopes (coming next!).
",copybara-service[bot],2024-07-03 15:45:52+00:00,['ezhulenev'],2024-07-03 18:33:16+00:00,2024-07-03 18:33:15+00:00,https://github.com/tensorflow/tensorflow/pull/70807,[],[],
2388915716,pull_request,closed,,"PR #14092: NVTX: name threads, CUDA devices and CUDA streams","PR #14092: NVTX: name threads, CUDA devices and CUDA streams

Imported from GitHub PR https://github.com/openxla/xla/pull/14092

See https://github.com/openxla/xla/pull/13603, which landed and got rolled back.
f75962e80d387f32dc9055cd1fff9029d97f0026 attempts to fix the issue described in https://github.com/openxla/xla/pull/13603#discussion_r1647078940.
Copybara import of the project:

--
c2f947687ecc1ce8844ba7d0b258b5fd1f3b8afd by Olli Lupton <olupton@nvidia.com>:

NVTX: name threads, CUDA devices and CUDA streams

Second attempt at https://github.com/openxla/xla/pull/13603, which was
rolled back.

This aims to improve the profiling experience. These names are shown in the Nsight Systems UI.

Device names:
![Screenshot 2024-06-10 at 14 52 37](https://github.com/openxla/xla/assets/6459623/d889d37e-ca2e-4f5e-b5bd-240bbb625b4c)

Stream names:
![Screenshot 2024-06-10 at 14 53 25](https://github.com/openxla/xla/assets/6459623/4bfc4ffa-8fdf-4b93-b23e-95bf056799f3)

Thread names:
![Screenshot 2024-06-10 at 14 54 04](https://github.com/openxla/xla/assets/6459623/8852ca9e-f2f4-4a45-8334-a18f8ab5ce18)

This also provides a missing link between replica IDs in the HLO and the physical devices in the profile.

--
ac4af75b2f934a1d4fe06d07519b891fbaa7f88a by Olli Lupton <olupton@nvidia.com>:

Work around nvtx_utils_libtpu error

--
2b3407bea90c486fd15cfffba80ba2391b1a4e5c by Olli Lupton <olupton@nvidia.com>:

Set visibility

--
a79d09f9a77c12968459770faf4bd7d0cf5db27a by Olli Lupton <olupton@nvidia.com>:

add missing ifdef

--
7aa0800429fbbf4033f8a4da54d4114d1bd4d228 by Olli Lupton <olupton@nvidia.com>:

Move device/thread naming into separate function

Merging this change closes #14092

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14092 from olupton:name-devices-streams-and-threads-v2 7aa0800429fbbf4033f8a4da54d4114d1bd4d228
",copybara-service[bot],2024-07-03 15:26:01+00:00,[],2024-07-04 12:21:26+00:00,2024-07-04 12:21:25+00:00,https://github.com/tensorflow/tensorflow/pull/70806,[],[],
2388897862,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2024-07-03 15:17:18+00:00,[],2024-07-10 19:31:12+00:00,2024-07-10 19:31:10+00:00,https://github.com/tensorflow/tensorflow/pull/70805,[],[],
2388826630,pull_request,closed,,Internal code change,"Internal code change
",copybara-service[bot],2024-07-03 14:45:41+00:00,[],2024-07-03 17:05:36+00:00,2024-07-03 17:05:36+00:00,https://github.com/tensorflow/tensorflow/pull/70804,[],[],
2388637734,pull_request,closed,,[XLA:CPU] Add runtime check if `RngBitGenerator` was expanded.,"[XLA:CPU] Add runtime check if `RngBitGenerator` was expanded.


`RngBitGeneratorExpander` pass should expand `RngBitGenerator` op. If this op was not expanded, default action was applied which was failing and resulting in crashes. This CL adds runtime checks to return error instead of segfault. Checks added to both runtimes: current runtime (`IrEmitter`) and thunks runtime (`ThunkEmitter`).

Also added tests covering this missing case.
",copybara-service[bot],2024-07-03 13:29:09+00:00,[],2024-07-08 16:26:15+00:00,2024-07-08 16:26:15+00:00,https://github.com/tensorflow/tensorflow/pull/70800,[],"[{'comment_id': 2206082370, 'issue_id': 2388637734, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70800/checks?check_run_id=26996493047) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 3, 13, 29, 15, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-03 13:29:15 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70800/checks?check_run_id=26996493047) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2388631233,pull_request,closed,,[XLA:GPU][MLIR-based emitters] Use simplified scatters in gpu tests.,"[XLA:GPU][MLIR-based emitters] Use simplified scatters in gpu tests.
",copybara-service[bot],2024-07-03 13:27:07+00:00,['pifon2a'],2024-07-04 07:27:20+00:00,2024-07-04 07:27:19+00:00,https://github.com/tensorflow/tensorflow/pull/70799,[],[],
2388574670,pull_request,closed,,Make NvPtxCompiler work without ptxas when libnvptxcompiler is enabled,"Make NvPtxCompiler work without ptxas when libnvptxcompiler is enabled

Running XLA with `--xla_gpu_enable_libnvptxcompiler` makes all the PTX compilation go through libnvptxcompiler but there is still a code path
which is checking whether the version of ptxas is sufficient.

This change makes it check the version of libnvptxcompiler instead which
means XLA can truly run without ptxas.
",copybara-service[bot],2024-07-03 13:01:58+00:00,[],2024-07-04 06:09:19+00:00,2024-07-04 06:09:18+00:00,https://github.com/tensorflow/tensorflow/pull/70798,[],[],
2388571952,pull_request,closed,,Move constants out of anonymous namespace,"Move constants out of anonymous namespace
",copybara-service[bot],2024-07-03 13:00:42+00:00,[],2024-07-08 12:46:51+00:00,2024-07-08 12:46:51+00:00,https://github.com/tensorflow/tensorflow/pull/70797,[],[],
2388488002,pull_request,open,,PR #14202: [fusion] Add RS->DUS dynamic slice fusion,"PR #14202: [fusion] Add RS->DUS dynamic slice fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/14202

This patch adds execution support and fusion rewriting support for reduce-scatter -> dynamic-update-slice pattern.
Copybara import of the project:

--
180b1d57405aac7cb60607cb73c7f67d78f16426 by Shraiysh Vaishay <svaishay@nvidia.com>:

[fusion] Add RS->DUS dynamic slice fusion

This patch adds execution support and fusion rewriting support for
reduce-scatter -> dynamic-update-slice pattern.

Merging this change closes #14202

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14202 from shraiysh:rs_ds_fusion 180b1d57405aac7cb60607cb73c7f67d78f16426
",copybara-service[bot],2024-07-03 12:20:11+00:00,[],2024-07-04 12:12:22+00:00,,https://github.com/tensorflow/tensorflow/pull/70795,[],[],
2388477062,pull_request,closed,,Vectorized multi-row reductions.,"Vectorized multi-row reductions.

We might be able to squeeze out a tiny bit more by making the writes fully
coalesced, but I doubt it's worth the increase in complexity.
",copybara-service[bot],2024-07-03 12:14:42+00:00,[],2024-07-03 13:56:01+00:00,2024-07-03 13:56:00+00:00,https://github.com/tensorflow/tensorflow/pull/70794,[],[],
2388462729,pull_request,closed,,[XLA] Fix missing build depenency.,"[XLA] Fix missing build depenency.
",copybara-service[bot],2024-07-03 12:07:24+00:00,[],2024-07-03 13:37:38+00:00,2024-07-03 13:37:36+00:00,https://github.com/tensorflow/tensorflow/pull/70793,[],[],
2388437517,pull_request,closed,,Avoid depending on gpu_runtime target from xla_launch_util.,"Avoid depending on gpu_runtime target from xla_launch_util.

All we need is a target that provides the gpu_device_context header. Introduce
such a target, and replace gpu_runtime dependency with that one.
",copybara-service[bot],2024-07-03 11:54:27+00:00,['akuegel'],2024-07-04 05:40:43+00:00,2024-07-04 05:40:42+00:00,https://github.com/tensorflow/tensorflow/pull/70792,[],[],
2388426635,pull_request,closed,,[XLA:GPU][MLIR-based emitters] Do not use variable names in tests directly.,"[XLA:GPU][MLIR-based emitters] Do not use variable names in tests directly.
",copybara-service[bot],2024-07-03 11:48:49+00:00,['pifon2a'],2024-07-03 13:30:51+00:00,2024-07-03 13:30:50+00:00,https://github.com/tensorflow/tensorflow/pull/70791,[],[],
2388372297,pull_request,open,,[XLA:GPU] Remove float normalization before Triton GEMM/cuBLAS rewrite,"[XLA:GPU] Remove float normalization before Triton GEMM/cuBLAS rewrite

It seems that it's not needed anymore, and I wasn't able to come up with a use case where it's required.

Reverts 5fe3cb13f3d5b2e07de9a3b8606fbd49b56605ab
",copybara-service[bot],2024-07-03 11:19:51+00:00,[],2024-07-03 11:19:51+00:00,,https://github.com/tensorflow/tensorflow/pull/70790,[],[],
2388306838,pull_request,closed,,"[XLA:GPU][MLIR-based emitters] Specify atomic store alignment in bytes, not bits.","[XLA:GPU][MLIR-based emitters] Specify atomic store alignment in bytes, not bits.
",copybara-service[bot],2024-07-03 10:48:11+00:00,['pifon2a'],2024-07-03 11:57:29+00:00,2024-07-03 11:57:28+00:00,https://github.com/tensorflow/tensorflow/pull/70789,[],[],
2388294626,pull_request,open,,[XLA:GPU] Add a dependancy to read input from cns in hlo-opt.,"[XLA:GPU] Add a dependancy to read input from cns in hlo-opt.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14255 from apivovarov:fix_hlo_sharding_util_test d6d688926eed8fc6fbc711d079ee812c030e5868
",copybara-service[bot],2024-07-03 10:41:46+00:00,[],2024-07-03 10:41:46+00:00,,https://github.com/tensorflow/tensorflow/pull/70788,[],[],
2388179914,pull_request,closed,,Reverts 5fe3cb13f3d5b2e07de9a3b8606fbd49b56605ab,"Reverts 5fe3cb13f3d5b2e07de9a3b8606fbd49b56605ab

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/62310 from Tai78641:pr_fully_connected 0a913570e78e9e33be4d7f3cd4319b8625d7555b
",copybara-service[bot],2024-07-03 09:45:59+00:00,['akuegel'],2024-07-03 11:16:20+00:00,2024-07-03 11:16:19+00:00,https://github.com/tensorflow/tensorflow/pull/70787,[],[],
2388164151,pull_request,closed,,[XLA:GPU] Fix invalid memory dereference in `GpuCudaMallocAsyncAllocator`.,"[XLA:GPU] Fix invalid memory dereference in `GpuCudaMallocAsyncAllocator`.

The issue is this:

- On line 252, the code compares `*pool_item_ == pool_` and ASAN complains about `stack-use-after-return`. This means that `*pool_item_` is an invalid dereference.
- `pool_item` is the address of a `GpuCudaMallocAsyncAllocator::pool_` field that was inserted in the global `all_pools_` in a previous execution of the `GpuCudaMallocAsyncAllocator` constructor.
- However, after that previous `GpuCudaMallocAsyncAllocator` object is no longer live, all addresses of its fields are now invalid, leading the invalid dereference.

The solution is to not store pointers and so not need any dereference. The underlying type is anyway a pointer so we can store and compare it directly.
",copybara-service[bot],2024-07-03 09:38:26+00:00,[],2024-07-03 11:08:43+00:00,2024-07-03 11:08:42+00:00,https://github.com/tensorflow/tensorflow/pull/70786,[],[],
2388079180,pull_request,closed,,Integrate LLVM at llvm/llvm-project@c5b67dde981d,"Integrate LLVM at llvm/llvm-project@c5b67dde981d

Updates LLVM usage to match
[c5b67dde981d](https://github.com/llvm/llvm-project/commit/c5b67dde981d)
",copybara-service[bot],2024-07-03 08:59:53+00:00,[],2024-07-03 13:48:10+00:00,2024-07-03 13:48:10+00:00,https://github.com/tensorflow/tensorflow/pull/70785,[],[],
2388064313,pull_request,closed,,Test for reduction indexing maps being bijections.,"Test for reduction indexing maps being bijections.

Currently, we often test exact indexing map strings. This is not useful for a
couple of reasons:

- it's very hard to verify these strings by hand
- they're very brittle, since changes to the simplifier or correct changes to
  indexing map expressions still break lots of these tests at the same time,
  after which we typically copy the test output back to the test code (i.e.,
  they're mostly change detectors).

This change modifies some of these tests to instead verify that the indexing
maps are bijections. Together with a test that verifies the actual reduction
output against the interpreter, this gives us good test coverage, while bening
less brittle.

For example, when adding vectorization to an emitter, but with an incorrect
indexing, the test will tell you that multiple points map to the same element,
or to an element that is out of bounds, or some elements aren't mapped to at
all.
",copybara-service[bot],2024-07-03 08:52:47+00:00,[],2024-07-03 12:26:22+00:00,2024-07-03 12:26:21+00:00,https://github.com/tensorflow/tensorflow/pull/70784,[],[],
2387983747,pull_request,closed,,Reverts 1f6b4e9733885c1bcb89b2d84d693a72bcf9197c,"Reverts 1f6b4e9733885c1bcb89b2d84d693a72bcf9197c
",copybara-service[bot],2024-07-03 08:14:39+00:00,[],2024-07-03 08:55:32+00:00,2024-07-03 08:55:31+00:00,https://github.com/tensorflow/tensorflow/pull/70783,[],[],
2387959573,pull_request,open,,Avoid depending on gpu_runtime target from xla_launch_util.,"Avoid depending on gpu_runtime target from xla_launch_util.

All we need is a target that provides the gpu_device_context header. Introduce
such a target, and replace gpu_runtime dependency with that one.
",copybara-service[bot],2024-07-03 08:03:43+00:00,[],2024-07-04 05:48:02+00:00,,https://github.com/tensorflow/tensorflow/pull/70782,[],[],
2387921960,pull_request,closed,,Add missing header include (NFC).,"Add missing header include (NFC).
",copybara-service[bot],2024-07-03 07:45:09+00:00,['akuegel'],2024-07-03 08:19:46+00:00,2024-07-03 08:19:45+00:00,https://github.com/tensorflow/tensorflow/pull/70781,[],[],
2387767734,pull_request,closed,,PR #14255: Fix build issue in xla/hlo/utils/hlo_sharding_util_test.cc,"PR #14255: Fix build issue in xla/hlo/utils/hlo_sharding_util_test.cc

Imported from GitHub PR https://github.com/openxla/xla/pull/14255

This PR fixes the following build error in `xla/hlo/utils/hlo_sharding_util_test.cc` (used GCC-13):
```bash
xla/hlo/utils/hlo_sharding_util_test.cc:538:41: error: call of overloaded 'TileAssignment(<brace-enclosed initializer list>)' is ambiguous
  538 |   TileAssignment tile_assignment({16, 4});
```
Reed, can you look at this build fix too? @reedwm 
Copybara import of the project:

--
d6d688926eed8fc6fbc711d079ee812c030e5868 by Alexander Pivovarov <pivovaa@amazon.com>:

Fix build issue in xla/hlo/utils/hlo_sharding_util_test.cc

Merging this change closes #14255

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14255 from apivovarov:fix_hlo_sharding_util_test d6d688926eed8fc6fbc711d079ee812c030e5868
",copybara-service[bot],2024-07-03 06:17:27+00:00,[],2024-07-03 11:00:52+00:00,2024-07-03 11:00:52+00:00,https://github.com/tensorflow/tensorflow/pull/70780,[],[],
2387747033,pull_request,closed,,Update TFRT dependency to use revision,"Update TFRT dependency to use revision
http://github.com/tensorflow/runtime/commit/60277ba976739502e45ad26585e071568fa44af1.
",copybara-service[bot],2024-07-03 06:04:03+00:00,[],2024-07-04 03:19:11+00:00,2024-07-04 03:19:10+00:00,https://github.com/tensorflow/tensorflow/pull/70779,[],[],
2387619645,pull_request,closed,,Support i4 EmbeddingLookup in TFLite reference,"Support i4 EmbeddingLookup in TFLite reference
",copybara-service[bot],2024-07-03 04:02:26+00:00,['paulinesho'],2024-07-18 23:36:34+00:00,2024-07-18 23:36:33+00:00,https://github.com/tensorflow/tensorflow/pull/70778,[],[],
2387372606,pull_request,closed,,[PJRT] Use AnyInvocable for WorkerThread.,"[PJRT] Use AnyInvocable for WorkerThread.
",copybara-service[bot],2024-07-03 00:11:29+00:00,[],2024-07-03 14:16:05+00:00,2024-07-03 14:16:03+00:00,https://github.com/tensorflow/tensorflow/pull/70777,[],[],
2387353940,pull_request,closed,,Adding translation from HLO --> StableHLO,"Adding translation from HLO --> StableHLO

This is complementary to the StableHLO --> HLO translations implemented at https://github.com/openxla/xla/tree/main/xla/translate/stablehlo_to_hlo
",copybara-service[bot],2024-07-02 23:49:47+00:00,['sdasgup3'],2024-07-03 19:05:47+00:00,2024-07-03 19:05:46+00:00,https://github.com/tensorflow/tensorflow/pull/70776,[],[],
2387344761,pull_request,closed,,Integrate LLVM at llvm/llvm-project@efefee28a41e,"Integrate LLVM at llvm/llvm-project@efefee28a41e

Updates LLVM usage to match
[efefee28a41e](https://github.com/llvm/llvm-project/commit/efefee28a41e)
",copybara-service[bot],2024-07-02 23:40:35+00:00,[],2024-07-03 05:56:39+00:00,2024-07-03 05:56:39+00:00,https://github.com/tensorflow/tensorflow/pull/70775,[],[],
2387291907,pull_request,open,,Extend CustomCallOp backend_config to take a DictionaryAttr,"Extend CustomCallOp backend_config to take a DictionaryAttr
",copybara-service[bot],2024-07-02 22:51:26+00:00,[],2024-07-09 16:52:35+00:00,,https://github.com/tensorflow/tensorflow/pull/70774,[],[],
2387214054,pull_request,closed,,Add ulp error field for FP8 floats.,"Add ulp error field for FP8 floats.
",copybara-service[bot],2024-07-02 21:41:08+00:00,[],2024-07-12 22:54:35+00:00,2024-07-12 22:54:34+00:00,https://github.com/tensorflow/tensorflow/pull/70773,[],[],
2387202438,pull_request,closed,,Migrate tests to use shared TestDataPath util.,"Migrate tests to use shared TestDataPath util.
",copybara-service[bot],2024-07-02 21:30:59+00:00,['rocketas'],2024-07-02 21:56:26+00:00,2024-07-02 21:56:26+00:00,https://github.com/tensorflow/tensorflow/pull/70772,[],[],
2387191625,pull_request,closed,,Re-enable a bunch of tests with TFRT:TPU,"Re-enable a bunch of tests with TFRT:TPU
",copybara-service[bot],2024-07-02 21:22:21+00:00,[],2024-07-11 22:53:35+00:00,2024-07-11 22:53:34+00:00,https://github.com/tensorflow/tensorflow/pull/70771,[],[],
2387182622,pull_request,closed,,Remove obsolete workflows from XLA and TensorFlow,"Remove obsolete workflows from XLA and TensorFlow
",copybara-service[bot],2024-07-02 21:16:44+00:00,['ddunl'],2024-07-02 22:15:43+00:00,2024-07-02 22:15:43+00:00,https://github.com/tensorflow/tensorflow/pull/70770,[],[],
2387156777,pull_request,closed,,Fix breakage to TF Serving,"Fix breakage to TF Serving

TF Serving has not been able to release due to a breakage in one
of its dependencies.

mkl_sparse_matrix_matmul_op began using CSRMatMulOp in
https://github.com/tensorflow/tensorflow/pull/63030. CSRMatMulOp
uses extensive templating but the templating specialization was
split between the header and cc files. This cl moves it entirely into
the header file.

For some reason, the original change did not cause breakages to
the main TF release but it does break TF serving when it is included.
",copybara-service[bot],2024-07-02 21:00:44+00:00,['tf-marissaw'],2024-07-09 20:49:53+00:00,2024-07-09 20:49:52+00:00,https://github.com/tensorflow/tensorflow/pull/70769,[],[],
2387154030,pull_request,closed,,Create testing util for getting test data path for v2 api. Sets up base directory for future utilities and testing needs. Testdata will be migrated to this directory as well.,"Create testing util for getting test data path for v2 api. Sets up base directory for future utilities and testing needs. Testdata will be migrated to this directory as well.
",copybara-service[bot],2024-07-02 20:58:58+00:00,['rocketas'],2024-07-02 21:37:52+00:00,2024-07-02 21:37:51+00:00,https://github.com/tensorflow/tensorflow/pull/70768,[],[],
2387143356,pull_request,closed,,PR #13805: [ROCm] Fix pjrt topology code to support ROCm,"PR #13805: [ROCm] Fix pjrt topology code to support ROCm

Imported from GitHub PR https://github.com/openxla/xla/pull/13805


Copybara import of the project:

--
a4bce65d028426a46c93527cdea734aa4d5370b6 by Ruturaj4 <Ruturaj.Vaidya@amd.com>:

[ROCm] Fix pjrt topology code to support ROCm

Merging this change closes #13805

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/13805 from ROCm:ci_pjrt_platform_fix a4bce65d028426a46c93527cdea734aa4d5370b6
",copybara-service[bot],2024-07-02 20:51:16+00:00,[],2024-07-03 09:08:01+00:00,2024-07-03 09:07:59+00:00,https://github.com/tensorflow/tensorflow/pull/70767,[],[],
2387101089,pull_request,closed,,[xla:cpu] Add benchmark for compiling a chain if f32[12] buffers,"[xla:cpu] Add benchmark for compiling a chain if f32[12] buffers

This is an example of missing aliasing information leading to ~1000x performance regression in a thunk runtime

Thunk (""new"") vs classic (""old"") runtime:
name                               old cpu/op   new cpu/op      delta
BM_ChainOfAddF32/8/process_time    6.59µs ± 2%     6.92µs ± 3%      +4.96%  (p=0.008 n=5+5)
BM_ChainOfAddF32/16/process_time   7.03µs ± 1%     7.85µs ± 3%     +11.66%  (p=0.008 n=5+5)
BM_ChainOfAddF32/64/process_time   10.6µs ± 3%     13.0µs ± 2%     +23.23%  (p=0.008 n=5+5)
BM_ChainOfAddF32/128/process_time  15.1µs ± 3%   2894.8µs ± 1%  +19105.60%  (p=0.008 n=5+5)
BM_ChainOfAddF32/256/process_time  25.4µs ± 2%   8361.8µs ± 0%  +32819.31%  (p=0.008 n=5+5)
BM_ChainOfAddF32/512/process_time  47.2µs ± 3%  19282.6µs ± 1%  +40728.54%  (p=0.008 n=5+5)
",copybara-service[bot],2024-07-02 20:23:23+00:00,['ezhulenev'],2024-07-03 11:42:09+00:00,2024-07-03 11:42:08+00:00,https://github.com/tensorflow/tensorflow/pull/70766,[],[],
2386990448,pull_request,closed,,[oneDNN] Update oneDNN library to v3.5,,yimeisun123,2024-07-02 19:22:33+00:00,['gbaned'],2024-07-04 16:08:02+00:00,2024-07-04 16:08:02+00:00,https://github.com/tensorflow/tensorflow/pull/70765,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:S', 'CL Change Size: Small')]","[{'comment_id': 2204171062, 'issue_id': 2386990448, 'author': 'yimeisun123', 'body': '@penpornk , do we need to create a separate PR in openxla to update the oneDNN library OR will this PR change be ported over to openxla? Thanks', 'created_at': datetime.datetime(2024, 7, 2, 19, 28, 3, tzinfo=datetime.timezone.utc)}, {'comment_id': 2205086156, 'issue_id': 2386990448, 'author': 'keerthanakadiri', 'body': 'Hi @MichaelHudgins Can you please review this PR? Thank you .', 'created_at': datetime.datetime(2024, 7, 3, 4, 38, 59, tzinfo=datetime.timezone.utc)}]","yimeisun123 (Issue Creator) on (2024-07-02 19:28:03 UTC): @penpornk , do we need to create a separate PR in openxla to update the oneDNN library OR will this PR change be ported over to openxla? Thanks

keerthanakadiri on (2024-07-03 04:38:59 UTC): Hi @MichaelHudgins Can you please review this PR? Thank you .

"
2386987470,pull_request,closed,,Add an XLA:CPU fusion benchmark.,"Add an XLA:CPU fusion benchmark.

Thunk runtime (""new"") is 5-12% slower than the classic runtime (""old"")

```
name                                                old cpu/op   new cpu/op   delta
BM_FusionF32_2/40/process_time                      1.56µs ± 2%  1.75µs ± 1%   +12.13%  (p=0.008 n=5+5)
BM_FusionF32_2/80/process_time                      2.21µs ± 1%  2.41µs ± 1%    +9.04%  (p=0.008 n=5+5)
BM_FusionF32_2/160/process_time                     3.54µs ± 0%  3.77µs ± 1%    +6.56%  (p=0.008 n=5+5)
BM_FusionF32_2/240/process_time                     4.88µs ± 0%  5.12µs ± 1%    +4.82%  (p=0.008 n=5+5)
```

Reverts 9467e3ac6f16ae1ceb3b246b53fa7db34a1a9999
",copybara-service[bot],2024-07-02 19:21:00+00:00,['penpornk'],2024-07-02 20:09:19+00:00,2024-07-02 20:09:19+00:00,https://github.com/tensorflow/tensorflow/pull/70764,[],[],
2386923895,pull_request,closed,,Refactor build transforms and header replacements,"Refactor build transforms and header replacements
",copybara-service[bot],2024-07-02 18:50:11+00:00,['ddunl'],2024-07-03 23:58:12+00:00,2024-07-03 23:58:12+00:00,https://github.com/tensorflow/tensorflow/pull/70763,[],[],
2386914765,pull_request,closed,,[xla:gpu] Increase the threshold for strength reducing small dots to 10M elements,"[xla:gpu] Increase the threshold for strength reducing small dots to 10M elements
",copybara-service[bot],2024-07-02 18:44:29+00:00,['anlunx'],2024-07-03 22:40:03+00:00,2024-07-03 22:40:03+00:00,https://github.com/tensorflow/tensorflow/pull/70762,[],[],
2386863928,pull_request,closed,,[XLA] Give NumMappedDims() internal linkage and use a simple constant instead.,"[XLA] Give NumMappedDims() internal linkage and use a simple constant instead.

Since this constant is only used inside the implementation of SpaceToBatchConverter, it can be made local to space_to_batch_converter.cc. This avoids a potential ODR collision if some other class were to attempt to define the symbol xla::NumMappedDims, which is a fairly generic name.
",copybara-service[bot],2024-07-02 18:12:37+00:00,[],2024-07-02 19:37:25+00:00,2024-07-02 19:37:24+00:00,https://github.com/tensorflow/tensorflow/pull/70761,[],[],
2386861644,pull_request,closed,,Inline buildozer rule for `stream_executor_impl`,"Inline buildozer rule for `stream_executor_impl`

Reverts 9467e3ac6f16ae1ceb3b246b53fa7db34a1a9999
",copybara-service[bot],2024-07-02 18:11:03+00:00,['ddunl'],2024-07-02 20:02:59+00:00,2024-07-02 20:02:58+00:00,https://github.com/tensorflow/tensorflow/pull/70760,[],[],
2386860500,pull_request,open,,[XLA] Make sure we generate erf results which are in-range,"[XLA] Make sure we generate erf results which are in-range

erf(x) should be in [-1, 1]. Due to rounding, we may fall just outside of that range. Clamp the output so that we will be properly in-range.
",copybara-service[bot],2024-07-02 18:10:18+00:00,['majnemer'],2024-07-10 15:30:22+00:00,,https://github.com/tensorflow/tensorflow/pull/70759,[],[],
2386827952,pull_request,closed,,Allow duplicate handler registration when traits and bundle addresses are equal,"Allow duplicate handler registration when traits and bundle addresses are equal

The behavior of the FFI handler registration is currently stricter than the ""legacy"" custom call behavior. Here we reproduce the legacy behavior by allowing duplicate registration when the traits and addresses for all elements in the handler bundle.
",copybara-service[bot],2024-07-02 17:49:18+00:00,[],2024-07-03 11:47:16+00:00,2024-07-03 11:47:15+00:00,https://github.com/tensorflow/tensorflow/pull/70758,[],[],
2386774171,pull_request,open,,PR #14202: [fusion] Add RS->DUS dynamic slice fusion,"PR #14202: [fusion] Add RS->DUS dynamic slice fusion

Imported from GitHub PR https://github.com/openxla/xla/pull/14202

This patch adds execution support and fusion rewriting support for reduce-scatter -> dynamic-update-slice pattern.
Copybara import of the project:

--
180b1d57405aac7cb60607cb73c7f67d78f16426 by Shraiysh Vaishay <svaishay@nvidia.com>:

[fusion] Add RS->DUS dynamic slice fusion

This patch adds execution support and fusion rewriting support for
reduce-scatter -> dynamic-update-slice pattern.

Merging this change closes #14202

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14202 from shraiysh:rs_ds_fusion 180b1d57405aac7cb60607cb73c7f67d78f16426
",copybara-service[bot],2024-07-02 17:21:04+00:00,[],2024-07-03 09:59:19+00:00,,https://github.com/tensorflow/tensorflow/pull/70756,[],[],
2386771710,pull_request,open,,[XLA] Simplify logic in hlo broadcast splitter.,"[XLA] Simplify logic in hlo broadcast splitter.
",copybara-service[bot],2024-07-02 17:19:45+00:00,['blakehechtman'],2024-07-02 17:19:46+00:00,,https://github.com/tensorflow/tensorflow/pull/70755,[],[],
2386763227,pull_request,closed,,Reverts 9467e3ac6f16ae1ceb3b246b53fa7db34a1a9999,"Reverts 9467e3ac6f16ae1ceb3b246b53fa7db34a1a9999
",copybara-service[bot],2024-07-02 17:14:16+00:00,['Tongfei-Guo'],2024-07-02 19:29:50+00:00,2024-07-02 19:29:50+00:00,https://github.com/tensorflow/tensorflow/pull/70754,[],[],
2386757741,pull_request,closed,,[XLA] Remove the special input bounder,"[XLA] Remove the special input bounder

It is non-deterministic and is not really needed.
",copybara-service[bot],2024-07-02 17:11:06+00:00,['majnemer'],2024-07-04 04:56:38+00:00,2024-07-04 04:56:37+00:00,https://github.com/tensorflow/tensorflow/pull/70753,[],[],
2386699956,pull_request,closed,,PR #14264: [XLA:GPU] Add  debug info for command buffer trace cache,"PR #14264: [XLA:GPU] Add  debug info for command buffer trace cache

Imported from GitHub PR https://github.com/openxla/xla/pull/14264


Copybara import of the project:

--
81b420b002d751777ff8fed442ca6a277ce14a0a by Shawn Wang <shawnw@nvidia.com>:

add some debug info for command buffer trace cache

--
40657c8af9d9cb99563367afd66128469182fe24 by Shawn Wang <shawnw@nvidia.com>:

fix tests

Merging this change closes #14264

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14264 from shawnwang18:shawnw/add_trace_cache_debug 40657c8af9d9cb99563367afd66128469182fe24
",copybara-service[bot],2024-07-02 16:36:01+00:00,[],2024-07-03 09:35:23+00:00,2024-07-03 09:35:23+00:00,https://github.com/tensorflow/tensorflow/pull/70752,[],"[{'comment_id': 2203792942, 'issue_id': 2386699956, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70752/checks?check_run_id=26953855278) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 2, 16, 36, 6, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-02 16:36:06 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70752/checks?check_run_id=26953855278) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2386603588,pull_request,closed,,PR #14203: [ROCm] Fix dot_bf16 using feature conditions,"PR #14203: [ROCm] Fix dot_bf16 using feature conditions

Imported from GitHub PR https://github.com/openxla/xla/pull/14203

Better workaround for dot_bf16.hlo.test. 
Copybara import of the project:

--
041b60e9b45cf269d68bed21eaf98e658f137e52 by mmakevic <Milica.Makevic@amd.com>:

Fix dot_bf16 using feature conditions

Remove unused params

Fix if statement in lit.cfg.py

Merging this change closes #14203

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14203 from ROCm:ci_dot_bf16_fix 041b60e9b45cf269d68bed21eaf98e658f137e52
",copybara-service[bot],2024-07-02 15:46:26+00:00,[],2024-07-03 09:27:52+00:00,2024-07-03 09:27:50+00:00,https://github.com/tensorflow/tensorflow/pull/70751,[],[],
2386602903,pull_request,closed,,Use schema target in compiler/mlir for converter_python_api.,"Use schema target in compiler/mlir for converter_python_api.
",copybara-service[bot],2024-07-02 15:46:03+00:00,[],2024-07-02 17:53:50+00:00,2024-07-02 17:53:49+00:00,https://github.com/tensorflow/tensorflow/pull/70750,[],[],
2386585722,pull_request,closed,,gen_gpu_hlo_compile_tests: Don't run in internal coverage infrastructure.,"gen_gpu_hlo_compile_tests: Don't run in internal coverage infrastructure.
",copybara-service[bot],2024-07-02 15:37:27+00:00,[],2024-07-03 16:55:58+00:00,2024-07-03 16:55:57+00:00,https://github.com/tensorflow/tensorflow/pull/70749,[],[],
2386535426,pull_request,closed,,Remove superfluous dependency on reduced precision support.,"Remove superfluous dependency on reduced precision support.
",copybara-service[bot],2024-07-02 15:16:28+00:00,[],2024-07-02 18:39:54+00:00,2024-07-02 18:39:53+00:00,https://github.com/tensorflow/tensorflow/pull/70748,[],[],
2386474905,pull_request,closed,,Add a cumulative query count per model to the batch stats module.,"Add a cumulative query count per model to the batch stats module.
",copybara-service[bot],2024-07-02 14:50:22+00:00,[],2024-07-02 15:32:23+00:00,2024-07-02 15:32:21+00:00,https://github.com/tensorflow/tensorflow/pull/70746,[],[],
2386447433,pull_request,open,,Reverts 9467e3ac6f16ae1ceb3b246b53fa7db34a1a9999,"Reverts 9467e3ac6f16ae1ceb3b246b53fa7db34a1a9999
",copybara-service[bot],2024-07-02 14:38:41+00:00,['changm'],2024-07-02 14:38:42+00:00,,https://github.com/tensorflow/tensorflow/pull/70745,[],[],
2386325010,pull_request,closed,,Fix tensorflow lite label_image cmake build error.,Fix #70659,NobuoTsukamoto,2024-07-02 13:49:38+00:00,['gbaned'],2024-10-21 22:57:54+00:00,2024-08-07 06:47:59+00:00,https://github.com/tensorflow/tensorflow/pull/70742,"[('awaiting review', 'Pull request awaiting review'), ('comp:lite', 'TF Lite related issues'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small'), ('prtype:bugfix', 'PR to fix a bug')]","[{'comment_id': 2205138780, 'issue_id': 2386325010, 'author': 'keerthanakadiri', 'body': 'Hi @mattsoulanille Can you please review this PR? Thank you .', 'created_at': datetime.datetime(2024, 7, 3, 5, 39, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2228122973, 'issue_id': 2386325010, 'author': 'keerthanakadiri', 'body': 'Hi @mattsoulanille Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 7, 15, 9, 58, 31, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244322991, 'issue_id': 2386325010, 'author': 'keerthanakadiri', 'body': 'Hi @mattsoulanille, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 7, 23, 6, 5, 11, tzinfo=datetime.timezone.utc)}, {'comment_id': 2270838934, 'issue_id': 2386325010, 'author': 'keerthanakadiri', 'body': 'Hi @mattsoulanille, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 8, 6, 9, 37, 19, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-07-03 05:39:26 UTC): Hi @mattsoulanille Can you please review this PR? Thank you .

keerthanakadiri on (2024-07-15 09:58:31 UTC): Hi @mattsoulanille Can you please review this PR? Thank you !

keerthanakadiri on (2024-07-23 06:05:11 UTC): Hi @mattsoulanille, Can you please review this PR? Thank you !

keerthanakadiri on (2024-08-06 09:37:19 UTC): Hi @mattsoulanille, Can you please review this PR? Thank you !

"
2386228936,pull_request,closed,,Integrate Triton up to [a7e3476e](https://github.com/openai/triton/commits/a7e3476e86757780c2528d1100eb7aabe58d8c19),"Integrate Triton up to [a7e3476e](https://github.com/openai/triton/commits/a7e3476e86757780c2528d1100eb7aabe58d8c19)
",copybara-service[bot],2024-07-02 13:15:30+00:00,[],2024-07-03 14:59:40+00:00,2024-07-03 14:59:39+00:00,https://github.com/tensorflow/tensorflow/pull/70741,[],[],
2386174637,pull_request,closed,,PR #14353: Fix //xla/service/gpu:triton_support_test in OSS,"PR #14353: Fix //xla/service/gpu:triton_support_test in OSS

Imported from GitHub PR https://github.com/openxla/xla/pull/14353

Currently the test fails with:

xla/service/gpu/triton_support_test.cc:49:18: error: no member named 'status' in namespace 'testing'                                                                                                                
   49 | using ::testing::status::IsOk;                                                                                                                                                                              

Copybara import of the project:

--
f64fef5fea1a4bd9c42a4d3e63538902554a9428 by Sergey Kozub <skozub@nvidia.com>:

Fix //xla/service/gpu:triton_support_test in OSS

Merging this change closes #14353

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14353 from openxla:skozub/triton_support_test f64fef5fea1a4bd9c42a4d3e63538902554a9428
",copybara-service[bot],2024-07-02 12:50:59+00:00,[],2024-07-02 13:25:04+00:00,2024-07-02 13:25:03+00:00,https://github.com/tensorflow/tensorflow/pull/70740,[],[],
2386085870,pull_request,closed,,[XLA:CPU] Align thunks runtime to current runtime behavior for `rng` op.,"[XLA:CPU] Align thunks runtime to current runtime behavior for `rng` op.


Current runtime returns an explicit error that `rng` cannot be called directly and should be expanded. This CL introduces the same behavior for thunks runtime.

Additionally, this CL adds a test that covers the case when `rng` op expander is disabled.
",copybara-service[bot],2024-07-02 12:08:16+00:00,[],2024-07-03 11:52:24+00:00,2024-07-03 11:52:23+00:00,https://github.com/tensorflow/tensorflow/pull/70739,[],"[{'comment_id': 2202997939, 'issue_id': 2386085870, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70739/checks?check_run_id=26939913826) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 2, 12, 8, 22, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-02 12:08:22 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70739/checks?check_run_id=26939913826) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2386070087,pull_request,closed,,Remove libtensorflow_framework.so.2 dependency.,"Remove libtensorflow_framework.so.2 dependency.

This was a workaround for a bazel bug which seems to have been fixed.
",copybara-service[bot],2024-07-02 12:00:25+00:00,['akuegel'],2024-07-02 14:02:16+00:00,2024-07-02 14:02:15+00:00,https://github.com/tensorflow/tensorflow/pull/70738,[],[],
2386068474,pull_request,closed,,[XLA:GPU] Change `ConstraintExpression` to use `llvm::SmallVector` under the hood.,"[XLA:GPU] Change `ConstraintExpression` to use `llvm::SmallVector` under the hood.

Gives a 20% compile-time speedup on benchmarks.
",copybara-service[bot],2024-07-02 11:59:37+00:00,[],2024-07-02 12:49:10+00:00,2024-07-02 12:49:09+00:00,https://github.com/tensorflow/tensorflow/pull/70737,[],[],
2386063349,pull_request,closed,,Remove a duplicate bounds check.,"Remove a duplicate bounds check.

This condition is already checked in EvaluateEpilogue (`thread_id[1]`
is constrained to {0, 0}).
",copybara-service[bot],2024-07-02 11:56:59+00:00,[],2024-07-02 14:10:18+00:00,2024-07-02 14:10:18+00:00,https://github.com/tensorflow/tensorflow/pull/70736,[],[],
2385888708,pull_request,closed,,PR #14354: Fix //xla/service/gpu:autotuner_util_test in OSS,"PR #14354: Fix //xla/service/gpu:autotuner_util_test in OSS

Imported from GitHub PR https://github.com/openxla/xla/pull/14354

Currently the test fails with:

external/com_google_googletest/googletest/include/gtest/gtest-message.h:103:3: note: candidate constructor not viable: no known conversion from 'const AutotuneResult' to 'const Message &' for 1st argument        
  103 |   Message(const Message& msg) : ss_(new ::std::stringstream) {  // NOLINT                                                                                                                                   

Copybara import of the project:

--
d2fa608d3bcdbbf5388535e72517229e6e2562db by Sergey Kozub <skozub@nvidia.com>:

Fix //xla/service/gpu:autotuner_util_test in OSS

Merging this change closes #14354

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14354 from openxla:skozub/autotuner_util_test d2fa608d3bcdbbf5388535e72517229e6e2562db
",copybara-service[bot],2024-07-02 10:36:45+00:00,[],2024-07-02 12:14:50+00:00,2024-07-02 12:14:49+00:00,https://github.com/tensorflow/tensorflow/pull/70735,[],[],
2385794409,pull_request,closed,,Inline XLA_DEVICE_DEPS and run build_cleaner,"Inline XLA_DEVICE_DEPS and run build_cleaner

Factoring out common deps is an antipattern. It makes it harder for dependency
management tools, and it often happens that some deps creep in which are in
fact not commonly used in all targets that reference the ""common"" deps.
",copybara-service[bot],2024-07-02 09:53:02+00:00,['akuegel'],2024-07-02 13:17:14+00:00,2024-07-02 13:17:13+00:00,https://github.com/tensorflow/tensorflow/pull/70734,[],[],
2385774200,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14357 from openxla:skozub/gpu_latency_hiding_scheduler_test 5de2ab7f8cf625af002059215b29ecf2a6a45535
",copybara-service[bot],2024-07-02 09:43:47+00:00,[],2024-07-02 09:43:47+00:00,,https://github.com/tensorflow/tensorflow/pull/70733,[],[],
2385724455,pull_request,closed,,PR #14359: Add Blackwell-related methods to CudaComputeCapability class,"PR #14359: Add Blackwell-related methods to CudaComputeCapability class

Imported from GitHub PR https://github.com/openxla/xla/pull/14359

Also remove unused methods `GetMaxResidentBlocksPerSM` and `GetMaxResidentWarpsPerSM`
Copybara import of the project:

--
42e4c163eb88f4f662eaf08cc19c2d8f6ffe5e29 by Sergey Kozub <skozub@nvidia.com>:

Add Blackwell-related methods to CudaComputeCapability class


Merging this change closes #14359

Reverts 1f6b4e9733885c1bcb89b2d84d693a72bcf9197c

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14359 from openxla:skozub/blackwell 42e4c163eb88f4f662eaf08cc19c2d8f6ffe5e29
",copybara-service[bot],2024-07-02 09:22:06+00:00,[],2024-07-03 10:04:48+00:00,2024-07-03 10:04:48+00:00,https://github.com/tensorflow/tensorflow/pull/70732,[],[],
2385692672,pull_request,closed,,Fix file path in target patterns.,"Fix file path in target patterns.

tensorflow/compiler/tensorrt doesn't exist.
tensorflow/python/compiler/tensorrt exists. So use that.

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14357 from openxla:skozub/gpu_latency_hiding_scheduler_test 5de2ab7f8cf625af002059215b29ecf2a6a45535
",copybara-service[bot],2024-07-02 09:09:12+00:00,['akuegel'],2024-07-02 10:46:59+00:00,2024-07-02 10:46:58+00:00,https://github.com/tensorflow/tensorflow/pull/70731,[],[],
2385598003,pull_request,closed,,PR #14358: Fix build failure for //xla/service/gpu/kernels:cutlass_gemm_custom_kernel_benchmarks in OSS,"PR #14358: Fix build failure for //xla/service/gpu/kernels:cutlass_gemm_custom_kernel_benchmarks in OSS

Imported from GitHub PR https://github.com/openxla/xla/pull/14358

Currently the build fails with:

ERROR: /home/skozub/xla/xla/service/gpu/kernels/BUILD:294:10: Linking xla/service/gpu/kernels/cutlass_gemm_custom_kernel_benchmarks failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error exe
cuting command (from target //xla/service/gpu/kernels:cutlass_gemm_custom_kernel_benchmarks) external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt/bin/xla/service/gpu/k
ernels/cutlass_gemm_custom_kernel_benchmarks-2.params                                                                                                                                                                  
ld.lld: error: undefined symbol: xla::AutotuneResult::AutotuneResult(google::protobuf::Arena*, bool)                                                                                                                   

Copybara import of the project:

--
afbf03c7e5ad4c0348d31ab59e87603afa452c2b by Sergey Kozub <skozub@nvidia.com>:

Fix build failure for //xla/service/gpu/kernels:cutlass_gemm_custom_kernel_benchmarks in OSS

Merging this change closes #14358

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14358 from openxla:skozub/cutlass_gemm_custom_kernel_benchmarks afbf03c7e5ad4c0348d31ab59e87603afa452c2b
",copybara-service[bot],2024-07-02 08:29:03+00:00,[],2024-07-02 09:19:49+00:00,2024-07-02 09:19:48+00:00,https://github.com/tensorflow/tensorflow/pull/70729,[],[],
2385559019,pull_request,closed,,PR #14357: Fix build failure for //xla/service/gpu:gpu_latency_hiding_scheduler_test in OSS,"PR #14357: Fix build failure for //xla/service/gpu:gpu_latency_hiding_scheduler_test in OSS

Imported from GitHub PR https://github.com/openxla/xla/pull/14357

Currently fails with:

ERROR: /home/skozub/xla/xla/service/gpu/BUILD:6322:8: Linking xla/service/gpu/gpu_latency_hiding_scheduler_test failed: (Exit 1): crosstool_wrapper_driver_is_not_gcc failed: error executing command (from
 target //xla/service/gpu:gpu_latency_hiding_scheduler_test) external/local_config_cuda/crosstool/clang/bin/crosstool_wrapper_driver_is_not_gcc @bazel-out/k8-opt/bin/xla/service/gpu/gpu_latency_hiding_scheduler_test
-2.params                                                                                                                                                                                                              
ld.lld: error: undefined reference due to --no-allow-shlib-undefined: nextafter                                                                                                                                        
>>> referenced by bazel-out/k8-opt/bin/_solib_local/libexternal_Scom_Ugoogle_Ugoogletest_Slibgtest.so                                                                                                                  
clang: error: linker command failed with exit code 1 (use -v to see invocation)                            

BTW, why do we even have empty test files?
Copybara import of the project:

--
5de2ab7f8cf625af002059215b29ecf2a6a45535 by Sergey Kozub <skozub@nvidia.com>:

Fix build failure for //xla/service/gpu:gpu_latency_hiding_scheduler_test in OSS

Merging this change closes #14357

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14357 from openxla:skozub/gpu_latency_hiding_scheduler_test 5de2ab7f8cf625af002059215b29ecf2a6a45535
",copybara-service[bot],2024-07-02 08:12:21+00:00,[],2024-07-02 09:38:39+00:00,2024-07-02 09:38:38+00:00,https://github.com/tensorflow/tensorflow/pull/70728,[],[],
2385514555,pull_request,closed,,Integrate LLVM at llvm/llvm-project@9b8c2fae38bc,"Integrate LLVM at llvm/llvm-project@9b8c2fae38bc

Updates LLVM usage to match
[9b8c2fae38bc](https://github.com/llvm/llvm-project/commit/9b8c2fae38bc)
",copybara-service[bot],2024-07-02 07:53:53+00:00,[],2024-07-02 15:53:00+00:00,2024-07-02 15:52:59+00:00,https://github.com/tensorflow/tensorflow/pull/70727,[],[],
2385500489,pull_request,closed,,Create a wrapper for `tensorflow.ConvMapProto` returning deterministically serialized keys and values,"Create a wrapper for `tensorflow.ConvMapProto` returning deterministically serialized keys and values
",copybara-service[bot],2024-07-02 07:47:38+00:00,[],2024-07-08 19:06:52+00:00,2024-07-08 19:06:51+00:00,https://github.com/tensorflow/tensorflow/pull/70725,[],[],
2385479590,pull_request,closed,,PR #14356: Fix //xla/service/gpu:execution_stream_assignment_test in OSS,"PR #14356: Fix //xla/service/gpu:execution_stream_assignment_test in OSS

Imported from GitHub PR https://github.com/openxla/xla/pull/14356

Currently the test fails with:

./xla/service/gpu/execution_stream_assignment.h:52:10: note: candidate constructor (the implicit default constructor) not viable: requires 0 arguments, but 2 were provided
xla/service/gpu/execution_stream_assignment_test.cc:107:30: error: no matching constructor for initialization of 'AsyncExecutionStreamIds' (aka 'xla::gpu::ExecutionStreamAssignment::AsyncExecutionStreamIds')     

Copybara import of the project:

--
b75c79dc9d842935358eb0554767b6f3d7c67448 by Sergey Kozub <skozub@nvidia.com>:

Fix //xla/service/gpu:execution_stream_assignment_test in OSS

Merging this change closes #14356

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/14356 from openxla:skozub/execution_stream_assignment_test b75c79dc9d842935358eb0554767b6f3d7c67448
",copybara-service[bot],2024-07-02 07:37:30+00:00,[],2024-07-02 08:05:59+00:00,2024-07-02 08:05:58+00:00,https://github.com/tensorflow/tensorflow/pull/70723,[],[],
2385454166,pull_request,closed,,Reduce stack usage of HLO->MLIR conversion functions.,"Reduce stack usage of HLO->MLIR conversion functions.

- Don't recurse for elementwise ops.
- Set sizes of SmallVectors to the common case (1 for operands,
  3 for indices) instead of using the default 6.
- Don't materialize input indices of elementwise ops.
- Use ValueRange instead of SmallVector<Value> where possible.

Also split up SubgraphToMlir.
",copybara-service[bot],2024-07-02 07:24:37+00:00,[],2024-07-02 16:24:32+00:00,2024-07-02 16:24:30+00:00,https://github.com/tensorflow/tensorflow/pull/70722,[],[],
2385100131,pull_request,open,,Integrate LLVM at llvm/llvm-project@9b8c2fae38bc,"Integrate LLVM at llvm/llvm-project@9b8c2fae38bc

Updates LLVM usage to match
[9b8c2fae38bc](https://github.com/llvm/llvm-project/commit/9b8c2fae38bc)
",copybara-service[bot],2024-07-02 03:12:41+00:00,[],2024-07-02 03:12:41+00:00,,https://github.com/tensorflow/tensorflow/pull/70721,[],[],
2385027809,pull_request,closed,,Refactor more build target transforms,"Refactor more build target transforms
",copybara-service[bot],2024-07-02 01:49:52+00:00,['ddunl'],2024-07-02 19:56:16+00:00,2024-07-02 19:56:15+00:00,https://github.com/tensorflow/tensorflow/pull/70720,[],[],
2385000290,pull_request,closed,,Include control_edges.h in TFLite install,"Include control_edges.h in TFLite install

This patch includes compiler/mlir/lite/utils/control_edges.h as it is used by mlir/lite/experimental/remat/metadata_util.h which is a necessary include for interpreter.h.

Without this header file in the installation, we are seeing build errors when building LLVM with TFLite.
",copybara-service[bot],2024-07-02 01:18:55+00:00,[],2024-07-04 06:30:35+00:00,2024-07-04 06:30:35+00:00,https://github.com/tensorflow/tensorflow/pull/70719,[],[],
2384994541,pull_request,open,,Remove invalid target pattern from TensorFlow builds,"Remove invalid target pattern from TensorFlow builds
",copybara-service[bot],2024-07-02 01:11:25+00:00,['ddunl'],2024-07-02 01:11:26+00:00,,https://github.com/tensorflow/tensorflow/pull/70718,[],[],
2384991315,pull_request,open,,[XLA:SPMD] Remove stale shard group instruction after sharding-aware CSE in sharding proapgation.,"[XLA:SPMD] Remove stale shard group instruction after sharding-aware CSE in sharding proapgation.
",copybara-service[bot],2024-07-02 01:07:06+00:00,['Tongfei-Guo'],2024-07-02 01:07:07+00:00,,https://github.com/tensorflow/tensorflow/pull/70717,[],[],
2384991261,pull_request,closed,,"Refactor hlo -> tfl. Move reduce patterns into reduce specific header. In said header, move inline methods and internal functions into the cc. Dedupe with ""legalize_hlo.cc""","Refactor hlo -> tfl. Move reduce patterns into reduce specific header. In said header, move inline methods and internal functions into the cc. Dedupe with ""legalize_hlo.cc""
",copybara-service[bot],2024-07-02 01:07:01+00:00,['LukeBoyer'],2024-07-09 03:00:59+00:00,2024-07-09 03:00:58+00:00,https://github.com/tensorflow/tensorflow/pull/70716,[],[],
2384990077,pull_request,closed,,Direct legalizations for reshape and dynamic reshape.,"Direct legalizations for reshape and dynamic reshape.
",copybara-service[bot],2024-07-02 01:05:16+00:00,['LukeBoyer'],2024-08-09 05:10:06+00:00,2024-08-09 05:10:05+00:00,https://github.com/tensorflow/tensorflow/pull/70715,[],[],
2384981217,pull_request,closed,,Refactor/cleanup hlo -> tfl pass,"Refactor/cleanup hlo -> tfl pass

* Make the convert dot general function an explicit pattern class and register in cc
* Remove unused functions
* Remove redundant commentary
",copybara-service[bot],2024-07-02 00:53:53+00:00,['LukeBoyer'],2024-07-05 23:08:31+00:00,2024-07-05 23:08:31+00:00,https://github.com/tensorflow/tensorflow/pull/70714,[],[],
2384944057,pull_request,closed,,"[odml DL] Actually use ""split-input-file"".","[odml DL] Actually use ""split-input-file"".
",copybara-service[bot],2024-07-02 00:08:26+00:00,['LukeBoyer'],2024-07-02 17:33:41+00:00,2024-07-02 17:33:40+00:00,https://github.com/tensorflow/tensorflow/pull/70713,[],[],
2384907753,pull_request,open,,Add mising `llvm/Support` dependency on `run_hlo_module_test` target,"Add mising `llvm/Support` dependency on `run_hlo_module_test` target
",copybara-service[bot],2024-07-01 23:29:57+00:00,['sdasgup3'],2024-07-01 23:29:58+00:00,,https://github.com/tensorflow/tensorflow/pull/70712,[],[],
2384856754,pull_request,open,,Use the cpu tag filters for the CPU build and cuda tag filters for the CUDA build,"Use the cpu tag filters for the CPU build and cuda tag filters for the CUDA build
",copybara-service[bot],2024-07-01 22:43:30+00:00,['ddunl'],2024-07-01 22:43:31+00:00,,https://github.com/tensorflow/tensorflow/pull/70711,[],[],
2384831568,pull_request,closed,,Refactor more build target transformations,"Refactor more build target transformations
",copybara-service[bot],2024-07-01 22:24:45+00:00,['ddunl'],2024-07-02 02:24:59+00:00,2024-07-02 02:24:58+00:00,https://github.com/tensorflow/tensorflow/pull/70710,[],[],
2384767761,pull_request,closed,,Add support for compiling for visionOS,"Add support for compiling for visionOS
",copybara-service[bot],2024-07-01 21:28:58+00:00,[],2024-07-03 18:18:14+00:00,2024-07-03 18:18:13+00:00,https://github.com/tensorflow/tensorflow/pull/70709,[],[],
2384767367,pull_request,closed,,Use the cpu tag filters for the CPU build and cuda tag filters for the CUDA build,"Use the cpu tag filters for the CPU build and cuda tag filters for the CUDA build
",copybara-service[bot],2024-07-01 21:28:38+00:00,['ddunl'],2024-07-01 23:09:00+00:00,2024-07-01 23:08:59+00:00,https://github.com/tensorflow/tensorflow/pull/70708,[],[],
2384755362,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@2a6ae6e1,"Integrate StableHLO at openxla/stablehlo@2a6ae6e1
",copybara-service[bot],2024-07-01 21:19:10+00:00,['ghpvnist'],2024-07-02 20:52:35+00:00,2024-07-02 20:52:34+00:00,https://github.com/tensorflow/tensorflow/pull/70707,[],[],
2384741194,pull_request,closed,,Remove early return when verifying async custom-call instructions.,"Remove early return when verifying async custom-call instructions.
",copybara-service[bot],2024-07-01 21:08:11+00:00,[],2024-07-03 18:25:51+00:00,2024-07-03 18:25:51+00:00,https://github.com/tensorflow/tensorflow/pull/70706,[],[],
2384699384,pull_request,closed,,Inline odml.embedding_lookup composite,"Inline odml.embedding_lookup composite
",copybara-service[bot],2024-07-01 20:42:57+00:00,['paulinesho'],2024-07-15 20:59:41+00:00,2024-07-15 20:59:40+00:00,https://github.com/tensorflow/tensorflow/pull/70705,[],[],
2384674569,pull_request,closed,,[xla:sdy] Open source xla passes for Shardy.,"[xla:sdy] Open source xla passes for Shardy.
",copybara-service[bot],2024-07-01 20:27:02+00:00,['bixia1'],2024-07-11 23:46:24+00:00,2024-07-11 23:46:23+00:00,https://github.com/tensorflow/tensorflow/pull/70704,[],[],
2384641272,pull_request,open,,"[xla:ffi] Use lazy decoding for Buffer<dtype,rank>","[xla:ffi] Use lazy decoding for Buffer<dtype,rank>

name                old cpu/op   new cpu/op   delta
BM_AnyBufferArgX1   11.0ns ± 3%  11.2ns ±10%   +1.76%  (p=0.000 n=67+69)
BM_AnyBufferArgX4   12.4ns ± 3%  12.4ns ± 4%   -0.31%  (p=0.006 n=69+69)
BM_BufferArgX1      12.5ns ± 1%  11.1ns ± 4%  -11.20%  (p=0.000 n=62+76)
BM_BufferArgX4      19.1ns ± 1%  14.4ns ± 4%  -24.84%  (p=0.000 n=64+73)
BM_BufferArgX8      36.0ns ± 5%  20.3ns ± 4%  -43.59%  (p=0.000 n=79+75)
BM_TupleOfI32Attrs  66.4ns ± 1%  66.4ns ± 2%   -0.03%  (p=0.000 n=66+72)
",copybara-service[bot],2024-07-01 20:04:49+00:00,['ezhulenev'],2024-07-09 16:58:30+00:00,,https://github.com/tensorflow/tensorflow/pull/70703,[],[],
2384557891,pull_request,closed,,Refactor BuildHloFromModule to only do the MLIR lowering passes. This entry point is only used by MlirXlaOpKernel which is used to lower a single operation and thus does not require all the other MLIR transformations.,"Refactor BuildHloFromModule to only do the MLIR lowering passes. This entry point is only used by MlirXlaOpKernel which is used to lower a single operation and thus does not require all the other MLIR transformations.
",copybara-service[bot],2024-07-01 19:10:45+00:00,[],2024-07-08 16:52:16+00:00,2024-07-08 16:52:16+00:00,https://github.com/tensorflow/tensorflow/pull/70702,[],[],
2384494841,pull_request,closed,,Returning MatrixDiag to the local kernel op,"Returning MatrixDiag to the local kernel op
",copybara-service[bot],2024-07-01 18:37:41+00:00,[],2024-07-08 02:04:24+00:00,2024-07-08 02:04:23+00:00,https://github.com/tensorflow/tensorflow/pull/70701,[],[],
2384425385,pull_request,closed,,Refactor build target transformations,"Refactor build target transformations
",copybara-service[bot],2024-07-01 17:56:04+00:00,['ddunl'],2024-07-02 00:28:36+00:00,2024-07-02 00:28:35+00:00,https://github.com/tensorflow/tensorflow/pull/70700,[],[],
2384396932,pull_request,closed,,Change `test_filters` and targets for TensorFlow builds,"Change `test_filters` and targets for TensorFlow builds
",copybara-service[bot],2024-07-01 17:37:39+00:00,['ddunl'],2024-07-01 18:57:17+00:00,2024-07-01 18:57:15+00:00,https://github.com/tensorflow/tensorflow/pull/70699,[],[],
2384258881,pull_request,closed,,[PJRT] Remove StableHLO bytecode patches now that VHLO is used.,"[PJRT] Remove StableHLO bytecode patches now that VHLO is used.

Several hacks/patches were put in place to preserve StableHLO compatibility, now that we are sending VHLO in PJRT we can clean these all up.
",copybara-service[bot],2024-07-01 16:30:00+00:00,['GleasonK'],2024-07-01 22:02:58+00:00,2024-07-01 22:02:58+00:00,https://github.com/tensorflow/tensorflow/pull/70698,[],[],
2384230154,pull_request,open,,Integrate LLVM at llvm/llvm-project@99d8bc9e7686,"Integrate LLVM at llvm/llvm-project@99d8bc9e7686

Updates LLVM usage to match
[99d8bc9e7686](https://github.com/llvm/llvm-project/commit/99d8bc9e7686)
",copybara-service[bot],2024-07-01 16:13:35+00:00,[],2024-07-01 16:13:35+00:00,,https://github.com/tensorflow/tensorflow/pull/70697,[],[],
2384146623,pull_request,closed,,[XLA:GPU] Remove recursion from SymbolicTileAnalysis::ComputeTiledHloInstructions.,"[XLA:GPU] Remove recursion from SymbolicTileAnalysis::ComputeTiledHloInstructions.

The recursion was needed to order tiled hlo instructions in def-before-use order, but since symbolic tiled hlo instruction are already sorted, a simple look does the same job.
",copybara-service[bot],2024-07-01 15:31:13+00:00,[],2024-07-02 09:11:48+00:00,2024-07-02 09:11:46+00:00,https://github.com/tensorflow/tensorflow/pull/70696,[],[],
2384127212,pull_request,closed,,[xla:sdy] Add a toy example for using shardy.,"[xla:sdy] Add a toy example for using shardy.
",copybara-service[bot],2024-07-01 15:21:58+00:00,['bixia1'],2024-07-09 03:28:49+00:00,2024-07-09 03:28:49+00:00,https://github.com/tensorflow/tensorflow/pull/70695,[],[],
2384110380,pull_request,closed,,Split multi row reduction into a separate class.,"Split multi row reduction into a separate class.

Also refactor EmitPerThreadReducedElements to prepare for one thread
writing multiple rows in row reductions.
",copybara-service[bot],2024-07-01 15:13:52+00:00,[],2024-07-02 08:33:39+00:00,2024-07-02 08:33:37+00:00,https://github.com/tensorflow/tensorflow/pull/70694,[],[],
2384047843,pull_request,open,,[XLA:GPU] Make `HloIotaInstruction` elementwise.,"[XLA:GPU] Make `HloIotaInstruction` elementwise.

Like `HloConstantInstruction` or `HloRngInstruction`, `HloIotaInstruction` is
trivially elementwise.
",copybara-service[bot],2024-07-01 14:45:46+00:00,[],2024-07-01 14:45:46+00:00,,https://github.com/tensorflow/tensorflow/pull/70693,[],[],
2384029860,pull_request,closed,,Remove unnecessary includes from `traceme.h`,"Remove unnecessary includes from `traceme.h`
",copybara-service[bot],2024-07-01 14:37:36+00:00,[],2024-07-01 17:44:12+00:00,2024-07-01 17:44:12+00:00,https://github.com/tensorflow/tensorflow/pull/70692,[],[],
2383955338,pull_request,open,,Fixes tensorflow/tensorflow#70581.,"As per the title, this PR fixes tensorflow/tensorflow#70581.

The way I went about it is to allow the caller to specify whether or not the code calling the `KubernetesClusterResolver` is within a K8S cluster or in any other environment outside it.",msteiner-google,2024-07-01 14:06:17+00:00,['gbaned'],2025-01-16 08:48:39+00:00,,https://github.com/tensorflow/tensorflow/pull/70691,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:M', 'CL Change Size: Medium'), ('prtype:bugfix', 'PR to fix a bug')]","[{'comment_id': 2205079376, 'issue_id': 2383955338, 'author': 'keerthanakadiri', 'body': 'Hi @MichaelHudgins Can you please review this PR? Thank you .', 'created_at': datetime.datetime(2024, 7, 3, 4, 30, 37, tzinfo=datetime.timezone.utc)}, {'comment_id': 2222418941, 'issue_id': 2383955338, 'author': 'msteiner-google', 'body': '@MichaelHudgins can you add the `readytopull` tag again to sync the internal cl?', 'created_at': datetime.datetime(2024, 7, 11, 9, 9, 56, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-07-03 04:30:37 UTC): Hi @MichaelHudgins Can you please review this PR? Thank you .

msteiner-google (Issue Creator) on (2024-07-11 09:09:56 UTC): @MichaelHudgins can you add the `readytopull` tag again to sync the internal cl?

"
2383915058,pull_request,closed,,Moved testdata to sparsity folder.,"Moved testdata to sparsity folder.
",copybara-service[bot],2024-07-01 13:49:09+00:00,[],2024-07-01 16:16:47+00:00,2024-07-01 16:16:46+00:00,https://github.com/tensorflow/tensorflow/pull/70690,[],[],
2383869647,pull_request,closed,,Remove unit dimensions in row reduction tile and block sizes.,"Remove unit dimensions in row reduction tile and block sizes.

Currently, it's a bit hard to understand what the indexing of a row
reduction is. With this CL, it's still a bit hard to understand, but
maybe slightly less so.
",copybara-service[bot],2024-07-01 13:30:55+00:00,[],2024-07-01 14:55:01+00:00,2024-07-01 14:55:00+00:00,https://github.com/tensorflow/tensorflow/pull/70689,[],[],
2383837015,pull_request,closed,,Add a test case for 3d row reductions.,"Add a test case for 3d row reductions.

This wasn't covered by a unit test before, afaict.
",copybara-service[bot],2024-07-01 13:18:44+00:00,[],2024-07-01 13:45:15+00:00,2024-07-01 13:45:14+00:00,https://github.com/tensorflow/tensorflow/pull/70688,[],[],
2383649417,pull_request,closed,,Reverts a3f86f1c5f62e8516396c5687e0511c7bb3c0d47,"Reverts a3f86f1c5f62e8516396c5687e0511c7bb3c0d47
",copybara-service[bot],2024-07-01 11:58:08+00:00,[],2024-07-01 14:05:01+00:00,2024-07-01 14:05:00+00:00,https://github.com/tensorflow/tensorflow/pull/70686,[],[],
2383628187,pull_request,closed,,[XLA:CPU] Emit 'reduce precision' thunk.,"[XLA:CPU] Emit 'reduce precision' thunk.
",copybara-service[bot],2024-07-01 11:47:37+00:00,[],2024-07-01 15:43:23+00:00,2024-07-01 15:43:22+00:00,https://github.com/tensorflow/tensorflow/pull/70685,[],"[{'comment_id': 2199932373, 'issue_id': 2383628187, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70685/checks?check_run_id=26887490919) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2024, 7, 1, 11, 47, 42, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2024-07-01 11:47:42 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/70685/checks?check_run_id=26887490919) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2383521565,pull_request,open,,Rename Shardonnay to Shardy in leakr_badwords.dic,"Rename Shardonnay to Shardy in leakr_badwords.dic
",copybara-service[bot],2024-07-01 10:58:00+00:00,[],2024-07-01 10:58:00+00:00,,https://github.com/tensorflow/tensorflow/pull/70684,[],[],
2383486857,pull_request,open,,"This is not a public CL, but a presubmit check wants to see this part, likely because this CL is in a chain with other public CLs.","This is not a public CL, but a presubmit check wants to see this part, likely because this CL is in a chain with other public CLs.

Reverts 80f36caf93bc5adf6591d381c8a5a68dbf441fc2
",copybara-service[bot],2024-07-01 10:40:28+00:00,[],2024-07-01 10:40:28+00:00,,https://github.com/tensorflow/tensorflow/pull/70683,[],[],
2383331910,pull_request,closed,,[XLA:GPU] Use sort size threshold of 33K for :gpu_cub_sort_test,"[XLA:GPU] Use sort size threshold of 33K for :gpu_cub_sort_test
",copybara-service[bot],2024-07-01 09:31:38+00:00,['chihuahua'],2024-07-01 10:17:46+00:00,2024-07-01 10:17:46+00:00,https://github.com/tensorflow/tensorflow/pull/70681,[],[],
2383315679,pull_request,closed,,Integrate LLVM at llvm/llvm-project@8598bcb9934d,"Integrate LLVM at llvm/llvm-project@8598bcb9934d

Updates LLVM usage to match
[8598bcb9934d](https://github.com/llvm/llvm-project/commit/8598bcb9934d)
",copybara-service[bot],2024-07-01 09:24:29+00:00,[],2024-07-01 15:12:32+00:00,2024-07-01 15:12:32+00:00,https://github.com/tensorflow/tensorflow/pull/70680,[],[],
2383307377,pull_request,open,,[TOSA] support tfl.batch_matmul with input broadcasting,"add support of unequal rank inputs with broadcasting in `TFL_BatchMatMulOp` lowering to `tosa.matmul`

example:
In the case of `batch_matmul` with broadcasting:
```
%0 = ""tfl.batch_matmul""(%arg0, %arg1) {...} : (tensor<2x3x4x5x6xf32>, tensor<4x6x5xf32>) -> tensor<2x3x4x5x5xf32>
```

broadcast `tensor<4x6x5xf32>`  to `tensor<2x3x4x6x5xf32>` in 4 operations:
```
%0 = tosa.const_shape  {value = dense<[1, 1, 4, 6, 5]> : tensor<5xindex>} : () -> !tosa.shape<5>
%4 = ""tosa.const""() <{value = dense<-0.000000e+00> : tensor<2x3x4x6x5xf32>}
%5 = tosa.reshape %arg1, %0 : (tensor<4x6x5xf32>, !tosa.shape<5>) -> tensor<1x1x4x6x5xf32>
%6 = tosa.add %5, %4 : (tensor<1x1x4x6x5xf32>, tensor<2x3x4x6x5xf32>) -> tensor<2x3x4x6x5xf32>
```",psunn,2024-07-01 09:21:03+00:00,['gbaned'],2025-02-05 15:42:30+00:00,,https://github.com/tensorflow/tensorflow/pull/70679,"[('awaiting review', 'Pull request awaiting review'), ('size:M', 'CL Change Size: Medium'), ('comp:lite-tosa', 'TFLite TOSA conversion issues')]","[{'comment_id': 2205132451, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov Can you please review this PR? Thank you .', 'created_at': datetime.datetime(2024, 7, 3, 5, 32, 26, tzinfo=datetime.timezone.utc)}, {'comment_id': 2244333580, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you .', 'created_at': datetime.datetime(2024, 7, 23, 6, 13, 7, tzinfo=datetime.timezone.utc)}, {'comment_id': 2270844155, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 8, 6, 9, 39, 48, tzinfo=datetime.timezone.utc)}, {'comment_id': 2298039297, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 8, 20, 6, 7, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2311700662, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 8, 27, 6, 46, 6, tzinfo=datetime.timezone.utc)}, {'comment_id': 2326286664, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 9, 3, 11, 30, 33, tzinfo=datetime.timezone.utc)}, {'comment_id': 2357865109, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 9, 18, 8, 45, 23, tzinfo=datetime.timezone.utc)}, {'comment_id': 2401401968, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 9, 6, 15, 35, tzinfo=datetime.timezone.utc)}, {'comment_id': 2431557899, 'issue_id': 2383307377, 'author': 'keerthanakadiri', 'body': 'Hi @rdzhabarov, Can you please review this PR? Thank you !', 'created_at': datetime.datetime(2024, 10, 23, 9, 50, 45, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-07-03 05:32:26 UTC): Hi @rdzhabarov Can you please review this PR? Thank you .

keerthanakadiri on (2024-07-23 06:13:07 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you .

keerthanakadiri on (2024-08-06 09:39:48 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

keerthanakadiri on (2024-08-20 06:07:46 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

keerthanakadiri on (2024-08-27 06:46:06 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

keerthanakadiri on (2024-09-03 11:30:33 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

keerthanakadiri on (2024-09-18 08:45:23 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-09 06:15:35 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

keerthanakadiri on (2024-10-23 09:50:45 UTC): Hi @rdzhabarov, Can you please review this PR? Thank you !

"
2383202542,pull_request,closed,,Bump the github-actions group with 2 updates,"Bumps the github-actions group with 2 updates: [google/osv-scanner-action](https://github.com/google/osv-scanner-action) and [github/codeql-action](https://github.com/github/codeql-action).

Updates `google/osv-scanner-action` from 1.7.4 to 1.8.1
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/google/osv-scanner-action/commit/3c399db9dd6dd8106a27d280d53c55077d3f7cea""><code>3c399db</code></a> Merge pull request <a href=""https://redirect.github.com/google/osv-scanner-action/issues/29"">#29</a> from google/update-to-v1.8.1</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/3ea235ac683b304b60d57feda8f2c9200d307c87""><code>3ea235a</code></a> Update unified workflow example to point to v1.8.1 reusable workflows</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/6d2b388dfd698241547c91007c380a52e5155ff7""><code>6d2b388</code></a> Update reusable workflows to point to v1.8.1 actions</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/cd72c04b43d9a3dbc85e56c1205e4d9b0e6a379b""><code>cd72c04</code></a> Update actions to use v1.8.1 osv-scanner image</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/f0e45d2960258cf40285d596a10f817af70af1f7""><code>f0e45d2</code></a> Update workflows (<a href=""https://redirect.github.com/google/osv-scanner-action/issues/19"">#19</a>)</li>
<li><a href=""https://github.com/google/osv-scanner-action/commit/f92c263791e7958ebe88429d810541048a2275bd""><code>f92c263</code></a> Update workflows to v1.7.4 (<a href=""https://redirect.github.com/google/osv-scanner-action/issues/25"">#25</a>)</li>
<li>See full diff in <a href=""https://github.com/google/osv-scanner-action/compare/v1.7.4...v1.8.1"">compare view</a></li>
</ul>
</details>
<br />

Updates `github/codeql-action` from 3.25.10 to 3.25.11
<details>
<summary>Changelog</summary>
<p><em>Sourced from <a href=""https://github.com/github/codeql-action/blob/main/CHANGELOG.md"">github/codeql-action's changelog</a>.</em></p>
<blockquote>
<h1>CodeQL Action Changelog</h1>
<p>See the <a href=""https://github.com/github/codeql-action/releases"">releases page</a> for the relevant changes to the CodeQL CLI and language packs.</p>
<p>Note that the only difference between <code>v2</code> and <code>v3</code> of the CodeQL Action is the node version they support, with <code>v3</code> running on node 20 while we continue to release <code>v2</code> to support running on node 16. For example <code>3.22.11</code> was the first <code>v3</code> release and is functionally identical to <code>2.22.11</code>. This approach ensures an easy way to track exactly which features are included in different versions, indicated by the minor and patch version numbers.</p>
<h2>[UNRELEASED]</h2>
<p>No user facing changes.</p>
<h2>3.25.11 - 28 Jun 2024</h2>
<ul>
<li>Avoid failing the workflow run if there is an error while uploading debug artifacts. <a href=""https://redirect.github.com/github/codeql-action/pull/2349"">#2349</a></li>
<li>Update default CodeQL bundle version to 2.17.6. <a href=""https://redirect.github.com/github/codeql-action/pull/2352"">#2352</a></li>
</ul>
<h2>3.25.10 - 13 Jun 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.17.5. <a href=""https://redirect.github.com/github/codeql-action/pull/2327"">#2327</a></li>
</ul>
<h2>3.25.9 - 12 Jun 2024</h2>
<ul>
<li>Avoid failing database creation if the database folder already exists and contains some unexpected files. Requires CodeQL 2.18.0 or higher. <a href=""https://redirect.github.com/github/codeql-action/pull/2330"">#2330</a></li>
<li>The init Action will attempt to clean up the database cluster directory before creating a new database and at the end of the job. This will help to avoid issues where the database cluster directory is left in an inconsistent state. <a href=""https://redirect.github.com/github/codeql-action/pull/2332"">#2332</a></li>
</ul>
<h2>3.25.8 - 04 Jun 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.17.4. <a href=""https://redirect.github.com/github/codeql-action/pull/2321"">#2321</a></li>
</ul>
<h2>3.25.7 - 31 May 2024</h2>
<ul>
<li>We are rolling out a feature in May/June 2024 that will reduce the Actions cache usage of the Action by keeping only the newest TRAP cache for each language. <a href=""https://redirect.github.com/github/codeql-action/pull/2306"">#2306</a></li>
</ul>
<h2>3.25.6 - 20 May 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.17.3. <a href=""https://redirect.github.com/github/codeql-action/pull/2295"">#2295</a></li>
</ul>
<h2>3.25.5 - 13 May 2024</h2>
<ul>
<li>Add a compatibility matrix of supported CodeQL Action, CodeQL CLI, and GitHub Enterprise Server versions to the <a href=""https://github.com/github/codeql-action/blob/main/README.md"">https://github.com/github/codeql-action/blob/main/README.md</a>. <a href=""https://redirect.github.com/github/codeql-action/pull/2273"">#2273</a></li>
<li>Avoid printing out a warning for a missing <code>on.push</code> trigger when the CodeQL Action is triggered via a <code>workflow_call</code> event. <a href=""https://redirect.github.com/github/codeql-action/pull/2274"">#2274</a></li>
<li>The <code>tools: latest</code> input to the <code>init</code> Action has been renamed to <code>tools: linked</code>. This option specifies that the Action should use the tools shipped at the same time as the Action. The old name will continue to work for backwards compatibility, but we recommend that new workflows use the new name. <a href=""https://redirect.github.com/github/codeql-action/pull/2281"">#2281</a></li>
</ul>
<h2>3.25.4 - 08 May 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.17.2. <a href=""https://redirect.github.com/github/codeql-action/pull/2270"">#2270</a></li>
</ul>
<h2>3.25.3 - 25 Apr 2024</h2>
<ul>
<li>Update default CodeQL bundle version to 2.17.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2247"">#2247</a></li>
<li>Workflows running on <code>macos-latest</code> using CodeQL CLI versions before v2.15.1 will need to either upgrade their CLI version to v2.15.1 or newer, or change the platform to an Intel MacOS runner, such as <code>macos-12</code>. ARM machines with SIP disabled, including the newest <code>macos-latest</code> image, are unsupported for CLI versions before 2.15.1. <a href=""https://redirect.github.com/github/codeql-action/pull/2261"">#2261</a></li>
</ul>
<!-- raw HTML omitted -->
</blockquote>
<p>... (truncated)</p>
</details>
<details>
<summary>Commits</summary>
<ul>
<li><a href=""https://github.com/github/codeql-action/commit/b611370bb5703a7efb587f9d136a52ea24c5c38c""><code>b611370</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2357"">#2357</a> from github/update-v3.25.11-de945755c</li>
<li><a href=""https://github.com/github/codeql-action/commit/3e6431f3accd84bb42779fc3c9d9f447caa3a6d3""><code>3e6431f</code></a> Update changelog for v3.25.11</li>
<li><a href=""https://github.com/github/codeql-action/commit/de945755c9edd3a4e5d160a71f1482ece6a3c271""><code>de94575</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2352"">#2352</a> from github/update-bundle/codeql-bundle-v2.17.6</li>
<li><a href=""https://github.com/github/codeql-action/commit/a32d3058b827f5d2ba08dc2570887f14b164a794""><code>a32d305</code></a> Add changelog note</li>
<li><a href=""https://github.com/github/codeql-action/commit/9ccc99508a819cb9c340028d7711b129f96c8a2e""><code>9ccc995</code></a> Update default bundle to codeql-bundle-v2.17.6</li>
<li><a href=""https://github.com/github/codeql-action/commit/9b7c22c3b39078582fa6d0d8f3841e944ec54582""><code>9b7c22c</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2351"">#2351</a> from github/dependabot/npm_and_yarn/npm-6791eaa26c</li>
<li><a href=""https://github.com/github/codeql-action/commit/9cf3243b0be3a9e0efff20a7fabd5a11246168e9""><code>9cf3243</code></a> Rebuild</li>
<li><a href=""https://github.com/github/codeql-action/commit/1895b29ac8e2046ddb708ac1eca53e6d5e143337""><code>1895b29</code></a> Update checked-in dependencies</li>
<li><a href=""https://github.com/github/codeql-action/commit/9dcfde966d641c9a59ee02a83f18329a2b2caace""><code>9dcfde9</code></a> Bump the npm group with 2 updates</li>
<li><a href=""https://github.com/github/codeql-action/commit/8723b5be41df185b62efd22191bb83fc24539ca0""><code>8723b5b</code></a> Merge pull request <a href=""https://redirect.github.com/github/codeql-action/issues/2350"">#2350</a> from github/angelapwen/add-exclude-pr-check-param</li>
<li>Additional commits viewable in <a href=""https://github.com/github/codeql-action/compare/23acc5c183826b7a8a97bce3cecc52db901f8251...b611370bb5703a7efb587f9d136a52ea24c5c38c"">compare view</a></li>
</ul>
</details>
<br />


Dependabot will resolve any conflicts with this PR as long as you don't alter it yourself. You can also trigger a rebase manually by commenting `@dependabot rebase`.

[//]: # (dependabot-automerge-start)
[//]: # (dependabot-automerge-end)

---

<details>
<summary>Dependabot commands and options</summary>
<br />

You can trigger Dependabot actions by commenting on this PR:
- `@dependabot rebase` will rebase this PR
- `@dependabot recreate` will recreate this PR, overwriting any edits that have been made to it
- `@dependabot merge` will merge this PR after your CI passes on it
- `@dependabot squash and merge` will squash and merge this PR after your CI passes on it
- `@dependabot cancel merge` will cancel a previously requested merge and block automerging
- `@dependabot reopen` will reopen this PR if it is closed
- `@dependabot close` will close this PR and stop Dependabot recreating it. You can achieve the same result by closing it manually
- `@dependabot show <dependency name> ignore conditions` will show all of the ignore conditions of the specified dependency
- `@dependabot ignore <dependency name> major version` will close this group update PR and stop Dependabot creating any more for the specific dependency's major version (unless you unignore this specific dependency's major version or upgrade to it yourself)
- `@dependabot ignore <dependency name> minor version` will close this group update PR and stop Dependabot creating any more for the specific dependency's minor version (unless you unignore this specific dependency's minor version or upgrade to it yourself)
- `@dependabot ignore <dependency name>` will close this group update PR and stop Dependabot creating any more for the specific dependency (unless you unignore this specific dependency or upgrade to it yourself)
- `@dependabot unignore <dependency name>` will remove all of the ignore conditions of the specified dependency
- `@dependabot unignore <dependency name> <ignore condition>` will remove the ignore condition of the specified dependency and ignore conditions


</details>",dependabot[bot],2024-07-01 08:33:15+00:00,['gbaned'],2024-07-04 07:53:23+00:00,2024-07-04 07:53:22+00:00,https://github.com/tensorflow/tensorflow/pull/70678,"[('awaiting review', 'Pull request awaiting review'), ('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small'), ('dependencies', 'Pull requests that update a dependency file'), ('github_actions', 'Pull requests that update GitHub Actions code')]","[{'comment_id': 2205070405, 'issue_id': 2383202542, 'author': 'keerthanakadiri', 'body': 'Hi @MichaelHudgins Can you please review this PR? Thank you .', 'created_at': datetime.datetime(2024, 7, 3, 4, 20, 5, tzinfo=datetime.timezone.utc)}]","keerthanakadiri on (2024-07-03 04:20:05 UTC): Hi @MichaelHudgins Can you please review this PR? Thank you .

"
2383199932,pull_request,closed,,Unify shared memory code for column and row reductions.,"Unify shared memory code for column and row reductions.

- Use indexing maps for read and write indices and predicates
- Derive tile size from maps
",copybara-service[bot],2024-07-01 08:31:57+00:00,[],2024-07-01 10:24:22+00:00,2024-07-01 10:24:22+00:00,https://github.com/tensorflow/tensorflow/pull/70677,[],[],
2383163972,pull_request,closed,,Add missing const in IndexingMap constructor.,"Add missing const in IndexingMap constructor.
",copybara-service[bot],2024-07-01 08:14:58+00:00,[],2024-07-01 08:45:21+00:00,2024-07-01 08:45:20+00:00,https://github.com/tensorflow/tensorflow/pull/70676,[],[],
