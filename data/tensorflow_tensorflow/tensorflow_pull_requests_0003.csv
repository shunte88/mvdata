id,type,state,state_reason,title,body,author,created_at,assignees,updated_at,closed_at,url,labels,comments_list,comment_thread
2823058806,pull_request,closed,,[XLA:GPU] Extract more fragments into the smaller functions.,"[XLA:GPU] Extract more fragments into the smaller functions.

It is noop change.
",copybara-service[bot],2025-01-31 10:58:21+00:00,[],2025-01-31 14:51:56+00:00,2025-01-31 14:51:55+00:00,https://github.com/tensorflow/tensorflow/pull/86280,[],[],
2823034014,pull_request,closed,,Elementwise check,,amrinfathima-mcw,2025-01-31 10:45:57+00:00,['gbaned'],2025-01-31 12:17:11+00:00,2025-01-31 12:17:11+00:00,https://github.com/tensorflow/tensorflow/pull/86279,"[('size:XL', 'CL Change Size:Extra Large')]","[{'comment_id': 2626904087, 'issue_id': 2823034014, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/86279/checks?check_run_id=36473032284) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2025, 1, 31, 10, 46, 1, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2025-01-31 10:46:01 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/86279/checks?check_run_id=36473032284) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

"
2823017660,pull_request,closed,,[pjrt] Use the `PjRtMemorySpace` version of `BufferFromHostLiteral`,"[pjrt] Use the `PjRtMemorySpace` version of `BufferFromHostLiteral`

Buffers live in memory spaces and not on devices. The `PjRtDevice` version
of `BufferFromHostLiteral` is deprecated and will be removed once the migration
is complete.
",copybara-service[bot],2025-01-31 10:37:50+00:00,['superbobry'],2025-01-31 20:38:00+00:00,2025-01-31 20:38:00+00:00,https://github.com/tensorflow/tensorflow/pull/86278,[],[],
2822932102,pull_request,closed,,[XLA:GPU] Convert add_dim lambda to to a private method AddDimToTensorParams.,"[XLA:GPU] Convert add_dim lambda to to a private method AddDimToTensorParams.

It is a noop refactoring
",copybara-service[bot],2025-01-31 09:55:12+00:00,[],2025-01-31 11:16:50+00:00,2025-01-31 11:16:49+00:00,https://github.com/tensorflow/tensorflow/pull/86277,[],[],
2822905612,pull_request,closed,,[hlo-opt] Fix references to non-existing flags (--gpu_device_config_filename and --xla-hlo-enable-passes-only).,"[hlo-opt] Fix references to non-existing flags (--gpu_device_config_filename and --xla-hlo-enable-passes-only).
",copybara-service[bot],2025-01-31 09:42:59+00:00,['thomasjoerg'],2025-02-05 20:36:43+00:00,2025-02-05 20:36:41+00:00,https://github.com/tensorflow/tensorflow/pull/86276,[],[],
2822875004,pull_request,closed,,[XLA:GPU] Prepare add_dim lambda to become a member function.,"[XLA:GPU] Prepare add_dim lambda to become a member function.

this is a noop refactoring.
",copybara-service[bot],2025-01-31 09:27:21+00:00,[],2025-01-31 10:46:18+00:00,2025-01-31 10:46:17+00:00,https://github.com/tensorflow/tensorflow/pull/86275,[],[],
2822859265,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:19:22+00:00,[],2025-01-31 09:19:22+00:00,,https://github.com/tensorflow/tensorflow/pull/86274,[],[],
2822858403,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:18:53+00:00,[],2025-02-04 08:37:11+00:00,2025-02-04 08:37:10+00:00,https://github.com/tensorflow/tensorflow/pull/86273,[],[],
2822856974,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:18:07+00:00,[],2025-01-31 09:18:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86272,[],[],
2822856684,pull_request,open,,Update GraphDef version to 2124.,"Update GraphDef version to 2124.
",copybara-service[bot],2025-01-31 09:17:56+00:00,[],2025-01-31 09:17:56+00:00,,https://github.com/tensorflow/tensorflow/pull/86271,[],[],
2822855209,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:17:09+00:00,[],2025-02-04 11:16:18+00:00,2025-02-04 11:16:17+00:00,https://github.com/tensorflow/tensorflow/pull/86270,[],[],
2822853661,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:16:18+00:00,[],2025-01-31 10:09:53+00:00,,https://github.com/tensorflow/tensorflow/pull/86269,[],[],
2822853038,pull_request,open,,Remove unused dependencies.,"Remove unused dependencies.

The dependencies may have been needed before, but some passes have been moved.
",copybara-service[bot],2025-01-31 09:15:57+00:00,[],2025-02-04 10:10:42+00:00,,https://github.com/tensorflow/tensorflow/pull/86268,[],[],
2822852736,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:15:47+00:00,[],2025-02-01 04:56:48+00:00,2025-02-01 04:56:48+00:00,https://github.com/tensorflow/tensorflow/pull/86267,[],[],
2822851699,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:15:15+00:00,[],2025-01-31 10:09:48+00:00,,https://github.com/tensorflow/tensorflow/pull/86266,[],[],
2822850818,pull_request,open,,compat: Update forward compatibility horizon to 2025-01-31,"compat: Update forward compatibility horizon to 2025-01-31
",copybara-service[bot],2025-01-31 09:14:47+00:00,[],2025-01-31 09:14:47+00:00,,https://github.com/tensorflow/tensorflow/pull/86265,[],[],
2822850511,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 723246423

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/85476 from jiunkaiy:dev/weilhuan/wrapper 06e061657d780fe341be8404e27697b762c00805
",copybara-service[bot],2025-01-31 09:14:38+00:00,[],2025-02-05 07:53:01+00:00,,https://github.com/tensorflow/tensorflow/pull/86264,[],[],
2822849560,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:14:07+00:00,[],2025-02-01 07:15:46+00:00,2025-02-01 07:15:46+00:00,https://github.com/tensorflow/tensorflow/pull/86263,[],[],
2822847705,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:13:05+00:00,[],2025-02-01 05:59:59+00:00,2025-02-01 05:59:59+00:00,https://github.com/tensorflow/tensorflow/pull/86262,[],[],
2822847431,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:12:57+00:00,[],2025-02-01 08:29:22+00:00,2025-02-01 08:29:22+00:00,https://github.com/tensorflow/tensorflow/pull/86261,[],[],
2822846818,pull_request,closed,,"PR #22101: Define SO_ZEROCOPY, SO_EE_ORIGIN_ZEROCOPY when missing (e.g. in conda sysroot)","PR #22101: Define SO_ZEROCOPY, SO_EE_ORIGIN_ZEROCOPY when missing (e.g. in conda sysroot)

Imported from GitHub PR https://github.com/openxla/xla/pull/22101

As in the title.

Conda sysroot includes headers from an old version of linux kernel that does not define SO_ZEROCOPY nor SO_EE_ORIGIN_ZEROCOPY but are required by the feature implemented in https://github.com/openxla/xla/pull/21496 .

Fixes https://github.com/openxla/xla/issues/22083
Copybara import of the project:

--
9881261c572e59892912cd548b02ed057be3cc7e by Pearu Peterson <pearu.peterson@gmail.com>:

Define SO_ZEROCOPY, SO_EE_ORIGIN_ZEROCOPY when not defined (e.g. in conda sysroot)

Merging this change closes #22101

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22101 from pearu:pearu/undeclared-zerocopy 9881261c572e59892912cd548b02ed057be3cc7e
",copybara-service[bot],2025-01-31 09:12:39+00:00,[],2025-01-31 09:46:42+00:00,2025-01-31 09:46:41+00:00,https://github.com/tensorflow/tensorflow/pull/86260,[],[],
2822845467,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:11:57+00:00,[],2025-01-31 13:52:48+00:00,,https://github.com/tensorflow/tensorflow/pull/86259,[],[],
2822843154,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-31 09:10:39+00:00,[],2025-02-04 08:03:21+00:00,2025-02-04 08:03:19+00:00,https://github.com/tensorflow/tensorflow/pull/86258,[],[],
2822696934,pull_request,open,,Integrate LLVM at llvm/llvm-project@29441e4f5fa5,"Integrate LLVM at llvm/llvm-project@29441e4f5fa5

Updates LLVM usage to match
[29441e4f5fa5](https://github.com/llvm/llvm-project/commit/29441e4f5fa5)
",copybara-service[bot],2025-01-31 07:48:00+00:00,[],2025-01-31 07:48:00+00:00,,https://github.com/tensorflow/tensorflow/pull/86257,[],[],
2822657005,pull_request,closed,,Allowing pre-initialized tensors in _create_slots,"Allowing pre-initialized tensors in _create_slots
",copybara-service[bot],2025-01-31 07:23:15+00:00,['hhb'],2025-02-08 00:58:28+00:00,2025-02-08 00:58:26+00:00,https://github.com/tensorflow/tensorflow/pull/86255,[],[],
2822637302,pull_request,open,,Reverts b7a1cfd0e9092c9054ae27a7913e5d4c5b13e1c3,"Reverts b7a1cfd0e9092c9054ae27a7913e5d4c5b13e1c3
",copybara-service[bot],2025-01-31 07:11:22+00:00,[],2025-01-31 09:38:09+00:00,,https://github.com/tensorflow/tensorflow/pull/86254,[],[],
2822402083,pull_request,closed,,[xla:cpu] Move ObjectPool and ParallelLoopRunner to top level runtime folder,"[xla:cpu] Move ObjectPool and ParallelLoopRunner to top level runtime folder
",copybara-service[bot],2025-01-31 04:15:04+00:00,['ezhulenev'],2025-01-31 17:14:20+00:00,2025-01-31 17:14:19+00:00,https://github.com/tensorflow/tensorflow/pull/86253,[],[],
2822401684,pull_request,open,,[xla:cpu] Add OneDnnThreadPool based on parallel loop runner,"[xla:cpu] Add OneDnnThreadPool based on parallel loop runner
",copybara-service[bot],2025-01-31 04:14:56+00:00,['ezhulenev'],2025-02-06 19:14:03+00:00,,https://github.com/tensorflow/tensorflow/pull/86252,[],[],
2822389834,pull_request,open,,Generate PID during serving events if host_id is provided,"Generate PID during serving events if host_id is provided
",copybara-service[bot],2025-01-31 04:03:07+00:00,[],2025-01-31 04:03:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86251,[],[],
2822290944,pull_request,closed,,Do not fuse instructions inside custom fusions/calls,"Do not fuse instructions inside custom fusions/calls
",copybara-service[bot],2025-01-31 02:22:46+00:00,[],2025-01-31 03:03:37+00:00,2025-01-31 03:03:36+00:00,https://github.com/tensorflow/tensorflow/pull/86250,[],[],
2822200261,pull_request,closed,,Integrate LLVM at llvm/llvm-project@3a1e157454ec,"Integrate LLVM at llvm/llvm-project@3a1e157454ec

Updates LLVM usage to match
[3a1e157454ec](https://github.com/llvm/llvm-project/commit/3a1e157454ec)
",copybara-service[bot],2025-01-31 01:07:42+00:00,[],2025-01-31 06:20:33+00:00,2025-01-31 06:20:33+00:00,https://github.com/tensorflow/tensorflow/pull/86249,[],[],
2822163533,pull_request,closed,,Internal only change for instrumentation.,"Internal only change for instrumentation.
",copybara-service[bot],2025-01-31 00:45:05+00:00,[],2025-01-31 19:54:52+00:00,2025-01-31 19:54:51+00:00,https://github.com/tensorflow/tensorflow/pull/86248,[],[],
2822154562,pull_request,closed,,Update TF CUDA 12 Dockerfiles for Python 3.13-nogil support,"Update TF CUDA 12 Dockerfiles for Python 3.13-nogil support

This CL updates the TensorFlow CUDA 12 Dockerfile to support free-threaded Python (python3.13-nogil) in JAX x86 nightly builds.

`portpicker` is temporarily excluded from the docker images for free threaded python due to compatibility issues in the docker image build.
",copybara-service[bot],2025-01-31 00:36:56+00:00,['kanglant'],2025-01-31 05:53:31+00:00,2025-01-31 05:53:30+00:00,https://github.com/tensorflow/tensorflow/pull/86247,[],[],
2822144673,pull_request,closed,,Reverts 42898a878b1fd2269a7de1ea22c6cfa1c8914247,"Reverts 42898a878b1fd2269a7de1ea22c6cfa1c8914247
",copybara-service[bot],2025-01-31 00:30:11+00:00,[],2025-01-31 01:21:14+00:00,2025-01-31 01:21:13+00:00,https://github.com/tensorflow/tensorflow/pull/86246,[],[],
2822130114,pull_request,open,,Mark data transfer completion,"Mark data transfer completion
",copybara-service[bot],2025-01-31 00:18:23+00:00,[],2025-02-06 06:31:20+00:00,,https://github.com/tensorflow/tensorflow/pull/86245,[],[],
2822123114,pull_request,closed,,litert: Refactor EnvironmentSingleton to use it outside,"litert: Refactor EnvironmentSingleton to use it outside

The Create() method is to create the EnvironmentSingleton with options. It will fail if there is pre-created instance.
",copybara-service[bot],2025-01-31 00:12:44+00:00,['terryheo'],2025-02-04 04:57:40+00:00,2025-02-04 04:57:40+00:00,https://github.com/tensorflow/tensorflow/pull/86244,[],[],
2822113424,pull_request,closed,,[XLA:GPU] remove Assert(No)Transform helper methods,"[XLA:GPU] remove Assert(No)Transform helper methods
",copybara-service[bot],2025-01-31 00:05:15+00:00,[],2025-01-31 04:37:36+00:00,2025-01-31 04:37:36+00:00,https://github.com/tensorflow/tensorflow/pull/86243,[],[],
2821990378,pull_request,open,,[XLA:LatencyHidingScheduler] Let `GetResourcesFromInstruction` return a complete list of resources used by instructions in a while loop. This will make async `done` and while ops have similar priority (in terms of occupying resource types) and avoid delaying the while loops only because they cross the overlap limit (even though they have a higher async depth).,"[XLA:LatencyHidingScheduler] Let `GetResourcesFromInstruction` return a complete list of resources used by instructions in a while loop. This will make async `done` and while ops have similar priority (in terms of occupying resource types) and avoid delaying the while loops only because they cross the overlap limit (even though they have a higher async depth).

This CL also fixes the double counting of a resource in `GetNumResourcesPerInstruction` because of multiple async `done` ops in the while body.
",copybara-service[bot],2025-01-30 22:59:54+00:00,['seherellis'],2025-02-08 00:17:06+00:00,,https://github.com/tensorflow/tensorflow/pull/86242,[],[],
2821979929,pull_request,closed,,Add an option to the TF standard pipeline to enable the StableHLO shape propagation,"Add an option to the TF standard pipeline to enable the StableHLO shape propagation
",copybara-service[bot],2025-01-30 22:51:59+00:00,[],2025-01-30 23:36:36+00:00,2025-01-30 23:36:35+00:00,https://github.com/tensorflow/tensorflow/pull/86241,[],[],
2821960341,pull_request,closed,,Also use matcher in MayPipeline,"Also use matcher in MayPipeline
",copybara-service[bot],2025-01-30 22:39:59+00:00,['frgossen'],2025-02-03 15:38:55+00:00,2025-02-03 15:38:54+00:00,https://github.com/tensorflow/tensorflow/pull/86240,[],[],
2821913879,pull_request,closed,,Revert to using `tsl/platform:test_main` for tests with benchmarks in TensorFlow,"Revert to using `tsl/platform:test_main` for tests with benchmarks in TensorFlow

Benchmarks don't work properly with `gtest_main`
",copybara-service[bot],2025-01-30 22:07:29+00:00,['ddunl'],2025-02-03 22:27:42+00:00,2025-02-03 22:27:41+00:00,https://github.com/tensorflow/tensorflow/pull/86239,[],[],
2821892185,pull_request,closed,,Add the ability to log simulated elapsed time (with async copy time factored in) to MSA.,"Add the ability to log simulated elapsed time (with async copy time factored in) to MSA.
",copybara-service[bot],2025-01-30 21:52:29+00:00,['sparc1998'],2025-02-05 21:09:31+00:00,2025-02-05 21:09:29+00:00,https://github.com/tensorflow/tensorflow/pull/86238,[],[],
2821889424,pull_request,closed,,Remove unnecessary backend_tags,"Remove unnecessary backend_tags
",copybara-service[bot],2025-01-30 21:50:32+00:00,[],2025-02-01 08:08:18+00:00,2025-02-01 08:08:17+00:00,https://github.com/tensorflow/tensorflow/pull/86237,[],[],
2821855578,pull_request,closed,,"Remove redundant TODO, the proposed change has been implemented.","Remove redundant TODO, the proposed change has been implemented.
",copybara-service[bot],2025-01-30 21:28:03+00:00,[],2025-01-31 21:22:37+00:00,2025-01-31 21:22:37+00:00,https://github.com/tensorflow/tensorflow/pull/86236,[],[],
2821853926,pull_request,closed,,Reverts a5c0385cb45c4fbaab7ee2edc0884061be684eb8,"Reverts a5c0385cb45c4fbaab7ee2edc0884061be684eb8
",copybara-service[bot],2025-01-30 21:26:57+00:00,['kenfranko'],2025-01-30 22:34:11+00:00,2025-01-30 22:34:10+00:00,https://github.com/tensorflow/tensorflow/pull/86235,[],[],
2821830355,pull_request,closed,,Fix 03 broken links in index.md,"Hi, Team
I found 03 broken documentation links in this [index.md](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/lite/g3doc/models/build/index.md) file so I have updated those links to functional links. Please review and merge this change as appropriate.

Thank you for your consideration.",gaikwadrahul8,2025-01-30 21:11:47+00:00,['gbaned'],2025-01-30 22:15:56+00:00,2025-01-30 22:15:55+00:00,https://github.com/tensorflow/tensorflow/pull/86234,"[('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]",[],
2821790002,pull_request,closed,,litert: Do not strip symbol for debug build,"litert: Do not strip symbol for debug build
",copybara-service[bot],2025-01-30 20:49:55+00:00,['terryheo'],2025-01-31 01:32:25+00:00,2025-01-31 01:32:24+00:00,https://github.com/tensorflow/tensorflow/pull/86233,[],[],
2821726286,pull_request,closed,,Don't fail on ./dist directory having already been created.,"Don't fail on ./dist directory having already been created.

For bisect runs.
",copybara-service[bot],2025-01-30 20:12:32+00:00,['belitskiy'],2025-01-30 20:38:35+00:00,2025-01-30 20:38:34+00:00,https://github.com/tensorflow/tensorflow/pull/86232,[],[],
2821721812,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-30 20:10:10+00:00,['ddunl'],2025-01-31 23:07:32+00:00,2025-01-31 23:07:31+00:00,https://github.com/tensorflow/tensorflow/pull/86231,[],[],
2821675930,pull_request,closed,,Create GitHub Actions based build for JAX CPU tests,"Create GitHub Actions based build for JAX CPU tests
",copybara-service[bot],2025-01-30 19:45:09+00:00,['ddunl'],2025-02-03 20:08:00+00:00,2025-02-03 20:08:00+00:00,https://github.com/tensorflow/tensorflow/pull/86230,[],[],
2821634565,pull_request,closed,,Remove now unused StreamExecutor::HostMemoryDeallocate method and overrides.,"Remove now unused StreamExecutor::HostMemoryDeallocate method and overrides.
",copybara-service[bot],2025-01-30 19:22:24+00:00,[],2025-01-31 02:41:57+00:00,2025-01-31 02:41:56+00:00,https://github.com/tensorflow/tensorflow/pull/86229,[],[],
2821626165,pull_request,closed,,Add documentation for regenerating `warnings.bazelrc`,"Add documentation for regenerating `warnings.bazelrc`
",copybara-service[bot],2025-01-30 19:17:38+00:00,['ddunl'],2025-01-31 00:28:05+00:00,2025-01-31 00:28:04+00:00,https://github.com/tensorflow/tensorflow/pull/86228,[],[],
2821613829,pull_request,closed,,Use GenericMemoryAllocation instead of HostMemoryAllocation.,"Use GenericMemoryAllocation instead of HostMemoryAllocation.

This eliminates a layer of indirection, and makes it more obvious what's going to happen to the memory during deallocation.
",copybara-service[bot],2025-01-30 19:10:57+00:00,[],2025-01-30 23:54:15+00:00,2025-01-30 23:54:14+00:00,https://github.com/tensorflow/tensorflow/pull/86227,[],[],
2821577254,pull_request,closed,,litert: Use BuiltinOpResolver to enable lazy applying Xnnpack delegate,"litert: Use BuiltinOpResolver to enable lazy applying Xnnpack delegate

Now, getting a signature runner before applying delegate isn't needed.
So we can use BuiltinOpResolver safely.
",copybara-service[bot],2025-01-30 18:50:48+00:00,['terryheo'],2025-01-31 00:35:23+00:00,2025-01-31 00:35:23+00:00,https://github.com/tensorflow/tensorflow/pull/86226,[],[],
2821545224,pull_request,closed,,Add a possibility to override HostStream by using custom HostStream factory.,"Add a possibility to override HostStream by using custom HostStream factory.
",copybara-service[bot],2025-01-30 18:33:27+00:00,[],2025-01-31 19:40:02+00:00,2025-01-31 19:40:02+00:00,https://github.com/tensorflow/tensorflow/pull/86225,[],[],
2821529207,pull_request,closed,,"[Shardy] Replace ""mhlo"" str with ""stablehlo"" from files,functions,dirs names","[Shardy] Replace ""mhlo"" str with ""stablehlo"" from files,functions,dirs names
",copybara-service[bot],2025-01-30 18:25:06+00:00,[],2025-02-03 19:22:58+00:00,2025-02-03 19:22:57+00:00,https://github.com/tensorflow/tensorflow/pull/86224,[],[],
2821521955,pull_request,closed,,Update ml_dtypes version and path.,"Update ml_dtypes version and path.

The include paths for headers within the ml_dtypes package have changed.
We therefore need to adjust the TF/XLA build rules and paths to account
for this.  Also updated the pip ml_dtypes version to match.

The main ml_dtypes repo name needed to be changed to avoid
conflicts with the ml_dtypes subfolder.  The subfolder contains the main
python package that needs to be added to the PYTHON_PATH.
",copybara-service[bot],2025-01-30 18:20:53+00:00,['cantonios'],2025-02-05 22:48:06+00:00,2025-02-05 22:48:05+00:00,https://github.com/tensorflow/tensorflow/pull/86223,[],[],
2821512230,pull_request,closed,,#tflite Fix compilation of experimental tests.,"#tflite Fix compilation of experimental tests.
",copybara-service[bot],2025-01-30 18:15:33+00:00,['qukhan'],2025-01-30 19:49:18+00:00,2025-01-30 19:49:18+00:00,https://github.com/tensorflow/tensorflow/pull/86222,[],[],
2821505202,pull_request,closed,,[XLA] tool to print indexing map of operands,"[XLA] tool to print indexing map of operands

example output

```
Output 0 operand 0:
(d0) -> (d0), domain: d0 in [0, 1023]
Output 0 operand 1:
(d0) -> (), domain: d0 in [0, 1023]
Output 1 operand 0:
(d0) -> (d0), domain: d0 in [0, 1023]
Output 1 operand 1:
(d0) -> (), domain: d0 in [0, 1023]
Output 1 operand 2:
(d0) -> (d0), domain: d0 in [0, 1023]
```
",copybara-service[bot],2025-01-30 18:12:10+00:00,['metaflow'],2025-02-04 17:01:38+00:00,2025-02-04 17:01:36+00:00,https://github.com/tensorflow/tensorflow/pull/86221,[],[],
2821504089,pull_request,closed,,Adding a test for strided slice which triggers a path fixed earlier,"Adding a test for strided slice which triggers a path fixed earlier

Reverts 8b90c7755e298136842b0a952ace340e5b535d23
",copybara-service[bot],2025-01-30 18:11:39+00:00,[],2025-01-30 19:01:30+00:00,2025-01-30 19:01:29+00:00,https://github.com/tensorflow/tensorflow/pull/86220,[],[],
2821431593,pull_request,open,,Example added for Max_pool1D API,Example added for Max_pool1D API,LakshmiKalaKadali,2025-01-30 17:38:26+00:00,['gbaned'],2025-02-03 10:17:05+00:00,,https://github.com/tensorflow/tensorflow/pull/86219,"[('stat:awaiting response', 'Status  - Awaiting response from author'), ('comp:ops', 'OPs related issues'), ('size:S', 'CL Change Size: Small')]",[],
2821401045,pull_request,closed,,[XLA:CPU][roll forward] Underlying ObjectLoader dylibs are using DefinitionGenerator now.,"[XLA:CPU][roll forward] Underlying ObjectLoader dylibs are using DefinitionGenerator now.

Reverts changelist 721389214
",copybara-service[bot],2025-01-30 17:23:08+00:00,[],2025-01-31 15:10:23+00:00,2025-01-31 15:10:22+00:00,https://github.com/tensorflow/tensorflow/pull/86218,[],[],
2821367056,pull_request,closed,,"[XLA/Triton] Don't restrict contracting dimension tiling for predicate inputs in a GEMM during autotuning. Historically, the restriction was acceptable until a change to FMA landed from Triton upstream that started spilling registers for such configurations. The more correct way to handle this is to lift the restriction on predicates rather than applying it to small dots.","[XLA/Triton] Don't restrict contracting dimension tiling for predicate inputs in a GEMM during autotuning. Historically, the restriction was acceptable until a change to FMA landed from Triton upstream that started spilling registers for such configurations. The more correct way to handle this is to lift the restriction on predicates rather than applying it to small dots.
",copybara-service[bot],2025-01-30 17:06:31+00:00,[],2025-01-31 11:02:44+00:00,2025-01-31 11:02:43+00:00,https://github.com/tensorflow/tensorflow/pull/86217,[],[],
2821345276,pull_request,closed,,[xla:cpu] Don't use deprecated AsyncValueRef::SetError API,"[xla:cpu] Don't use deprecated AsyncValueRef::SetError API
",copybara-service[bot],2025-01-30 16:56:29+00:00,['ezhulenev'],2025-01-31 06:05:31+00:00,2025-01-31 06:05:30+00:00,https://github.com/tensorflow/tensorflow/pull/86216,[],[],
2821331543,pull_request,open,,Integrate LLVM at llvm/llvm-project@3a1e157454ec,"Integrate LLVM at llvm/llvm-project@3a1e157454ec

Updates LLVM usage to match
[3a1e157454ec](https://github.com/llvm/llvm-project/commit/3a1e157454ec)

Reverts changelist 721352942

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 16:50:06+00:00,[],2025-01-30 16:50:06+00:00,,https://github.com/tensorflow/tensorflow/pull/86215,[],[],
2821181544,pull_request,closed,,Reverts 395000c6a82bdfb51b6ac24c9e9d649556bf292a,"Reverts 395000c6a82bdfb51b6ac24c9e9d649556bf292a
",copybara-service[bot],2025-01-30 15:47:24+00:00,[],2025-01-31 00:08:15+00:00,2025-01-31 00:08:15+00:00,https://github.com/tensorflow/tensorflow/pull/86214,[],[],
2821168945,pull_request,open,,Rollback of Parse XLA_FLAGS environment variable every time. Created some data race.,"Rollback of Parse XLA_FLAGS environment variable every time. Created some data race.

Reverts 395000c6a82bdfb51b6ac24c9e9d649556bf292a

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 15:42:01+00:00,[],2025-01-30 15:42:01+00:00,,https://github.com/tensorflow/tensorflow/pull/86213,[],[],
2821118719,pull_request,closed,,Enforece sequential order in send/recv pipeline parallelism test,"Enforece sequential order in send/recv pipeline parallelism test

These collectives will be issues on the same stream later. There is no
advantage in allowing for them to overlap.
",copybara-service[bot],2025-01-30 15:23:05+00:00,['frgossen'],2025-01-31 22:58:31+00:00,2025-01-31 22:58:31+00:00,https://github.com/tensorflow/tensorflow/pull/86212,[],[],
2821104260,pull_request,open,,Reverts changelist 721352942,"Reverts changelist 721352942

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 15:17:16+00:00,[],2025-01-30 15:17:16+00:00,,https://github.com/tensorflow/tensorflow/pull/86211,[],[],
2820997075,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.

Reverts changelist 721352942

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 14:38:03+00:00,['ddunl'],2025-01-30 17:17:30+00:00,2025-01-30 17:17:29+00:00,https://github.com/tensorflow/tensorflow/pull/86210,[],[],
2820991631,pull_request,closed,,[xla:cpu:xnn] Add microbenchmarks for XNN fusions.,"[xla:cpu:xnn] Add microbenchmarks for XNN fusions.

Results on Skylake:
```
--------------------------------------------------------------------------------------
Benchmark                                            Time             CPU   Iterations
--------------------------------------------------------------------------------------
BM_EltwiseF32/1024/4/process_time               115208 ns       502503 ns         1317
BM_EltwiseF32/1024/8/process_time                97944 ns       952783 ns          714
BM_EltwiseF32/1024/16/process_time              140010 ns      1430383 ns          449
BM_EltwiseF32/1024/32/process_time              294100 ns      3133641 ns          223
BM_XnnEltwiseF32/1024/4/process_time           1178461 ns     13569640 ns           52
BM_XnnEltwiseF32/1024/8/process_time           2654120 ns     31326086 ns           22
BM_XnnEltwiseF32/1024/16/process_time          5659382 ns     67584217 ns           10
BM_XnnEltwiseF32/1024/32/process_time         11015385 ns    132094337 ns            5
BM_DotAndEltwiseF32/1024/4/process_time        2912142 ns     37998968 ns           18
BM_DotAndEltwiseF32/1024/8/process_time        2772257 ns     40048256 ns           18
BM_DotAndEltwiseF32/1024/16/process_time       3291990 ns     46087065 ns           15
BM_DotAndEltwiseF32/1024/32/process_time       4459718 ns     60150253 ns           11
BM_XnnDotAndEltwiseF32/1024/4/process_time     3933949 ns     55587842 ns           13
BM_XnnDotAndEltwiseF32/1024/8/process_time     5419765 ns     73534150 ns            9
BM_XnnDotAndEltwiseF32/1024/16/process_time    8420796 ns    110771699 ns            6
BM_XnnDotAndEltwiseF32/1024/32/process_time   13692058 ns    173777604 ns            4
--------------------------------------------------------------------------------------
```

Benchmark command:
```
bazel run -c opt --dynamic_mode=off --define pthreadpool_header_only=true \
  //xla/backends/cpu/benchmarks:xnn_fusion_benchmark_test \
  -- --benchmark_filter=all
```
",copybara-service[bot],2025-01-30 14:33:16+00:00,['penpornk'],2025-01-31 17:34:02+00:00,2025-01-31 17:34:01+00:00,https://github.com/tensorflow/tensorflow/pull/86209,[],[],
2820991579,pull_request,open,,[xla:cpu] Do not overwrite existing `backend_config` in `ParallelTaskAssigner`.,"[xla:cpu] Do not overwrite existing `backend_config` in `ParallelTaskAssigner`.

`ParallelTaskAssigner` uses a new `BackendConfig` to store the number of parallel partitions (`outer_dimension_partitions`). This erases other unrelated configs in the proto. We need to retain other configs for further uses down the pipeline.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 14:33:14+00:00,['penpornk'],2025-01-30 14:33:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86208,[],[],
2820897562,pull_request,closed,,[XLA:GPU] Add the `GemmFusion` pass to the `hlo-opt` tool.,"[XLA:GPU] Add the `GemmFusion` pass to the `hlo-opt` tool.

Fix the `--xla_gpu_target_config_filename` path in `gpu_hlo_pass.hlo.test` that was broken and silently ignored.
",copybara-service[bot],2025-01-30 13:52:02+00:00,['thomasjoerg'],2025-02-03 13:29:50+00:00,2025-02-03 13:29:50+00:00,https://github.com/tensorflow/tensorflow/pull/86207,[],[],
2820883786,pull_request,open,,PR #72863: Added example usage in some functions of config.py,"PR #72863: Added example usage in some functions of config.py

Imported from GitHub PR https://github.com/tensorflow/tensorflow/pull/72863

Some example usage are added to the systemconfig.py: for get_lib(), get_build_info, get_include()
Copybara import of the project:

--
a19e3f65fee27e488e299816a19aa80281da2041 by LakshmiKalaKadali <149650845+LakshmiKalaKadali@users.noreply.github.com>:

Added example usage n some functions in config.py

Merging this change closes #72863

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/72863 from tensorflow:Test_Branch a19e3f65fee27e488e299816a19aa80281da2041
",copybara-service[bot],2025-01-30 13:46:17+00:00,[],2025-01-30 13:46:17+00:00,,https://github.com/tensorflow/tensorflow/pull/86206,[],[],
2820882309,pull_request,closed,,[XLA:GPU] assign tid_* names to indexing maps for tile offsets,"[XLA:GPU] assign tid_* names to indexing maps for tile offsets

reading debug output is a bit easier
",copybara-service[bot],2025-01-30 13:45:40+00:00,['metaflow'],2025-02-05 17:56:18+00:00,2025-02-05 17:56:17+00:00,https://github.com/tensorflow/tensorflow/pull/86205,[],[],
2820836003,pull_request,open,,Plugin Implementation (google_tensor_compiler_plugin.cc),"Plugin Implementation (google_tensor_compiler_plugin.cc)

1. Added plugin configurations for supported SoCs (Pixel10) and their corresponding TPU compiler stack versions.
Implemented functions to retrieve plugin metadata (e.g., manufacturer, supported hardware, and SoC models).
2. Developed support for subgraph partitioning

Unit Tests (google_tensor_compiler_plugin_test.cc)

1. Verified plugin metadata retrieval, including supported SoC models.
2. Added tests for subgraph partitioning functionality, ensuring correct identification of supported operations.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 13:25:32+00:00,[],2025-01-30 15:40:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86204,[],[],
2820739228,pull_request,open,,Fix a few typos in SymbolicTile related comments (NFC).,"Fix a few typos in SymbolicTile related comments (NFC).

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 12:44:15+00:00,['akuegel'],2025-01-30 12:44:17+00:00,,https://github.com/tensorflow/tensorflow/pull/86203,[],[],
2820727506,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-30 12:38:52+00:00,[],2025-01-31 07:19:50+00:00,,https://github.com/tensorflow/tensorflow/pull/86202,[],[],
2820699563,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-30 12:26:06+00:00,[],2025-02-04 05:54:01+00:00,,https://github.com/tensorflow/tensorflow/pull/86201,[],[],
2820698572,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 12:25:37+00:00,[],2025-01-30 13:05:08+00:00,,https://github.com/tensorflow/tensorflow/pull/86200,[],[],
2820673804,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-30 12:14:37+00:00,[],2025-01-31 10:24:49+00:00,2025-01-31 10:24:49+00:00,https://github.com/tensorflow/tensorflow/pull/86199,[],[],
2820657643,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-30 12:07:16+00:00,[],2025-01-31 08:02:07+00:00,2025-01-31 08:02:06+00:00,https://github.com/tensorflow/tensorflow/pull/86198,[],[],
2820637645,pull_request,open,,[XLA:GPU] Add a mode to the multihost runner to compile through StableHLO.,"[XLA:GPU] Add a mode to the multihost runner to compile through StableHLO.

Controlled by the --compile_as_stablehlo flag (default is off)

HLO is converted to StableHLO right before calling the PjRt.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 11:57:47+00:00,[],2025-01-30 11:57:47+00:00,,https://github.com/tensorflow/tensorflow/pull/86197,[],[],
2820597673,pull_request,open,,[XLA:CPU] Add an enum used to infer number of different thunk kinds.,"[XLA:CPU] Add an enum used to infer number of different thunk kinds.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 11:39:17+00:00,[],2025-01-30 11:39:17+00:00,,https://github.com/tensorflow/tensorflow/pull/86196,[],[],
2820596993,pull_request,closed,,[XLA:CPU] Rename `thunk_serdes_proto` to `thunk_proto_serdes`,"[XLA:CPU] Rename `thunk_serdes_proto` to `thunk_proto_serdes`
",copybara-service[bot],2025-01-30 11:38:57+00:00,[],2025-01-30 20:05:32+00:00,2025-01-30 20:05:31+00:00,https://github.com/tensorflow/tensorflow/pull/86195,[],[],
2820594055,pull_request,open,,Reverts 8b90c7755e298136842b0a952ace340e5b535d23,"Reverts 8b90c7755e298136842b0a952ace340e5b535d23

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 11:37:29+00:00,[],2025-01-30 18:03:47+00:00,,https://github.com/tensorflow/tensorflow/pull/86194,[],[],
2820593236,pull_request,open,,[XLA:CPU] Add fixed capacity vector to thunk serdes tests,"[XLA:CPU] Add fixed capacity vector to thunk serdes tests

This is just a very simple change that ensures we never make reallocations on the vector holding onto buffer allocations.
",copybara-service[bot],2025-01-30 11:37:04+00:00,[],2025-01-31 12:09:11+00:00,,https://github.com/tensorflow/tensorflow/pull/86193,[],[],
2820585155,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-30 11:32:54+00:00,[],2025-01-31 10:37:14+00:00,2025-01-31 10:37:14+00:00,https://github.com/tensorflow/tensorflow/pull/86192,[],[],
2820572080,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 11:26:19+00:00,[],2025-01-30 12:38:43+00:00,,https://github.com/tensorflow/tensorflow/pull/86191,[],[],
2820522277,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-30 11:03:05+00:00,[],2025-02-04 05:37:04+00:00,2025-02-04 05:37:03+00:00,https://github.com/tensorflow/tensorflow/pull/86190,[],[],
2820506067,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-30 10:55:46+00:00,[],2025-02-04 05:45:31+00:00,2025-02-04 05:45:30+00:00,https://github.com/tensorflow/tensorflow/pull/86189,[],[],
2820471040,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 10:39:40+00:00,[],2025-01-30 10:39:40+00:00,,https://github.com/tensorflow/tensorflow/pull/86188,[],[],
2820467143,pull_request,open,,Automated Code Change,"Automated Code Change

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 10:37:56+00:00,[],2025-01-30 10:37:56+00:00,,https://github.com/tensorflow/tensorflow/pull/86187,[],[],
2820437878,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.

Reverts changelist 721352942

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 10:24:41+00:00,['ddunl'],2025-01-30 16:54:00+00:00,2025-01-30 16:53:59+00:00,https://github.com/tensorflow/tensorflow/pull/86186,[],[],
2820341527,pull_request,open,,PR #22053: [XLA:GPU] Fix triton: do not use MMA v3 on Blackwell,"PR #22053: [XLA:GPU] Fix triton: do not use MMA v3 on Blackwell

Imported from GitHub PR https://github.com/openxla/xla/pull/22053

Triton commit https://github.com/triton-lang/triton/commit/b39c1e14b8f2029bc6a8798e4914d2692edf97d8 enables MMA v5 support for Blackwell.

Until it is integrated into OpenXLA, Triton generates unsupported PTX instructions for SM100 - this PR fixes the issue by falling back to MMA v2 for SM100+. Without it, the compilation of Triton GEMM kernels fails on Blackwell.
Copybara import of the project:

--
81a3a27a12502a63bf0c4bcdc71871396306ae8e by Sergey Kozub <skozub@nvidia.com>:

[XLA:GPU] Fix triton: do not use MMA v3 on Blackwell


Merging this change closes #22053

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-30 09:40:26+00:00,[],2025-01-30 09:40:26+00:00,,https://github.com/tensorflow/tensorflow/pull/86185,[],[],
2820245298,pull_request,open,,Reverts changelist 721179542,"Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/86164 from tensorflow:mihaimaruseac-patch-1 d5e7459e51c112b117e52a5d5ec0629ebf384715
",copybara-service[bot],2025-01-30 08:54:26+00:00,[],2025-01-30 08:54:26+00:00,,https://github.com/tensorflow/tensorflow/pull/86184,[],[],
2820097024,pull_request,closed,,PR #21764: [ROCm] Make hipfft bazel rule publicly visible,"PR #21764: [ROCm] Make hipfft bazel rule publicly visible

Imported from GitHub PR https://github.com/openxla/xla/pull/21764


Copybara import of the project:

--
87f7f56cb1ca6aa90fee6128774346bfa83c29f6 by Harsha HS <Harsha.HavanurShamsundara@amd.com>:

[ROCm] Make hipfft bazel rule publicly visible

Merging this change closes #21764

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21764 from ROCm:ci_hipfft_visibility_20250123 87f7f56cb1ca6aa90fee6128774346bfa83c29f6
",copybara-service[bot],2025-01-30 07:22:23+00:00,[],2025-01-31 18:41:37+00:00,2025-01-31 18:41:37+00:00,https://github.com/tensorflow/tensorflow/pull/86183,[],[],
2819958381,pull_request,open,,"Add v8 host lib as ""latest"".","Add v8 host lib as ""latest"".
",copybara-service[bot],2025-01-30 05:47:32+00:00,['LukeBoyer'],2025-01-30 05:47:33+00:00,,https://github.com/tensorflow/tensorflow/pull/86182,[],[],
2819842373,pull_request,closed,,"Disable pipeline parallelism test, which runs into deadlock","Disable pipeline parallelism test, which runs into deadlock
",copybara-service[bot],2025-01-30 03:53:14+00:00,['frgossen'],2025-01-30 18:25:41+00:00,2025-01-30 18:25:41+00:00,https://github.com/tensorflow/tensorflow/pull/86181,[],[],
2819803798,pull_request,open,,Migrate last convertgraphdeftomlir and delete deprecated api.,"Migrate last convertgraphdeftomlir and delete deprecated api.
",copybara-service[bot],2025-01-30 03:18:37+00:00,['rocketas'],2025-01-30 03:18:38+00:00,,https://github.com/tensorflow/tensorflow/pull/86180,[],[],
2819725259,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-30 01:56:55+00:00,['ddunl'],2025-02-07 01:56:12+00:00,2025-02-07 01:56:11+00:00,https://github.com/tensorflow/tensorflow/pull/86179,[],[],
2819722780,pull_request,closed,,Add async support for NPU,"Add async support for NPU
",copybara-service[bot],2025-01-30 01:53:56+00:00,[],2025-01-31 01:42:04+00:00,2025-01-31 01:42:03+00:00,https://github.com/tensorflow/tensorflow/pull/86178,[],[],
2819683872,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-30 01:18:32+00:00,['ddunl'],2025-01-30 01:59:46+00:00,2025-01-30 01:59:45+00:00,https://github.com/tensorflow/tensorflow/pull/86176,[],[],
2819677508,pull_request,closed,,"Call Cleanup in thunks holding other thunks, like SequentialThunk.","Call Cleanup in thunks holding other thunks, like SequentialThunk.

Before, Cleanup methods overridden in subclasses were not called, since SequentialThunk didn't call them.
",copybara-service[bot],2025-01-30 01:11:47+00:00,['reedwm'],2025-01-30 23:09:24+00:00,2025-01-30 23:09:22+00:00,https://github.com/tensorflow/tensorflow/pull/86175,[],[],
2819656556,pull_request,open,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/86164 from tensorflow:mihaimaruseac-patch-1 d5e7459e51c112b117e52a5d5ec0629ebf384715
",copybara-service[bot],2025-01-30 00:51:43+00:00,['ddunl'],2025-01-30 09:35:31+00:00,,https://github.com/tensorflow/tensorflow/pull/86174,[],[],
2819652412,pull_request,open,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-30 00:48:01+00:00,['ddunl'],2025-01-30 00:48:02+00:00,,https://github.com/tensorflow/tensorflow/pull/86173,[],[],
2819652013,pull_request,open,,[oneDNN][CPU] fuse a matmul pattern,"This PR helps fuse this sub-graph MatMul + BiasAdd + Mul + Add + Elu.
Mul & Add come from BatchNorm and they can be folded into Matmul + BiasAdd to create MM + BiasAdd + Elu which can be easily fused into _FusedMatMul which has an optimized implementation on cpu using oneDNN. With this PR we see upto 18% perf gain.

Pattern before fusion:
![image](https://github.com/user-attachments/assets/b35ec3db-4e14-4a34-a57a-7377ded3eaa5)

After folding and fusion:
![image](https://github.com/user-attachments/assets/f930853a-54f0-4414-83df-6e8de32c3c0b)
",gaurides,2025-01-30 00:47:34+00:00,['gbaned'],2025-01-31 06:24:03+00:00,,https://github.com/tensorflow/tensorflow/pull/86172,"[('awaiting review', 'Pull request awaiting review'), ('size:L', 'CL Change Size: Large'), ('comp:core', 'issues related to core part of tensorflow')]",[],
2819640854,pull_request,closed,,[GPU] Fix compilation with NVIDIA driver 570.,"[GPU] Fix compilation with NVIDIA driver 570.

This closes https://github.com/openxla/xla/pull/22060
",copybara-service[bot],2025-01-30 00:36:58+00:00,[],2025-01-30 01:09:49+00:00,2025-01-30 01:09:48+00:00,https://github.com/tensorflow/tensorflow/pull/86171,[],[],
2819624555,pull_request,open,,"Copybara change, may affect some comments in `third_party` BUILD files.","Copybara change, may affect some comments in `third_party` BUILD files.
",copybara-service[bot],2025-01-30 00:22:16+00:00,['ddunl'],2025-01-30 01:27:41+00:00,,https://github.com/tensorflow/tensorflow/pull/86170,[],[],
2819607655,pull_request,open,,Enable latency hiding scheduler in pipeline parallelism tests,"Enable latency hiding scheduler in pipeline parallelism tests

Also enable collective permute cycle decomposition
",copybara-service[bot],2025-01-30 00:12:25+00:00,['frgossen'],2025-01-30 00:12:26+00:00,,https://github.com/tensorflow/tensorflow/pull/86169,[],[],
2819585951,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-29 23:54:29+00:00,['ddunl'],2025-01-30 01:52:49+00:00,2025-01-30 01:52:49+00:00,https://github.com/tensorflow/tensorflow/pull/86168,[],[],
2819575498,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-29 23:44:48+00:00,['ddunl'],2025-01-30 00:41:11+00:00,2025-01-30 00:41:10+00:00,https://github.com/tensorflow/tensorflow/pull/86167,[],[],
2819572094,pull_request,closed,,Introduce `OpaqueExecutable` and conversion functions.,"Introduce `OpaqueExecutable` and conversion functions.

This patch also updates the remaining tests to use `OpaqueExecutable` correctly.
",copybara-service[bot],2025-01-29 23:42:23+00:00,[],2025-02-07 20:29:24+00:00,2025-02-07 20:29:23+00:00,https://github.com/tensorflow/tensorflow/pull/86166,[],[],
2819566995,pull_request,closed,,Advanced version of MatchShapeCoveringDynamicIndexInstruction to handle,"Advanced version of MatchShapeCoveringDynamicIndexInstruction to handle
  non-unit slice sizes.
",copybara-service[bot],2025-01-29 23:37:13+00:00,[],2025-02-05 23:19:25+00:00,2025-02-05 23:19:24+00:00,https://github.com/tensorflow/tensorflow/pull/86165,[],[],
2819561142,pull_request,closed,,Disable creation of issues that don't follow the template,"This is an attempt to eliminate the spam created by bot accounts.

If it works here, we can then try on the other repos too.",mihaimaruseac,2025-01-29 23:31:50+00:00,"['MichaelHudgins', 'gbaned']",2025-01-30 17:41:40+00:00,2025-01-30 17:41:39+00:00,https://github.com/tensorflow/tensorflow/pull/86164,"[('ready to pull', 'PR ready for merge process'), ('size:XS', 'CL Change Size: Extra Small')]","[{'comment_id': 2623307542, 'issue_id': 2819561142, 'author': 'MichaelHudgins', 'body': 'Worth a try given the spam', 'created_at': datetime.datetime(2025, 1, 30, 1, 18, 9, tzinfo=datetime.timezone.utc)}, {'comment_id': 2624958959, 'issue_id': 2819561142, 'author': 'mihaimaruseac', 'body': 'Added the license part to prevent rollback.', 'created_at': datetime.datetime(2025, 1, 30, 16, 22, 43, tzinfo=datetime.timezone.utc)}, {'comment_id': 2625042641, 'issue_id': 2819561142, 'author': 'mihaimaruseac', 'body': 'Reopning since the squash also had the rollback and now this also has the copyright header :)', 'created_at': datetime.datetime(2025, 1, 30, 16, 52, 4, tzinfo=datetime.timezone.utc)}]","MichaelHudgins (Assginee) on (2025-01-30 01:18:09 UTC): Worth a try given the spam

mihaimaruseac (Issue Creator) on (2025-01-30 16:22:43 UTC): Added the license part to prevent rollback.

mihaimaruseac (Issue Creator) on (2025-01-30 16:52:04 UTC): Reopning since the squash also had the rollback and now this also has the copyright header :)

"
2819520663,pull_request,open,,Integrate LLVM at llvm/llvm-project@ab1ee912be95,"Integrate LLVM at llvm/llvm-project@ab1ee912be95

Updates LLVM usage to match
[ab1ee912be95](https://github.com/llvm/llvm-project/commit/ab1ee912be95)
",copybara-service[bot],2025-01-29 23:00:37+00:00,[],2025-01-30 23:39:51+00:00,,https://github.com/tensorflow/tensorflow/pull/86163,[],[],
2819511337,pull_request,closed,,Add some vlogging and code simplifications.,"Add some vlogging and code simplifications.
",copybara-service[bot],2025-01-29 22:55:51+00:00,['sparc1998'],2025-02-03 22:11:19+00:00,2025-02-03 22:11:18+00:00,https://github.com/tensorflow/tensorflow/pull/86162,[],[],
2819488498,pull_request,closed,,litert: Tune link flags of LiteRT Runtime,"litert: Tune link flags of LiteRT Runtime

Trim unnecessary symbols of the shared library.
",copybara-service[bot],2025-01-29 22:38:39+00:00,['terryheo'],2025-01-30 01:42:05+00:00,2025-01-30 01:42:04+00:00,https://github.com/tensorflow/tensorflow/pull/86161,[],[],
2819444100,pull_request,closed,,Bump up arm64 Linux and Mac wheel size limits: 240M -> 245M.,"Bump up arm64 Linux and Mac wheel size limits: 240M -> 245M.
",copybara-service[bot],2025-01-29 22:09:46+00:00,['belitskiy'],2025-01-29 22:47:27+00:00,2025-01-29 22:47:26+00:00,https://github.com/tensorflow/tensorflow/pull/86160,[],[],
2819440408,pull_request,open,,Add an ICYU pragma to silence linters.,"Add an ICYU pragma to silence linters.
",copybara-service[bot],2025-01-29 22:07:05+00:00,[],2025-01-29 22:07:05+00:00,,https://github.com/tensorflow/tensorflow/pull/86159,[],[],
2819410354,pull_request,closed,,Move dlinfo wrapper to dynamic loading to simplify compilations dependencies.,"Move dlinfo wrapper to dynamic loading to simplify compilations dependencies.
",copybara-service[bot],2025-01-29 21:53:40+00:00,['LukeBoyer'],2025-02-03 22:39:13+00:00,2025-02-03 22:39:12+00:00,https://github.com/tensorflow/tensorflow/pull/86158,[],[],
2819378288,pull_request,closed,,Add some optional verbosity to the dynamic loading lib,"Add some optional verbosity to the dynamic loading lib
",copybara-service[bot],2025-01-29 21:36:07+00:00,['LukeBoyer'],2025-02-03 20:50:13+00:00,2025-02-03 20:50:12+00:00,https://github.com/tensorflow/tensorflow/pull/86157,[],[],
2819350046,pull_request,closed,,Mark uses of `-std=c++17` in BUILD files as being a workaround for older Bazel versions.,"Mark uses of `-std=c++17` in BUILD files as being a workaround for older Bazel versions.
",copybara-service[bot],2025-01-29 21:18:42+00:00,[],2025-01-31 15:02:51+00:00,2025-01-31 15:02:51+00:00,https://github.com/tensorflow/tensorflow/pull/86156,[],[],
2819308446,pull_request,closed,,Remove helper methods from tests to make them easier to read.,"Remove helper methods from tests to make them easier to read.
These helper methods are no longer needed as RunAndCheckHloRewrite can be used
directly.
",copybara-service[bot],2025-01-29 21:01:26+00:00,[],2025-02-01 00:08:27+00:00,2025-02-01 00:08:27+00:00,https://github.com/tensorflow/tensorflow/pull/86155,[],[],
2819203899,pull_request,closed,,Add debug logging,"Add debug logging
",copybara-service[bot],2025-01-29 20:23:31+00:00,[],2025-01-29 23:22:16+00:00,2025-01-29 23:22:16+00:00,https://github.com/tensorflow/tensorflow/pull/86154,[],[],
2819159007,pull_request,open,,Reverts 42898a878b1fd2269a7de1ea22c6cfa1c8914247,"Reverts 42898a878b1fd2269a7de1ea22c6cfa1c8914247
",copybara-service[bot],2025-01-29 20:06:02+00:00,[],2025-01-29 20:06:02+00:00,,https://github.com/tensorflow/tensorflow/pull/86153,[],[],
2819119652,pull_request,closed,,PR #22029: [XLA:GPU] Add support for SM101a and SM120a architectures (Blackwell),"PR #22029: [XLA:GPU] Add support for SM101a and SM120a architectures (Blackwell)

Imported from GitHub PR https://github.com/openxla/xla/pull/22029

In addition to SM120a, also add SM101a mentioned in the PTX 8.7 spec (https://docs.nvidia.com/cuda/parallel-thread-execution/#release-notes), which is a slight variation of SM100a.

Bumping the max supported PTX version to 8.7, as the LLVM PR (https://github.com/llvm/llvm-project/pull/124155) adding the support is now integrated to OpenXLA.
Copybara import of the project:

--
be59b7a51721637d880207e7adb69a18c3a92bea by Sergey Kozub <skozub@nvidia.com>:

[XLA:GPU] Add support for SM101a and SM120a architectures (Blackwell)

Merging this change closes #22029

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22029 from openxla:devel/sm120a be59b7a51721637d880207e7adb69a18c3a92bea
",copybara-service[bot],2025-01-29 19:44:54+00:00,[],2025-01-29 21:40:04+00:00,2025-01-29 21:40:04+00:00,https://github.com/tensorflow/tensorflow/pull/86134,[],[],
2819101086,pull_request,open,,[XLA:CPU] Add CPU client support for layout modes.,"[XLA:CPU] Add CPU client support for layout modes.

The main motivation for this change is to support user-specified input and output layouts for JAX interoperability with other libraries. For example, https://github.com/jax-ml/jax/issues/25066.

The logic is more-or-less a direct copy of the implementation in `PjRtStreamExecutorClient`.
",copybara-service[bot],2025-01-29 19:36:21+00:00,[],2025-01-29 19:36:21+00:00,,https://github.com/tensorflow/tensorflow/pull/86124,[],[],
2819100509,pull_request,closed,,Use StreamExecutorAllocator instead of DeviceHostAllocator.,"Use StreamExecutorAllocator instead of DeviceHostAllocator.
",copybara-service[bot],2025-01-29 19:36:11+00:00,[],2025-01-30 00:20:12+00:00,2025-01-30 00:20:11+00:00,https://github.com/tensorflow/tensorflow/pull/86123,[],[],
2819089041,pull_request,closed,,[xla:cpu] Add benchmarks for transpose + copy + dot,"[xla:cpu] Add benchmarks for transpose + copy + dot
",copybara-service[bot],2025-01-29 19:32:53+00:00,['ezhulenev'],2025-01-29 20:30:51+00:00,2025-01-29 20:30:51+00:00,https://github.com/tensorflow/tensorflow/pull/86113,[],[],
2819081788,pull_request,closed,,Reverts 576474666afd9fd7efa409d56edd48027db4b169,"Reverts 576474666afd9fd7efa409d56edd48027db4b169
",copybara-service[bot],2025-01-29 19:30:12+00:00,['junjiang-lab'],2025-01-29 21:29:15+00:00,2025-01-29 21:29:15+00:00,https://github.com/tensorflow/tensorflow/pull/86112,[],[],
2819005840,pull_request,closed,,Fix tsan/asan error,"Fix tsan/asan error
",copybara-service[bot],2025-01-29 19:00:58+00:00,[],2025-01-29 21:46:45+00:00,2025-01-29 21:46:44+00:00,https://github.com/tensorflow/tensorflow/pull/86082,[],[],
2818997061,pull_request,closed,,Reverts 8b90c7755e298136842b0a952ace340e5b535d23,"Reverts 8b90c7755e298136842b0a952ace340e5b535d23
",copybara-service[bot],2025-01-29 18:57:50+00:00,[],2025-01-30 18:13:52+00:00,2025-01-30 18:13:52+00:00,https://github.com/tensorflow/tensorflow/pull/86081,[],[],
2818973173,pull_request,closed,,Clean-up LiteRT Compiler error message.,"Clean-up LiteRT Compiler error message.

This message is no longer relevant and is misleading in most cases. More than just `variable constant folding` is run in this stage of the converter.
",copybara-service[bot],2025-01-29 18:46:26+00:00,['vamsimanchala'],2025-01-31 18:29:11+00:00,2025-01-31 18:29:10+00:00,https://github.com/tensorflow/tensorflow/pull/86080,[],[],
2818963837,pull_request,closed,,- Run E2E CPU benchmarks and microbenchmarks on Linux x86 CPU and Linux ARM64 CPU,"- Run E2E CPU benchmarks and microbenchmarks on Linux x86 CPU and Linux ARM64 CPU
- Fix relative paths to save results
- Disable building and running individual hlos until the build is fixed
",copybara-service[bot],2025-01-29 18:42:12+00:00,['juliagmt-google'],2025-01-30 21:10:16+00:00,2025-01-30 21:10:14+00:00,https://github.com/tensorflow/tensorflow/pull/86079,[],[],
2818961262,pull_request,open,,[xla:hlo] Add `backend_config` to comparison in `HloComputationDeduplicator` pass.,"[xla:hlo] Add `backend_config` to comparison in `HloComputationDeduplicator` pass.

Code deduplicator is ignoring attributes on XLA FFI calls i.e., if two FFI calls are the same aside from their attributes, one will be purged.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/86164 from tensorflow:mihaimaruseac-patch-1 d5e7459e51c112b117e52a5d5ec0629ebf384715
",copybara-service[bot],2025-01-29 18:40:56+00:00,[],2025-01-30 09:46:31+00:00,,https://github.com/tensorflow/tensorflow/pull/86078,[],[],
2818937958,pull_request,open,,Integrate LLVM at llvm/llvm-project@9534d27e3321,"Integrate LLVM at llvm/llvm-project@9534d27e3321

Updates LLVM usage to match
[9534d27e3321](https://github.com/llvm/llvm-project/commit/9534d27e3321)
",copybara-service[bot],2025-01-29 18:30:18+00:00,[],2025-01-30 23:37:55+00:00,,https://github.com/tensorflow/tensorflow/pull/86077,[],[],
2818922057,pull_request,closed,,Integrate StableHLO at openxla/stablehlo@48a1e14e,"Integrate StableHLO at openxla/stablehlo@48a1e14e
",copybara-service[bot],2025-01-29 18:21:41+00:00,[],2025-01-30 01:29:45+00:00,2025-01-30 01:29:44+00:00,https://github.com/tensorflow/tensorflow/pull/86076,[],[],
2818919878,pull_request,closed,,Handle the cases when mask is not presented.,"Handle the cases when mask is not presented.

When tflite is running on GPU, mask might cause some expensive operations like
reshape. When mask is not used, all-zeros mask have to be passed because xnnpack
expects mask is always presented.

This CL is for xnnpack delegate to handle the case when mask is not presented,
and/so tflite can omit mask when it's not used both for xnnpack delegate and other
gpu delegates like ML drift.
",copybara-service[bot],2025-01-29 18:20:28+00:00,[],2025-02-03 20:20:14+00:00,2025-02-03 20:20:13+00:00,https://github.com/tensorflow/tensorflow/pull/86074,[],[],
2818919330,pull_request,open,,[JAX][StableHLO] Migrate JAX to use StableHLO custom call with dictionary,"[JAX][StableHLO] Migrate JAX to use StableHLO custom call with dictionary
",copybara-service[bot],2025-01-29 18:20:10+00:00,['GleasonK'],2025-01-29 18:20:11+00:00,,https://github.com/tensorflow/tensorflow/pull/86073,[],[],
2818902750,pull_request,open,,PR #21746: [NVIDIA GPU] Add collective-permute combiner,"PR #21746: [NVIDIA GPU] Add collective-permute combiner

Imported from GitHub PR https://github.com/openxla/xla/pull/21746

For collective-permutes with small message sizes, it is beneficial to combine them into a single collective because
1. it gets rid of some kernel launch overhead, and allows NCCL to do some message fusion;
2. fewer collectives make it easier for LHS to make better decision.

On top of the multi-operand collective-permute added in https://github.com/openxla/xla/pull/18838, this PR adds a combiner for collective-permutes.
Copybara import of the project:

--
c03a8fb5bd42cf3a365e1684537e78544a75a937 by Terry Sun <tesun@nvidia.com>:

add collective permute combiner

--
6a3159e89444ea342c25d8d996c994accd68a30d by Terry Sun <tesun@nvidia.com>:

polishing and doc string updates

Merging this change closes #21746

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21746 from terryysun:terryysun/combine_collective_permute 9de30a2ee252cf546ebda371e3b6aec852b6167d
",copybara-service[bot],2025-01-29 18:10:50+00:00,[],2025-01-31 19:47:10+00:00,,https://github.com/tensorflow/tensorflow/pull/86072,[],[],
2818900374,pull_request,open,,Avoid operating on aborted NCCL communicator.,"Avoid operating on aborted NCCL communicator.
",copybara-service[bot],2025-01-29 18:09:34+00:00,[],2025-02-04 18:26:45+00:00,,https://github.com/tensorflow/tensorflow/pull/86071,[],[],
2818900231,pull_request,closed,,PR #21825: Exclude the usage of CPU memory from the GPU memory scheduler,"PR #21825: Exclude the usage of CPU memory from the GPU memory scheduler

Imported from GitHub PR https://github.com/openxla/xla/pull/21825

In the MaxText optimizer state offloading, we observed no memory savings when switching from f16 to f32. The root cause is that the GPU memory scheduler does not distinguish between CPU memory and GPU memory. This commit modifies the scheduler to exclude CPU memory.
Copybara import of the project:

--
c77eefa1b4e31724dbfa40f4ab2aa7aff16e0840 by Jane Liu <janeliu@nvidia.com>:

Exclude the usage of CPU memory from the GPU memory scheduler

--
1c5720711c6a7d8173e132922b67eee6e2e8b9dd by Jane Liu <janeliu@nvidia.com>:

Add the explicit return type for the closure

Merging this change closes #21825

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21825 from zhenying-liu:scheduler 1c5720711c6a7d8173e132922b67eee6e2e8b9dd
",copybara-service[bot],2025-01-29 18:09:29+00:00,[],2025-01-31 17:58:48+00:00,2025-01-31 17:58:48+00:00,https://github.com/tensorflow/tensorflow/pull/86070,[],[],
2818874707,pull_request,closed,,[xla:cpu] Add XnnConvolutionThunk,"[xla:cpu] Add XnnConvolutionThunk
",copybara-service[bot],2025-01-29 17:55:38+00:00,['ezhulenev'],2025-01-30 21:23:57+00:00,2025-01-30 21:23:56+00:00,https://github.com/tensorflow/tensorflow/pull/86069,[],[],
2818869348,pull_request,closed,,Add an ICYU pragma to silence linters.,"Add an ICYU pragma to silence linters.
",copybara-service[bot],2025-01-29 17:52:40+00:00,[],2025-01-29 22:25:33+00:00,2025-01-29 22:25:32+00:00,https://github.com/tensorflow/tensorflow/pull/86068,[],[],
2818866161,pull_request,closed,,[xla:cpu] Move convolution shape verification and canonical dims computation to the shared library,"[xla:cpu] Move convolution shape verification and canonical dims computation to the shared library
",copybara-service[bot],2025-01-29 17:50:55+00:00,['ezhulenev'],2025-01-29 22:06:25+00:00,2025-01-29 22:06:24+00:00,https://github.com/tensorflow/tensorflow/pull/86067,[],[],
2818837213,pull_request,closed,,[XLA:CPU] Make loop unrolling on by default in IrCompiler.,"[XLA:CPU] Make loop unrolling on by default in IrCompiler.
",copybara-service[bot],2025-01-29 17:35:42+00:00,[],2025-02-04 17:53:06+00:00,2025-02-04 17:53:05+00:00,https://github.com/tensorflow/tensorflow/pull/86066,[],[],
2818823435,pull_request,closed,,Rolling integrate Triton up to [515467a9](https://github.com/openai/triton/commits/515467a9b42b92f24af988b83b7de6c8910a0a69) forward,"Rolling integrate Triton up to [515467a9](https://github.com/openai/triton/commits/515467a9b42b92f24af988b83b7de6c8910a0a69) forward

Reverts eeaa53430b85adf40faa9086683fc420bc79c7ca
",copybara-service[bot],2025-01-29 17:28:44+00:00,['gflegar'],2025-01-31 09:31:50+00:00,2025-01-31 09:31:49+00:00,https://github.com/tensorflow/tensorflow/pull/86065,[],[],
2818790469,pull_request,closed,,[Checkpoint] Add units (microseconds) to duration log message.,"[Checkpoint] Add units (microseconds) to duration log message.
",copybara-service[bot],2025-01-29 17:12:55+00:00,[],2025-01-29 18:47:21+00:00,2025-01-29 18:47:21+00:00,https://github.com/tensorflow/tensorflow/pull/86064,[],[],
2818746093,pull_request,open,,[XLA:CPU] Add execution engine and remove AddObjFile from JITCompiler,"[XLA:CPU] Add execution engine and remove AddObjFile from JITCompiler

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-29 16:53:55+00:00,[],2025-01-30 13:03:46+00:00,,https://github.com/tensorflow/tensorflow/pull/86063,[],[],
2818723033,pull_request,closed,,PR #21901: Ci add rocm6.1 deps for ubuntu 20.04,"PR #21901: Ci add rocm6.1 deps for ubuntu 20.04

Imported from GitHub PR https://github.com/openxla/xla/pull/21901

Add rocm 6.1.0 dependency for ubuntu 20.04
Copybara import of the project:

--
0acf028eeca5923c7f2aa5762297686836eda310 by Alexandros Theodoridis <atheodor@amd.com>:

Add rocm6.1 deps for ubuntu 20.04

--
fc88c83061d6efff2482599489d622ab3114b9a7 by Alexandros Theodoridis <atheodor@amd.com>:

Fix hermetic build for 6.0

--
73ace5591f4731e1b95b6d3e6a349b528977c580 by Alexandros Theodoridis <atheodor@amd.com>:

Add ci config for hermetic build

--
bbc048bcffd9d35bfad76ff816ed22f3e3f761f8 by Alexandros Theodoridis <atheodor@amd.com>:

Introduce rocm 6.1.0 dependency for 22.04

--
9776f398c2711ba37333d29b934d6ba67c55dbef by Alexandros Theodoridis <atheodor@amd.com>:

Add missing 24.04 redist

--
acf275d57cc185b9c2122d5930d8cf54e473ad95 by Alexandros Theodoridis <atheodor@amd.com>:

Fix test

--
3e49285b0f55597ab5f44c1d0a422bf931d72cda by Alexandros Theodoridis <atheodor@amd.com>:

Add comment explaining the reason for a new target

--
35838bf8d6e678717e9b1c551f840918b00a91f8 by Alexandros Theodoridis <atheodor@amd.com>:

Rever force verbose in the compiler wrapper

--
2952e115b044e1a8ac8aadc7eac7802e8d79cf91 by Alexandros Theodoridis <atheodor@amd.com>:

Add explanation comment for the new target

Merging this change closes #21901

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21901 from ROCm:ci_add_rocm6.1_deps_for_ubuntu_20.04 2952e115b044e1a8ac8aadc7eac7802e8d79cf91
",copybara-service[bot],2025-01-29 16:43:19+00:00,[],2025-01-29 19:21:00+00:00,2025-01-29 19:20:59+00:00,https://github.com/tensorflow/tensorflow/pull/86062,[],[],
2818476462,pull_request,open,,Integrate LLVM at llvm/llvm-project@9534d27e3321,"Integrate LLVM at llvm/llvm-project@9534d27e3321

Updates LLVM usage to match
[9534d27e3321](https://github.com/llvm/llvm-project/commit/9534d27e3321)
",copybara-service[bot],2025-01-29 15:03:24+00:00,[],2025-01-30 07:52:02+00:00,,https://github.com/tensorflow/tensorflow/pull/86061,[],[],
2818473926,pull_request,closed,,litert builddefs updates.,"litert builddefs updates.
",copybara-service[bot],2025-01-29 15:02:23+00:00,[],2025-02-06 20:31:51+00:00,2025-02-06 20:31:50+00:00,https://github.com/tensorflow/tensorflow/pull/86060,[],[],
2818473185,pull_request,closed,,[xla:gpu] simplify sparsity patches,"[xla:gpu] simplify sparsity patches

As discussed before, we can move the sparsity patches to exist in the openxla/triton commit rather than in patches. This simplifies where all the code lives :).
",copybara-service[bot],2025-01-29 15:02:06+00:00,[],2025-01-31 13:47:05+00:00,2025-01-31 13:47:04+00:00,https://github.com/tensorflow/tensorflow/pull/86059,[],[],
2818396915,pull_request,closed,,[XLA:GPU] Allow AUTO layout in the multihost runner.,"[XLA:GPU] Allow AUTO layout in the multihost runner.
",copybara-service[bot],2025-01-29 14:33:29+00:00,[],2025-01-29 17:57:22+00:00,2025-01-29 17:57:21+00:00,https://github.com/tensorflow/tensorflow/pull/86058,[],[],
2818386758,pull_request,closed,,[pjrt] `PjRtStreamExecutorDevice` now has a default memory space,"[pjrt] `PjRtStreamExecutorDevice` now has a default memory space

The space is set via `AttachMemorySpace` with `is_default` set to true.
",copybara-service[bot],2025-01-29 14:29:22+00:00,['superbobry'],2025-01-29 22:33:22+00:00,2025-01-29 22:33:21+00:00,https://github.com/tensorflow/tensorflow/pull/86057,[],[],
2818376402,pull_request,open,,[pjrt] `PjRtStreamExecutorClient` now accepts owned memory spaces,"[pjrt] `PjRtStreamExecutorClient` now accepts owned memory spaces
",copybara-service[bot],2025-01-29 14:25:18+00:00,['superbobry'],2025-01-29 14:25:20+00:00,,https://github.com/tensorflow/tensorflow/pull/86056,[],[],
2818317704,pull_request,closed,,Reverts 9dcbe84fd12c1a2c48925dfd5be954fad6d9c864,"Reverts 9dcbe84fd12c1a2c48925dfd5be954fad6d9c864
",copybara-service[bot],2025-01-29 14:04:06+00:00,[],2025-01-29 14:40:00+00:00,2025-01-29 14:39:59+00:00,https://github.com/tensorflow/tensorflow/pull/86055,[],[],
2818314424,pull_request,closed,,Update XNNPack to the lastest version (and dependencies).,"Update XNNPack to the lastest version (and dependencies).
",copybara-service[bot],2025-01-29 14:02:44+00:00,['qukhan'],2025-01-29 18:56:18+00:00,2025-01-29 18:56:18+00:00,https://github.com/tensorflow/tensorflow/pull/86054,[],[],
2818274721,pull_request,closed,,[xla:gpu] [cleanup] Pull out some logic into IterableInput,"[xla:gpu] [cleanup] Pull out some logic into IterableInput

This both simplifies the giant EmitMatmul function & makes it more generic, simplifying the TMA change (see CL chain).
",copybara-service[bot],2025-01-29 13:47:36+00:00,[],2025-01-29 15:19:09+00:00,2025-01-29 15:19:09+00:00,https://github.com/tensorflow/tensorflow/pull/86053,[],[],
2818187883,pull_request,open,,[XLA:GPU] Add dependency and build configurations for NVHSMEM.,"[XLA:GPU] Add dependency and build configurations for NVHSMEM.
",copybara-service[bot],2025-01-29 13:13:15+00:00,[],2025-01-29 13:13:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86052,[],[],
2818075719,pull_request,closed,,Integrate LLVM at llvm/llvm-project@a06c89387621,"Integrate LLVM at llvm/llvm-project@a06c89387621

Updates LLVM usage to match
[a06c89387621](https://github.com/llvm/llvm-project/commit/a06c89387621)
",copybara-service[bot],2025-01-29 12:27:38+00:00,[],2025-01-29 13:51:24+00:00,2025-01-29 13:51:23+00:00,https://github.com/tensorflow/tensorflow/pull/86051,[],[],
2818050862,pull_request,open,,Integrate LLVM at llvm/llvm-project@d0052ebbe2e2,"Integrate LLVM at llvm/llvm-project@d0052ebbe2e2

Updates LLVM usage to match
[d0052ebbe2e2](https://github.com/llvm/llvm-project/commit/d0052ebbe2e2)
",copybara-service[bot],2025-01-29 12:16:54+00:00,[],2025-01-29 13:11:12+00:00,,https://github.com/tensorflow/tensorflow/pull/86050,[],[],
2818041385,pull_request,closed,,PR #21948: [GPU] Upgrade cuDNN frontend to 1.10.0.,"PR #21948: [GPU] Upgrade cuDNN frontend to 1.10.0.

Imported from GitHub PR https://github.com/openxla/xla/pull/21948


Copybara import of the project:

--
affa734c3c6e2af934dd12eafe7e8771ab0ee8db by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Upgrade cuDNN frontend to 1.10.0.

Merging this change closes #21948

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21948 from openxla:cudnn_fe_1100 affa734c3c6e2af934dd12eafe7e8771ab0ee8db
",copybara-service[bot],2025-01-29 12:12:32+00:00,[],2025-01-29 20:52:58+00:00,2025-01-29 20:52:57+00:00,https://github.com/tensorflow/tensorflow/pull/86049,[],[],
2818024419,pull_request,open,,Only look when looking up or inserting into the file stat cache,"Only look when looking up or inserting into the file stat cache

This allows better performance for latency sensitive workload that require multithreading.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-29 12:05:34+00:00,[],2025-01-30 16:03:30+00:00,,https://github.com/tensorflow/tensorflow/pull/86047,[],[],
2818016589,pull_request,closed,,Reverts 3bf73c73e338b45a5e849808e53c2494508d415a,"Reverts 3bf73c73e338b45a5e849808e53c2494508d415a
",copybara-service[bot],2025-01-29 12:01:56+00:00,[],2025-01-29 14:01:59+00:00,2025-01-29 14:01:59+00:00,https://github.com/tensorflow/tensorflow/pull/86046,[],[],
2817962367,pull_request,open,,[XLA:GPU] Do not reset AUTO layouts to defaults when parsing text HLO.,"[XLA:GPU] Do not reset AUTO layouts to defaults when parsing text HLO.

Enabling this by default.
",copybara-service[bot],2025-01-29 11:37:13+00:00,[],2025-01-29 14:21:53+00:00,,https://github.com/tensorflow/tensorflow/pull/86042,[],[],
2817872447,pull_request,closed,,[XLA:GPU] Introduce a separate option which would control falling back to the default layout in HLO parser just for entry_computation_layout.,"[XLA:GPU] Introduce a separate option which would control falling back to the default layout in HLO parser just for entry_computation_layout.
",copybara-service[bot],2025-01-29 10:58:07+00:00,[],2025-01-29 15:44:39+00:00,2025-01-29 15:44:39+00:00,https://github.com/tensorflow/tensorflow/pull/86040,[],[],
2817831471,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-29 10:41:35+00:00,['ddunl'],2025-01-29 17:48:19+00:00,2025-01-29 17:48:19+00:00,https://github.com/tensorflow/tensorflow/pull/86039,[],[],
2817817150,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-29 10:34:49+00:00,['ddunl'],2025-01-29 19:31:13+00:00,2025-01-29 19:31:13+00:00,https://github.com/tensorflow/tensorflow/pull/86038,[],[],
2817710286,pull_request,closed,,Fix typos in documentation strings,"Hi, Team
I observed few typos in the documentation strings and I have fixed those typos so please do the needful. Thank you.",Venkat6871,2025-01-29 09:48:37+00:00,['gbaned'],2025-01-29 21:24:36+00:00,2025-01-29 21:24:33+00:00,https://github.com/tensorflow/tensorflow/pull/86037,"[('size:S', 'CL Change Size: Small')]","[{'comment_id': 2622884998, 'issue_id': 2817710286, 'author': 'mihaimaruseac', 'body': "">  Import didn't affect any internal file\r\n\r\nThis is already fixed internally. Please make sure to sync your repo to head."", 'created_at': datetime.datetime(2025, 1, 29, 21, 24, 33, tzinfo=datetime.timezone.utc)}]","mihaimaruseac on (2025-01-29 21:24:33 UTC): This is already fixed internally. Please make sure to sync your repo to head.

"
2817679264,pull_request,closed,,Add a reproducer for issue with reduce->bitcast->broadcast->slice pattern,"Add a reproducer for issue with reduce->bitcast->broadcast->slice pattern

This caused a crash after a Triton integrate that was only caught post-submit, so we should have a regression test to ensure it does not happen again.
",copybara-service[bot],2025-01-29 09:34:11+00:00,['gflegar'],2025-01-29 11:09:23+00:00,2025-01-29 11:09:22+00:00,https://github.com/tensorflow/tensorflow/pull/86036,[],[],
2817663949,pull_request,open,,PR #22008: [XLA:GPU] Upgrade cuDNN frontend library to v1.10,"PR #22008: [XLA:GPU] Upgrade cuDNN frontend library to v1.10

Imported from GitHub PR https://github.com/openxla/xla/pull/22008

The new version of cuDNN will enable using block scaled matmul in cuDNN graphs.

The support of accelerated block scaled matmul (available on Blackwell GPU) in XLA requires this upgrade.
Copybara import of the project:

--
c0fda6c2633dedfc79d037b9f0db7d0012476f06 by Sergey Kozub <skozub@nvidia.com>:

Upgrade cuDNN frontend library to v1.10

Merging this change closes #22008

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22008 from openxla:devel/cudnn_frontend_110 c0fda6c2633dedfc79d037b9f0db7d0012476f06
",copybara-service[bot],2025-01-29 09:26:56+00:00,[],2025-01-29 09:26:56+00:00,,https://github.com/tensorflow/tensorflow/pull/86035,[],[],
2817654928,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:22:29+00:00,[],2025-01-29 10:35:52+00:00,,https://github.com/tensorflow/tensorflow/pull/86034,[],[],
2817643646,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:18:07+00:00,[],2025-01-29 09:18:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86033,[],[],
2817642543,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:17:35+00:00,[],2025-01-29 09:17:35+00:00,,https://github.com/tensorflow/tensorflow/pull/86032,[],[],
2817642529,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:17:34+00:00,[],2025-01-29 09:17:34+00:00,,https://github.com/tensorflow/tensorflow/pull/86031,[],[],
2817640203,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:16:34+00:00,[],2025-01-29 11:34:31+00:00,,https://github.com/tensorflow/tensorflow/pull/86030,[],[],
2817639968,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:16:27+00:00,[],2025-01-29 09:16:27+00:00,,https://github.com/tensorflow/tensorflow/pull/86029,[],[],
2817638723,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:15:49+00:00,[],2025-01-29 09:15:49+00:00,,https://github.com/tensorflow/tensorflow/pull/86028,[],[],
2817638199,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:15:32+00:00,[],2025-01-29 12:55:53+00:00,,https://github.com/tensorflow/tensorflow/pull/86027,[],[],
2817637996,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:15:26+00:00,[],2025-01-29 09:15:26+00:00,,https://github.com/tensorflow/tensorflow/pull/86026,[],[],
2817637511,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:15:11+00:00,[],2025-01-29 12:39:46+00:00,,https://github.com/tensorflow/tensorflow/pull/86025,[],[],
2817637159,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:15:00+00:00,[],2025-02-03 06:14:20+00:00,2025-02-03 06:14:19+00:00,https://github.com/tensorflow/tensorflow/pull/86024,[],[],
2817636987,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:14:55+00:00,[],2025-01-29 11:49:46+00:00,,https://github.com/tensorflow/tensorflow/pull/86023,[],[],
2817636360,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:14:36+00:00,[],2025-01-29 13:45:38+00:00,2025-01-29 13:45:37+00:00,https://github.com/tensorflow/tensorflow/pull/86022,[],[],
2817635959,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:14:25+00:00,[],2025-01-29 13:16:39+00:00,,https://github.com/tensorflow/tensorflow/pull/86021,[],[],
2817635731,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:14:17+00:00,[],2025-01-29 13:52:34+00:00,,https://github.com/tensorflow/tensorflow/pull/86020,[],[],
2817635664,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:14:15+00:00,[],2025-01-29 09:14:15+00:00,,https://github.com/tensorflow/tensorflow/pull/86019,[],[],
2817633455,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:13:18+00:00,[],2025-01-29 11:35:16+00:00,,https://github.com/tensorflow/tensorflow/pull/86018,[],[],
2817633113,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:13:07+00:00,[],2025-01-29 09:13:07+00:00,,https://github.com/tensorflow/tensorflow/pull/86017,[],[],
2817632243,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:12:40+00:00,[],2025-01-29 09:12:40+00:00,,https://github.com/tensorflow/tensorflow/pull/86016,[],[],
2817631399,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:12:15+00:00,[],2025-01-29 12:10:13+00:00,,https://github.com/tensorflow/tensorflow/pull/86015,[],[],
2817631345,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:12:13+00:00,[],2025-02-01 12:02:47+00:00,2025-02-01 12:02:46+00:00,https://github.com/tensorflow/tensorflow/pull/86014,[],[],
2817630364,pull_request,closed,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-29 09:11:42+00:00,[],2025-01-31 07:18:49+00:00,2025-01-31 07:18:48+00:00,https://github.com/tensorflow/tensorflow/pull/86013,[],[],
2817603356,pull_request,closed,,Fix bug in AlgebraicSimplifier,"Fix bug in AlgebraicSimplifier

HandleMaximum and HandleMinimum did not consider ops with mixed floating point
precision. Add handling for that.
",copybara-service[bot],2025-01-29 08:58:53+00:00,['akuegel'],2025-01-29 11:18:40+00:00,2025-01-29 11:18:40+00:00,https://github.com/tensorflow/tensorflow/pull/86012,[],[],
2817546057,pull_request,closed,,PR #21800: [XLA:GPU] Add block scaling rewriter pass,"PR #21800: [XLA:GPU] Add block scaling rewriter pass

Imported from GitHub PR https://github.com/openxla/xla/pull/21800

This PR adds a transformation pass that supports custom calls to block quantize/dequantize/dot ops.
Such calls are replaced by an equivalent sequence of HLO operations.

This pass is supposed to support MX scaling formats, such as MXFP8, but is not limited to those and can be used with any data types and block sizes.
The quantization op sequence matches the one described in the section 6.3 of the MX spec:
https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf

Once cuDNN frontend 1.10 is released, a lowering to a cuDNN graph will be enabled for the hardware that supports block scaled dot natively (i.e. Blackwell). This pass will stay disabled until then.

I also plan on introducing a new HLO op, ""block-scaled-dot"", which will be more generic than a custom call - for example, will have configurable dimensions numbers akin to the general dot op. This will follow in a separate PR, once that is approved, I'll replace the custom call ""__op$block_scaled_dot"" with it.

Copybara import of the project:

--
5dcc610e804e7aaad9b79369f714a63f9f096ad8 by Sergey Kozub <skozub@nvidia.com>:

Add block scaling rewriter pass

Merging this change closes #21800

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21800 from openxla:skozub/block_scaling 5dcc610e804e7aaad9b79369f714a63f9f096ad8
",copybara-service[bot],2025-01-29 08:27:54+00:00,[],2025-01-29 14:20:06+00:00,2025-01-29 14:20:04+00:00,https://github.com/tensorflow/tensorflow/pull/86011,[],[],
2817496885,pull_request,closed,,Reverts 14967296f7faae46550bf5d3e240194e74ebc552,"Reverts 14967296f7faae46550bf5d3e240194e74ebc552
",copybara-service[bot],2025-01-29 08:01:29+00:00,[],2025-01-29 08:43:15+00:00,2025-01-29 08:43:15+00:00,https://github.com/tensorflow/tensorflow/pull/86010,[],[],
2817450239,pull_request,closed,,Update xla_ops.cc,,gowthamSKs,2025-01-29 07:32:42+00:00,['gbaned'],2025-01-29 14:00:48+00:00,2025-01-29 14:00:48+00:00,https://github.com/tensorflow/tensorflow/pull/86009,"[('size:XS', 'CL Change Size: Extra Small'), ('invalid', 'Hacktoberfest spam PR')]","[{'comment_id': 2620894141, 'issue_id': 2817450239, 'author': 'google-cla[bot]', 'body': ""Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).\n\nView this [failed invocation](https://github.com/tensorflow/tensorflow/pull/86009/checks?check_run_id=36336637762) of the CLA check for more information.\n\nFor the most up to date status, view the checks section at the bottom of the pull request."", 'created_at': datetime.datetime(2025, 1, 29, 7, 32, 46, tzinfo=datetime.timezone.utc)}, {'comment_id': 2620894301, 'issue_id': 2817450239, 'author': 'gowthamSKs', 'body': 'Added comment', 'created_at': datetime.datetime(2025, 1, 29, 7, 32, 54, tzinfo=datetime.timezone.utc)}, {'comment_id': 2621733858, 'issue_id': 2817450239, 'author': 'mihaimaruseac', 'body': 'Please don\'t use ""add file""/""update file""/""fix file""/etc. commit messages. These are hard to reason about when looking at the history of the file/repository. Instead, please write explanatory git commit messages.\r\n\r\nThe commit message is also the title of the PR if the PR has only one commit. It is thus twice important to have commit messages that are relevant, as PRs would be easier to understand and easier to analyze in search results.\r\n\r\nFor how to write good quality git commit messages, please consult https://cbea.ms/git-commit/', 'created_at': datetime.datetime(2025, 1, 29, 13, 59, 47, tzinfo=datetime.timezone.utc)}]","google-cla[bot] on (2025-01-29 07:32:46 UTC): Thanks for your pull request! It looks like this may be your first contribution to a Google open source project. Before we can look at your pull request, you'll need to sign a Contributor License Agreement (CLA).

View this [failed invocation](https://github.com/tensorflow/tensorflow/pull/86009/checks?check_run_id=36336637762) of the CLA check for more information.

For the most up to date status, view the checks section at the bottom of the pull request.

gowthamSKs (Issue Creator) on (2025-01-29 07:32:54 UTC): Added comment

mihaimaruseac on (2025-01-29 13:59:47 UTC): Please don't use ""add file""/""update file""/""fix file""/etc. commit messages. These are hard to reason about when looking at the history of the file/repository. Instead, please write explanatory git commit messages.

The commit message is also the title of the PR if the PR has only one commit. It is thus twice important to have commit messages that are relevant, as PRs would be easier to understand and easier to analyze in search results.

For how to write good quality git commit messages, please consult https://cbea.ms/git-commit/

"
2817418456,pull_request,closed,,Fix collective memory allocation in cuda executor,"Fix collective memory allocation in cuda executor

`CudaExecutor::Allocate` used to always return a nullptr when the user requested an allocation the collective memory space. This was caused by a mistake in one of my refactorings a while ago.
",copybara-service[bot],2025-01-29 07:11:50+00:00,[],2025-01-29 18:08:03+00:00,2025-01-29 18:08:02+00:00,https://github.com/tensorflow/tensorflow/pull/86008,[],[],
2817311348,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.

Reverts 8b90c7755e298136842b0a952ace340e5b535d23
",copybara-service[bot],2025-01-29 05:53:55+00:00,['ddunl'],2025-01-30 19:17:20+00:00,2025-01-30 19:17:20+00:00,https://github.com/tensorflow/tensorflow/pull/86007,[],[],
2817270848,pull_request,closed,,litert: Fix LiteRT Runtime C library build,"litert: Fix LiteRT Runtime C library build

Update the rule to include all LiteRtXXXX symbols.
",copybara-service[bot],2025-01-29 05:28:05+00:00,['terryheo'],2025-01-29 19:37:58+00:00,2025-01-29 19:37:57+00:00,https://github.com/tensorflow/tensorflow/pull/86006,[],[],
2817229529,pull_request,open,,Automated Code Change,"Automated Code Change

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21822 from openxla:devel/sm100a 267cf74a084c933e532a622da2485befdc47f8ce
",copybara-service[bot],2025-01-29 04:47:10+00:00,[],2025-01-29 04:47:10+00:00,,https://github.com/tensorflow/tensorflow/pull/86005,[],[],
2817203570,pull_request,closed,,litert: Refine c/litert_dispatch_delegate.h,"litert: Refine c/litert_dispatch_delegate.h

- c/litert_dispatch_delegate.h shouldn't rely on external C++ header files
- Created separate cc/litert_dispatch_delegate.h for C++ APIs
",copybara-service[bot],2025-01-29 04:19:02+00:00,['terryheo'],2025-01-29 04:54:14+00:00,2025-01-29 04:54:13+00:00,https://github.com/tensorflow/tensorflow/pull/86004,[],[],
2817183863,pull_request,closed,,[xla:ffi] Add support for passing RunId to FFI handlers,"[xla:ffi] Add support for passing RunId to FFI handlers
",copybara-service[bot],2025-01-29 03:59:16+00:00,['ezhulenev'],2025-01-29 17:39:03+00:00,2025-01-29 17:39:01+00:00,https://github.com/tensorflow/tensorflow/pull/86003,[],[],
2817139933,pull_request,closed,,[pjrt] Use the `PjRtMemorySpace` version of `BufferFromHostBuffer`,"[pjrt] Use the `PjRtMemorySpace` version of `BufferFromHostBuffer`

Buffers live in memory spaces and not on devices. The `PjRtDevice` version
of `BufferFromHostBuffer` is deprecated and will be removed once the migration
is complete.
",copybara-service[bot],2025-01-29 03:14:41+00:00,['superbobry'],2025-01-29 23:14:13+00:00,2025-01-29 23:14:12+00:00,https://github.com/tensorflow/tensorflow/pull/86002,[],[],
2817136188,pull_request,open,,Reverts 8b90c7755e298136842b0a952ace340e5b535d23,"Reverts 8b90c7755e298136842b0a952ace340e5b535d23
",copybara-service[bot],2025-01-29 03:12:22+00:00,[],2025-01-29 03:12:22+00:00,,https://github.com/tensorflow/tensorflow/pull/86001,[],[],
2817134444,pull_request,closed,,Increase tolerance of MatmulReplicated test.,"Increase tolerance of MatmulReplicated test.

It was previously failing on H100s. We didn't notice since our CI doesn't run tests requiring more than 2 GPUs.
",copybara-service[bot],2025-01-29 03:11:21+00:00,['reedwm'],2025-02-03 18:57:36+00:00,2025-02-03 18:57:35+00:00,https://github.com/tensorflow/tensorflow/pull/86000,[],[],
2817103803,pull_request,closed,,Fix rare crash in memcpy a2a.,"Fix rare crash in memcpy a2a.

NcclAllToAllStartThunk's memcpy implementation would register pointers to values of an absl::flat_hash_map with cuMemHostRegister. But flat_hash_map doesn't guarantee pointer stability, so if a rehash occurred, the pointers would change, making them potentially no longer registered. Now instead of flat_hash_map, a pointer to an array is used. A node_hash_map could have alternatively been used but requires more calls to HostMemoryRegister and has worse performance.

I added an 8-GPU all-to-all test since I didn't see the issue occur with only 2 GPUs.

This issue caused occasional crashes with various errors like CUDA_ERROR_ILLEGAL_ADDRESS. I'm not sure why it didn't consistently crash. Maybe cuMemHostRegister registers a larger range of memory than what is passed in as the 'size' argument.
",copybara-service[bot],2025-01-29 02:39:21+00:00,['reedwm'],2025-01-30 21:56:06+00:00,2025-01-30 21:56:05+00:00,https://github.com/tensorflow/tensorflow/pull/85999,[],[],
2817056087,pull_request,closed,,Add transformation to allow transposed input to BatchMatMul,"Add transformation to allow transposed input to BatchMatMul
",copybara-service[bot],2025-01-29 01:43:45+00:00,['vamsimanchala'],2025-01-30 21:45:20+00:00,2025-01-30 21:45:19+00:00,https://github.com/tensorflow/tensorflow/pull/85998,[],[],
2817024954,pull_request,open,,Update Bazel/CMake to use a version of XNNPACK,"Update Bazel/CMake to use a version of XNNPACK
",copybara-service[bot],2025-01-29 01:16:53+00:00,[],2025-01-29 01:16:53+00:00,,https://github.com/tensorflow/tensorflow/pull/85997,[],[],
2817006170,pull_request,open,,Refactor XLA's common.bara.sky to make copying of top level files and dirs more terse,"Refactor XLA's common.bara.sky to make copying of top level files and dirs more terse

This is in preparation for introducing the concept of a ""move-only"" file explicitly
",copybara-service[bot],2025-01-29 00:58:35+00:00,['ddunl'],2025-01-29 01:48:26+00:00,,https://github.com/tensorflow/tensorflow/pull/85996,[],[],
2816983947,pull_request,closed,,Add async/c/types.h to core/c:headers_filegroup,"Add async/c/types.h to core/c:headers_filegroup

async/c/types.h is needed by tensorflow/lite/core/c/c_api.h
",copybara-service[bot],2025-01-29 00:36:43+00:00,['terryheo'],2025-01-29 03:37:28+00:00,2025-01-29 03:37:27+00:00,https://github.com/tensorflow/tensorflow/pull/85995,[],[],
2816969593,pull_request,closed,,Make GPU PJRT use CreateMemoryAllocator for Host memory.,"Make GPU PJRT use CreateMemoryAllocator for Host memory.
",copybara-service[bot],2025-01-29 00:23:10+00:00,[],2025-01-29 23:59:00+00:00,2025-01-29 23:58:59+00:00,https://github.com/tensorflow/tensorflow/pull/85994,[],[],
2816960332,pull_request,closed,,Disable async dispatch within the body of a host callback.,"Disable async dispatch within the body of a host callback.

This is a follow up to https://github.com/jax-ml/jax/pull/26160 and https://github.com/openxla/xla/pull/21980. See those PRs for more discussion of the motivation for this change.

In this PR, we disable CPU asynchronous execution when running within the body of a host callback, because this can cause deadlocks.
",copybara-service[bot],2025-01-29 00:14:13+00:00,[],2025-01-29 12:32:24+00:00,2025-01-29 12:32:23+00:00,https://github.com/tensorflow/tensorflow/pull/85993,[],[],
2816945241,pull_request,closed,,Set CPU as the default acceleration option for a Compiled Model,"Set CPU as the default acceleration option for a Compiled Model
",copybara-service[bot],2025-01-28 23:59:38+00:00,[],2025-01-29 01:53:22+00:00,2025-01-29 01:53:22+00:00,https://github.com/tensorflow/tensorflow/pull/85992,[],[],
2816928664,pull_request,closed,,Use efficient packed flatbuffer api to handle underlying tfl models.,"Use efficient packed flatbuffer api to handle underlying tfl models.
",copybara-service[bot],2025-01-28 23:43:48+00:00,['LukeBoyer'],2025-01-29 01:35:10+00:00,2025-01-29 01:35:10+00:00,https://github.com/tensorflow/tensorflow/pull/85991,[],[],
2816892652,pull_request,closed,,Allow `GetModelBufWithByteCode` to work with models that contain more then one op.,"Allow `GetModelBufWithByteCode` to work with models that contain more then one op.
",copybara-service[bot],2025-01-28 23:07:37+00:00,['turbotoribio'],2025-01-29 01:02:47+00:00,2025-01-29 01:02:47+00:00,https://github.com/tensorflow/tensorflow/pull/85990,[],[],
2816885248,pull_request,closed,,Add GitHub Actions based XLA ARM64 CPU build,"Add GitHub Actions based XLA ARM64 CPU build
",copybara-service[bot],2025-01-28 23:01:10+00:00,['ddunl'],2025-01-30 02:08:21+00:00,2025-01-30 02:08:21+00:00,https://github.com/tensorflow/tensorflow/pull/85989,[],[],
2816860087,pull_request,closed,,Add support for MemoryType::kHost to CreateStreamExecutor on the relevant Executor types.,"Add support for MemoryType::kHost to CreateStreamExecutor on the relevant Executor types.
",copybara-service[bot],2025-01-28 22:43:50+00:00,[],2025-01-29 22:42:08+00:00,2025-01-29 22:42:08+00:00,https://github.com/tensorflow/tensorflow/pull/85988,[],[],
2816853372,pull_request,closed,,[xla:pjrt] Pass host callback pointers to FFI handlers via FFI's ExecutionContext.,"[xla:pjrt] Pass host callback pointers to FFI handlers via FFI's ExecutionContext.
",copybara-service[bot],2025-01-28 22:38:10+00:00,[],2025-02-01 14:44:47+00:00,2025-02-01 14:44:46+00:00,https://github.com/tensorflow/tensorflow/pull/85987,[],[],
2816848626,pull_request,closed,,"Create ""internal"" visibility for LiteRT-internal targets","Create ""internal"" visibility for LiteRT-internal targets
",copybara-service[bot],2025-01-28 22:34:08+00:00,['turbotoribio'],2025-01-29 14:49:50+00:00,2025-01-29 14:49:49+00:00,https://github.com/tensorflow/tensorflow/pull/85986,[],[],
2816838661,pull_request,closed,,Return arrays from `ArrayImpl._check_and_rearrange`.,"Return arrays from `ArrayImpl._check_and_rearrange`.

This is in preparation for a larger change, so that `_check_arrays` can be called before Array creation in XLA and the user gets more helpful JAX error messages instead of XLA errors.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/22053 from openxla:devel/sm100_mmav2 81a3a27a12502a63bf0c4bcdc71871396306ae8e
",copybara-service[bot],2025-01-28 22:27:18+00:00,[],2025-01-30 17:28:42+00:00,2025-01-30 17:28:42+00:00,https://github.com/tensorflow/tensorflow/pull/85985,[],[],
2816837720,pull_request,open,,Refactor Jax FFI lowering to prepare for implementing CPU/GPU callbacks using XLA's FFI.,"Refactor Jax FFI lowering to prepare for implementing CPU/GPU callbacks using XLA's FFI.

- This refactor should have no impact on tests or public-facing APIs.
- `mlir.emit_python_callback` would eventually depend on `ffi.ffi_lowering`, which in turn depends on definitions in `mlir.py`. We break this circular dependency.
",copybara-service[bot],2025-01-28 22:26:32+00:00,[],2025-01-29 20:03:21+00:00,,https://github.com/tensorflow/tensorflow/pull/85984,[],[],
2816834126,pull_request,open,,Implement Jax CPU/GPU callbacks with XLA's FFI.,"Implement Jax CPU/GPU callbacks with XLA's FFI.

- Change 4 of 4 addressing #3 in https://github.com/jax-ml/jax/issues/25842.
",copybara-service[bot],2025-01-28 22:23:36+00:00,[],2025-01-31 23:47:26+00:00,,https://github.com/tensorflow/tensorflow/pull/85983,[],[],
2816831920,pull_request,closed,,Actually copy the extra wheels into the expected directory afterwards.,"Actually copy the extra wheels into the expected directory afterwards.
",copybara-service[bot],2025-01-28 22:21:50+00:00,['belitskiy'],2025-01-29 02:35:03+00:00,2025-01-29 02:35:02+00:00,https://github.com/tensorflow/tensorflow/pull/85982,[],[],
2816817692,pull_request,closed,,Make TensorBuffer owner of the associated Event,"Make TensorBuffer owner of the associated Event
",copybara-service[bot],2025-01-28 22:11:48+00:00,[],2025-01-29 02:43:33+00:00,2025-01-29 02:43:32+00:00,https://github.com/tensorflow/tensorflow/pull/85981,[],[],
2816811808,pull_request,closed,,Add IFRT wrappers to public API,"Add IFRT wrappers to public API
",copybara-service[bot],2025-01-28 22:08:03+00:00,[],2025-01-29 00:20:43+00:00,2025-01-29 00:20:41+00:00,https://github.com/tensorflow/tensorflow/pull/85980,[],[],
2816768666,pull_request,open,,Create an ml-build image that has libcudnn9,"Create an ml-build image that has libcudnn9
",copybara-service[bot],2025-01-28 21:40:44+00:00,['quoctruong'],2025-01-30 23:11:46+00:00,,https://github.com/tensorflow/tensorflow/pull/85979,[],[],
2816768522,pull_request,open,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-28 21:40:38+00:00,['ddunl'],2025-02-07 01:17:37+00:00,,https://github.com/tensorflow/tensorflow/pull/85978,[],[],
2816754976,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.

Reverts a47a28e840cf97148669ba3483cd72e87f0efa5b
",copybara-service[bot],2025-01-28 21:31:45+00:00,['ddunl'],2025-01-28 23:22:16+00:00,2025-01-28 23:22:15+00:00,https://github.com/tensorflow/tensorflow/pull/85977,[],[],
2816725658,pull_request,open,,Integrate LLVM at llvm/llvm-project@b108fbe6ea42,"Integrate LLVM at llvm/llvm-project@b108fbe6ea42

Updates LLVM usage to match
[b108fbe6ea42](https://github.com/llvm/llvm-project/commit/b108fbe6ea42)
",copybara-service[bot],2025-01-28 21:12:07+00:00,[],2025-01-29 00:52:55+00:00,,https://github.com/tensorflow/tensorflow/pull/85976,[],[],
2816683803,pull_request,closed,,Always dispatch CPU executables synchronously when they include callbacks.,"Always dispatch CPU executables synchronously when they include callbacks.

As discussed in https://github.com/jax-ml/jax/issues/25861 and https://github.com/jax-ml/jax/issues/24255, using host callbacks within an asynchronously-dispatched CPU executable can deadlock when the body of the callback itself asynchronously dispatches JAX CPU code. My rough understanding of the problem is that the XLA intra op thread pool gets filled up with callbacks waiting for their body to execute, but there aren't enough resources to schedule the inner computations.

There's probably a better way to fix this within XLA:CPU, but the temporary fix that I've come up with is to disable asynchronous dispatch on CPU when either:

1. Executing a program that includes any host callbacks, or
2. when running within the body of a callback.

It seems like both of these conditions are needed in general because I was able to find test cases that failed with just one or the other implemented.

This PR includes just the first change, and the second will be implemented in a follow-up.
",copybara-service[bot],2025-01-28 20:46:06+00:00,[],2025-01-29 03:02:35+00:00,2025-01-29 03:02:35+00:00,https://github.com/tensorflow/tensorflow/pull/85975,[],[],
2816640369,pull_request,closed,,Don't run thread sans on apply plugin test. In general we can't use sanitizers for x86 code that dlopens.,"Don't run thread sans on apply plugin test. In general we can't use sanitizers for x86 code that dlopens.
",copybara-service[bot],2025-01-28 20:20:30+00:00,['LukeBoyer'],2025-01-29 00:33:26+00:00,2025-01-29 00:33:25+00:00,https://github.com/tensorflow/tensorflow/pull/85974,[],[],
2816640004,pull_request,closed,,Update users of TSL headers and targets to new location in XLA,"Update users of TSL headers and targets to new location in XLA

Updating:
 - `env.h`
 - `env_time.h`
 - `errors.h`
 - `file_statistics.h`
 - `file_system.h`
 - `file_system_helper.h`
 - `logging.h`
 - `macros.h`
 - `status.h`
 - `status_matchers.h`
 - `status_to_from_proto.h`
 - `statusor.h`
 - `test.h`
 - `test_benchmark.h`
 - `threadpool.h`
 - `threadpool_async_executor.h`
 - `threadpool_interface.h`
 - `threadpool_options.h`
 - `types.h`

and associated targets.
",copybara-service[bot],2025-01-28 20:20:16+00:00,['ddunl'],2025-02-01 02:16:19+00:00,2025-02-01 02:16:19+00:00,https://github.com/tensorflow/tensorflow/pull/85973,[],[],
2816638250,pull_request,closed,,Add some additional args for select_and_scatter_test for certain backends.,"Add some additional args for select_and_scatter_test for certain backends.
",copybara-service[bot],2025-01-28 20:19:15+00:00,[],2025-01-30 19:40:08+00:00,2025-01-30 19:40:07+00:00,https://github.com/tensorflow/tensorflow/pull/85972,[],[],
2816596959,pull_request,closed,,[pjrt] Use the `PjRtMemorySpace` version of `BufferFromHostBuffer`,"[pjrt] Use the `PjRtMemorySpace` version of `BufferFromHostBuffer`

Buffers live in memory spaces and not on devices. The `PjRtDevice` version
of `BufferFromHostBuffer` is deprecated and will be removed once the migration
is complete.

Reverts a47a28e840cf97148669ba3483cd72e87f0efa5b

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21375 from shraiysh:while_loop_analysis a435fbd2eadc17269d7bccbe141dcf7a21cc20e8
",copybara-service[bot],2025-01-28 19:56:49+00:00,['superbobry'],2025-01-28 23:39:22+00:00,2025-01-28 23:39:21+00:00,https://github.com/tensorflow/tensorflow/pull/85971,[],[],
2816596690,pull_request,closed,,PR #21822: [XLA:GPU] Add support for SM100a architecture (Blackwell),"PR #21822: [XLA:GPU] Add support for SM100a architecture (Blackwell)

Imported from GitHub PR https://github.com/openxla/xla/pull/21822

Created `ShouldUsePtxExtension` helper for the extension suffix (this will also be used for sm120, etc).

CUDA 12.8 was recently released, which supports PTX 8.7, but that is not supported by the integrated LLVM (support added in https://github.com/llvm/llvm-project/pull/124155), so leaving the association with PTX 8.6 - this doesn't raise warnings during compilation.

Copybara import of the project:

--
267cf74a084c933e532a622da2485befdc47f8ce by Sergey Kozub <skozub@nvidia.com>:

Add support for SM100a architecture (Blackwell)

Merging this change closes #21822

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21822 from openxla:devel/sm100a 267cf74a084c933e532a622da2485befdc47f8ce
",copybara-service[bot],2025-01-28 19:56:40+00:00,[],2025-01-29 04:40:57+00:00,2025-01-29 04:40:56+00:00,https://github.com/tensorflow/tensorflow/pull/85970,[],[],
2816594767,pull_request,open,,Remove `UpdateEntryComputationLayout` from `HloRunnerAgnosticTestBase`,"Remove `UpdateEntryComputationLayout` from `HloRunnerAgnosticTestBase`

Reverts a47a28e840cf97148669ba3483cd72e87f0efa5b
",copybara-service[bot],2025-01-28 19:55:34+00:00,[],2025-01-28 21:53:15+00:00,,https://github.com/tensorflow/tensorflow/pull/85969,[],[],
2816572345,pull_request,closed,,[pjrt] Use the `PjRtMemorySpace` version of `BufferFromHostBuffer`,"[pjrt] Use the `PjRtMemorySpace` version of `BufferFromHostBuffer`

Buffers live in memory spaces and not on devices. The `PjRtDevice` version
of `BufferFromHostBuffer` is deprecated and will be removed once the migration
is complete.
",copybara-service[bot],2025-01-28 19:43:53+00:00,['superbobry'],2025-01-28 22:16:54+00:00,2025-01-28 22:16:53+00:00,https://github.com/tensorflow/tensorflow/pull/85968,[],[],
2816565223,pull_request,open,,[StableHLO] Enable XLA to properly translate StableHLO custom calls with typed FFI.,"[StableHLO] Enable XLA to properly translate StableHLO custom calls with typed FFI.
",copybara-service[bot],2025-01-28 19:40:19+00:00,['GleasonK'],2025-01-29 21:36:22+00:00,,https://github.com/tensorflow/tensorflow/pull/85967,[],[],
2816524725,pull_request,closed,,#litert Remove unused include in `litert_expected.h`,"#litert Remove unused include in `litert_expected.h`
",copybara-service[bot],2025-01-28 19:17:06+00:00,['qukhan'],2025-01-28 21:21:56+00:00,2025-01-28 21:21:55+00:00,https://github.com/tensorflow/tensorflow/pull/85966,[],[],
2816523868,pull_request,closed,,Move TSL's `workspace*.bzl` files to XLA,"Move TSL's `workspace*.bzl` files to XLA

Also steal `def_file_filter` from TensorFlow as was previously done by TSL.

In a followup these can be compressed further
",copybara-service[bot],2025-01-28 19:16:38+00:00,['ddunl'],2025-01-29 00:14:10+00:00,2025-01-29 00:14:09+00:00,https://github.com/tensorflow/tensorflow/pull/85965,[],[],
2816516621,pull_request,closed,,Migrate convert_test to always use PjRt for its test backend.,"Migrate convert_test to always use PjRt for its test backend.
",copybara-service[bot],2025-01-28 19:12:46+00:00,[],2025-01-31 00:19:00+00:00,2025-01-31 00:18:59+00:00,https://github.com/tensorflow/tensorflow/pull/85964,[],[],
2816488041,pull_request,closed,,[XLA:LAYOUT_CONSTRAINTS] Move custom call constraints before backend constraints but after other,"[XLA:LAYOUT_CONSTRAINTS] Move custom call constraints before backend constraints but after other
mandatory constriants.
",copybara-service[bot],2025-01-28 18:56:24+00:00,['blakehechtman'],2025-01-28 23:06:18+00:00,2025-01-28 23:06:17+00:00,https://github.com/tensorflow/tensorflow/pull/85963,[],[],
2816483854,pull_request,closed,,Add `--ppc64le-compliance-tag` mandatory argument to manylinux_compliance_test.,"Add `--ppc64le-compliance-tag` mandatory argument to manylinux_compliance_test.
",copybara-service[bot],2025-01-28 18:54:05+00:00,[],2025-01-29 22:14:45+00:00,2025-01-29 22:14:44+00:00,https://github.com/tensorflow/tensorflow/pull/85962,[],[],
2816440748,pull_request,closed,,Add NCCL dict entry for CUDA 12.8.0.,"Add NCCL dict entry for CUDA 12.8.0.
",copybara-service[bot],2025-01-28 18:30:15+00:00,[],2025-01-28 20:11:09+00:00,2025-01-28 20:11:09+00:00,https://github.com/tensorflow/tensorflow/pull/85961,[],[],
2816412636,pull_request,closed,,Fix `TfrtCpuClient` allocating oversized buffers.,"Fix `TfrtCpuClient` allocating oversized buffers.

`TfrtCpuClient` allocates buffers using
`AbstractTfrtCpuBuffer::AllocateTrackedDeviceBuffer`, which takes an 'on device
shape'. This shape informs the number of bytes that are allocated for the
buffer. Since the buffer packs sub-byte (non-predicate) arrays, the buffer is
oversized if using the host shape and layout for this purpose, because the host
layout is not packed.

This patch fixes the buffer allocation and adds a host to device roundtrip test
to ensure that it is populated correctly.
",copybara-service[bot],2025-01-28 18:15:31+00:00,[],2025-01-30 22:06:17+00:00,2025-01-30 22:06:17+00:00,https://github.com/tensorflow/tensorflow/pull/85960,[],[],
2816283876,pull_request,closed,,Parse XLA_FLAGS environment variable every time.,"Parse XLA_FLAGS environment variable every time.
",copybara-service[bot],2025-01-28 17:14:24+00:00,[],2025-01-29 13:11:25+00:00,2025-01-29 13:11:24+00:00,https://github.com/tensorflow/tensorflow/pull/85959,[],[],
2816211239,pull_request,closed,,Add support for CUDA 12.8.0 and CUDNN 9.7.0.,"Add support for CUDA 12.8.0 and CUDNN 9.7.0.
",copybara-service[bot],2025-01-28 16:42:25+00:00,[],2025-01-28 18:26:58+00:00,2025-01-28 18:26:57+00:00,https://github.com/tensorflow/tensorflow/pull/85957,[],[],
2816207125,pull_request,closed,,Replace LITERT_ASSERT_STATUS_OK with LITERT_ASSERT_OK.,"Replace LITERT_ASSERT_STATUS_OK with LITERT_ASSERT_OK.
",copybara-service[bot],2025-01-28 16:40:38+00:00,['qukhan'],2025-01-31 20:18:12+00:00,2025-01-31 20:18:11+00:00,https://github.com/tensorflow/tensorflow/pull/85956,[],[],
2816189561,pull_request,closed,,#litert Use `LiteRtGetStatusString()` to make error messages clearer.,"#litert Use `LiteRtGetStatusString()` to make error messages clearer.
",copybara-service[bot],2025-01-28 16:33:03+00:00,['qukhan'],2025-01-28 17:50:11+00:00,2025-01-28 17:50:10+00:00,https://github.com/tensorflow/tensorflow/pull/85955,[],[],
2816090546,pull_request,open,,PR #21800: [XLA:GPU] Add block scaling rewriter pass,"PR #21800: [XLA:GPU] Add block scaling rewriter pass

Imported from GitHub PR https://github.com/openxla/xla/pull/21800

This PR adds a transformation pass that supports custom calls to block quantize/dequantize/dot ops.
Such calls are replaced by an equivalent sequence of HLO operations.

This pass is supposed to support MX scaling formats, such as MXFP8, but is not limited to those and can be used with any data types and block sizes.
The quantization op sequence matches the one described in the section 6.3 of the MX spec:
https://www.opencompute.org/documents/ocp-microscaling-formats-mx-v1-0-spec-final-pdf

Once cuDNN frontend 1.10 is released, a lowering to a cuDNN graph will be enabled for the hardware that supports block scaled dot natively (i.e. Blackwell). This pass will stay disabled until then.

I also plan on introducing a new HLO op, ""block-scaled-dot"", which will be more generic than a custom call - for example, will have configurable dimensions numbers akin to the general dot op. This will follow in a separate PR, once that is approved, I'll replace the custom call ""__op$block_scaled_dot"" with it.

Copybara import of the project:

--
5dcc610e804e7aaad9b79369f714a63f9f096ad8 by Sergey Kozub <skozub@nvidia.com>:

Add block scaling rewriter pass

Merging this change closes #21800

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21800 from openxla:skozub/block_scaling bba9d3f711bf3b18ecdd45a4de4e96d422a2122a
",copybara-service[bot],2025-01-28 15:55:56+00:00,[],2025-01-29 11:53:25+00:00,,https://github.com/tensorflow/tensorflow/pull/85954,[],[],
2816075804,pull_request,open,,"Create ""internal"" visibility for LiteRT-internal targets","Create ""internal"" visibility for LiteRT-internal targets
",copybara-service[bot],2025-01-28 15:49:52+00:00,['turbotoribio'],2025-01-28 15:49:53+00:00,,https://github.com/tensorflow/tensorflow/pull/85953,[],[],
2816043636,pull_request,closed,,PR #21960: Updated nanobind commit,"PR #21960: Updated nanobind commit

Imported from GitHub PR https://github.com/openxla/xla/pull/21960

Point nanobind to the commit fixing python/c++ object concurrent accessing: https://github.com/wjakob/nanobind/issues/867


cc @hawkinsp 
Copybara import of the project:

--
77e693fb39e0b737016770585c3f8786eb141474 by vfdev-5 <vfdev.5@gmail.com>:

Updated nanobind commit

Merging this change closes #21960

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21960 from vfdev-5:update-nanobind 77e693fb39e0b737016770585c3f8786eb141474
",copybara-service[bot],2025-01-28 15:36:50+00:00,[],2025-01-29 07:58:18+00:00,2025-01-29 07:58:17+00:00,https://github.com/tensorflow/tensorflow/pull/85952,[],[],
2815982706,pull_request,open,,Actually copy the extra wheels into the expected directory afterwards.,"Actually copy the extra wheels into the expected directory afterwards.

Reverts a47a28e840cf97148669ba3483cd72e87f0efa5b
",copybara-service[bot],2025-01-28 15:13:48+00:00,['belitskiy'],2025-01-28 21:40:14+00:00,,https://github.com/tensorflow/tensorflow/pull/85951,[],[],
2815937367,pull_request,closed,,Integrate LLVM at llvm/llvm-project@aa65f93b71de,"Integrate LLVM at llvm/llvm-project@aa65f93b71de

Updates LLVM usage to match
[aa65f93b71de](https://github.com/llvm/llvm-project/commit/aa65f93b71de)
",copybara-service[bot],2025-01-28 14:59:51+00:00,[],2025-01-28 17:13:57+00:00,2025-01-28 17:13:55+00:00,https://github.com/tensorflow/tensorflow/pull/85950,[],[],
2815895968,pull_request,open,,Integrate LLVM at llvm/llvm-project@e0c7f081f158,"Integrate LLVM at llvm/llvm-project@e0c7f081f158

Updates LLVM usage to match
[e0c7f081f158](https://github.com/llvm/llvm-project/commit/e0c7f081f158)
",copybara-service[bot],2025-01-28 14:46:14+00:00,[],2025-01-28 14:46:14+00:00,,https://github.com/tensorflow/tensorflow/pull/85949,[],[],
2815893139,pull_request,open,,PR #21886: [ROCM][NFC] BlasLt interface refactoring & simplifying: part I,"PR #21886: [ROCM][NFC] BlasLt interface refactoring & simplifying: part I

Imported from GitHub PR https://github.com/openxla/xla/pull/21886

After this PR https://github.com/tensorflow/tensorflow/pull/73926 is merged, we can remove unnecessary low-level DoMatmul functions from GpuBlasLt interface (which otherwise looks scary and unnecessarily complicated).

Furthermore, we can also remove **ValidateInputs** function from the interface and derived classes since a high-level **ExecuteOnStream** function already handles data-types correctly. This also greatly simplifies the code.

Also, I have packed the input arguments of ExecuteOnStream calls to a struct **MemoryArgs** to simplify arguments passing in derived classes and improve code readability.

Finally, in the original GpuBlasLt PR: https://github.com/openxla/xla/pull/5911, I made a sort of mistake by adding a reference to **blas_lt** to the MatmulPlan class [here](https://github.com/openxla/xla/blob/main/xla/stream_executor/rocm/hip_blas_lt.h#L135), thereby making MatmulPlans bound to a **particular BlasLt instance**. This resulted in some further bugfixes and, most importantly, complicated GpuBlasLt cache design in gpublas_lt_matmul_thunk.cc/.h. In this PR, I remove this reference again from MatmulPlan class and in the next NFC PR the cache mechanics can also be simplified. 

Unfortunately, this change also requires a tandem PR for Tensorflow: https://github.com/tensorflow/tensorflow/pull/85835

@xla-rotation Would you please have a look


Copybara import of the project:

--
e96bb2fbedab3f53b31ef0e1748582c76e9fb105 by Pavel Emeliyanenko <pavel.emeliyanenko@amd.com>:

blaslt interface refactoring: removing blas_lt_ref

added cuda adaptions

cuda-side adaptions

cuda side adaptions

fix

fixing pointers

Merging this change closes #21886

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21886 from ROCm:ci_gpublas_lt_refactor_1 e96bb2fbedab3f53b31ef0e1748582c76e9fb105
",copybara-service[bot],2025-01-28 14:45:31+00:00,[],2025-01-28 16:27:59+00:00,,https://github.com/tensorflow/tensorflow/pull/85948,[],[],
2815863083,pull_request,open,,Rename enums in CudaComputeCapability according to the style guide,"Rename enums in CudaComputeCapability according to the style guide
",copybara-service[bot],2025-01-28 14:35:54+00:00,[],2025-01-29 17:27:23+00:00,,https://github.com/tensorflow/tensorflow/pull/85947,[],[],
2815662206,pull_request,closed,,Triton: Fix missing include header,"Triton: Fix missing include header
",copybara-service[bot],2025-01-28 13:22:49+00:00,[],2025-01-28 16:08:05+00:00,2025-01-28 16:08:02+00:00,https://github.com/tensorflow/tensorflow/pull/85946,[],[],
2815640915,pull_request,closed,,[XLA:GPU] Triton support test - minor fixes,"[XLA:GPU] Triton support test - minor fixes

* stop calling IsTritonSupportedInstruction explicitly, RunSupportTest calls it and verify that the output is in sync with actual behavior, 
* call RunSupportTest for all ops when multiple are tested in a single test.

Reverts a47a28e840cf97148669ba3483cd72e87f0efa5b
",copybara-service[bot],2025-01-28 13:14:06+00:00,[],2025-01-28 22:54:16+00:00,2025-01-28 22:54:16+00:00,https://github.com/tensorflow/tensorflow/pull/85945,[],[],
2815487190,pull_request,open,,PR #21948: [GPU] Upgrade cuDNN frontend to 1.10.0.,"PR #21948: [GPU] Upgrade cuDNN frontend to 1.10.0.

Imported from GitHub PR https://github.com/openxla/xla/pull/21948


Copybara import of the project:

--
affa734c3c6e2af934dd12eafe7e8771ab0ee8db by Ilia Sergachev <isergachev@nvidia.com>:

[GPU] Upgrade cuDNN frontend to 1.10.0.

Merging this change closes #21948

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/openxla/xla/pull/21948 from openxla:cudnn_fe_1100 affa734c3c6e2af934dd12eafe7e8771ab0ee8db
",copybara-service[bot],2025-01-28 12:16:26+00:00,[],2025-01-28 17:39:46+00:00,,https://github.com/tensorflow/tensorflow/pull/85944,[],[],
2815323316,pull_request,closed,,Reverts 1af1de23aaf9efd5e68522a4f9b9e8b27ef0c58a,"Reverts 1af1de23aaf9efd5e68522a4f9b9e8b27ef0c58a
",copybara-service[bot],2025-01-28 11:10:26+00:00,[],2025-01-28 11:43:30+00:00,2025-01-28 11:43:30+00:00,https://github.com/tensorflow/tensorflow/pull/85943,[],[],
2815313495,pull_request,closed,,Integrate LLVM at llvm/llvm-project@2e5a5237daf8,"Integrate LLVM at llvm/llvm-project@2e5a5237daf8

Updates LLVM usage to match
[2e5a5237daf8](https://github.com/llvm/llvm-project/commit/2e5a5237daf8)
",copybara-service[bot],2025-01-28 11:05:51+00:00,[],2025-01-28 12:12:01+00:00,2025-01-28 12:12:00+00:00,https://github.com/tensorflow/tensorflow/pull/85942,[],[],
2815305876,pull_request,closed,,[xla:cpu] Add more sort keywords to correctly order XLA:CPU debug options.,"[xla:cpu] Add more sort keywords to correctly order XLA:CPU debug options.
",copybara-service[bot],2025-01-28 11:02:45+00:00,['penpornk'],2025-01-28 19:10:02+00:00,2025-01-28 19:10:01+00:00,https://github.com/tensorflow/tensorflow/pull/85941,[],[],
2815175569,pull_request,open,,Integrate LLVM at llvm/llvm-project@c4891089125d,"Integrate LLVM at llvm/llvm-project@c4891089125d

Updates LLVM usage to match
[c4891089125d](https://github.com/llvm/llvm-project/commit/c4891089125d)
",copybara-service[bot],2025-01-28 10:05:07+00:00,[],2025-01-28 10:05:07+00:00,,https://github.com/tensorflow/tensorflow/pull/85940,[],[],
2815163742,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 10:01:11+00:00,[],2025-01-28 10:01:11+00:00,,https://github.com/tensorflow/tensorflow/pull/85939,[],[],
2815135559,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:51:50+00:00,[],2025-01-28 09:51:50+00:00,,https://github.com/tensorflow/tensorflow/pull/85938,[],[],
2815116669,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:43:28+00:00,[],2025-01-28 09:43:28+00:00,,https://github.com/tensorflow/tensorflow/pull/85937,[],[],
2815095933,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:35:22+00:00,[],2025-01-28 09:35:22+00:00,,https://github.com/tensorflow/tensorflow/pull/85936,[],[],
2815095456,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:35:09+00:00,[],2025-01-28 09:35:09+00:00,,https://github.com/tensorflow/tensorflow/pull/85935,[],[],
2815087191,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:31:11+00:00,[],2025-01-28 09:31:11+00:00,,https://github.com/tensorflow/tensorflow/pull/85934,[],[],
2815082040,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:28:44+00:00,[],2025-01-28 09:28:44+00:00,,https://github.com/tensorflow/tensorflow/pull/85933,[],[],
2815076228,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:25:58+00:00,[],2025-01-28 09:25:58+00:00,,https://github.com/tensorflow/tensorflow/pull/85932,[],[],
2815067121,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:21:38+00:00,[],2025-01-28 14:11:37+00:00,,https://github.com/tensorflow/tensorflow/pull/85931,[],[],
2815065547,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:20:53+00:00,[],2025-01-28 09:20:53+00:00,,https://github.com/tensorflow/tensorflow/pull/85930,[],[],
2815060032,pull_request,closed,,Preserve backend_config when writing the HLO for the ScriptChecker.,"Preserve backend_config when writing the HLO for the ScriptChecker.

backend_config can contain important information for the lowering pipeline.
If we want to run a bisect without running HLO passes, this
information is not generated, so must be taken from the original HLO.

Reverts 1af1de23aaf9efd5e68522a4f9b9e8b27ef0c58a
",copybara-service[bot],2025-01-28 09:18:12+00:00,['akuegel'],2025-01-28 12:25:36+00:00,2025-01-28 12:25:35+00:00,https://github.com/tensorflow/tensorflow/pull/85929,[],[],
2815059905,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:18:08+00:00,[],2025-01-28 09:18:08+00:00,,https://github.com/tensorflow/tensorflow/pull/85928,[],[],
2815058832,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:17:36+00:00,[],2025-01-28 09:17:36+00:00,,https://github.com/tensorflow/tensorflow/pull/85927,[],[],
2815053758,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:15:06+00:00,[],2025-01-28 09:15:06+00:00,,https://github.com/tensorflow/tensorflow/pull/85926,[],[],
2815052601,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:14:31+00:00,[],2025-01-28 09:14:31+00:00,,https://github.com/tensorflow/tensorflow/pull/85925,[],[],
2815050753,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:13:38+00:00,[],2025-01-28 09:13:38+00:00,,https://github.com/tensorflow/tensorflow/pull/85924,[],[],
2815048777,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 09:12:42+00:00,[],2025-01-28 12:49:23+00:00,,https://github.com/tensorflow/tensorflow/pull/85923,[],[],
2815004792,pull_request,open,,[XLA] Add TraceMe for ThunksEmitter::EmitEntryComputation.,"[XLA] Add TraceMe for ThunksEmitter::EmitEntryComputation.

Reverts changelist 721179542

FUTURE_COPYBARA_INTEGRATE_REVIEW=https://github.com/tensorflow/tensorflow/pull/86164 from tensorflow:mihaimaruseac-patch-1 d5e7459e51c112b117e52a5d5ec0629ebf384715
",copybara-service[bot],2025-01-28 08:54:50+00:00,[],2025-01-30 09:57:13+00:00,,https://github.com/tensorflow/tensorflow/pull/85922,[],[],
2814889483,pull_request,closed,,Convert from `std::string_view` to `absl::string_view` explicitly,"Convert from `std::string_view` to `absl::string_view` explicitly
",copybara-service[bot],2025-01-28 08:00:13+00:00,[],2025-01-28 12:38:18+00:00,2025-01-28 12:38:18+00:00,https://github.com/tensorflow/tensorflow/pull/85921,[],[],
2814800876,pull_request,closed,,Skip TSAN tests as they are also not supported for GPU.,"Skip TSAN tests as they are also not supported for GPU.
",copybara-service[bot],2025-01-28 07:03:51+00:00,[],2025-01-28 18:18:47+00:00,2025-01-28 18:18:47+00:00,https://github.com/tensorflow/tensorflow/pull/85920,[],[],
2814733195,pull_request,closed,,"Fix `mxfloat` build dependencies and remove test BUILD file, to remove duplication.","Fix `mxfloat` build dependencies and remove test BUILD file, to remove duplication.
",copybara-service[bot],2025-01-28 06:17:33+00:00,[],2025-01-28 07:34:07+00:00,2025-01-28 07:34:07+00:00,https://github.com/tensorflow/tensorflow/pull/85919,[],[],
2814678971,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 05:36:00+00:00,[],2025-01-28 06:19:39+00:00,,https://github.com/tensorflow/tensorflow/pull/85918,[],[],
2814671449,pull_request,open,,Automated Code Change,"Automated Code Change
",copybara-service[bot],2025-01-28 05:29:55+00:00,[],2025-01-28 05:29:55+00:00,,https://github.com/tensorflow/tensorflow/pull/85917,[],[],
2814613490,pull_request,closed,,Support CreateBuffersForAsyncHostToDevice with shape_spec + layout in TfrtCpuClient.,"Support CreateBuffersForAsyncHostToDevice with shape_spec + layout in TfrtCpuClient.
",copybara-service[bot],2025-01-28 04:43:27+00:00,['pschuh'],2025-01-28 21:35:04+00:00,2025-01-28 21:35:03+00:00,https://github.com/tensorflow/tensorflow/pull/85916,[],[],
2814601910,pull_request,closed,,"Create ""internal"" visibility for LiteRT-internal targets","Create ""internal"" visibility for LiteRT-internal targets
",copybara-service[bot],2025-01-28 04:32:38+00:00,['turbotoribio'],2025-01-28 07:25:59+00:00,2025-01-28 07:22:03+00:00,https://github.com/tensorflow/tensorflow/pull/85915,[],[],
2814516891,pull_request,open,,Add `--xnnpack_slinky_disable_schedule` flag,"Add `--xnnpack_slinky_disable_schedule` flag
",copybara-service[bot],2025-01-28 03:05:07+00:00,[],2025-01-28 19:53:08+00:00,,https://github.com/tensorflow/tensorflow/pull/85914,[],[],
2814457994,pull_request,closed,,Set expected entry point name to empty string in model buffer append.,"Set expected entry point name to empty string in model buffer append.
",copybara-service[bot],2025-01-28 02:09:04+00:00,['LukeBoyer'],2025-01-28 16:34:42+00:00,2025-01-28 16:34:41+00:00,https://github.com/tensorflow/tensorflow/pull/85913,[],[],
2814455155,pull_request,closed,,Support offset tensors in model load. This finishes offset tensor support.,"Support offset tensors in model load. This finishes offset tensor support.
",copybara-service[bot],2025-01-28 02:05:35+00:00,['LukeBoyer'],2025-01-29 00:50:27+00:00,2025-01-29 00:50:26+00:00,https://github.com/tensorflow/tensorflow/pull/85912,[],[],
2814434295,pull_request,closed,,Reverts a47a28e840cf97148669ba3483cd72e87f0efa5b,"Reverts a47a28e840cf97148669ba3483cd72e87f0efa5b
",copybara-service[bot],2025-01-28 01:44:13+00:00,['seherellis'],2025-01-28 21:46:55+00:00,2025-01-28 21:46:55+00:00,https://github.com/tensorflow/tensorflow/pull/85911,[],[],
2814407228,pull_request,closed,,Handle offset tensor buffers with unified buffer management in model serialize.,"Handle offset tensor buffers with unified buffer management in model serialize.
",copybara-service[bot],2025-01-28 01:25:58+00:00,['LukeBoyer'],2025-01-28 22:33:15+00:00,2025-01-28 22:33:15+00:00,https://github.com/tensorflow/tensorflow/pull/85910,[],[],
2814403579,pull_request,closed,,Add flags to tf_tfl_translate for pytorch saved model conversion,"Add flags to tf_tfl_translate for pytorch saved model conversion
",copybara-service[bot],2025-01-28 01:22:02+00:00,['chunnienc'],2025-01-28 02:00:24+00:00,2025-01-28 02:00:24+00:00,https://github.com/tensorflow/tensorflow/pull/85909,[],[],
2814398791,pull_request,closed,,Add todo to add additional control dependencies,"Add todo to add additional control dependencies
",copybara-service[bot],2025-01-28 01:18:10+00:00,['frgossen'],2025-01-30 23:17:35+00:00,2025-01-30 23:17:34+00:00,https://github.com/tensorflow/tensorflow/pull/85908,[],[],
2814395948,pull_request,open,,Disable sync collectives for pipeline parallelism,"Disable sync collectives for pipeline parallelism
",copybara-service[bot],2025-01-28 01:14:59+00:00,['frgossen'],2025-01-28 01:15:00+00:00,,https://github.com/tensorflow/tensorflow/pull/85907,[],[],
